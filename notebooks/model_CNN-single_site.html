
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; Storm Surge NZ - Summary</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/thebelab-helper.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Storm Surge NZ - Summary</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   geoocean-nz-ss
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="repo_workflow.html">
   1. Repository workflow + THEORY
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="useful_theory.html">
   2. Useful theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data_visualization.html">
   3. Data visualization and validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="more_validations.html">
   4. LINZ and OTHER data analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="analysis_pca.html">
   5. PC analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models_linear.html">
   6. MultiLinear regression models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models_knn.html">
   7. KNN regression models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models_xgboost.html">
   8. XGBoost regression models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="experiments.html">
   9. RUN experiments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models_results.html">
   10. VISUALIZE experiments results
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/model_CNN-single_site.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/javitausia/geocean-nz-ss"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/javitausia/geocean-nz-ss/issues/new?title=Issue%20on%20page%20%2Fnotebooks/model_CNN-single_site.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/javitausia/geocean-nz-ss/master?urlpath=tree/notebooks/model_CNN-single_site.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/javitausia/geocean-nz-ss/blob/master/notebooks/model_CNN-single_site.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><no title></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="simple visible nav section-nav flex-column">
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># basics</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>

<span class="c1"># arrays</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="nn">xr</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">datetime</span><span class="p">,</span>
    <span class="n">timedelta</span>
<span class="p">)</span>

<span class="c1"># plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">cartopy.crs</span> <span class="k">as</span> <span class="nn">ccrs</span>

<span class="c1"># append sscode to path</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;/home/metocean/geocean-nz-ss&#39;</span><span class="p">)</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;/data&#39;</span> <span class="c1">#&#39;/data/storm_surge_data/&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;SSURGE_DATA_PATH&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_path</span>

<span class="c1"># custom</span>
<span class="kn">from</span> <span class="nn">sscode.config</span> <span class="kn">import</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">default_region_reduced</span><span class="p">,</span> <span class="n">default_evaluation_metrics</span><span class="p">,</span> <span class="n">default_region</span>
<span class="kn">from</span> <span class="nn">sscode.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">calculate_relative_winds</span><span class="p">,</span>
    <span class="n">spatial_gradient</span>
<span class="p">)</span>

<span class="c1"># warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># this is to allow plots to be centered</span>
<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">&lt;style&gt;</span>
<span class="s2">.output_png {</span>
<span class="s2">    display: table-cell;</span>
<span class="s2">    text-align: center;</span>
<span class="s2">    vertical-align: middle;</span>
<span class="s2">}</span>
<span class="s2">&lt;/style&gt;</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DATA PATH /data
</pre></div>
</div>
<div class="output text_html">
<style>
.output_png {
    display: table-cell;
    text-align: center;
    vertical-align: middle;
}
</style>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dataset attrs</span>
<span class="n">datasets_attrs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;era5&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;ERA 5 reanalysis&#39;</span><span class="p">,</span><span class="s1">&#39;u10&#39;</span><span class="p">,</span><span class="s1">&#39;v10&#39;</span><span class="p">),</span>
    <span class="c1">#&#39;cfsr&#39;: (&#39;lon&#39;,&#39;lat&#39;,None,&#39;CFSR reanalysis&#39;,&#39;U_GRD_L103&#39;,&#39;V_GRD_L103&#39;),</span>
     <span class="s1">&#39;cfsr&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;CFSR reanalysis&#39;</span><span class="p">,</span><span class="s1">&#39;ugrd10m&#39;</span><span class="p">,</span><span class="s1">&#39;vgrd10m&#39;</span><span class="p">),</span>
    <span class="s1">&#39;dac&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;DAC global reanalysis&#39;</span><span class="p">),</span>
    <span class="s1">&#39;moana&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;lon&#39;</span><span class="p">,</span><span class="s1">&#39;lat&#39;</span><span class="p">,</span><span class="s1">&#39;site&#39;</span><span class="p">,</span><span class="s1">&#39;Moana v2 hindcast&#39;</span><span class="p">),</span>
    <span class="s1">&#39;codec&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;codec_coords_lon&#39;</span><span class="p">,</span><span class="s1">&#39;codec_coords_lat&#39;</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;CoDEC reanalysis&#39;</span><span class="p">),</span>
    <span class="s1">&#39;uhslc&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;UHSLC tgs&#39;</span><span class="p">),</span>
    <span class="s1">&#39;linz&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;LINZ tgs&#39;</span><span class="p">),</span>
    <span class="s1">&#39;other&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;OTHER tgs&#39;</span><span class="p">),</span>
    <span class="s1">&#39;privtgs&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">,</span><span class="s1">&#39;Private tgs&#39;</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ss_dset</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_zarr</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;storm_surge_data/moana_hindcast_v2/moana_coast.zarr/&#39;</span><span class="p">))</span>
<span class="n">ss_dset</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">ss_dset</span><span class="o">.</span><span class="n">lat</span><span class="o">&gt;-</span><span class="mi">50</span><span class="p">,</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">lon</span> <span class="o">&lt;</span> <span class="mi">180</span><span class="p">))</span>
<span class="n">predictand</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">ss</span>\
                    <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">datetime</span><span class="p">(</span><span class="mi">1994</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>\
                    <span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>\
                    <span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>\
                    <span class="o">.</span><span class="n">interpolate_na</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>\
                    <span class="o">.</span><span class="n">transpose</span><span class="p">()</span>\
                    <span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_best_predictor_for_site</span><span class="p">(</span><span class="n">location</span><span class="p">,</span>
                                <span class="n">dx</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
                                <span class="n">region</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">normalised</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    
    <span class="kn">from</span> <span class="nn">sscode.utils</span> <span class="kn">import</span> <span class="n">spatial_gradient</span>
    
    <span class="n">pres_vars</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;SLP&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">)</span>
    <span class="n">wind_vars</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;wind_proj_mask&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;U_GRD_L103&#39;</span><span class="p">,</span><span class="s1">&#39;V_GRD_L103&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">region</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">region</span> <span class="o">=</span> <span class="p">(</span>
                  <span class="n">location</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">dx</span><span class="p">,</span>
                  <span class="n">location</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">dx</span><span class="p">,</span>
                  <span class="n">location</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">dx</span><span class="p">,</span>
                  <span class="n">location</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">dx</span>
                <span class="p">)</span>
    
    <span class="n">region_large</span> <span class="o">=</span> <span class="p">(</span>
              <span class="n">region</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
              <span class="n">region</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
              <span class="n">region</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
              <span class="n">region</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
            <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading U&quot;</span><span class="p">)</span>
    <span class="n">uw</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;cfsr&#39;</span><span class="p">,</span>
                                      <span class="s1">&#39;wnd10m/cfsr_wnd_1979_2021.nc&#39;</span><span class="p">))[</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">4</span><span class="p">]]</span>\
                    <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">datetime</span><span class="p">(</span><span class="mi">1994</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>\
                    <span class="o">.</span><span class="n">sel</span><span class="p">({</span>
                      <span class="n">wind_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region_large</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">region_large</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                      <span class="n">wind_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region_large</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">region_large</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
                    <span class="p">})</span>\
                    <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>\
                    <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading V&quot;</span><span class="p">)</span>
    <span class="n">vw</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;cfsr&#39;</span><span class="p">,</span>
                                                  <span class="s1">&#39;wnd10m/cfsr_wnd_1979_2021.nc&#39;</span><span class="p">))[</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">5</span><span class="p">]]</span>\
                    <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">datetime</span><span class="p">(</span><span class="mi">1994</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>\
                    <span class="o">.</span><span class="n">sel</span><span class="p">({</span>
                      <span class="n">wind_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region_large</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">region_large</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                      <span class="n">wind_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region_large</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">region_large</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
                    <span class="p">})</span>\
                    <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>\
                    <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Calculating relative winds&quot;</span><span class="p">)</span>
    <span class="n">wind</span> <span class="o">=</span> <span class="n">calculate_relative_winds</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span> <span class="c1"># load_winds[1],</span>
                                    <span class="n">lat_name</span><span class="o">=</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                                    <span class="n">lon_name</span><span class="o">=</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                                    <span class="n">uw</span><span class="o">=</span><span class="n">uw</span><span class="p">,</span><span class="n">vw</span><span class="o">=</span><span class="n">vw</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Clearing U,V&quot;</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">uw</span>
    <span class="k">del</span> <span class="n">vw</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading MSLP&quot;</span><span class="p">)</span>
    <span class="n">pres</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataarray</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s1">&#39;cfsr&#39;</span><span class="p">,</span>
                                          <span class="s1">&#39;CFSR_MSLP_1H_1990_2021.nc&#39;</span><span class="p">))</span>\
             <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">datetime</span><span class="p">(</span><span class="mi">1994</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>\
             <span class="o">.</span><span class="n">sel</span><span class="p">({</span>
                    <span class="n">pres_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">region</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="n">pres_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="nb">slice</span><span class="p">(</span><span class="n">region</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">region</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
                    <span class="p">})</span>\
             <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="s1">&#39;longitude&#39;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>\
             <span class="o">.</span><span class="n">sortby</span><span class="p">(</span><span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">pres_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;wind_proj&#39;</span> <span class="ow">or</span> <span class="n">pres_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;wind_proj_mask&#39;</span><span class="p">:</span> <span class="c1"># when just winds are loaded                                                                               </span>
        <span class="n">pres</span> <span class="o">=</span> <span class="n">pres</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pres</span> <span class="o">=</span> <span class="n">pres</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span><span class="n">how</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
    
    <span class="n">wind</span> <span class="o">=</span> <span class="n">wind</span><span class="p">[</span><span class="n">wind_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>\
                             <span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="n">wind_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">pres</span><span class="p">[</span><span class="n">pres_vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
                                             <span class="n">wind_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="n">pres</span><span class="p">[</span><span class="n">pres_vars</span><span class="p">[</span><span class="mi">2</span><span class="p">]]})</span>\
                             <span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">pres</span><span class="o">.</span><span class="n">time</span><span class="p">)</span> <span class="c1"># interp to pressure coords                            </span>
    
    <span class="c1"># calculate the gradient                                                            </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> calculating the gradient of the sea-level-pressure fields... </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">pres</span> <span class="o">=</span> <span class="n">spatial_gradient</span><span class="p">(</span><span class="n">pres</span><span class="p">,</span><span class="n">pres_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># from utils.py                      </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> pressure/gradient predictor both with shape: </span><span class="se">\n</span><span class="s1"> </span><span class="si">{}</span><span class="s1"> </span><span class="se">\n</span><span class="s1">&#39;</span>\
            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pres</span><span class="p">[</span><span class="n">pres_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        
    <span class="c1"># Normalising</span>
    <span class="k">if</span> <span class="n">normalised</span><span class="p">:</span>
        <span class="n">all_predictors</span> <span class="o">=</span>\
           <span class="n">xr</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
                      <span class="p">(</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
                      <span class="p">(</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP_gradient</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP_gradient</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP_gradient</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
                      <span class="p">(</span><span class="n">wind</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">-</span><span class="n">wind</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">wind</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">wind</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
                     <span class="p">],</span>
                     <span class="s2">&quot;channel&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">all_predictors</span> <span class="o">=</span>\
           <span class="n">xr</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
                      <span class="n">pres</span><span class="o">.</span><span class="n">SLP</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                      <span class="n">pres</span><span class="o">.</span><span class="n">SLP_gradient</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                      <span class="n">wind</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                     <span class="p">],</span>
                     <span class="s2">&quot;channel&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">all_predictors</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tfv2</span>
<span class="c1"># pylint: disable=g-classes-have-attributes</span>

<span class="c1"># These functions are adapted from</span>
<span class="c1"># https://github.com/keras-team/keras/blob/06ba37b8662dea768b3bc8201942f1eb877708e8/keras/preprocessing/timeseries.py</span>
<span class="c1"># The main addition is that they targets have been modified to contain both the input grid and the ss output</span>
<span class="c1"># That way it is possible to use the dataset to train both heads of the network</span>
    
<span class="k">def</span> <span class="nf">sequences_from_indices</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">indices_ds</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">):</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensors</span><span class="p">(</span><span class="n">array</span><span class="p">[</span><span class="n">start_index</span> <span class="p">:</span> <span class="n">end_index</span><span class="p">])</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">((</span><span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(),</span> <span class="n">indices_ds</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
      <span class="k">lambda</span> <span class="n">steps</span><span class="p">,</span> <span class="n">inds</span><span class="p">:</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">inds</span><span class="p">),</span>  <span class="c1"># pylint: disable=unnecessary-lambda</span>
      <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dataset</span>

<span class="k">def</span> <span class="nf">timeseries_dataset_from_array_seb</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">,</span>
    <span class="n">targets_2</span><span class="p">,</span>
    <span class="n">sequence_length</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sequence_stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">start_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">end_index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates a dataset of sliding windows over a timeseries provided as array.</span>
<span class="sd">  This function takes in a sequence of data-points gathered at</span>
<span class="sd">  equal intervals, along with time series parameters such as</span>
<span class="sd">  length of the sequences/windows, spacing between two sequence/windows, etc.,</span>
<span class="sd">  to produce batches of timeseries inputs and targets.</span>
<span class="sd">  Args:</span>
<span class="sd">    data: Numpy array or eager tensor</span>
<span class="sd">      containing consecutive data points (timesteps).</span>
<span class="sd">      Axis 0 is expected to be the time dimension.</span>
<span class="sd">    targets: Targets corresponding to timesteps in `data`.</span>
<span class="sd">      `targets[i]` should be the target</span>
<span class="sd">      corresponding to the window that starts at index `i`</span>
<span class="sd">      (see example 2 below).</span>
<span class="sd">      Pass None if you don&#39;t have target data (in this case the dataset will</span>
<span class="sd">      only yield the input data).</span>
<span class="sd">    sequence_length: Length of the output sequences (in number of timesteps).</span>
<span class="sd">    sequence_stride: Period between successive output sequences.</span>
<span class="sd">      For stride `s`, output samples would</span>
<span class="sd">      start at index `data[i]`, `data[i + s]`, `data[i + 2 * s]`, etc.</span>
<span class="sd">    sampling_rate: Period between successive individual timesteps</span>
<span class="sd">      within sequences. For rate `r`, timesteps</span>
<span class="sd">      `data[i], data[i + r], ... data[i + sequence_length]`</span>
<span class="sd">      are used for create a sample sequence.</span>
<span class="sd">    batch_size: Number of timeseries samples in each batch</span>
<span class="sd">      (except maybe the last one).</span>
<span class="sd">    shuffle: Whether to shuffle output samples,</span>
<span class="sd">      or instead draw them in chronological order.</span>
<span class="sd">    seed: Optional int; random seed for shuffling.</span>
<span class="sd">    start_index: Optional int; data points earlier (exclusive)</span>
<span class="sd">      than `start_index` will not be used</span>
<span class="sd">      in the output sequences. This is useful to reserve part of the</span>
<span class="sd">      data for test or validation.</span>
<span class="sd">    end_index: Optional int; data points later (exclusive) than `end_index`</span>
<span class="sd">      will not be used in the output sequences.</span>
<span class="sd">      This is useful to reserve part of the data for test or validation.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A tfv2.data.Dataset instance. If `targets` was passed, the dataset yields</span>
<span class="sd">    tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields</span>
<span class="sd">    only `batch_of_sequences`.</span>
<span class="sd">  Example 1:</span>
<span class="sd">  Consider indices `[0, 1, ... 99]`.</span>
<span class="sd">  With `sequence_length=10,  sampling_rate=2, sequence_stride=3`,</span>
<span class="sd">  `shuffle=False`, the dataset will yield batches of sequences</span>
<span class="sd">  composed of the following indices:</span>
<span class="sd">  ```</span>
<span class="sd">  First sequence:  [0  2  4  6  8 10 12 14 16 18]</span>
<span class="sd">  Second sequence: [3  5  7  9 11 13 15 17 19 21]</span>
<span class="sd">  Third sequence:  [6  8 10 12 14 16 18 20 22 24]</span>
<span class="sd">  ...</span>
<span class="sd">  Last sequence:   [78 80 82 84 86 88 90 92 94 96]</span>
<span class="sd">  ```</span>
<span class="sd">  In this case the last 3 data points are discarded since no full sequence</span>
<span class="sd">  can be generated to include them (the next sequence would have started</span>
<span class="sd">  at index 81, and thus its last step would have gone over 99).</span>
<span class="sd">  Example 2: Temporal regression.</span>
<span class="sd">  Consider an array `data` of scalar values, of shape `(steps,)`.</span>
<span class="sd">  To generate a dataset that uses the past 10</span>
<span class="sd">  timesteps to predict the next timestep, you would use:</span>
<span class="sd">  ```python</span>
<span class="sd">  input_data = data[:-10]</span>
<span class="sd">  targets = data[10:]</span>
<span class="sd">  dataset = tfv2.keras.preprocessing.timeseries_dataset_from_array(</span>
<span class="sd">      input_data, targets, sequence_length=10)</span>
<span class="sd">  for batch in dataset:</span>
<span class="sd">    inputs, targets = batch</span>
<span class="sd">    assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]</span>
<span class="sd">    assert np.array_equal(targets[0], data[10])  # Corresponding target: step 10</span>
<span class="sd">    break</span>
<span class="sd">  ```</span>
<span class="sd">  Example 3: Temporal regression for many-to-many architectures.</span>
<span class="sd">  Consider two arrays of scalar values `X` and `Y`,</span>
<span class="sd">  both of shape `(100,)`. The resulting dataset should consist samples with</span>
<span class="sd">  20 timestamps each. The samples should not overlap.</span>
<span class="sd">  To generate a dataset that uses the current timestamp</span>
<span class="sd">  to predict the corresponding target timestep, you would use:</span>
<span class="sd">  ```python</span>
<span class="sd">  X = np.arange(100)</span>
<span class="sd">  Y = X*2</span>
<span class="sd">  sample_length = 20</span>
<span class="sd">  input_dataset = tfv2.keras.preprocessing.timeseries_dataset_from_array(</span>
<span class="sd">    X, None, sequence_length=sample_length, sequence_stride=sample_length)</span>
<span class="sd">  target_dataset = tfv2.keras.preprocessing.timeseries_dataset_from_array(</span>
<span class="sd">    Y, None, sequence_length=sample_length, sequence_stride=sample_length)</span>
<span class="sd">  for batch in zip(input_dataset, target_dataset):</span>
<span class="sd">    inputs, targets = batch</span>
<span class="sd">    assert np.array_equal(inputs[0], X[:sample_length])</span>
<span class="sd">    # second sample equals output timestamps 20-40</span>
<span class="sd">    assert np.array_equal(targets[1], Y[sample_length:2*sample_length])</span>
<span class="sd">    break</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">start_index</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">start_index</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`start_index` must be 0 or greater. Received: &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;start_index=</span><span class="si">{</span><span class="n">start_index</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">start_index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`start_index` must be lower than the length of the &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;data. Received: start_index=</span><span class="si">{</span><span class="n">start_index</span><span class="si">}</span><span class="s1">, for data &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_index</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">start_index</span> <span class="ow">and</span> <span class="n">end_index</span> <span class="o">&lt;=</span> <span class="n">start_index</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`end_index` must be higher than `start_index`. &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;Received: start_index=</span><span class="si">{</span><span class="n">start_index</span><span class="si">}</span><span class="s1">, and &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;end_index=</span><span class="si">{</span><span class="n">end_index</span><span class="si">}</span><span class="s1"> &#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">end_index</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`end_index` must be lower than the length of the &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;data. Received: end_index=</span><span class="si">{</span><span class="n">end_index</span><span class="si">}</span><span class="s1">, for data of &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">end_index</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`end_index` must be higher than 0. &#39;</span>
                       <span class="sa">f</span><span class="s1">&#39;Received: end_index=</span><span class="si">{</span><span class="n">end_index</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

  <span class="c1"># Validate strides</span>
  <span class="k">if</span> <span class="n">sampling_rate</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`sampling_rate` must be higher than 0. Received: &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;sampling_rate=</span><span class="si">{</span><span class="n">sampling_rate</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">sampling_rate</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`sampling_rate` must be lower than the length of the &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;data. Received: sampling_rate=</span><span class="si">{</span><span class="n">sampling_rate</span><span class="si">}</span><span class="s1">, for data &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">sequence_stride</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`sequence_stride` must be higher than 0. Received: &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;sequence_stride=</span><span class="si">{</span><span class="n">sequence_stride</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">sequence_stride</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;`sequence_stride` must be lower than the length of the &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;data. Received: sequence_stride=</span><span class="si">{</span><span class="n">sequence_stride</span><span class="si">}</span><span class="s1">, for &#39;</span>
                     <span class="sa">f</span><span class="s1">&#39;data of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">start_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">if</span> <span class="n">end_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

  <span class="c1"># Determine the lowest dtype to store start positions (to lower memory usage).</span>
  <span class="n">num_seqs</span> <span class="o">=</span> <span class="n">end_index</span> <span class="o">-</span> <span class="n">start_index</span> <span class="o">-</span> <span class="p">(</span><span class="n">sequence_length</span> <span class="o">*</span> <span class="n">sampling_rate</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_seqs</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_seqs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">num_seqs</span> <span class="o">&lt;</span> <span class="mi">2147483647</span><span class="p">:</span>
    <span class="n">index_dtype</span> <span class="o">=</span> <span class="s1">&#39;int32&#39;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">index_dtype</span> <span class="o">=</span> <span class="s1">&#39;int64&#39;</span>

  <span class="c1"># Generate start positions</span>
  <span class="n">start_positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_seqs</span><span class="p">,</span> <span class="n">sequence_stride</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">index_dtype</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e6</span><span class="p">)</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)</span>

  <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">index_dtype</span><span class="p">)</span>
  <span class="n">sampling_rate</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">sampling_rate</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">index_dtype</span><span class="p">)</span>

  <span class="n">positions_ds</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensors</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>

  <span class="c1"># For each initial window position, generates indices of the window elements</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span>
      <span class="p">(</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)),</span> <span class="n">positions_ds</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">positions</span><span class="p">:</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">range</span><span class="p">(</span>  <span class="c1"># pylint: disable=g-long-lambda</span>
              <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
              <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">sequence_length</span> <span class="o">*</span> <span class="n">sampling_rate</span><span class="p">,</span>
              <span class="n">sampling_rate</span><span class="p">),</span>
          <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

  <span class="n">dataset</span> <span class="o">=</span> <span class="n">sequences_from_indices</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">)</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)),</span> <span class="n">positions_ds</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">positions</span><span class="p">:</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
    <span class="n">target_ds</span> <span class="o">=</span> <span class="n">sequences_from_indices</span><span class="p">(</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">targets_2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_ds_2</span> <span class="o">=</span> <span class="n">sequences_from_indices</span><span class="p">(</span>
            <span class="n">targets_2</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">target_ds</span><span class="p">,</span> <span class="n">target_ds_2</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
    <span class="c1">#outputs.append((target_ds, dataset))</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_ds</span><span class="p">)</span>
    <span class="c1">##dataset = tfv2.data.Dataset.zip((dataset, (target_ds, dataset)))</span>
    
    <span class="c1">#outputs.append((target_ds, dataset))</span>
    <span class="c1">#outputs.append(target_ds)</span>

  <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)),</span> <span class="n">positions_ds</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">positions</span><span class="p">:</span> <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
    <span class="n">target_weights_dset</span> <span class="o">=</span> <span class="n">sequences_from_indices</span><span class="p">(</span>
            <span class="n">weights</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">)</span>
    
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span>
      <span class="p">(</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)),</span> <span class="n">positions_ds</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">positions</span><span class="p">:</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">range</span><span class="p">(</span>  <span class="c1"># pylint: disable=g-long-lambda</span>
              <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
              <span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">sequence_length</span> <span class="o">*</span> <span class="n">sampling_rate</span><span class="p">,</span>
              <span class="n">sampling_rate</span><span class="p">),</span>
          <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

    <span class="n">ae_weights_dset</span> <span class="o">=</span> <span class="n">sequences_from_indices</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="p">(</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">indices</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">)</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">target_weights_dset</span><span class="p">,</span> <span class="n">ae_weights_dset</span><span class="p">))</span>
    <span class="c1">#dataset = tfv2.data.Dataset.zip((dataset, (target_ds, dataset)))</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
    <span class="c1"># Shuffle locally at each iteration</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tfv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sscode.validation</span> <span class="kn">import</span> <span class="n">generate_stats</span>
<span class="kn">from</span> <span class="nn">sscode.config</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">default_evaluation_metrics</span><span class="p">,</span>
    <span class="n">default_ext_quantile</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_stats</span><span class="p">(</span><span class="n">ts1</span><span class="p">,</span> <span class="n">ts2</span><span class="p">):</span>
    <span class="n">title</span><span class="p">,</span> <span class="n">stats</span> <span class="o">=</span> <span class="n">generate_stats</span><span class="p">(</span><span class="n">ts1</span><span class="p">,</span>
                              <span class="n">ts2</span><span class="p">,</span>
                              <span class="n">metrics</span><span class="o">=</span><span class="n">default_evaluation_metrics</span><span class="p">,</span>
                              <span class="n">ext_quantile</span><span class="o">=</span><span class="n">default_ext_quantile</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="s1">&#39;si&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="s1">&#39;kgeprime&#39;</span><span class="p">,</span> <span class="s1">&#39;rmse_95&#39;</span><span class="p">,</span> <span class="s1">&#39;rmse_99&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;pearson&#39;</span><span class="p">,</span> <span class="s1">&#39;pearson_95&#39;</span><span class="p">,</span> <span class="s1">&#39;pearson_99&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;rscore&#39;</span><span class="p">,</span> <span class="s1">&#39;rscore_95&#39;</span><span class="p">,</span> <span class="s1">&#39;rscore_99&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;nse&#39;</span><span class="p">,</span> <span class="s1">&#39;nse_95&#39;</span><span class="p">,</span> <span class="s1">&#39;nse_99&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;kge&#39;</span><span class="p">,</span> <span class="s1">&#39;ext_kge_95&#39;</span><span class="p">,</span> <span class="s1">&#39;ext_kge_99&#39;</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">stats</span><span class="p">[</span><span class="n">metric</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Conv2D</span><span class="p">,</span>
    <span class="n">Conv3D</span><span class="p">,</span>
    <span class="n">BatchNormalization</span><span class="p">,</span>
    <span class="n">MaxPool2D</span><span class="p">,</span>
    <span class="n">MaxPool3D</span><span class="p">,</span>
    <span class="n">ConvLSTM2D</span><span class="p">,</span>
    <span class="n">GlobalMaxPool2D</span><span class="p">,</span>
    <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span>
    <span class="n">TimeDistributed</span><span class="p">,</span>
    <span class="n">GRU</span><span class="p">,</span>
    <span class="n">Dense</span><span class="p">,</span>
    <span class="n">Dropout</span><span class="p">,</span>
    <span class="n">Conv1D</span><span class="p">,</span>
    <span class="n">LSTM</span><span class="p">,</span>
    <span class="n">Conv2DTranspose</span><span class="p">,</span>
    <span class="n">Reshape</span><span class="p">,</span>
    <span class="n">Cropping2D</span><span class="p">,</span>
    <span class="n">Cropping1D</span><span class="p">,</span>
    <span class="n">Activation</span><span class="p">,</span>
    <span class="n">Lambda</span><span class="p">,</span>
    <span class="n">Concatenate</span><span class="p">,</span>
    <span class="n">TimeDistributed</span><span class="p">,</span>
    <span class="n">Flatten</span><span class="p">,</span>
    <span class="n">Reshape</span>
<span class="p">)</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This one works!!!</span>
<span class="k">def</span> <span class="nf">build_model_cnn</span><span class="p">(</span><span class="n">shape_in</span><span class="p">,</span>
                    <span class="n">nbout</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape_in</span><span class="p">)</span>
    
    <span class="n">conv_1</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">cnn_outputs</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))(</span><span class="n">conv_1</span><span class="p">)</span>     
    
    <span class="n">flat</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">cnn_outputs</span><span class="p">)</span>

    <span class="n">dense_1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">48</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
                    <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                    <span class="p">)(</span><span class="n">flat</span><span class="p">)</span>
    
    <span class="n">dropout_1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)(</span><span class="n">dense_1</span><span class="p">)</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">nbout</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">dropout_1</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">to_use</span><span class="o">=</span><span class="mi">1</span>

<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">(</span><span class="n">gpus</span><span class="p">[</span><span class="n">to_use</span><span class="p">],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
    <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s2">&quot;Physical GPUs,&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s2">&quot;Logical GPU&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c1"># Visible devices must be set before GPUs have been initialized</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c1"># Invalid device or cannot modify virtual devices once initialized.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Failed to select GPU&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2 Physical GPUs, 1 Logical GPU
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_training_and_validation_sets</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span>
                                     <span class="n">predictand</span><span class="p">,</span>
                                     <span class="n">input_sequence_length</span><span class="p">,</span>
                                     <span class="n">input_sequence_frequency</span><span class="p">,</span>
                                     <span class="n">lead_time</span><span class="p">,</span>
                                     <span class="n">target_sequence_frequency</span><span class="p">,</span>
                                     <span class="n">fold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                     <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                     <span class="n">print_test</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="k">if</span> <span class="p">(</span> <span class="ow">not</span> <span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">-</span><span class="n">predictand</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span>\
        <span class="p">(</span><span class="n">predictand</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">-</span><span class="n">predictand</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time spacing is not constant in predictand dataset&quot;</span><span class="p">)</span>
        <span class="k">raise</span>
    
    <span class="k">if</span> <span class="p">(</span> <span class="ow">not</span> <span class="p">(</span><span class="n">predictors</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">-</span><span class="n">predictors</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">==</span>\
        <span class="p">(</span><span class="n">predictors</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">-</span><span class="n">predictors</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time spacing is not constant in predictor dataset&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
    
    <span class="c1"># Find start, end and extent of dataset</span>
    <span class="p">[</span><span class="n">tstart_predictor</span><span class="p">,</span> <span class="n">tend_predictor</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictors</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[s]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="p">[</span><span class="n">tstart_predictand</span><span class="p">,</span> <span class="n">tend_predictand</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictand</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[s]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">tstart</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">tstart_predictand</span><span class="p">,</span> <span class="n">tstart_predictor</span><span class="p">)</span>
    <span class="n">tend</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">tend_predictand</span><span class="p">,</span> <span class="n">tend_predictor</span><span class="p">)</span>
    <span class="n">time_extent</span> <span class="o">=</span> <span class="n">tend</span> <span class="o">-</span> <span class="n">tstart</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Returning fold &quot;</span><span class="p">,</span><span class="n">fold</span><span class="p">,</span><span class="s2">&quot; of &quot;</span><span class="p">,</span> <span class="n">n_folds</span><span class="p">,</span> <span class="s2">&quot; e.g. </span><span class="si">%2.1f</span><span class="s2"> percent training data&quot;</span><span class="o">%</span><span class="p">((</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">n_folds</span><span class="o">*</span><span class="mf">100.</span><span class="p">))</span>

    <span class="c1"># Finding time bounds of training data segments</span>
    <span class="n">tstart_1</span> <span class="o">=</span> <span class="n">tstart</span>
    <span class="n">tend_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">tstart</span> <span class="o">+</span> <span class="n">time_extent</span><span class="o">*</span><span class="p">((</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">fold</span><span class="p">)</span><span class="o">/</span><span class="n">n_folds</span><span class="p">))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">second</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">microsecond</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">minute</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">tstart_2</span> <span class="o">=</span> <span class="p">(</span><span class="n">tstart</span> <span class="o">+</span> <span class="n">time_extent</span><span class="o">*</span><span class="p">((</span><span class="n">n_folds</span><span class="o">-</span><span class="n">fold</span><span class="p">)</span><span class="o">/</span><span class="n">n_folds</span><span class="p">))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">second</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">microsecond</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">minute</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">tend_2</span> <span class="o">=</span> <span class="n">tend</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    
    <span class="n">train_dset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">tstart_train</span><span class="p">,</span> <span class="n">tend_train</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">tstart_1</span><span class="p">,</span> <span class="n">tstart_2</span><span class="p">],[</span><span class="n">tend_1</span><span class="p">,</span> <span class="n">tend_2</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">tstart_train</span> <span class="o">!=</span> <span class="n">tend_train</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">tstart_train</span><span class="p">,</span> <span class="n">tend_train</span><span class="p">)</span>

            <span class="n">predictor_train</span> <span class="o">=</span>\
                <span class="n">predictors</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">tstart_train</span><span class="p">,</span>
                                          <span class="n">tend_train</span><span class="o">-</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="p">(</span><span class="n">lead_time</span><span class="o">-</span><span class="n">target_sequence_frequency</span><span class="p">))))</span>\
                          <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>\
                          <span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="p">(</span><span class="n">input_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>\
                          <span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="p">(</span><span class="n">input_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>\
                          <span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">ss_train</span> <span class="o">=</span> <span class="n">predictand</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">tstart_train</span><span class="o">+</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="n">input_sequence_length</span><span class="o">+</span><span class="n">lead_time</span><span class="o">-</span><span class="n">target_sequence_frequency</span><span class="p">),</span>
                                      <span class="n">tend_train</span><span class="p">))</span>\
                                 <span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>\
                                 <span class="o">.</span><span class="n">interpolate_na</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>\
                                 <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">target_sequence_frequency</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>\
                                 <span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>\
                                 <span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>\
                                 <span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>

            <span class="k">if</span> <span class="n">print_test</span><span class="p">:</span> <span class="c1"># To check indices are fine</span>
                <span class="n">test_dset</span> <span class="o">=</span> <span class="n">timeseries_dataset_from_array_seb</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">predictor_train</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">-</span><span class="mi">786412800000000000</span><span class="p">)</span><span class="o">//</span><span class="mi">3600000000000</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">ss_train</span><span class="o">.</span><span class="n">time</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">-</span><span class="mi">786412800000000000</span><span class="p">)</span><span class="o">//</span><span class="mi">3600000000000</span><span class="p">,</span>
                    <span class="n">targets_2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">sequence_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">input_sequence_length</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
                    <span class="n">sequence_stride</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
                    <span class="n">sampling_rate</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_index</span><span class="o">=</span><span class="kc">None</span>
                    <span class="p">)</span>
        
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All integer correspond to number of hours with respect to reference date&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">test_dset</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span>
                    <span class="k">for</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Times in:&quot;</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="s2">&quot;Times out:&quot;</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
                    <span class="n">print_test</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">break</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="n">train_dset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">timeseries_dataset_from_array_seb</span><span class="p">(</span>
                    <span class="n">predictor_train</span><span class="p">,</span>
                    <span class="n">ss_train</span><span class="p">,</span>
                    <span class="n">targets_2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">sequence_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">input_sequence_length</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
                <span class="n">sequence_stride</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
                <span class="n">sampling_rate</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_index</span><span class="o">=</span><span class="kc">None</span>
                <span class="p">))</span>
            
    <span class="c1"># If multiple segments concatenate them into a single dataset</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">train_dset</span> <span class="o">=</span> <span class="n">train_dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dset</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="n">train_dset</span> <span class="o">=</span> <span class="n">train_dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">train_dset</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


    <span class="c1"># Validation data</span>
    <span class="n">predictor_val</span> <span class="o">=</span> <span class="n">predictors</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">tend_1</span><span class="p">,</span>
                                              <span class="n">tstart_2</span><span class="o">-</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="p">(</span><span class="n">lead_time</span><span class="o">-</span><span class="n">target_sequence_frequency</span><span class="p">))))</span>\
                              <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>\
                              <span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="p">(</span><span class="n">input_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>\
                              <span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="p">(</span><span class="n">input_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>\
                              <span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">ss_val</span> <span class="o">=</span> <span class="n">predictand</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="n">tend_1</span><span class="o">+</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="n">input_sequence_length</span><span class="o">+</span><span class="n">lead_time</span><span class="o">-</span><span class="n">target_sequence_frequency</span><span class="p">),</span>
                                       <span class="n">tstart_2</span><span class="p">))</span>\
                       <span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>\
                       <span class="o">.</span><span class="n">interpolate_na</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>\
                       <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">target_sequence_frequency</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>\
                       <span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">time</span><span class="o">=-</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>\
                       <span class="o">.</span><span class="n">isel</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>\
                       <span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="s2">&quot;channel&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span>


    <span class="n">val_dset</span> <span class="o">=</span> <span class="n">timeseries_dataset_from_array_seb</span><span class="p">(</span>
        <span class="n">predictor_val</span><span class="p">,</span>
        <span class="n">ss_val</span><span class="p">,</span>
        <span class="n">targets_2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sequence_length</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">input_sequence_length</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
        <span class="n">sequence_stride</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">target_sequence_frequency</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),</span>
        <span class="n">sampling_rate</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end_index</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">train_dset</span><span class="p">,</span> <span class="n">val_dset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1">#for site_id in [ 224 ]:</span>
<span class="k">for</span> <span class="n">site_id</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span> <span class="c1"># closest Moana v2 Hindcast to tidal gauges</span>
                <span class="p">[</span> <span class="mi">689</span><span class="p">,</span><span class="mi">328</span><span class="p">,</span><span class="mi">393</span><span class="p">,</span><span class="mi">1327</span><span class="p">,</span><span class="mi">393</span><span class="p">,</span><span class="mi">480</span><span class="p">,</span><span class="mi">999</span><span class="p">,</span><span class="mi">116</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">1124</span><span class="p">,</span><span class="mi">949</span><span class="p">,</span><span class="mi">708</span><span class="p">,</span> <span class="c1"># UHSLC</span>
                  <span class="mi">1296</span><span class="p">,</span><span class="mi">1124</span><span class="p">,</span><span class="mi">780</span><span class="p">,</span><span class="mi">613</span><span class="p">,</span><span class="mi">488</span><span class="p">,</span><span class="mi">1442</span><span class="p">,</span><span class="mi">1217</span><span class="p">,</span><span class="mi">578</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">1177</span><span class="p">,</span><span class="mi">1025</span><span class="p">,</span><span class="mi">689</span><span class="p">,</span><span class="mi">949</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">1146</span><span class="p">,</span> <span class="c1"># LINZ</span>
                  <span class="mi">1174</span><span class="p">,</span><span class="mi">1260</span><span class="p">,</span><span class="mi">1217</span><span class="p">,</span><span class="mi">744</span><span class="p">,</span><span class="mi">1064</span><span class="p">,</span><span class="mi">1214</span><span class="p">,</span><span class="mi">803</span><span class="p">,</span><span class="mi">999</span> <span class="c1"># OTHER (ports...)</span>
                <span class="p">]</span>
            <span class="p">):</span>
    
    
    <span class="n">location</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
                    <span class="nb">float</span><span class="p">(</span><span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
    
    
    <span class="n">all_predictors</span> <span class="o">=</span> <span class="n">get_best_predictor_for_site</span><span class="p">(</span><span class="n">location</span><span class="p">)</span>
    
    <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>
    
    
    
    <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        
    <span class="c1">#try:</span>
    <span class="c1">#if True:</span>

        <span class="n">dset_train</span><span class="p">,</span> <span class="n">dset_val</span> <span class="o">=</span> <span class="n">get_training_and_validation_sets</span><span class="p">(</span><span class="n">predictors</span><span class="o">=</span><span class="n">all_predictors</span><span class="p">,</span>
                                                        <span class="n">predictand</span><span class="o">=</span><span class="n">predictand</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">),</span>
                                                        <span class="n">input_sequence_length</span><span class="o">=</span><span class="n">input_sequence_length</span><span class="p">,</span>
                                                        <span class="n">input_sequence_frequency</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">,</span>
                                                        <span class="n">lead_time</span><span class="o">=</span><span class="n">lead_time</span><span class="p">,</span>
                                                        <span class="n">target_sequence_frequency</span><span class="o">=</span><span class="n">target_sequence_frequency</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                                        <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                        <span class="n">fold</span><span class="o">=</span><span class="n">fold</span><span class="p">,</span>
                                                        <span class="n">print_test</span><span class="o">=</span><span class="kc">True</span>
                                                               <span class="p">)</span>


        <span class="n">shape_in</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_sequence_length</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),)</span> <span class="o">+</span> <span class="n">dset_train</span><span class="o">.</span><span class="n">element_spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">model_cnn</span> <span class="o">=</span> <span class="n">build_model_cnn</span><span class="p">(</span><span class="n">shape_in</span><span class="o">=</span><span class="n">shape_in</span><span class="p">,</span>
                                    <span class="n">nbout</span><span class="o">=</span><span class="n">dset_train</span><span class="o">.</span><span class="n">element_spec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
        <span class="n">model_cnn</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> 
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="s1">&#39;mae&#39;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dset_train</span><span class="p">,</span>
                                <span class="n">validation_data</span><span class="o">=</span><span class="n">dset_val</span><span class="p">,</span>
                                <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

        <span class="n">prediction_val</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dset_val</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculate_stats</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dset_val</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span> <span class="n">prediction_val</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">][</span><span class="s1">&#39;history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span>
        <span class="n">w_results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">][</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction_val</span>
        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 2.572
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 4.861
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">261</span><span class="o">-</span><span class="mi">10377</span><span class="n">aa14c0d</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> 
<span class="g g-Whitespace">     </span><span class="mi">14</span> 
<span class="ne">---&gt; </span><span class="mi">15</span>     <span class="n">all_predictors</span> <span class="o">=</span> <span class="n">get_best_predictor_for_site</span><span class="p">(</span><span class="n">location</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> 
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="n">new_results</span><span class="p">[</span><span class="n">site_id</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>

<span class="nn">&lt;ipython-input-4-5a22ff3da862&gt;</span> in <span class="ni">get_best_predictor_for_site</span><span class="nt">(location)</span>
<span class="g g-Whitespace">     </span><span class="mi">49</span> 
<span class="g g-Whitespace">     </span><span class="mi">50</span>     <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Calculating relative winds&quot;</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">51</span>     <span class="n">wind</span> <span class="o">=</span> <span class="n">calculate_relative_winds</span><span class="p">(</span><span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span> <span class="c1"># load_winds[1],</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>                                     <span class="n">lat_name</span><span class="o">=</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>                                     <span class="n">lon_name</span><span class="o">=</span><span class="n">datasets_attrs</span><span class="p">[</span><span class="s1">&#39;cfsr&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>

<span class="nn">~/geocean-nz-ss/sscode/utils.py</span> in <span class="ni">calculate_relative_winds</span><span class="nt">(location, uw, vw, lat_name, lon_name, delete_direc, chunk)</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span>     <span class="c1"># calculate relative directions</span>
<span class="g g-Whitespace">     </span><span class="mi">77</span>     <span class="n">rel_direcs</span> <span class="o">=</span> <span class="n">bearings</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">*</span><span class="n">bearings</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">wind_direcs</span>
<span class="ne">---&gt; </span><span class="mi">78</span>     <span class="n">rel_direcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">rel_direcs</span><span class="o">&lt;-</span><span class="mi">180</span><span class="p">,</span><span class="n">rel_direcs</span><span class="o">+</span><span class="mi">360</span><span class="p">,</span><span class="n">rel_direcs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span>     <span class="n">rel_direcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">rel_direcs</span><span class="o">&gt;</span><span class="mi">180</span><span class="p">,</span><span class="n">rel_direcs</span><span class="o">-</span><span class="mi">360</span><span class="p">,</span><span class="n">rel_direcs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">80</span>     <span class="c1"># delete winds in opposite directions</span>

<span class="nn">&lt;__array_function__ internals&gt;</span> in <span class="ni">where</span><span class="nt">(*args, **kwargs)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;pearson&#39;</span>
<span class="n">site_id</span> <span class="o">=</span> <span class="mi">116</span>
<span class="c1">#for fold, res in new_results[site_id].items():</span>
<span class="k">for</span> <span class="n">site_id</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">site_id</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()],</span> <span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>116 [0.85  0.863 0.866 0.857 0.87 ] 0.8613134188662361
200 [0.865 0.879 0.865 0.855 0.87 ] 0.8666296471974133
224 [0.812 0.845 0.838 0.811 0.844] 0.830150901523344
328 [0.799 0.841 0.81  0.788 0.819] 0.8116797462112617
393 [0.863 0.871 0.867 0.85  0.877] 0.86562029695218
480 [0.788 0.82  0.794 0.768 0.798] 0.7937408005973807
488 [0.788 0.821 0.796 0.777 0.793] 0.7950268220251023
578 [0.796 0.83  0.816 0.767 0.803] 0.8026105017565566
613 [0.862 0.876 0.864 0.83  0.869] 0.860105138391971
689 [0.841 0.867 0.844 0.826 0.848] 0.8447627955420692
708 [0.78  0.796 0.8   0.747 0.773] 0.779017156731028
744 [0.779 0.8   0.805 0.745 0.779] 0.781703093046672
780 [0.844 0.858 0.846 0.817 0.843] 0.8415980526407582
803 [0.794 0.81  0.803 0.753 0.777] 0.7875990644641302
949 [0.825 0.842 0.828 0.799 0.821] 0.8228952986869453
999 [0.877 0.877 0.854 0.853 0.872] 0.8664577313655633
1025 [0.828 0.822 0.824 0.804 0.813] 0.8185264109361607
1064 [0.881 0.879 0.858 0.854 0.874] 0.8690669773551983
1124 [0.824 0.83  0.829 0.809 0.829] 0.8242410809993856
1146 [0.831 0.83  0.828 0.8   0.814] 0.820640595069771
1174 [0.828 0.835 0.826 0.801 0.831] 0.8241888754456737
1177 [0.882 0.878 0.859 0.858 0.877] 0.870741802955941
1214 [0.83  0.836 0.83  0.815 0.827] 0.8275818033099593
1217 [0.841 0.832 0.818 0.816 0.834] 0.8282166283338102
1260 [0.886 0.875 0.86  0.861 0.875] 0.8711517476894638
1296 [0.843 0.841 0.829 0.816 0.827] 0.8312307478137739
1327 [0.828 0.825 0.802 0.808 0.811] 0.814456737641256
1442 [0.84  0.827 0.813 0.803 0.812] 0.8188040612576621
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">linear_results</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="s1">&#39;/home/metocean/geocean-nz-ss/data/statistics/experiments/experiment_linear_final_20211113.nc&#39;</span><span class="p">)</span>
<span class="n">best_linear_results</span> <span class="o">=</span> <span class="n">linear_results</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">winds</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tlapse</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">region</span><span class="o">=</span><span class="s1">&#39;local_2.5_2.5&#39;</span><span class="p">,</span> <span class="n">tresample</span><span class="o">=</span><span class="s1">&#39;1D&#39;</span><span class="p">)</span>
<span class="n">best_linear_results</span>

<span class="n">sites</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">site</span><span class="o">.</span><span class="n">values</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
<span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;ext_kge_99&#39;</span>
<span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;pearson&#39;</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pearson&#39;</span><span class="p">,</span> <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;rel_rmse&#39;</span><span class="p">,</span> <span class="s1">&#39;kgeprime&#39;</span><span class="p">]</span>

<span class="n">lons</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span>
<span class="n">lats</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
    
    <span class="n">vals_linear</span> <span class="o">=</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites</span><span class="p">)[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">vals_nn</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">]</span>
    <span class="n">vals_nn_max</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">]</span>
    <span class="n">vals_nn_min</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">]</span>
    
    <span class="n">vals_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">vdiff_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vals_diff</span><span class="p">))</span>
    
    <span class="n">vmin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_nn_max</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_nn_min</span><span class="p">)])</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_nn_max</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_nn_min</span><span class="p">)])</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons</span><span class="p">,</span> <span class="n">lats</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_linear</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Linear model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons</span><span class="p">,</span> <span class="n">lats</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_nn</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model: mean &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons</span><span class="p">,</span> <span class="n">lats</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_nn_max</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model max: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons</span><span class="p">,</span> <span class="n">lats</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_nn_min</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model min: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>
    
    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons</span><span class="p">,</span> <span class="n">lats</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_diff</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="n">vdiff_max</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vdiff_max</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model min: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

<span class="c1">#for v1,v2,v3 in zip(vals_nn, vals_nn_max, vals_nn_min):</span>
<span class="c1">#    print(v1,v2,v3)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/model_CNN-single_site_13_0.png" src="../_images/model_CNN-single_site_13_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#fig, axes = plt.subplots(figure=(16,4))</span>
<span class="c1">#axes.plot(np.concatenate([y.numpy()[:,0] for x, y in dset_val], axis=0))</span>
<span class="c1">#axes.plot(prediction_val[:,0])</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">fig</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dset_val</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">20000</span><span class="p">:</span><span class="mi">40000</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Truth&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prediction_val</span><span class="p">[</span><span class="mi">20000</span><span class="p">:</span><span class="mi">40000</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;CNN model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f055a2e2a90&gt;
</pre></div>
</div>
<img alt="../_images/model_CNN-single_site_14_1.png" src="../_images/model_CNN-single_site_14_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1">#for site_id in [ 224 ]:</span>
<span class="c1">#for site_id in np.unique( # closest Moana v2 Hindcast to tidal gauges</span>
<span class="c1">#                [ 689,328,393,1327,393,480,999,116,224,1124,949,708, # UHSLC</span>
<span class="c1">#                  1296,1124,780,613,488,1442,1217,578,200,1177,1025,689,949,224,1146, # LINZ</span>
<span class="c1">#                  1174,1260,1217,744,1064,1214,803,999 # OTHER (ports...)</span>
<span class="c1">#                ]</span>
<span class="c1">#            ):</span>
<span class="k">for</span> <span class="n">site_id</span> <span class="ow">in</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">site</span><span class="o">.</span><span class="n">values</span><span class="p">:</span> 
    
    <span class="k">if</span> <span class="n">site_id</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">continue</span>
    
    <span class="n">location</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
                    <span class="nb">float</span><span class="p">(</span><span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
    
    
    <span class="n">all_predictors</span> <span class="o">=</span> <span class="n">get_best_predictor_for_site</span><span class="p">(</span><span class="n">location</span><span class="p">)</span>
    
    <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>
    
    
    
    <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        
    <span class="c1">#try:</span>
    <span class="c1">#if True:</span>

        <span class="n">dset_train</span><span class="p">,</span> <span class="n">dset_val</span> <span class="o">=</span> <span class="n">get_training_and_validation_sets</span><span class="p">(</span><span class="n">predictors</span><span class="o">=</span><span class="n">all_predictors</span><span class="p">,</span>
                                                        <span class="n">predictand</span><span class="o">=</span><span class="n">predictand</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">site_id</span><span class="p">),</span>
                                                        <span class="n">input_sequence_length</span><span class="o">=</span><span class="n">input_sequence_length</span><span class="p">,</span>
                                                        <span class="n">input_sequence_frequency</span><span class="o">=</span><span class="n">input_sequence_frequency</span><span class="p">,</span>
                                                        <span class="n">lead_time</span><span class="o">=</span><span class="n">lead_time</span><span class="p">,</span>
                                                        <span class="n">target_sequence_frequency</span><span class="o">=</span><span class="n">target_sequence_frequency</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                                        <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                                        <span class="n">fold</span><span class="o">=</span><span class="n">fold</span><span class="p">,</span>
                                                        <span class="n">print_test</span><span class="o">=</span><span class="kc">True</span>
                                                               <span class="p">)</span>


        <span class="n">shape_in</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_sequence_length</span><span class="o">/</span><span class="n">input_sequence_frequency</span><span class="p">),)</span> <span class="o">+</span> <span class="n">dset_train</span><span class="o">.</span><span class="n">element_spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
        <span class="n">model_cnn</span> <span class="o">=</span> <span class="n">build_model_cnn</span><span class="p">(</span><span class="n">shape_in</span><span class="o">=</span><span class="n">shape_in</span><span class="p">,</span>
                                    <span class="n">nbout</span><span class="o">=</span><span class="n">dset_train</span><span class="o">.</span><span class="n">element_spec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span>
        <span class="n">model_cnn</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
                <span class="n">optimizer</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> 
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse&#39;</span><span class="p">,</span> <span class="s1">&#39;mae&#39;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="n">history</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dset_train</span><span class="p">,</span>
                                <span class="n">validation_data</span><span class="o">=</span><span class="n">dset_val</span><span class="p">,</span>
                                <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

        <span class="n">prediction_val</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dset_val</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculate_stats</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dset_val</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">,</span> <span class="n">prediction_val</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">][</span><span class="s1">&#39;history&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
        <span class="n">results</span><span class="p">[</span><span class="n">site_id</span><span class="p">][</span><span class="n">fold</span><span class="p">][</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction_val</span>
        
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.71 -10.57 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.67 11.77 ... -0.517
    uw2             (time, latitude, longitude) float32 114.7 111.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 136.2 138.5 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.84 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([30785 30809 30833], shape=(3,), dtype=int64) Times out: tf.Tensor(30833, shape=(), dtype=int64)
Times in: tf.Tensor([134754 134778 134802], shape=(3,), dtype=int64) Times out: tf.Tensor(134802, shape=(), dtype=int64)
Times in: tf.Tensor([3008 3032 3056], shape=(3,), dtype=int64) Times out: tf.Tensor(3056, shape=(), dtype=int64)
Times in: tf.Tensor([69862 69886 69910], shape=(3,), dtype=int64) Times out: tf.Tensor(69910, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_534&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_535 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1068 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1069 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_534 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1068 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_534 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1069 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.0882 - mse: 46.0234 - mae: 5.2447 - val_loss: 31.9683 - val_mse: 31.8856 - val_mae: 4.5307
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2334 - mse: 35.1409 - mae: 4.6319 - val_loss: 31.4095 - val_mse: 31.3080 - val_mae: 4.4919
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8979 - mse: 33.7902 - mae: 4.5391 - val_loss: 30.8695 - val_mse: 30.7556 - val_mae: 4.4479
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4319 - mse: 33.3141 - mae: 4.5079 - val_loss: 30.4530 - val_mse: 30.3310 - val_mae: 4.4187
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1981 - mse: 33.0734 - mae: 4.4932 - val_loss: 29.3859 - val_mse: 29.2581 - val_mae: 4.3414
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8876 - mse: 32.7571 - mae: 4.4706 - val_loss: 29.5561 - val_mse: 29.4224 - val_mae: 4.3571
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6463 - mse: 32.5097 - mae: 4.4500 - val_loss: 29.4407 - val_mse: 29.3010 - val_mae: 4.3479
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5116 - mse: 32.3689 - mae: 4.4402 - val_loss: 29.4278 - val_mse: 29.2816 - val_mae: 4.3513
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3485 - mse: 32.1995 - mae: 4.4309 - val_loss: 30.0497 - val_mse: 29.8975 - val_mae: 4.4001
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1111 - mse: 31.9555 - mae: 4.4143 - val_loss: 29.8181 - val_mse: 29.6590 - val_mae: 4.3858
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9928 - mse: 31.8305 - mae: 4.4056 - val_loss: 29.5615 - val_mse: 29.3962 - val_mae: 4.3668
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7642 - mse: 31.5958 - mae: 4.3881 - val_loss: 29.5706 - val_mse: 29.3988 - val_mae: 4.3693
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4296 - mse: 31.2549 - mae: 4.3636 - val_loss: 29.1032 - val_mse: 28.9258 - val_mae: 4.3388
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2754 - mse: 31.0956 - mae: 4.3551 - val_loss: 29.0005 - val_mse: 28.8186 - val_mae: 4.3311
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9329 - mse: 30.7492 - mae: 4.3291 - val_loss: 28.2798 - val_mse: 28.0944 - val_mae: 4.2782
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9028 - mse: 30.7159 - mae: 4.3237 - val_loss: 28.5406 - val_mse: 28.3523 - val_mae: 4.2989
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7438 - mse: 30.5543 - mae: 4.3127 - val_loss: 28.9982 - val_mse: 28.8073 - val_mae: 4.3312
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6261 - mse: 30.4341 - mae: 4.3073 - val_loss: 29.0045 - val_mse: 28.8115 - val_mae: 4.3326
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5718 - mse: 30.3778 - mae: 4.3026 - val_loss: 27.9149 - val_mse: 27.7199 - val_mae: 4.2514
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4410 - mse: 30.2451 - mae: 4.2908 - val_loss: 27.6525 - val_mse: 27.4560 - val_mae: 4.2286
bias -0.00824597
si 0.49794552
rmse 0.052398436
kgeprime [0.60274228]
rmse_95 0.067964435
rmse_99 0.08043599
pearson 0.8443933019092555
pearson_95 0.659365987579752
pearson_99 0.7938357971076202
rscore 0.7055836993836171
rscore_95 -1.1120140245373489
rscore_99 -6.0774543704676764
nse [0.7055837]
nse_95 [-1.11201402]
nse_99 [-6.07745437]
kge [0.69797122]
ext_kge_95 [0.5448864]
ext_kge_99 [0.07689775]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.71 -10.57 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.67 11.77 ... -0.517
    uw2             (time, latitude, longitude) float32 114.7 111.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 136.2 138.5 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.84 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([87161 87185 87209], shape=(3,), dtype=int64) Times out: tf.Tensor(87209, shape=(), dtype=int64)
Times in: tf.Tensor([20545 20569 20593], shape=(3,), dtype=int64) Times out: tf.Tensor(20593, shape=(), dtype=int64)
Times in: tf.Tensor([9479 9503 9527], shape=(3,), dtype=int64) Times out: tf.Tensor(9527, shape=(), dtype=int64)
Times in: tf.Tensor([8879 8903 8927], shape=(3,), dtype=int64) Times out: tf.Tensor(8927, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_535&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_536 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1070 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1071 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_535 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1070 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_535 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1071 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 56.0160 - mse: 55.9651 - mae: 5.7980 - val_loss: 42.9027 - val_mse: 42.8444 - val_mae: 5.1848
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.7642 - mse: 44.7061 - mae: 5.2071 - val_loss: 34.9319 - val_mse: 34.8731 - val_mae: 4.7257
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8195 - mse: 36.7575 - mae: 4.7433 - val_loss: 31.5772 - val_mse: 31.5099 - val_mae: 4.5217
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1147 - mse: 35.0410 - mae: 4.6292 - val_loss: 30.7070 - val_mse: 30.6273 - val_mae: 4.4575
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3463 - mse: 34.2616 - mae: 4.5726 - val_loss: 30.3331 - val_mse: 30.2439 - val_mae: 4.4302
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9342 - mse: 33.8410 - mae: 4.5412 - val_loss: 30.6422 - val_mse: 30.5454 - val_mae: 4.4453
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6884 - mse: 33.5881 - mae: 4.5280 - val_loss: 30.1901 - val_mse: 30.0869 - val_mae: 4.4115
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4442 - mse: 33.3379 - mae: 4.5119 - val_loss: 30.2322 - val_mse: 30.1229 - val_mae: 4.4199
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2426 - mse: 33.1302 - mae: 4.4975 - val_loss: 30.0770 - val_mse: 29.9617 - val_mae: 4.4091
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2187 - mse: 33.1004 - mae: 4.4911 - val_loss: 30.7769 - val_mse: 30.6559 - val_mae: 4.4568
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8640 - mse: 32.7399 - mae: 4.4730 - val_loss: 30.7970 - val_mse: 30.6700 - val_mae: 4.4600
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8715 - mse: 32.7418 - mae: 4.4656 - val_loss: 29.8154 - val_mse: 29.6831 - val_mae: 4.3876
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6237 - mse: 32.4887 - mae: 4.4503 - val_loss: 29.8026 - val_mse: 29.6648 - val_mae: 4.3887
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3865 - mse: 32.2461 - mae: 4.4372 - val_loss: 29.2337 - val_mse: 29.0907 - val_mae: 4.3484
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2607 - mse: 32.1150 - mae: 4.4296 - val_loss: 29.0147 - val_mse: 28.8670 - val_mae: 4.3346
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9438 - mse: 31.7938 - mae: 4.4043 - val_loss: 29.4519 - val_mse: 29.3000 - val_mae: 4.3644
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7010 - mse: 31.5474 - mae: 4.3945 - val_loss: 30.0032 - val_mse: 29.8481 - val_mae: 4.3994
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6443 - mse: 31.4876 - mae: 4.3855 - val_loss: 29.2535 - val_mse: 29.0955 - val_mae: 4.3526
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3859 - mse: 31.2267 - mae: 4.3662 - val_loss: 29.4402 - val_mse: 29.2800 - val_mae: 4.3614
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3725 - mse: 31.2111 - mae: 4.3647 - val_loss: 29.2390 - val_mse: 29.0765 - val_mae: 4.3463
bias -0.012041898
si 0.50193495
rmse 0.053922657
kgeprime [0.51910084]
rmse_95 0.064917065
rmse_99 0.077810116
pearson 0.842282075282352
pearson_95 0.6841475500159623
pearson_99 0.7972601458564251
rscore 0.6929033036166089
rscore_95 -0.8317050473103993
rscore_99 -5.407631860614566
nse [0.6929033]
nse_95 [-0.83170505]
nse_99 [-5.40763186]
kge [0.63014479]
ext_kge_95 [0.568491]
ext_kge_99 [0.06670084]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.71 -10.57 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.67 11.77 ... -0.517
    uw2             (time, latitude, longitude) float32 114.7 111.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 136.2 138.5 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.84 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([85139 85163 85187], shape=(3,), dtype=int64) Times out: tf.Tensor(85187, shape=(), dtype=int64)
Times in: tf.Tensor([29293 29317 29341], shape=(3,), dtype=int64) Times out: tf.Tensor(29341, shape=(), dtype=int64)
Times in: tf.Tensor([151918 151942 151966], shape=(3,), dtype=int64) Times out: tf.Tensor(151966, shape=(), dtype=int64)
Times in: tf.Tensor([73341 73365 73389], shape=(3,), dtype=int64) Times out: tf.Tensor(73389, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_536&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_537 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1072 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1073 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_536 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1072 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_536 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1073 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.3039 - mse: 45.2475 - mae: 5.1906 - val_loss: 31.5937 - val_mse: 31.5233 - val_mae: 4.5098
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9054 - mse: 34.8283 - mae: 4.6079 - val_loss: 30.6582 - val_mse: 30.5745 - val_mae: 4.4402
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0197 - mse: 33.9314 - mae: 4.5487 - val_loss: 30.2487 - val_mse: 30.1562 - val_mae: 4.4087
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7344 - mse: 33.6391 - mae: 4.5286 - val_loss: 29.8623 - val_mse: 29.7634 - val_mae: 4.3825
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3718 - mse: 33.2702 - mae: 4.5025 - val_loss: 29.9125 - val_mse: 29.8078 - val_mae: 4.3861
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1477 - mse: 33.0397 - mae: 4.4924 - val_loss: 29.8560 - val_mse: 29.7443 - val_mae: 4.3829
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9216 - mse: 32.8071 - mae: 4.4711 - val_loss: 29.8599 - val_mse: 29.7419 - val_mae: 4.3878
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7164 - mse: 32.5954 - mae: 4.4564 - val_loss: 29.6453 - val_mse: 29.5208 - val_mae: 4.3729
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5144 - mse: 32.3871 - mae: 4.4436 - val_loss: 29.7819 - val_mse: 29.6512 - val_mae: 4.3828
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3004 - mse: 32.1670 - mae: 4.4325 - val_loss: 29.6358 - val_mse: 29.4991 - val_mae: 4.3710
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1398 - mse: 32.0002 - mae: 4.4258 - val_loss: 29.7971 - val_mse: 29.6545 - val_mae: 4.3850
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1130 - mse: 31.9678 - mae: 4.4166 - val_loss: 29.2803 - val_mse: 29.1323 - val_mae: 4.3474
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9414 - mse: 31.7911 - mae: 4.4080 - val_loss: 29.4867 - val_mse: 29.3339 - val_mae: 4.3617
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7502 - mse: 31.5952 - mae: 4.3904 - val_loss: 29.3984 - val_mse: 29.2412 - val_mae: 4.3549
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7828 - mse: 31.6235 - mae: 4.3926 - val_loss: 29.2027 - val_mse: 29.0413 - val_mae: 4.3389
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6396 - mse: 31.4762 - mae: 4.3840 - val_loss: 29.4889 - val_mse: 29.3236 - val_mae: 4.3629
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4962 - mse: 31.3291 - mae: 4.3749 - val_loss: 29.2502 - val_mse: 29.0811 - val_mae: 4.3478
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3864 - mse: 31.2158 - mae: 4.3689 - val_loss: 29.4289 - val_mse: 29.2564 - val_mae: 4.3572
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3222 - mse: 31.1487 - mae: 4.3600 - val_loss: 29.4007 - val_mse: 29.2259 - val_mae: 4.3564
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3083 - mse: 31.1321 - mae: 4.3623 - val_loss: 28.8742 - val_mse: 28.6965 - val_mae: 4.3197
bias -0.005746391
si 0.50822264
rmse 0.05356907
kgeprime [0.64852602]
rmse_95 0.074660905
rmse_99 0.091131516
pearson 0.8370330659375664
pearson_95 0.6427876975795682
pearson_99 0.785314825315894
rscore 0.697126371053876
rscore_95 -1.4110880574896445
rscore_99 -7.752264946338974
nse [0.69712637]
nse_95 [-1.41108806]
nse_99 [-7.75226495]
kge [0.72395793]
ext_kge_95 [0.53036939]
ext_kge_99 [0.06311665]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.57 -10.43 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.77 11.9 ... -0.517
    uw2             (time, latitude, longitude) float32 111.7 108.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 138.5 141.6 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.82 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([51217 51241 51265], shape=(3,), dtype=int64) Times out: tf.Tensor(51265, shape=(), dtype=int64)
Times in: tf.Tensor([153478 153502 153526], shape=(3,), dtype=int64) Times out: tf.Tensor(153526, shape=(), dtype=int64)
Times in: tf.Tensor([123388 123412 123436], shape=(3,), dtype=int64) Times out: tf.Tensor(123436, shape=(), dtype=int64)
Times in: tf.Tensor([135026 135050 135074], shape=(3,), dtype=int64) Times out: tf.Tensor(135074, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_537&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_538 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1074 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1075 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_537 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1074 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_537 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1075 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.6250 - mse: 44.5494 - mae: 5.1318 - val_loss: 31.1768 - val_mse: 31.0834 - val_mae: 4.4801
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4523 - mse: 33.3512 - mae: 4.5057 - val_loss: 30.3165 - val_mse: 30.2094 - val_mae: 4.4177
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7485 - mse: 32.6370 - mae: 4.4587 - val_loss: 29.8043 - val_mse: 29.6893 - val_mae: 4.3772
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4447 - mse: 32.3273 - mae: 4.4347 - val_loss: 29.7169 - val_mse: 29.5971 - val_mae: 4.3708
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1747 - mse: 32.0522 - mae: 4.4180 - val_loss: 29.4537 - val_mse: 29.3291 - val_mae: 4.3524
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9369 - mse: 31.8092 - mae: 4.3990 - val_loss: 29.7861 - val_mse: 29.6561 - val_mae: 4.3763
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7073 - mse: 31.5740 - mae: 4.3853 - val_loss: 29.2426 - val_mse: 29.1066 - val_mae: 4.3399
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4272 - mse: 31.2876 - mae: 4.3700 - val_loss: 29.7317 - val_mse: 29.5889 - val_mae: 4.3752
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4098 - mse: 31.2635 - mae: 4.3620 - val_loss: 29.3469 - val_mse: 29.1972 - val_mae: 4.3529
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0909 - mse: 30.9375 - mae: 4.3387 - val_loss: 28.8780 - val_mse: 28.7215 - val_mae: 4.3219
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6217 - mse: 30.4612 - mae: 4.3133 - val_loss: 28.6819 - val_mse: 28.5181 - val_mae: 4.3081
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4817 - mse: 30.3145 - mae: 4.2988 - val_loss: 28.5359 - val_mse: 28.3663 - val_mae: 4.2952
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.1522 - mse: 29.9798 - mae: 4.2747 - val_loss: 28.7025 - val_mse: 28.5278 - val_mae: 4.3088
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0571 - mse: 29.8799 - mae: 4.2673 - val_loss: 28.2520 - val_mse: 28.0730 - val_mae: 4.2755
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.7132 - mse: 29.5323 - mae: 4.2459 - val_loss: 27.8981 - val_mse: 27.7158 - val_mae: 4.2490
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.6777 - mse: 29.4934 - mae: 4.2379 - val_loss: 28.4950 - val_mse: 28.3093 - val_mae: 4.2892
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.4538 - mse: 29.2665 - mae: 4.2255 - val_loss: 28.0571 - val_mse: 27.8688 - val_mae: 4.2592
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.3812 - mse: 29.1913 - mae: 4.2200 - val_loss: 28.3088 - val_mse: 28.1177 - val_mae: 4.2761
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.2034 - mse: 29.0109 - mae: 4.2113 - val_loss: 27.6046 - val_mse: 27.4109 - val_mae: 4.2246
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.2416 - mse: 29.0464 - mae: 4.2032 - val_loss: 27.6631 - val_mse: 27.4669 - val_mae: 4.2271
bias -0.009026913
si 0.49186715
rmse 0.052408863
kgeprime [0.58457507]
rmse_95 0.06973073
rmse_99 0.08360925
pearson 0.8481854981515377
pearson_95 0.6832984995386989
pearson_99 0.7914572226569384
rscore 0.7108351263465496
rscore_95 -1.1930804891066344
rscore_99 -6.300459931263067
nse [0.71083513]
nse_95 [-1.19308049]
nse_99 [-6.30045993]
kge [0.68516906]
ext_kge_95 [0.55757036]
ext_kge_99 [0.10505916]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.71 -10.57 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.67 11.77 ... -0.517
    uw2             (time, latitude, longitude) float32 114.7 111.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 136.2 138.5 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.84 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([64943 64967 64991], shape=(3,), dtype=int64) Times out: tf.Tensor(64991, shape=(), dtype=int64)
Times in: tf.Tensor([59769 59793 59817], shape=(3,), dtype=int64) Times out: tf.Tensor(59817, shape=(), dtype=int64)
Times in: tf.Tensor([131410 131434 131458], shape=(3,), dtype=int64) Times out: tf.Tensor(131458, shape=(), dtype=int64)
Times in: tf.Tensor([4064 4088 4112], shape=(3,), dtype=int64) Times out: tf.Tensor(4112, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_538&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_539 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1076 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1077 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_538 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1076 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_538 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1077 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.2864 - mse: 46.2343 - mae: 5.2546 - val_loss: 33.6648 - val_mse: 33.6019 - val_mae: 4.6601
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8508 - mse: 34.7809 - mae: 4.6135 - val_loss: 30.7167 - val_mse: 30.6402 - val_mae: 4.4564
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7346 - mse: 33.6532 - mae: 4.5338 - val_loss: 30.8609 - val_mse: 30.7741 - val_mae: 4.4600
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4657 - mse: 33.3748 - mae: 4.5165 - val_loss: 30.1008 - val_mse: 30.0059 - val_mae: 4.4087
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1110 - mse: 33.0128 - mae: 4.4941 - val_loss: 29.8637 - val_mse: 29.7617 - val_mae: 4.3906
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8805 - mse: 32.7752 - mae: 4.4716 - val_loss: 29.7483 - val_mse: 29.6393 - val_mae: 4.3813
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6413 - mse: 32.5295 - mae: 4.4598 - val_loss: 29.4266 - val_mse: 29.3114 - val_mae: 4.3565
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4437 - mse: 32.3259 - mae: 4.4447 - val_loss: 29.9244 - val_mse: 29.8032 - val_mae: 4.3927
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2147 - mse: 32.0906 - mae: 4.4248 - val_loss: 29.5602 - val_mse: 29.4327 - val_mae: 4.3683
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9109 - mse: 31.7803 - mae: 4.4078 - val_loss: 29.4513 - val_mse: 29.3175 - val_mae: 4.3592
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4310 - mse: 31.2944 - mae: 4.3749 - val_loss: 28.9697 - val_mse: 28.8301 - val_mae: 4.3270
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.2473 - mse: 31.1056 - mae: 4.3588 - val_loss: 28.6789 - val_mse: 28.5349 - val_mae: 4.3055
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.9382 - mse: 30.7922 - mae: 4.3404 - val_loss: 28.5848 - val_mse: 28.4367 - val_mae: 4.3029
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8043 - mse: 30.6549 - mae: 4.3274 - val_loss: 28.6590 - val_mse: 28.5081 - val_mae: 4.3050
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6830 - mse: 30.5309 - mae: 4.3229 - val_loss: 28.4276 - val_mse: 28.2738 - val_mae: 4.2886
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4466 - mse: 30.2917 - mae: 4.3007 - val_loss: 28.0749 - val_mse: 27.9187 - val_mae: 4.2613
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3830 - mse: 30.2258 - mae: 4.2973 - val_loss: 28.6289 - val_mse: 28.4707 - val_mae: 4.2997
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2021 - mse: 30.0432 - mae: 4.2849 - val_loss: 28.4039 - val_mse: 28.2442 - val_mae: 4.2845
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.0876 - mse: 29.9270 - mae: 4.2771 - val_loss: 28.4655 - val_mse: 28.3039 - val_mae: 4.2879
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1183 - mse: 29.9560 - mae: 4.2749 - val_loss: 27.8781 - val_mse: 27.7149 - val_mae: 4.2458
bias -0.008858345
si 0.49283597
rmse 0.052644897
kgeprime [0.59141847]
rmse_95 0.067405686
rmse_99 0.08180876
pearson 0.8478834371828953
pearson_95 0.6598297296830907
pearson_99 0.7995830594515735
rscore 0.710648947192976
rscore_95 -0.9898234613224504
rscore_99 -5.740923190246585
nse [0.71064895]
nse_95 [-0.98982346]
nse_99 [-5.74092319]
kge [0.69034348]
ext_kge_95 [0.55307417]
ext_kge_99 [0.13027157]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.57 -10.43 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.77 11.9 ... -0.517
    uw2             (time, latitude, longitude) float32 111.7 108.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 138.5 141.6 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.82 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([54641 54665 54689], shape=(3,), dtype=int64) Times out: tf.Tensor(54689, shape=(), dtype=int64)
Times in: tf.Tensor([69768 69792 69816], shape=(3,), dtype=int64) Times out: tf.Tensor(69816, shape=(), dtype=int64)
Times in: tf.Tensor([150220 150244 150268], shape=(3,), dtype=int64) Times out: tf.Tensor(150268, shape=(), dtype=int64)
Times in: tf.Tensor([104394 104418 104442], shape=(3,), dtype=int64) Times out: tf.Tensor(104442, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_539&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_540 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1078 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1079 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_539 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1078 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_539 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1079 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.9330 - mse: 45.8793 - mae: 5.2195 - val_loss: 31.7264 - val_mse: 31.6620 - val_mae: 4.5261
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6631 - mse: 34.5929 - mae: 4.5892 - val_loss: 30.4551 - val_mse: 30.3793 - val_mae: 4.4303
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6280 - mse: 33.5491 - mae: 4.5183 - val_loss: 30.0297 - val_mse: 29.9475 - val_mae: 4.3949
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3268 - mse: 33.2426 - mae: 4.4983 - val_loss: 29.9826 - val_mse: 29.8962 - val_mae: 4.3932
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1441 - mse: 33.0564 - mae: 4.4849 - val_loss: 29.6020 - val_mse: 29.5127 - val_mae: 4.3656
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9413 - mse: 32.8508 - mae: 4.4771 - val_loss: 29.4004 - val_mse: 29.3083 - val_mae: 4.3516
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8845 - mse: 32.7916 - mae: 4.4685 - val_loss: 29.5893 - val_mse: 29.4949 - val_mae: 4.3665
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7068 - mse: 32.6114 - mae: 4.4524 - val_loss: 30.1063 - val_mse: 30.0092 - val_mae: 4.4024
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6099 - mse: 32.5119 - mae: 4.4478 - val_loss: 29.2189 - val_mse: 29.1193 - val_mae: 4.3453
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4640 - mse: 32.3631 - mae: 4.4410 - val_loss: 29.1519 - val_mse: 29.0490 - val_mae: 4.3398
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3251 - mse: 32.2210 - mae: 4.4272 - val_loss: 29.3949 - val_mse: 29.2889 - val_mae: 4.3571
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.0636 - mse: 31.9562 - mae: 4.4096 - val_loss: 29.3604 - val_mse: 29.2511 - val_mae: 4.3549
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8260 - mse: 31.7152 - mae: 4.3872 - val_loss: 28.8764 - val_mse: 28.7633 - val_mae: 4.3207
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6095 - mse: 31.4947 - mae: 4.3740 - val_loss: 28.7367 - val_mse: 28.6200 - val_mae: 4.3111
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2606 - mse: 31.1428 - mae: 4.3519 - val_loss: 28.2976 - val_mse: 28.1781 - val_mae: 4.2830
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0451 - mse: 30.9245 - mae: 4.3344 - val_loss: 28.1836 - val_mse: 28.0612 - val_mae: 4.2727
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8036 - mse: 30.6804 - mae: 4.3198 - val_loss: 27.7212 - val_mse: 27.5963 - val_mae: 4.2394
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6754 - mse: 30.5499 - mae: 4.3073 - val_loss: 28.0724 - val_mse: 27.9455 - val_mae: 4.2638
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4543 - mse: 30.3267 - mae: 4.2929 - val_loss: 27.2028 - val_mse: 27.0739 - val_mae: 4.2031
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4251 - mse: 30.2957 - mae: 4.2900 - val_loss: 27.7869 - val_mse: 27.6563 - val_mae: 4.2427
bias -0.009924459
si 0.4944709
rmse 0.052589227
kgeprime [0.55947119]
rmse_95 0.06790645
rmse_99 0.08004292
pearson 0.8463986545799891
pearson_95 0.6462976109022851
pearson_99 0.781699650489804
rscore 0.7059106446202625
rscore_95 -1.0528817280346239
rscore_99 -6.069459128046585
nse [0.70591064]
nse_95 [-1.05288173]
nse_99 [-6.06945913]
kge [0.66550159]
ext_kge_95 [0.52322852]
ext_kge_99 [0.10219984]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.57 -10.43 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.77 11.9 ... -0.517
    uw2             (time, latitude, longitude) float32 111.7 108.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 138.5 141.6 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.82 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([93058 93082 93106], shape=(3,), dtype=int64) Times out: tf.Tensor(93106, shape=(), dtype=int64)
Times in: tf.Tensor([80036 80060 80084], shape=(3,), dtype=int64) Times out: tf.Tensor(80084, shape=(), dtype=int64)
Times in: tf.Tensor([118938 118962 118986], shape=(3,), dtype=int64) Times out: tf.Tensor(118986, shape=(), dtype=int64)
Times in: tf.Tensor([15190 15214 15238], shape=(3,), dtype=int64) Times out: tf.Tensor(15238, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_540&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_541 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1080 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1081 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_540 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1080 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_540 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1081 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.4683 - mse: 53.4208 - mae: 5.6207 - val_loss: 32.5827 - val_mse: 32.5200 - val_mae: 4.5672
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5251 - mse: 36.4565 - mae: 4.6923 - val_loss: 31.4376 - val_mse: 31.3633 - val_mae: 4.5013
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0938 - mse: 35.0146 - mae: 4.5989 - val_loss: 30.1385 - val_mse: 30.0549 - val_mae: 4.4117
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7950 - mse: 34.7082 - mae: 4.5815 - val_loss: 30.0158 - val_mse: 29.9264 - val_mae: 4.3965
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4421 - mse: 34.3500 - mae: 4.5529 - val_loss: 30.2924 - val_mse: 30.1980 - val_mae: 4.4183
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2035 - mse: 34.1064 - mae: 4.5460 - val_loss: 30.5730 - val_mse: 30.4738 - val_mae: 4.4379
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1403 - mse: 34.0385 - mae: 4.5321 - val_loss: 29.7691 - val_mse: 29.6651 - val_mae: 4.3830
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7755 - mse: 33.6692 - mae: 4.5155 - val_loss: 29.7022 - val_mse: 29.5939 - val_mae: 4.3782
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6741 - mse: 33.5636 - mae: 4.5067 - val_loss: 29.1624 - val_mse: 29.0502 - val_mae: 4.3413
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4679 - mse: 33.3535 - mae: 4.4933 - val_loss: 29.3801 - val_mse: 29.2640 - val_mae: 4.3565
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2623 - mse: 33.1444 - mae: 4.4799 - val_loss: 29.4866 - val_mse: 29.3669 - val_mae: 4.3671
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3264 - mse: 33.2045 - mae: 4.4853 - val_loss: 29.3788 - val_mse: 29.2554 - val_mae: 4.3579
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1364 - mse: 33.0110 - mae: 4.4687 - val_loss: 29.0590 - val_mse: 28.9325 - val_mae: 4.3362
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9963 - mse: 32.8679 - mae: 4.4618 - val_loss: 29.0706 - val_mse: 28.9411 - val_mae: 4.3361
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8358 - mse: 32.7044 - mae: 4.4544 - val_loss: 29.3525 - val_mse: 29.2199 - val_mae: 4.3569
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6618 - mse: 32.5273 - mae: 4.4375 - val_loss: 29.1123 - val_mse: 28.9769 - val_mae: 4.3372
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7561 - mse: 32.6190 - mae: 4.4415 - val_loss: 29.5081 - val_mse: 29.3699 - val_mae: 4.3647
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5424 - mse: 32.4028 - mae: 4.4275 - val_loss: 29.4077 - val_mse: 29.2670 - val_mae: 4.3573
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3453 - mse: 32.2033 - mae: 4.4159 - val_loss: 29.0653 - val_mse: 28.9220 - val_mae: 4.3342
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1955 - mse: 32.0510 - mae: 4.4107 - val_loss: 28.6857 - val_mse: 28.5399 - val_mae: 4.3088
bias -0.0066215964
si 0.5049863
rmse 0.05342274
kgeprime [0.63222615]
rmse_95 0.07675354
rmse_99 0.08870217
pearson 0.8389470754316456
pearson_95 0.6586776830118052
pearson_99 0.7994877155653928
rscore 0.6992076740085789
rscore_95 -1.7280358268307205
rscore_99 -7.334964054574881
nse [0.69920767]
nse_95 [-1.72803583]
nse_99 [-7.33496405]
kge [0.71520072]
ext_kge_95 [0.50165444]
ext_kge_99 [0.11043019]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.71 -10.57 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.67 11.77 ... -0.517
    uw2             (time, latitude, longitude) float32 114.7 111.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 136.2 138.5 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.84 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([79043 79067 79091], shape=(3,), dtype=int64) Times out: tf.Tensor(79091, shape=(), dtype=int64)
Times in: tf.Tensor([136551 136575 136599], shape=(3,), dtype=int64) Times out: tf.Tensor(136599, shape=(), dtype=int64)
Times in: tf.Tensor([95943 95967 95991], shape=(3,), dtype=int64) Times out: tf.Tensor(95991, shape=(), dtype=int64)
Times in: tf.Tensor([139986 140010 140034], shape=(3,), dtype=int64) Times out: tf.Tensor(140034, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_541&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_542 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1082 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1083 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_541 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1082 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_541 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1083 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 9s 2ms/step - loss: 42.6759 - mse: 42.6167 - mae: 5.0413 - val_loss: 31.0722 - val_mse: 31.0002 - val_mae: 4.4860
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5136 - mse: 33.4348 - mae: 4.5217 - val_loss: 30.1211 - val_mse: 30.0364 - val_mae: 4.4148
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6472 - mse: 32.5575 - mae: 4.4598 - val_loss: 30.6236 - val_mse: 30.5295 - val_mae: 4.4473
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2222 - mse: 32.1244 - mae: 4.4322 - val_loss: 29.9792 - val_mse: 29.8779 - val_mae: 4.3990
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0622 - mse: 31.9580 - mae: 4.4141 - val_loss: 30.1359 - val_mse: 30.0286 - val_mae: 4.4101
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9121 - mse: 31.8022 - mae: 4.4065 - val_loss: 30.5401 - val_mse: 30.4273 - val_mae: 4.4346
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6949 - mse: 31.5798 - mae: 4.3909 - val_loss: 29.8330 - val_mse: 29.7152 - val_mae: 4.3866
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4566 - mse: 31.3365 - mae: 4.3733 - val_loss: 29.8251 - val_mse: 29.7026 - val_mae: 4.3859
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2737 - mse: 31.1488 - mae: 4.3607 - val_loss: 29.4842 - val_mse: 29.3566 - val_mae: 4.3621
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0963 - mse: 30.9662 - mae: 4.3487 - val_loss: 30.1170 - val_mse: 29.9842 - val_mae: 4.4029
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.7104 - mse: 30.5752 - mae: 4.3205 - val_loss: 29.1392 - val_mse: 29.0014 - val_mae: 4.3389
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4300 - mse: 30.2897 - mae: 4.2954 - val_loss: 28.7887 - val_mse: 28.6460 - val_mae: 4.3138
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0419 - mse: 29.8968 - mae: 4.2709 - val_loss: 28.5014 - val_mse: 28.3545 - val_mae: 4.2933
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7904 - mse: 29.6417 - mae: 4.2486 - val_loss: 28.7563 - val_mse: 28.6061 - val_mae: 4.3113
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6266 - mse: 29.4752 - mae: 4.2364 - val_loss: 27.3644 - val_mse: 27.2118 - val_mae: 4.2129
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3301 - mse: 29.1764 - mae: 4.2142 - val_loss: 27.3690 - val_mse: 27.2145 - val_mae: 4.2149
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3162 - mse: 29.1607 - mae: 4.2140 - val_loss: 28.0428 - val_mse: 27.8864 - val_mae: 4.2556
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2348 - mse: 29.0775 - mae: 4.2062 - val_loss: 26.5432 - val_mse: 26.3850 - val_mae: 4.1562
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0969 - mse: 28.9379 - mae: 4.1958 - val_loss: 26.9191 - val_mse: 26.7593 - val_mae: 4.1753
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1812 - mse: 29.0204 - mae: 4.2014 - val_loss: 28.1457 - val_mse: 27.9838 - val_mae: 4.2628
bias -0.014524722
si 0.48572633
rmse 0.052899666
kgeprime [0.45652416]
rmse_95 0.061316885
rmse_99 0.072028674
pearson 0.8527976284079616
pearson_95 0.671000271141315
pearson_99 0.7929793844227602
rscore 0.704519672478725
rscore_95 -0.7778392038856075
rscore_99 -4.686348128126712
nse [0.70451967]
nse_95 [-0.7778392]
nse_99 [-4.68634813]
kge [0.57758556]
ext_kge_95 [0.53567143]
ext_kge_99 [0.0037527]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.74 -50.42 -50.11 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.57 -10.43 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.77 11.9 ... -0.517
    uw2             (time, latitude, longitude) float32 111.7 108.7 ... 0.3278
    vw2             (time, latitude, longitude) float32 138.5 141.6 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.82 15.82 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([15861 15885 15909], shape=(3,), dtype=int64) Times out: tf.Tensor(15909, shape=(), dtype=int64)
Times in: tf.Tensor([27651 27675 27699], shape=(3,), dtype=int64) Times out: tf.Tensor(27699, shape=(), dtype=int64)
Times in: tf.Tensor([17320 17344 17368], shape=(3,), dtype=int64) Times out: tf.Tensor(17368, shape=(), dtype=int64)
Times in: tf.Tensor([69669 69693 69717], shape=(3,), dtype=int64) Times out: tf.Tensor(69717, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_542&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_543 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1084 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1085 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_542 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1084 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_542 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1085 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.4198 - mse: 52.3778 - mae: 5.5257 - val_loss: 31.6719 - val_mse: 31.6198 - val_mae: 4.4906
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5482 - mse: 36.4930 - mae: 4.6773 - val_loss: 29.9446 - val_mse: 29.8875 - val_mae: 4.3804
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4778 - mse: 35.4188 - mae: 4.6139 - val_loss: 29.3906 - val_mse: 29.3293 - val_mae: 4.3437
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0360 - mse: 34.9726 - mae: 4.5903 - val_loss: 29.3133 - val_mse: 29.2473 - val_mae: 4.3376
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6577 - mse: 34.5892 - mae: 4.5669 - val_loss: 28.9473 - val_mse: 28.8763 - val_mae: 4.3160
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2430 - mse: 34.1691 - mae: 4.5382 - val_loss: 29.0265 - val_mse: 28.9498 - val_mae: 4.3195
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1740 - mse: 34.0948 - mae: 4.5367 - val_loss: 29.1153 - val_mse: 29.0334 - val_mae: 4.3272
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9444 - mse: 33.8597 - mae: 4.5165 - val_loss: 28.6943 - val_mse: 28.6069 - val_mae: 4.2980
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6116 - mse: 33.5216 - mae: 4.4995 - val_loss: 28.5580 - val_mse: 28.4655 - val_mae: 4.2884
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2842 - mse: 33.1895 - mae: 4.4757 - val_loss: 28.9127 - val_mse: 28.8157 - val_mae: 4.3114
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.2434 - mse: 33.1440 - mae: 4.4696 - val_loss: 28.8185 - val_mse: 28.7167 - val_mae: 4.3066
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9341 - mse: 32.8302 - mae: 4.4595 - val_loss: 28.6208 - val_mse: 28.5146 - val_mae: 4.2902
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9542 - mse: 32.8460 - mae: 4.4583 - val_loss: 28.7880 - val_mse: 28.6777 - val_mae: 4.3044
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7918 - mse: 32.6797 - mae: 4.4475 - val_loss: 29.4524 - val_mse: 29.3383 - val_mae: 4.3502
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6328 - mse: 32.5171 - mae: 4.4342 - val_loss: 28.2452 - val_mse: 28.1275 - val_mae: 4.2678
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.4544 - mse: 32.3351 - mae: 4.4228 - val_loss: 28.7524 - val_mse: 28.6313 - val_mae: 4.3050
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.5035 - mse: 32.3810 - mae: 4.4218 - val_loss: 28.7426 - val_mse: 28.6189 - val_mae: 4.3015
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.1584 - mse: 32.0329 - mae: 4.3998 - val_loss: 28.1295 - val_mse: 28.0027 - val_mae: 4.2608
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.0432 - mse: 31.9150 - mae: 4.3927 - val_loss: 28.6013 - val_mse: 28.4716 - val_mae: 4.2934
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.9091 - mse: 31.7784 - mae: 4.3892 - val_loss: 28.7343 - val_mse: 28.6023 - val_mae: 4.3039
bias -0.010524594
si 0.5010009
rmse 0.053481147
kgeprime [0.52920069]
rmse_95 0.07590543
rmse_99 0.08950765
pearson 0.8418736134741784
pearson_95 0.6622397560726471
pearson_99 0.791610746886073
rscore 0.6966183930777385
rscore_95 -1.6780973253302829
rscore_99 -7.540000034644107
nse [0.69661839]
nse_95 [-1.67809733]
nse_99 [-7.54000003]
kge [0.64060001]
ext_kge_95 [0.51402328]
ext_kge_99 [0.1277725]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([86114 86138 86162], shape=(3,), dtype=int64) Times out: tf.Tensor(86162, shape=(), dtype=int64)
Times in: tf.Tensor([2456 2480 2504], shape=(3,), dtype=int64) Times out: tf.Tensor(2504, shape=(), dtype=int64)
Times in: tf.Tensor([120377 120401 120425], shape=(3,), dtype=int64) Times out: tf.Tensor(120425, shape=(), dtype=int64)
Times in: tf.Tensor([69600 69624 69648], shape=(3,), dtype=int64) Times out: tf.Tensor(69648, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_543&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_544 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1086 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1087 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_543 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1086 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_543 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1087 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.2270 - mse: 43.1802 - mae: 5.0679 - val_loss: 30.8087 - val_mse: 30.7548 - val_mae: 4.4544
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0778 - mse: 34.0215 - mae: 4.5481 - val_loss: 29.5451 - val_mse: 29.4869 - val_mae: 4.3707
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4055 - mse: 33.3457 - mae: 4.5054 - val_loss: 30.0265 - val_mse: 29.9651 - val_mae: 4.4057
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3132 - mse: 33.2505 - mae: 4.4962 - val_loss: 29.0742 - val_mse: 29.0101 - val_mae: 4.3359
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1226 - mse: 33.0573 - mae: 4.4840 - val_loss: 29.2605 - val_mse: 29.1937 - val_mae: 4.3472
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8715 - mse: 32.8032 - mae: 4.4641 - val_loss: 28.9474 - val_mse: 28.8779 - val_mae: 4.3245
Epoch 7/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.8776 - mse: 32.8066 - mae: 4.4663 - val_loss: 29.1707 - val_mse: 29.0979 - val_mae: 4.3438
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.6692 - mse: 32.5952 - mae: 4.4509 - val_loss: 28.4930 - val_mse: 28.4173 - val_mae: 4.2942
Epoch 9/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.6177 - mse: 32.5404 - mae: 4.4502 - val_loss: 28.5989 - val_mse: 28.5200 - val_mae: 4.3023
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.4087 - mse: 32.3282 - mae: 4.4356 - val_loss: 28.4931 - val_mse: 28.4112 - val_mae: 4.2939
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.2587 - mse: 32.1750 - mae: 4.4225 - val_loss: 28.8838 - val_mse: 28.7986 - val_mae: 4.3224
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.1437 - mse: 32.0568 - mae: 4.4138 - val_loss: 28.5986 - val_mse: 28.5100 - val_mae: 4.3032
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.0187 - mse: 31.9283 - mae: 4.4036 - val_loss: 28.6895 - val_mse: 28.5972 - val_mae: 4.3104
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.8212 - mse: 31.7275 - mae: 4.3916 - val_loss: 28.5327 - val_mse: 28.4372 - val_mae: 4.2983
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.7112 - mse: 31.6138 - mae: 4.3844 - val_loss: 28.3015 - val_mse: 28.2023 - val_mae: 4.2820
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.3333 - mse: 31.2321 - mae: 4.3567 - val_loss: 27.5728 - val_mse: 27.4700 - val_mae: 4.2265
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.1309 - mse: 31.0266 - mae: 4.3404 - val_loss: 27.7189 - val_mse: 27.6132 - val_mae: 4.2385
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.9028 - mse: 30.7957 - mae: 4.3253 - val_loss: 27.8283 - val_mse: 27.7200 - val_mae: 4.2466
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.8806 - mse: 30.7710 - mae: 4.3174 - val_loss: 27.7033 - val_mse: 27.5927 - val_mae: 4.2361
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.5570 - mse: 30.4454 - mae: 4.2997 - val_loss: 27.1592 - val_mse: 27.0466 - val_mae: 4.1953
bias -0.009217071
si 0.49166206
rmse 0.052006327
kgeprime [0.55727132]
rmse_95 0.07000334
rmse_99 0.08145931
pearson 0.8491488118492875
pearson_95 0.6538694922173439
pearson_99 0.7842437851653887
rscore 0.7109949288704267
rscore_95 -1.4494527759542923
rscore_99 -6.770672006090651
nse [0.71099493]
nse_95 [-1.44945278]
nse_99 [-6.77067201]
kge [0.66326]
ext_kge_95 [0.50238803]
ext_kge_99 [0.07735174]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... -0.517
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 0.3278
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([144228 144252 144276], shape=(3,), dtype=int64) Times out: tf.Tensor(144276, shape=(), dtype=int64)
Times in: tf.Tensor([42171 42195 42219], shape=(3,), dtype=int64) Times out: tf.Tensor(42219, shape=(), dtype=int64)
Times in: tf.Tensor([61665 61689 61713], shape=(3,), dtype=int64) Times out: tf.Tensor(61713, shape=(), dtype=int64)
Times in: tf.Tensor([68166 68190 68214], shape=(3,), dtype=int64) Times out: tf.Tensor(68214, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_544&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_545 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1088 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1089 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_544 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1088 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_544 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1089 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.0079 - mse: 41.9422 - mae: 4.9854 - val_loss: 30.1539 - val_mse: 30.0745 - val_mae: 4.4135
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2426 - mse: 32.1572 - mae: 4.4307 - val_loss: 29.2870 - val_mse: 29.1965 - val_mae: 4.3527
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6752 - mse: 31.5798 - mae: 4.3851 - val_loss: 29.0686 - val_mse: 28.9691 - val_mae: 4.3358
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4030 - mse: 31.2987 - mae: 4.3667 - val_loss: 28.7965 - val_mse: 28.6883 - val_mae: 4.3149
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2244 - mse: 31.1122 - mae: 4.3564 - val_loss: 28.6423 - val_mse: 28.5261 - val_mae: 4.3020
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9596 - mse: 30.8396 - mae: 4.3349 - val_loss: 28.4879 - val_mse: 28.3640 - val_mae: 4.2927
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6822 - mse: 30.5545 - mae: 4.3169 - val_loss: 28.6164 - val_mse: 28.4850 - val_mae: 4.3010
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5855 - mse: 30.4506 - mae: 4.3132 - val_loss: 28.1509 - val_mse: 28.0126 - val_mae: 4.2685
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4004 - mse: 30.2583 - mae: 4.2974 - val_loss: 28.0981 - val_mse: 27.9524 - val_mae: 4.2702
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1679 - mse: 30.0186 - mae: 4.2839 - val_loss: 28.2204 - val_mse: 28.0674 - val_mae: 4.2756
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0439 - mse: 29.8874 - mae: 4.2715 - val_loss: 28.0920 - val_mse: 27.9320 - val_mae: 4.2694
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8573 - mse: 29.6946 - mae: 4.2586 - val_loss: 27.8876 - val_mse: 27.7218 - val_mae: 4.2506
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6342 - mse: 29.4653 - mae: 4.2429 - val_loss: 28.5252 - val_mse: 28.3535 - val_mae: 4.2979
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3679 - mse: 29.1941 - mae: 4.2221 - val_loss: 27.9181 - val_mse: 27.7419 - val_mae: 4.2495
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1336 - mse: 28.9554 - mae: 4.2111 - val_loss: 27.1896 - val_mse: 27.0097 - val_mae: 4.2035
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8881 - mse: 28.7069 - mae: 4.1874 - val_loss: 27.9154 - val_mse: 27.7330 - val_mae: 4.2471
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6194 - mse: 28.4365 - mae: 4.1670 - val_loss: 27.1346 - val_mse: 26.9507 - val_mae: 4.1966
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4465 - mse: 28.2620 - mae: 4.1576 - val_loss: 27.0018 - val_mse: 26.8166 - val_mae: 4.1813
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3913 - mse: 28.2058 - mae: 4.1481 - val_loss: 27.3142 - val_mse: 27.1280 - val_mae: 4.2017
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.1790 - mse: 27.9925 - mae: 4.1298 - val_loss: 26.7703 - val_mse: 26.5835 - val_mae: 4.1614
bias -0.007914674
si 0.48863938
rmse 0.05155916
kgeprime [0.62332236]
rmse_95 0.06977171
rmse_99 0.0808426
pearson 0.8502472169083035
pearson_95 0.6693136448902466
pearson_99 0.7637864894203107
rscore 0.715937520574849
rscore_95 -1.3170215253583475
rscore_99 -6.255915841647444
nse [0.71593752]
nse_95 [-1.31702153]
nse_99 [-6.25591584]
kge [0.71459907]
ext_kge_95 [0.51139015]
ext_kge_99 [0.08600616]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... -0.517
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 0.3278
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([24031 24055 24079], shape=(3,), dtype=int64) Times out: tf.Tensor(24079, shape=(), dtype=int64)
Times in: tf.Tensor([83876 83900 83924], shape=(3,), dtype=int64) Times out: tf.Tensor(83924, shape=(), dtype=int64)
Times in: tf.Tensor([89757 89781 89805], shape=(3,), dtype=int64) Times out: tf.Tensor(89805, shape=(), dtype=int64)
Times in: tf.Tensor([34377 34401 34425], shape=(3,), dtype=int64) Times out: tf.Tensor(34425, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_545&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_546 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1090 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1091 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_545 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1090 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_545 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1091 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.3064 - mse: 43.2413 - mae: 5.0696 - val_loss: 31.2576 - val_mse: 31.1751 - val_mae: 4.4794
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8804 - mse: 32.7872 - mae: 4.4733 - val_loss: 30.2907 - val_mse: 30.1895 - val_mae: 4.4190
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0961 - mse: 31.9876 - mae: 4.4176 - val_loss: 29.5621 - val_mse: 29.4482 - val_mae: 4.3643
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7994 - mse: 31.6797 - mae: 4.3954 - val_loss: 29.3506 - val_mse: 29.2267 - val_mae: 4.3513
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3948 - mse: 31.2660 - mae: 4.3680 - val_loss: 29.2335 - val_mse: 29.1013 - val_mae: 4.3441
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2135 - mse: 31.0769 - mae: 4.3573 - val_loss: 29.5135 - val_mse: 29.3739 - val_mae: 4.3632
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0421 - mse: 30.8983 - mae: 4.3444 - val_loss: 28.5856 - val_mse: 28.4392 - val_mae: 4.2962
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8328 - mse: 30.6823 - mae: 4.3273 - val_loss: 28.7803 - val_mse: 28.6271 - val_mae: 4.3120
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5968 - mse: 30.4399 - mae: 4.3142 - val_loss: 28.8116 - val_mse: 28.6523 - val_mae: 4.3117
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3808 - mse: 30.2177 - mae: 4.2992 - val_loss: 28.8790 - val_mse: 28.7133 - val_mae: 4.3183
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2492 - mse: 30.0805 - mae: 4.2865 - val_loss: 28.3108 - val_mse: 28.1403 - val_mae: 4.2798
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9429 - mse: 29.7691 - mae: 4.2668 - val_loss: 27.9456 - val_mse: 27.7701 - val_mae: 4.2526
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6972 - mse: 29.5193 - mae: 4.2455 - val_loss: 28.3551 - val_mse: 28.1759 - val_mae: 4.2811
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4212 - mse: 29.2402 - mae: 4.2268 - val_loss: 27.4466 - val_mse: 27.2649 - val_mae: 4.2134
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1332 - mse: 28.9503 - mae: 4.2054 - val_loss: 27.9298 - val_mse: 27.7470 - val_mae: 4.2474
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0926 - mse: 28.9086 - mae: 4.2036 - val_loss: 27.1515 - val_mse: 26.9674 - val_mae: 4.1874
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8473 - mse: 28.6623 - mae: 4.1820 - val_loss: 27.6656 - val_mse: 27.4805 - val_mae: 4.2250
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7815 - mse: 28.5959 - mae: 4.1704 - val_loss: 27.4162 - val_mse: 27.2306 - val_mae: 4.2106
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6870 - mse: 28.5004 - mae: 4.1690 - val_loss: 26.7964 - val_mse: 26.6095 - val_mae: 4.1618
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.6008 - mse: 28.4131 - mae: 4.1586 - val_loss: 26.9403 - val_mse: 26.7524 - val_mae: 4.1718
bias -0.008714187
si 0.48640388
rmse 0.051722735
kgeprime [0.59815869]
rmse_95 0.0703325
rmse_99 0.0793589
pearson 0.8513880743440522
pearson_95 0.6773251771708728
pearson_99 0.7893566250522002
rscore 0.7168079748618099
rscore_95 -1.319619336850974
rscore_99 -5.8551617864172805
nse [0.71680797]
nse_95 [-1.31961934]
nse_99 [-5.85516179]
kge [0.69612453]
ext_kge_95 [0.50760389]
ext_kge_99 [0.05244312]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... -1.799
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 3.511
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([96776 96800 96824], shape=(3,), dtype=int64) Times out: tf.Tensor(96824, shape=(), dtype=int64)
Times in: tf.Tensor([92883 92907 92931], shape=(3,), dtype=int64) Times out: tf.Tensor(92931, shape=(), dtype=int64)
Times in: tf.Tensor([48559 48583 48607], shape=(3,), dtype=int64) Times out: tf.Tensor(48607, shape=(), dtype=int64)
Times in: tf.Tensor([101924 101948 101972], shape=(3,), dtype=int64) Times out: tf.Tensor(101972, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_546&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_547 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1092 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1093 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_546 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1092 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_546 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1093 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.0375 - mse: 45.9809 - mae: 5.2224 - val_loss: 31.4770 - val_mse: 31.4080 - val_mae: 4.5003
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7179 - mse: 33.6438 - mae: 4.5309 - val_loss: 30.1222 - val_mse: 30.0437 - val_mae: 4.4094
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8960 - mse: 32.8141 - mae: 4.4714 - val_loss: 30.2756 - val_mse: 30.1901 - val_mae: 4.4162
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6203 - mse: 32.5320 - mae: 4.4496 - val_loss: 29.8494 - val_mse: 29.7581 - val_mae: 4.3816
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3751 - mse: 32.2810 - mae: 4.4339 - val_loss: 29.7237 - val_mse: 29.6267 - val_mae: 4.3745
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1139 - mse: 32.0142 - mae: 4.4127 - val_loss: 29.2957 - val_mse: 29.1926 - val_mae: 4.3472
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9558 - mse: 31.8505 - mae: 4.4027 - val_loss: 29.0598 - val_mse: 28.9515 - val_mae: 4.3294
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7286 - mse: 31.6179 - mae: 4.3921 - val_loss: 29.2150 - val_mse: 29.1010 - val_mae: 4.3413
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5145 - mse: 31.3983 - mae: 4.3731 - val_loss: 29.3974 - val_mse: 29.2782 - val_mae: 4.3545
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3218 - mse: 31.2002 - mae: 4.3586 - val_loss: 28.7616 - val_mse: 28.6369 - val_mae: 4.3117
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1197 - mse: 30.9924 - mae: 4.3434 - val_loss: 28.3285 - val_mse: 28.1982 - val_mae: 4.2837
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7314 - mse: 30.5985 - mae: 4.3180 - val_loss: 28.3782 - val_mse: 28.2423 - val_mae: 4.2853
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4221 - mse: 30.2843 - mae: 4.2972 - val_loss: 27.7912 - val_mse: 27.6514 - val_mae: 4.2503
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1753 - mse: 30.0338 - mae: 4.2774 - val_loss: 27.8505 - val_mse: 27.7069 - val_mae: 4.2474
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9540 - mse: 29.8091 - mae: 4.2600 - val_loss: 27.8563 - val_mse: 27.7097 - val_mae: 4.2445
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7360 - mse: 29.5882 - mae: 4.2446 - val_loss: 27.4747 - val_mse: 27.3254 - val_mae: 4.2182
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5986 - mse: 29.4482 - mae: 4.2345 - val_loss: 27.4908 - val_mse: 27.3389 - val_mae: 4.2202
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5758 - mse: 29.4230 - mae: 4.2314 - val_loss: 26.7310 - val_mse: 26.5769 - val_mae: 4.1735
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3688 - mse: 29.2135 - mae: 4.2167 - val_loss: 27.0465 - val_mse: 26.8899 - val_mae: 4.1869
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3255 - mse: 29.1677 - mae: 4.2073 - val_loss: 26.9437 - val_mse: 26.7847 - val_mae: 4.1809
bias -0.00765674
si 0.48587757
rmse 0.051753983
kgeprime [0.62478783]
rmse_95 0.07106167
rmse_99 0.08161693
pearson 0.8515793386335324
pearson_95 0.666474127528999
pearson_99 0.8056939273607164
rscore 0.7190347094629252
rscore_95 -1.291358662613594
rscore_99 -6.04370483513892
nse [0.71903471]
nse_95 [-1.29135866]
nse_99 [-6.04370484]
kge [0.71535071]
ext_kge_95 [0.50746889]
ext_kge_99 [0.02101132]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... -1.799
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 3.511
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([7206 7230 7254], shape=(3,), dtype=int64) Times out: tf.Tensor(7254, shape=(), dtype=int64)
Times in: tf.Tensor([110330 110354 110378], shape=(3,), dtype=int64) Times out: tf.Tensor(110378, shape=(), dtype=int64)
Times in: tf.Tensor([3610 3634 3658], shape=(3,), dtype=int64) Times out: tf.Tensor(3658, shape=(), dtype=int64)
Times in: tf.Tensor([27847 27871 27895], shape=(3,), dtype=int64) Times out: tf.Tensor(27895, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_547&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_548 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1094 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1095 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_547 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1094 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_547 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1095 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.6960 - mse: 47.6371 - mae: 5.3110 - val_loss: 31.3995 - val_mse: 31.3270 - val_mae: 4.4945
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8770 - mse: 34.7999 - mae: 4.5965 - val_loss: 30.8336 - val_mse: 30.7518 - val_mae: 4.4639
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2826 - mse: 34.1971 - mae: 4.5552 - val_loss: 29.9547 - val_mse: 29.8663 - val_mae: 4.3953
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9915 - mse: 33.9000 - mae: 4.5335 - val_loss: 29.9230 - val_mse: 29.8287 - val_mae: 4.3935
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7155 - mse: 33.6185 - mae: 4.5170 - val_loss: 29.6505 - val_mse: 29.5507 - val_mae: 4.3684
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6873 - mse: 33.5846 - mae: 4.5170 - val_loss: 29.6339 - val_mse: 29.5283 - val_mae: 4.3718
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3018 - mse: 33.1932 - mae: 4.4899 - val_loss: 29.5637 - val_mse: 29.4521 - val_mae: 4.3602
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5010 - mse: 33.3865 - mae: 4.5011 - val_loss: 29.5734 - val_mse: 29.4559 - val_mae: 4.3680
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2274 - mse: 33.1069 - mae: 4.4851 - val_loss: 29.4267 - val_mse: 29.3030 - val_mae: 4.3557
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0988 - mse: 32.9721 - mae: 4.4767 - val_loss: 29.3732 - val_mse: 29.2433 - val_mae: 4.3495
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9160 - mse: 32.7831 - mae: 4.4626 - val_loss: 29.2048 - val_mse: 29.0688 - val_mae: 4.3416
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7082 - mse: 32.5693 - mae: 4.4484 - val_loss: 29.3218 - val_mse: 29.1800 - val_mae: 4.3462
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6270 - mse: 32.4823 - mae: 4.4458 - val_loss: 29.6967 - val_mse: 29.5493 - val_mae: 4.3687
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5045 - mse: 32.3546 - mae: 4.4325 - val_loss: 29.2522 - val_mse: 29.0996 - val_mae: 4.3405
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3714 - mse: 32.2162 - mae: 4.4247 - val_loss: 29.1818 - val_mse: 29.0239 - val_mae: 4.3424
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1912 - mse: 32.0312 - mae: 4.4087 - val_loss: 29.5697 - val_mse: 29.4073 - val_mae: 4.3633
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1107 - mse: 31.9460 - mae: 4.4053 - val_loss: 29.5685 - val_mse: 29.4020 - val_mae: 4.3616
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9868 - mse: 31.8183 - mae: 4.3952 - val_loss: 29.3052 - val_mse: 29.1344 - val_mae: 4.3468
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.8150 - mse: 31.6422 - mae: 4.3864 - val_loss: 29.2679 - val_mse: 29.0931 - val_mae: 4.3382
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6675 - mse: 31.4909 - mae: 4.3787 - val_loss: 29.5898 - val_mse: 29.4114 - val_mae: 4.3664
bias -0.009486061
si 0.50454473
rmse 0.054232273
kgeprime [0.57540149]
rmse_95 0.07468804
rmse_99 0.08762928
pearson 0.8387755676794988
pearson_95 0.6488107651122604
pearson_99 0.8017300923530418
rscore 0.694027230986895
rscore_95 -1.495968006756892
rscore_99 -6.985903011430967
nse [0.69402723]
nse_95 [-1.49596801]
nse_99 [-6.98590301]
kge [0.67627988]
ext_kge_95 [0.52030534]
ext_kge_99 [0.13972668]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -1.799
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 3.511
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([86245 86269 86293], shape=(3,), dtype=int64) Times out: tf.Tensor(86293, shape=(), dtype=int64)
Times in: tf.Tensor([19418 19442 19466], shape=(3,), dtype=int64) Times out: tf.Tensor(19466, shape=(), dtype=int64)
Times in: tf.Tensor([131113 131137 131161], shape=(3,), dtype=int64) Times out: tf.Tensor(131161, shape=(), dtype=int64)
Times in: tf.Tensor([126116 126140 126164], shape=(3,), dtype=int64) Times out: tf.Tensor(126164, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_548&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_549 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1096 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1097 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_548 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1096 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_548 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1097 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 64.1777 - mse: 64.1504 - mae: 6.2099 - val_loss: 35.2536 - val_mse: 35.2220 - val_mae: 4.7299
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.8794 - mse: 42.8426 - mae: 5.0734 - val_loss: 32.3343 - val_mse: 32.2921 - val_mae: 4.5421
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.4129 - mse: 40.3659 - mae: 4.9070 - val_loss: 31.1856 - val_mse: 31.1344 - val_mae: 4.4622
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5627 - mse: 39.5094 - mae: 4.8566 - val_loss: 30.5623 - val_mse: 30.5071 - val_mae: 4.4164
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2691 - mse: 39.2128 - mae: 4.8367 - val_loss: 30.4468 - val_mse: 30.3892 - val_mae: 4.4075
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0818 - mse: 39.0232 - mae: 4.8254 - val_loss: 30.8317 - val_mse: 30.7719 - val_mae: 4.4362
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9729 - mse: 38.9118 - mae: 4.8164 - val_loss: 30.0535 - val_mse: 29.9910 - val_mae: 4.3816
Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.9135 - mse: 38.8494 - mae: 4.8121 - val_loss: 30.2334 - val_mse: 30.1677 - val_mae: 4.3924
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5313 - mse: 38.4642 - mae: 4.7876 - val_loss: 30.0788 - val_mse: 30.0099 - val_mae: 4.3823
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2529 - mse: 38.1822 - mae: 4.7778 - val_loss: 30.2676 - val_mse: 30.1950 - val_mae: 4.3959
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.0936 - mse: 38.0192 - mae: 4.7615 - val_loss: 30.0016 - val_mse: 29.9254 - val_mae: 4.3763
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.1275 - mse: 38.0493 - mae: 4.7642 - val_loss: 30.1081 - val_mse: 30.0277 - val_mae: 4.3861
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.7126 - mse: 37.6303 - mae: 4.7428 - val_loss: 30.4917 - val_mse: 30.4074 - val_mae: 4.4156
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.5763 - mse: 37.4898 - mae: 4.7308 - val_loss: 30.3589 - val_mse: 30.2703 - val_mae: 4.4006
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.3580 - mse: 37.2673 - mae: 4.7238 - val_loss: 30.2197 - val_mse: 30.1267 - val_mae: 4.3942
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.3870 - mse: 37.2920 - mae: 4.7177 - val_loss: 29.7620 - val_mse: 29.6649 - val_mae: 4.3624
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.2796 - mse: 37.1803 - mae: 4.7140 - val_loss: 30.3476 - val_mse: 30.2464 - val_mae: 4.4063
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.0918 - mse: 36.9885 - mae: 4.7033 - val_loss: 30.1137 - val_mse: 30.0083 - val_mae: 4.3875
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.9352 - mse: 36.8279 - mae: 4.6898 - val_loss: 30.3748 - val_mse: 30.2654 - val_mae: 4.4111
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.5869 - mse: 36.4757 - mae: 4.6726 - val_loss: 30.1816 - val_mse: 30.0688 - val_mae: 4.3966
bias -0.0097873425
si 0.50835556
rmse 0.054835055
kgeprime [0.52658958]
rmse_95 0.08326874
rmse_99 0.10173253
pearson 0.837795677233442
pearson_95 0.6594848146485262
pearson_99 0.8233156262048213
rscore 0.6889517835652973
rscore_95 -2.01643664283105
rscore_99 -9.695944641269106
nse [0.68895178]
nse_95 [-2.01643664]
nse_99 [-9.69594464]
kge [0.63462056]
ext_kge_95 [0.54096523]
ext_kge_99 [0.20767161]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -1.799
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 3.511
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([44196 44220 44244], shape=(3,), dtype=int64) Times out: tf.Tensor(44244, shape=(), dtype=int64)
Times in: tf.Tensor([33385 33409 33433], shape=(3,), dtype=int64) Times out: tf.Tensor(33433, shape=(), dtype=int64)
Times in: tf.Tensor([24409 24433 24457], shape=(3,), dtype=int64) Times out: tf.Tensor(24457, shape=(), dtype=int64)
Times in: tf.Tensor([40346 40370 40394], shape=(3,), dtype=int64) Times out: tf.Tensor(40394, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_549&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_550 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1098 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1099 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_549 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1098 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_549 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1099 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.7039 - mse: 47.6438 - mae: 5.3059 - val_loss: 31.6219 - val_mse: 31.5449 - val_mae: 4.5218
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4876 - mse: 34.4067 - mae: 4.5727 - val_loss: 31.3326 - val_mse: 31.2491 - val_mae: 4.4984
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8872 - mse: 33.8005 - mae: 4.5346 - val_loss: 30.5266 - val_mse: 30.4367 - val_mae: 4.4416
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6386 - mse: 33.5450 - mae: 4.5134 - val_loss: 30.3560 - val_mse: 30.2592 - val_mae: 4.4274
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4065 - mse: 33.3065 - mae: 4.5001 - val_loss: 30.0711 - val_mse: 29.9679 - val_mae: 4.4070
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1948 - mse: 33.0881 - mae: 4.4880 - val_loss: 30.0697 - val_mse: 29.9600 - val_mae: 4.4100
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9477 - mse: 32.8347 - mae: 4.4721 - val_loss: 29.9018 - val_mse: 29.7858 - val_mae: 4.3981
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8779 - mse: 32.7586 - mae: 4.4628 - val_loss: 29.9459 - val_mse: 29.8234 - val_mae: 4.3979
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6099 - mse: 32.4844 - mae: 4.4434 - val_loss: 29.6272 - val_mse: 29.4985 - val_mae: 4.3777
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3505 - mse: 32.2188 - mae: 4.4261 - val_loss: 29.9089 - val_mse: 29.7742 - val_mae: 4.3978
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3209 - mse: 32.1832 - mae: 4.4251 - val_loss: 29.5913 - val_mse: 29.4506 - val_mae: 4.3796
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1217 - mse: 31.9781 - mae: 4.4112 - val_loss: 29.4201 - val_mse: 29.2737 - val_mae: 4.3634
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9524 - mse: 31.8036 - mae: 4.4005 - val_loss: 29.8285 - val_mse: 29.6770 - val_mae: 4.3980
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7556 - mse: 31.6017 - mae: 4.3851 - val_loss: 29.6828 - val_mse: 29.5262 - val_mae: 4.3893
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7941 - mse: 31.6355 - mae: 4.3869 - val_loss: 29.7969 - val_mse: 29.6360 - val_mae: 4.3952
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5899 - mse: 31.4269 - mae: 4.3715 - val_loss: 29.9098 - val_mse: 29.7445 - val_mae: 4.4029
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5270 - mse: 31.3602 - mae: 4.3697 - val_loss: 29.7771 - val_mse: 29.6083 - val_mae: 4.3948
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.2826 - mse: 31.1120 - mae: 4.3563 - val_loss: 29.5831 - val_mse: 29.4104 - val_mae: 4.3770
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3131 - mse: 31.1390 - mae: 4.3537 - val_loss: 29.5671 - val_mse: 29.3912 - val_mae: 4.3768
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1476 - mse: 30.9705 - mae: 4.3411 - val_loss: 29.1157 - val_mse: 28.9371 - val_mae: 4.3478
bias -0.002062928
si 0.5058854
rmse 0.05379324
kgeprime [0.76465119]
rmse_95 0.07700238
rmse_99 0.08746368
pearson 0.8389449274987472
pearson_95 0.6570884004171776
pearson_99 0.8072029730117612
rscore 0.7017316914511214
rscore_95 -1.6036243136631998
rscore_99 -6.907531026672042
nse [0.70173169]
nse_95 [-1.60362431]
nse_99 [-6.90753103]
kge [0.79240061]
ext_kge_95 [0.49767058]
ext_kge_99 [0.04459584]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([119799 119823 119847], shape=(3,), dtype=int64) Times out: tf.Tensor(119847, shape=(), dtype=int64)
Times in: tf.Tensor([47240 47264 47288], shape=(3,), dtype=int64) Times out: tf.Tensor(47288, shape=(), dtype=int64)
Times in: tf.Tensor([94671 94695 94719], shape=(3,), dtype=int64) Times out: tf.Tensor(94719, shape=(), dtype=int64)
Times in: tf.Tensor([84677 84701 84725], shape=(3,), dtype=int64) Times out: tf.Tensor(84725, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_550&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_551 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1100 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1101 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_550 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1100 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_550 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1101 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.2337 - mse: 45.1893 - mae: 5.2003 - val_loss: 30.6823 - val_mse: 30.6339 - val_mae: 4.4611
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8805 - mse: 33.8301 - mae: 4.5468 - val_loss: 29.2435 - val_mse: 29.1902 - val_mae: 4.3617
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6941 - mse: 32.6371 - mae: 4.4616 - val_loss: 28.5965 - val_mse: 28.5360 - val_mae: 4.3075
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2258 - mse: 32.1630 - mae: 4.4273 - val_loss: 28.7249 - val_mse: 28.6596 - val_mae: 4.3203
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8776 - mse: 31.8106 - mae: 4.4009 - val_loss: 28.5371 - val_mse: 28.4678 - val_mae: 4.3050
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6878 - mse: 31.6167 - mae: 4.3849 - val_loss: 28.2242 - val_mse: 28.1509 - val_mae: 4.2817
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4549 - mse: 31.3800 - mae: 4.3719 - val_loss: 28.6078 - val_mse: 28.5306 - val_mae: 4.3079
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2756 - mse: 31.1966 - mae: 4.3602 - val_loss: 27.9719 - val_mse: 27.8905 - val_mae: 4.2615
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0783 - mse: 30.9952 - mae: 4.3480 - val_loss: 28.0105 - val_mse: 27.9252 - val_mae: 4.2667
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8578 - mse: 30.7705 - mae: 4.3265 - val_loss: 27.6737 - val_mse: 27.5840 - val_mae: 4.2387
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5034 - mse: 30.4116 - mae: 4.3031 - val_loss: 26.9795 - val_mse: 26.8856 - val_mae: 4.1863
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2105 - mse: 30.1147 - mae: 4.2840 - val_loss: 27.3185 - val_mse: 27.2209 - val_mae: 4.2074
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0467 - mse: 29.9476 - mae: 4.2694 - val_loss: 26.7643 - val_mse: 26.6634 - val_mae: 4.1723
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8940 - mse: 29.7917 - mae: 4.2547 - val_loss: 26.6450 - val_mse: 26.5412 - val_mae: 4.1613
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4802 - mse: 29.3752 - mae: 4.2243 - val_loss: 27.3453 - val_mse: 27.2387 - val_mae: 4.2117
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5182 - mse: 29.4106 - mae: 4.2231 - val_loss: 26.3703 - val_mse: 26.2612 - val_mae: 4.1445
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3906 - mse: 29.2805 - mae: 4.2212 - val_loss: 26.5566 - val_mse: 26.4452 - val_mae: 4.1495
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3124 - mse: 29.2001 - mae: 4.2115 - val_loss: 26.8939 - val_mse: 26.7803 - val_mae: 4.1732
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2495 - mse: 29.1352 - mae: 4.2028 - val_loss: 26.2540 - val_mse: 26.1386 - val_mae: 4.1279
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1244 - mse: 29.0080 - mae: 4.1972 - val_loss: 26.6040 - val_mse: 26.4866 - val_mae: 4.1519
bias -0.010371528
si 0.4859516
rmse 0.0514651
kgeprime [0.56216786]
rmse_95 0.06411623
rmse_99 0.07244505
pearson 0.8528502802459533
pearson_95 0.6546979577412472
pearson_99 0.753180541243419
rscore 0.7152164232788647
rscore_95 -1.1234182439539468
rscore_99 -5.184225495009044
nse [0.71521642]
nse_95 [-1.12341824]
nse_99 [-5.1842255]
kge [0.66755015]
ext_kge_95 [0.48010048]
ext_kge_99 [-0.0486783]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([51508 51532 51556], shape=(3,), dtype=int64) Times out: tf.Tensor(51556, shape=(), dtype=int64)
Times in: tf.Tensor([2627 2651 2675], shape=(3,), dtype=int64) Times out: tf.Tensor(2675, shape=(), dtype=int64)
Times in: tf.Tensor([1630 1654 1678], shape=(3,), dtype=int64) Times out: tf.Tensor(1678, shape=(), dtype=int64)
Times in: tf.Tensor([20203 20227 20251], shape=(3,), dtype=int64) Times out: tf.Tensor(20251, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_551&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_552 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1102 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1103 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_551 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1102 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_551 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1103 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.0200 - mse: 54.9658 - mae: 5.7416 - val_loss: 35.3096 - val_mse: 35.2424 - val_mae: 4.7505
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5883 - mse: 37.5147 - mae: 4.7949 - val_loss: 31.4442 - val_mse: 31.3624 - val_mae: 4.5160
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4521 - mse: 34.3623 - mae: 4.5797 - val_loss: 30.7293 - val_mse: 30.6317 - val_mae: 4.4662
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4693 - mse: 33.3655 - mae: 4.5107 - val_loss: 30.0925 - val_mse: 29.9832 - val_mae: 4.4114
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7785 - mse: 32.6651 - mae: 4.4608 - val_loss: 29.7221 - val_mse: 29.6050 - val_mae: 4.3859
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4843 - mse: 32.3640 - mae: 4.4421 - val_loss: 29.2898 - val_mse: 29.1665 - val_mae: 4.3556
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1924 - mse: 32.0663 - mae: 4.4188 - val_loss: 29.4670 - val_mse: 29.3385 - val_mae: 4.3651
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0222 - mse: 31.8912 - mae: 4.4059 - val_loss: 29.6914 - val_mse: 29.5576 - val_mae: 4.3811
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6869 - mse: 31.5509 - mae: 4.3869 - val_loss: 28.7044 - val_mse: 28.5660 - val_mae: 4.3147
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5877 - mse: 31.4469 - mae: 4.3735 - val_loss: 28.6369 - val_mse: 28.4941 - val_mae: 4.3105
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1601 - mse: 31.0151 - mae: 4.3464 - val_loss: 29.4347 - val_mse: 29.2880 - val_mae: 4.3675
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9274 - mse: 30.7791 - mae: 4.3329 - val_loss: 28.3880 - val_mse: 28.2385 - val_mae: 4.2951
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7456 - mse: 30.5949 - mae: 4.3147 - val_loss: 28.6888 - val_mse: 28.5366 - val_mae: 4.3192
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6619 - mse: 30.5082 - mae: 4.3087 - val_loss: 28.8024 - val_mse: 28.6477 - val_mae: 4.3263
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3997 - mse: 30.2438 - mae: 4.2923 - val_loss: 28.1857 - val_mse: 28.0289 - val_mae: 4.2820
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3252 - mse: 30.1672 - mae: 4.2856 - val_loss: 27.3695 - val_mse: 27.2108 - val_mae: 4.2234
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2646 - mse: 30.1048 - mae: 4.2782 - val_loss: 28.0251 - val_mse: 27.8643 - val_mae: 4.2727
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1478 - mse: 29.9864 - mae: 4.2694 - val_loss: 28.4950 - val_mse: 28.3330 - val_mae: 4.3065
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0028 - mse: 29.8398 - mae: 4.2623 - val_loss: 28.4413 - val_mse: 28.2775 - val_mae: 4.2965
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8205 - mse: 29.6556 - mae: 4.2529 - val_loss: 27.8509 - val_mse: 27.6853 - val_mae: 4.2554
bias -0.00981625
si 0.48671013
rmse 0.05261686
kgeprime [0.58878171]
rmse_95 0.06561831
rmse_99 0.07705661
pearson 0.8525390156766945
pearson_95 0.6677420949307155
pearson_99 0.7995364074927888
rscore 0.7157940615585983
rscore_95 -1.0313438914427877
rscore_99 -5.024456644775906
nse [0.71579406]
nse_95 [-1.03134389]
nse_99 [-5.02445664]
kge [0.68808739]
ext_kge_95 [0.52665703]
ext_kge_99 [0.0311772]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -1.799
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 3.511
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([18700 18724 18748], shape=(3,), dtype=int64) Times out: tf.Tensor(18748, shape=(), dtype=int64)
Times in: tf.Tensor([140427 140451 140475], shape=(3,), dtype=int64) Times out: tf.Tensor(140475, shape=(), dtype=int64)
Times in: tf.Tensor([133594 133618 133642], shape=(3,), dtype=int64) Times out: tf.Tensor(133642, shape=(), dtype=int64)
Times in: tf.Tensor([119973 119997 120021], shape=(3,), dtype=int64) Times out: tf.Tensor(120021, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_552&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_553 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1104 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1105 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_552 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1104 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_552 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1105 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.0262 - mse: 45.9639 - mae: 5.2190 - val_loss: 31.9376 - val_mse: 31.8604 - val_mae: 4.5400
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3248 - mse: 34.2428 - mae: 4.5644 - val_loss: 30.4904 - val_mse: 30.4037 - val_mae: 4.4399
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7244 - mse: 33.6335 - mae: 4.5231 - val_loss: 30.6023 - val_mse: 30.5072 - val_mae: 4.4460
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2474 - mse: 33.1480 - mae: 4.4881 - val_loss: 30.0825 - val_mse: 29.9790 - val_mae: 4.4118
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1378 - mse: 33.0301 - mae: 4.4802 - val_loss: 30.0425 - val_mse: 29.9305 - val_mae: 4.4045
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7427 - mse: 32.6268 - mae: 4.4542 - val_loss: 29.4770 - val_mse: 29.3568 - val_mae: 4.3624
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5097 - mse: 32.3854 - mae: 4.4460 - val_loss: 29.6176 - val_mse: 29.4894 - val_mae: 4.3759
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4223 - mse: 32.2898 - mae: 4.4322 - val_loss: 29.6604 - val_mse: 29.5236 - val_mae: 4.3797
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1517 - mse: 32.0111 - mae: 4.4141 - val_loss: 29.4441 - val_mse: 29.2996 - val_mae: 4.3649
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0056 - mse: 31.8578 - mae: 4.4077 - val_loss: 29.3576 - val_mse: 29.2064 - val_mae: 4.3615
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8489 - mse: 31.6945 - mae: 4.3935 - val_loss: 29.1252 - val_mse: 28.9678 - val_mae: 4.3378
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6990 - mse: 31.5387 - mae: 4.3831 - val_loss: 29.5545 - val_mse: 29.3912 - val_mae: 4.3737
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6305 - mse: 31.4647 - mae: 4.3753 - val_loss: 29.2552 - val_mse: 29.0869 - val_mae: 4.3499
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4682 - mse: 31.2976 - mae: 4.3682 - val_loss: 29.7014 - val_mse: 29.5282 - val_mae: 4.3816
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2952 - mse: 31.1198 - mae: 4.3505 - val_loss: 29.5425 - val_mse: 29.3649 - val_mae: 4.3759
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3039 - mse: 31.1244 - mae: 4.3477 - val_loss: 29.0327 - val_mse: 28.8511 - val_mae: 4.3327
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1568 - mse: 30.9733 - mae: 4.3384 - val_loss: 29.0716 - val_mse: 28.8864 - val_mae: 4.3355
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0317 - mse: 30.8448 - mae: 4.3314 - val_loss: 29.4019 - val_mse: 29.2135 - val_mae: 4.3579
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9289 - mse: 30.7390 - mae: 4.3258 - val_loss: 29.0762 - val_mse: 28.8849 - val_mae: 4.3381
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8850 - mse: 30.6924 - mae: 4.3187 - val_loss: 28.7271 - val_mse: 28.5332 - val_mae: 4.3093
bias -0.0063198665
si 0.5010304
rmse 0.05341649
kgeprime [0.6619293]
rmse_95 0.07528707
rmse_99 0.08481692
pearson 0.8416579046369885
pearson_95 0.6437327337872533
pearson_99 0.8251201610275901
rscore 0.7036477235582823
rscore_95 -1.5452187953548417
rscore_99 -6.773133939549343
nse [0.70364772]
nse_95 [-1.5452188]
nse_99 [-6.77313394]
kge [0.7386115]
ext_kge_95 [0.47570527]
ext_kge_99 [-0.09424662]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 1.874
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -1.799
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 3.511
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 3.236
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 2.597
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([82571 82595 82619], shape=(3,), dtype=int64) Times out: tf.Tensor(82619, shape=(), dtype=int64)
Times in: tf.Tensor([27840 27864 27888], shape=(3,), dtype=int64) Times out: tf.Tensor(27888, shape=(), dtype=int64)
Times in: tf.Tensor([47278 47302 47326], shape=(3,), dtype=int64) Times out: tf.Tensor(47326, shape=(), dtype=int64)
Times in: tf.Tensor([132650 132674 132698], shape=(3,), dtype=int64) Times out: tf.Tensor(132698, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_553&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_554 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1106 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1107 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_553 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1106 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_553 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1107 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.4777 - mse: 44.4046 - mae: 5.1399 - val_loss: 31.9028 - val_mse: 31.8162 - val_mae: 4.5368
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1800 - mse: 34.0887 - mae: 4.5536 - val_loss: 32.2960 - val_mse: 32.2009 - val_mae: 4.5524
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5649 - mse: 33.4663 - mae: 4.5150 - val_loss: 30.6241 - val_mse: 30.5217 - val_mae: 4.4367
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2296 - mse: 33.1240 - mae: 4.4925 - val_loss: 30.7661 - val_mse: 30.6566 - val_mae: 4.4446
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0531 - mse: 32.9410 - mae: 4.4760 - val_loss: 30.2998 - val_mse: 30.1842 - val_mae: 4.4159
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7893 - mse: 32.6709 - mae: 4.4617 - val_loss: 30.5761 - val_mse: 30.4540 - val_mae: 4.4356
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6255 - mse: 32.5009 - mae: 4.4491 - val_loss: 30.2373 - val_mse: 30.1090 - val_mae: 4.4108
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4918 - mse: 32.3607 - mae: 4.4388 - val_loss: 30.8897 - val_mse: 30.7545 - val_mae: 4.4564
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2156 - mse: 32.0776 - mae: 4.4181 - val_loss: 29.7505 - val_mse: 29.6085 - val_mae: 4.3783
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7487 - mse: 31.6033 - mae: 4.3884 - val_loss: 29.8634 - val_mse: 29.7141 - val_mae: 4.3883
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2438 - mse: 31.0915 - mae: 4.3518 - val_loss: 28.9097 - val_mse: 28.7541 - val_mae: 4.3238
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9362 - mse: 30.7780 - mae: 4.3296 - val_loss: 28.8104 - val_mse: 28.6494 - val_mae: 4.3165
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7713 - mse: 30.6082 - mae: 4.3181 - val_loss: 28.6209 - val_mse: 28.4555 - val_mae: 4.3038
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3344 - mse: 30.1674 - mae: 4.2858 - val_loss: 28.2694 - val_mse: 28.1007 - val_mae: 4.2788
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2026 - mse: 30.0324 - mae: 4.2802 - val_loss: 28.7940 - val_mse: 28.6222 - val_mae: 4.3123
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.8384 - mse: 29.6656 - mae: 4.2487 - val_loss: 27.9519 - val_mse: 27.7775 - val_mae: 4.2590
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9056 - mse: 29.7302 - mae: 4.2516 - val_loss: 28.2966 - val_mse: 28.1198 - val_mae: 4.2761
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6808 - mse: 29.5033 - mae: 4.2323 - val_loss: 28.0887 - val_mse: 27.9100 - val_mae: 4.2667
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6459 - mse: 29.4664 - mae: 4.2346 - val_loss: 28.5170 - val_mse: 28.3364 - val_mae: 4.2924
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.5472 - mse: 29.3662 - mae: 4.2251 - val_loss: 27.3471 - val_mse: 27.1651 - val_mae: 4.2147
bias -0.0057028704
si 0.48724544
rmse 0.052120183
kgeprime [0.6701515]
rmse_95 0.070957504
rmse_99 0.082323395
pearson 0.8505500192405488
pearson_95 0.6731919403307165
pearson_99 0.8222626836170998
rscore 0.7200805975788807
rscore_95 -1.2359339686498219
rscore_99 -6.200465497383039
nse [0.7200806]
nse_95 [-1.23593397]
nse_99 [-6.2004655]
kge [0.74397629]
ext_kge_95 [0.53399935]
ext_kge_99 [0.06208297]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -3.22
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 5.353
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([151152 151176 151200], shape=(3,), dtype=int64) Times out: tf.Tensor(151200, shape=(), dtype=int64)
Times in: tf.Tensor([34283 34307 34331], shape=(3,), dtype=int64) Times out: tf.Tensor(34331, shape=(), dtype=int64)
Times in: tf.Tensor([122471 122495 122519], shape=(3,), dtype=int64) Times out: tf.Tensor(122519, shape=(), dtype=int64)
Times in: tf.Tensor([23704 23728 23752], shape=(3,), dtype=int64) Times out: tf.Tensor(23752, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_554&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_555 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1108 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1109 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_554 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1108 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_554 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1109 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.8955 - mse: 44.8449 - mae: 5.1633 - val_loss: 32.1614 - val_mse: 32.1008 - val_mae: 4.5520
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7136 - mse: 34.6488 - mae: 4.5955 - val_loss: 31.1928 - val_mse: 31.1249 - val_mae: 4.4815
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0239 - mse: 33.9535 - mae: 4.5487 - val_loss: 31.1700 - val_mse: 31.0968 - val_mae: 4.4762
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6686 - mse: 33.5937 - mae: 4.5263 - val_loss: 31.1103 - val_mse: 31.0333 - val_mae: 4.4733
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6172 - mse: 33.5388 - mae: 4.5180 - val_loss: 30.4994 - val_mse: 30.4192 - val_mae: 4.4251
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4178 - mse: 33.3360 - mae: 4.5069 - val_loss: 31.3352 - val_mse: 31.2512 - val_mae: 4.4923
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1037 - mse: 33.0182 - mae: 4.4839 - val_loss: 30.6141 - val_mse: 30.5263 - val_mae: 4.4386
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0720 - mse: 32.9820 - mae: 4.4783 - val_loss: 30.6244 - val_mse: 30.5316 - val_mae: 4.4362
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5967 - mse: 32.5013 - mae: 4.4504 - val_loss: 29.4943 - val_mse: 29.3958 - val_mae: 4.3570
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2191 - mse: 32.1181 - mae: 4.4219 - val_loss: 29.4955 - val_mse: 29.3918 - val_mae: 4.3595
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7666 - mse: 31.6604 - mae: 4.3904 - val_loss: 29.3834 - val_mse: 29.2747 - val_mae: 4.3539
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3090 - mse: 31.1983 - mae: 4.3566 - val_loss: 28.8495 - val_mse: 28.7365 - val_mae: 4.3195
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2767 - mse: 31.1620 - mae: 4.3499 - val_loss: 29.0018 - val_mse: 28.8853 - val_mae: 4.3276
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9293 - mse: 30.8113 - mae: 4.3260 - val_loss: 28.4947 - val_mse: 28.3750 - val_mae: 4.2920
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6553 - mse: 30.5340 - mae: 4.3106 - val_loss: 28.4924 - val_mse: 28.3696 - val_mae: 4.2872
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6349 - mse: 30.5107 - mae: 4.3056 - val_loss: 28.2694 - val_mse: 28.1436 - val_mae: 4.2729
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5227 - mse: 30.3957 - mae: 4.2936 - val_loss: 28.5588 - val_mse: 28.4301 - val_mae: 4.2936
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3564 - mse: 30.2266 - mae: 4.2803 - val_loss: 27.7184 - val_mse: 27.5870 - val_mae: 4.2329
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2941 - mse: 30.1616 - mae: 4.2781 - val_loss: 27.4469 - val_mse: 27.3132 - val_mae: 4.2166
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1748 - mse: 30.0401 - mae: 4.2709 - val_loss: 28.1443 - val_mse: 28.0083 - val_mae: 4.2621
bias -0.010360154
si 0.48629153
rmse 0.0529229
kgeprime [0.55302054]
rmse_95 0.06945752
rmse_99 0.08076607
pearson 0.8511633378575452
pearson_95 0.6779804229565967
pearson_99 0.8211400706979389
rscore 0.7133114067238857
rscore_95 -1.073429540855428
rscore_99 -5.9100529089506395
nse [0.71331141]
nse_95 [-1.07342954]
nse_99 [-5.91005291]
kge [0.66127939]
ext_kge_95 [0.55293246]
ext_kge_99 [0.09688131]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -3.22
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 5.353
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([67602 67626 67650], shape=(3,), dtype=int64) Times out: tf.Tensor(67650, shape=(), dtype=int64)
Times in: tf.Tensor([124044 124068 124092], shape=(3,), dtype=int64) Times out: tf.Tensor(124092, shape=(), dtype=int64)
Times in: tf.Tensor([62297 62321 62345], shape=(3,), dtype=int64) Times out: tf.Tensor(62345, shape=(), dtype=int64)
Times in: tf.Tensor([152152 152176 152200], shape=(3,), dtype=int64) Times out: tf.Tensor(152200, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_555&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_556 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1110 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1111 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_555 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1110 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_555 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1111 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.5295 - mse: 47.4777 - mae: 5.3144 - val_loss: 33.1555 - val_mse: 33.0938 - val_mae: 4.6220
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2729 - mse: 35.2053 - mae: 4.6331 - val_loss: 31.8435 - val_mse: 31.7695 - val_mae: 4.5298
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9107 - mse: 33.8298 - mae: 4.5395 - val_loss: 30.9580 - val_mse: 30.8701 - val_mae: 4.4609
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3816 - mse: 33.2871 - mae: 4.5064 - val_loss: 30.8595 - val_mse: 30.7586 - val_mae: 4.4557
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0154 - mse: 32.9085 - mae: 4.4778 - val_loss: 30.9483 - val_mse: 30.8354 - val_mae: 4.4625
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5235 - mse: 32.4049 - mae: 4.4435 - val_loss: 30.1664 - val_mse: 30.0429 - val_mae: 4.4117
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3637 - mse: 32.2345 - mae: 4.4379 - val_loss: 30.6207 - val_mse: 30.4865 - val_mae: 4.4436
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9402 - mse: 31.8011 - mae: 4.4037 - val_loss: 30.8840 - val_mse: 30.7403 - val_mae: 4.4639
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7381 - mse: 31.5899 - mae: 4.3879 - val_loss: 29.7585 - val_mse: 29.6064 - val_mae: 4.3874
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2968 - mse: 31.1407 - mae: 4.3586 - val_loss: 30.3017 - val_mse: 30.1422 - val_mae: 4.4278
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0491 - mse: 30.8864 - mae: 4.3393 - val_loss: 30.2813 - val_mse: 30.1157 - val_mae: 4.4272
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7991 - mse: 30.6311 - mae: 4.3218 - val_loss: 29.4067 - val_mse: 29.2366 - val_mae: 4.3688
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5856 - mse: 30.4133 - mae: 4.3007 - val_loss: 29.0129 - val_mse: 28.8386 - val_mae: 4.3401
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3618 - mse: 30.1856 - mae: 4.2881 - val_loss: 30.0843 - val_mse: 29.9064 - val_mae: 4.4126
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3466 - mse: 30.1672 - mae: 4.2846 - val_loss: 28.9206 - val_mse: 28.7399 - val_mae: 4.3294
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3017 - mse: 30.1196 - mae: 4.2799 - val_loss: 28.9413 - val_mse: 28.7579 - val_mae: 4.3335
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1584 - mse: 29.9738 - mae: 4.2705 - val_loss: 29.0734 - val_mse: 28.8879 - val_mae: 4.3409
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9735 - mse: 29.7866 - mae: 4.2567 - val_loss: 28.3503 - val_mse: 28.1622 - val_mae: 4.2877
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9874 - mse: 29.7980 - mae: 4.2540 - val_loss: 29.2513 - val_mse: 29.0610 - val_mae: 4.3528
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7552 - mse: 29.5639 - mae: 4.2408 - val_loss: 29.1461 - val_mse: 28.9538 - val_mae: 4.3420
bias -0.012642704
si 0.48989838
rmse 0.053808704
kgeprime [0.50474455]
rmse_95 0.06739379
rmse_99 0.07604461
pearson 0.8488918580456614
pearson_95 0.6679573864832138
pearson_99 0.8229050082509031
rscore 0.7042655552296868
rscore_95 -1.0451364139505177
rscore_99 -5.362738885127575
nse [0.70426556]
nse_95 [-1.04513641]
nse_99 [-5.36273889]
kge [0.62108008]
ext_kge_95 [0.52420595]
ext_kge_99 [0.02237488]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([88014 88038 88062], shape=(3,), dtype=int64) Times out: tf.Tensor(88062, shape=(), dtype=int64)
Times in: tf.Tensor([7212 7236 7260], shape=(3,), dtype=int64) Times out: tf.Tensor(7260, shape=(), dtype=int64)
Times in: tf.Tensor([74947 74971 74995], shape=(3,), dtype=int64) Times out: tf.Tensor(74995, shape=(), dtype=int64)
Times in: tf.Tensor([117678 117702 117726], shape=(3,), dtype=int64) Times out: tf.Tensor(117726, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_556&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_557 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1112 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1113 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_556 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1112 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_556 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1113 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.2336 - mse: 46.1791 - mae: 5.2402 - val_loss: 32.1049 - val_mse: 32.0413 - val_mae: 4.5541
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8838 - mse: 34.8152 - mae: 4.6084 - val_loss: 31.0015 - val_mse: 30.9281 - val_mae: 4.4790
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0268 - mse: 33.9496 - mae: 4.5437 - val_loss: 30.0593 - val_mse: 29.9787 - val_mae: 4.4079
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4557 - mse: 33.3726 - mae: 4.5084 - val_loss: 29.8750 - val_mse: 29.7897 - val_mae: 4.3960
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2171 - mse: 33.1298 - mae: 4.4911 - val_loss: 29.8656 - val_mse: 29.7767 - val_mae: 4.3960
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9970 - mse: 32.9067 - mae: 4.4776 - val_loss: 30.3971 - val_mse: 30.3053 - val_mae: 4.4338
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8029 - mse: 32.7097 - mae: 4.4643 - val_loss: 29.5517 - val_mse: 29.4571 - val_mae: 4.3721
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6728 - mse: 32.5766 - mae: 4.4553 - val_loss: 29.3901 - val_mse: 29.2927 - val_mae: 4.3613
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5416 - mse: 32.4424 - mae: 4.4453 - val_loss: 29.5101 - val_mse: 29.4095 - val_mae: 4.3683
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4815 - mse: 32.3793 - mae: 4.4427 - val_loss: 29.7189 - val_mse: 29.6153 - val_mae: 4.3842
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2092 - mse: 32.1040 - mae: 4.4227 - val_loss: 29.5113 - val_mse: 29.4042 - val_mae: 4.3715
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1863 - mse: 32.0774 - mae: 4.4224 - val_loss: 28.8835 - val_mse: 28.7727 - val_mae: 4.3265
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9328 - mse: 31.8204 - mae: 4.4029 - val_loss: 28.7852 - val_mse: 28.6712 - val_mae: 4.3182
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5998 - mse: 31.4835 - mae: 4.3774 - val_loss: 28.4983 - val_mse: 28.3801 - val_mae: 4.2964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3961 - mse: 31.2757 - mae: 4.3630 - val_loss: 28.7146 - val_mse: 28.5923 - val_mae: 4.3112
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1131 - mse: 30.9890 - mae: 4.3406 - val_loss: 27.8167 - val_mse: 27.6909 - val_mae: 4.2488
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8516 - mse: 30.7244 - mae: 4.3244 - val_loss: 28.1527 - val_mse: 28.0242 - val_mae: 4.2718
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7642 - mse: 30.6342 - mae: 4.3155 - val_loss: 27.7788 - val_mse: 27.6476 - val_mae: 4.2469
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6938 - mse: 30.5614 - mae: 4.3111 - val_loss: 27.6418 - val_mse: 27.5082 - val_mae: 4.2371
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5269 - mse: 30.3921 - mae: 4.2974 - val_loss: 27.2844 - val_mse: 27.1483 - val_mae: 4.2117
bias -0.008409303
si 0.48882684
rmse 0.052104063
kgeprime [0.5992211]
rmse_95 0.06795434
rmse_99 0.07937556
pearson 0.8506575359049391
pearson_95 0.6472451318161104
pearson_99 0.7719110884635977
rscore 0.7162256551330115
rscore_95 -1.2794430786491762
rscore_99 -5.859728677038801
nse [0.71622566]
nse_95 [-1.27944308]
nse_99 [-5.85972868]
kge [0.6965853]
ext_kge_95 [0.49156776]
ext_kge_99 [0.02986418]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([141643 141667 141691], shape=(3,), dtype=int64) Times out: tf.Tensor(141691, shape=(), dtype=int64)
Times in: tf.Tensor([139272 139296 139320], shape=(3,), dtype=int64) Times out: tf.Tensor(139320, shape=(), dtype=int64)
Times in: tf.Tensor([86259 86283 86307], shape=(3,), dtype=int64) Times out: tf.Tensor(86307, shape=(), dtype=int64)
Times in: tf.Tensor([22623 22647 22671], shape=(3,), dtype=int64) Times out: tf.Tensor(22671, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_557&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_558 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1114 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1115 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_557 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1114 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_557 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1115 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.1981 - mse: 47.1423 - mae: 5.2957 - val_loss: 32.2787 - val_mse: 32.2114 - val_mae: 4.5773
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1177 - mse: 35.0442 - mae: 4.6272 - val_loss: 32.3669 - val_mse: 32.2877 - val_mae: 4.5752
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0407 - mse: 33.9579 - mae: 4.5463 - val_loss: 30.3626 - val_mse: 30.2757 - val_mae: 4.4369
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6758 - mse: 33.5859 - mae: 4.5234 - val_loss: 30.9808 - val_mse: 30.8878 - val_mae: 4.4737
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5349 - mse: 33.4400 - mae: 4.5137 - val_loss: 29.8135 - val_mse: 29.7165 - val_mae: 4.3932
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2304 - mse: 33.1314 - mae: 4.4951 - val_loss: 29.5590 - val_mse: 29.4580 - val_mae: 4.3779
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9899 - mse: 32.8868 - mae: 4.4784 - val_loss: 29.4134 - val_mse: 29.3080 - val_mae: 4.3685
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5647 - mse: 32.4570 - mae: 4.4494 - val_loss: 29.1346 - val_mse: 29.0246 - val_mae: 4.3478
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0936 - mse: 31.9817 - mae: 4.4146 - val_loss: 28.6679 - val_mse: 28.5543 - val_mae: 4.3185
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8498 - mse: 31.7342 - mae: 4.4002 - val_loss: 28.4972 - val_mse: 28.3799 - val_mae: 4.3069
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6228 - mse: 31.5036 - mae: 4.3796 - val_loss: 28.0491 - val_mse: 27.9282 - val_mae: 4.2738
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4790 - mse: 31.3562 - mae: 4.3675 - val_loss: 28.3289 - val_mse: 28.2046 - val_mae: 4.2882
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3121 - mse: 31.1863 - mae: 4.3563 - val_loss: 28.6845 - val_mse: 28.5569 - val_mae: 4.3119
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9777 - mse: 30.8485 - mae: 4.3332 - val_loss: 28.3041 - val_mse: 28.1734 - val_mae: 4.2883
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8582 - mse: 30.7258 - mae: 4.3220 - val_loss: 28.2891 - val_mse: 28.1552 - val_mae: 4.2840
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7581 - mse: 30.6225 - mae: 4.3166 - val_loss: 27.6248 - val_mse: 27.4876 - val_mae: 4.2385
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6877 - mse: 30.5492 - mae: 4.3102 - val_loss: 28.1553 - val_mse: 28.0153 - val_mae: 4.2729
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4457 - mse: 30.3042 - mae: 4.2947 - val_loss: 27.8130 - val_mse: 27.6699 - val_mae: 4.2496
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4062 - mse: 30.2619 - mae: 4.2892 - val_loss: 27.4649 - val_mse: 27.3195 - val_mae: 4.2221
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3682 - mse: 30.2216 - mae: 4.2857 - val_loss: 27.7893 - val_mse: 27.6417 - val_mae: 4.2434
bias -0.010288059
si 0.48336285
rmse 0.05257542
kgeprime [0.56054667]
rmse_95 0.065858565
rmse_99 0.079293184
pearson 0.8540131290556728
pearson_95 0.6624089481959478
pearson_99 0.8008668802583744
rscore 0.7185614081551683
rscore_95 -1.0106088436872294
rscore_99 -5.19646456646777
nse [0.71856141]
nse_95 [-1.01060884]
nse_99 [-5.19646457]
kge [0.66763656]
ext_kge_95 [0.53163082]
ext_kge_99 [0.02304573]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.25 -10.11 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.74 11.88 ... -3.22
    uw2             (time, latitude, longitude) float32 105.0 102.2 ... 5.353
    vw2             (time, latitude, longitude) float32 137.8 141.1 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.58 15.6 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([69849 69873 69897], shape=(3,), dtype=int64) Times out: tf.Tensor(69897, shape=(), dtype=int64)
Times in: tf.Tensor([102884 102908 102932], shape=(3,), dtype=int64) Times out: tf.Tensor(102932, shape=(), dtype=int64)
Times in: tf.Tensor([12124 12148 12172], shape=(3,), dtype=int64) Times out: tf.Tensor(12172, shape=(), dtype=int64)
Times in: tf.Tensor([129770 129794 129818], shape=(3,), dtype=int64) Times out: tf.Tensor(129818, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_558&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_559 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1116 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1117 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_558 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1116 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_558 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1117 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.5830 - mse: 45.5314 - mae: 5.2127 - val_loss: 33.5916 - val_mse: 33.5330 - val_mae: 4.6450
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1991 - mse: 35.1369 - mae: 4.6273 - val_loss: 31.7175 - val_mse: 31.6517 - val_mae: 4.5146
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3540 - mse: 34.2851 - mae: 4.5711 - val_loss: 30.9045 - val_mse: 30.8330 - val_mae: 4.4503
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0698 - mse: 33.9964 - mae: 4.5508 - val_loss: 31.1465 - val_mse: 31.0713 - val_mae: 4.4761
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8012 - mse: 33.7250 - mae: 4.5286 - val_loss: 30.8912 - val_mse: 30.8139 - val_mae: 4.4504
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6601 - mse: 33.5817 - mae: 4.5178 - val_loss: 30.7657 - val_mse: 30.6860 - val_mae: 4.4420
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4495 - mse: 33.3689 - mae: 4.5068 - val_loss: 31.1834 - val_mse: 31.1018 - val_mae: 4.4748
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3778 - mse: 33.2953 - mae: 4.5029 - val_loss: 31.6603 - val_mse: 31.5766 - val_mae: 4.5087
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2959 - mse: 33.2112 - mae: 4.4973 - val_loss: 30.9407 - val_mse: 30.8549 - val_mae: 4.4556
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1326 - mse: 33.0457 - mae: 4.4853 - val_loss: 31.5100 - val_mse: 31.4218 - val_mae: 4.4968
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9134 - mse: 32.8242 - mae: 4.4703 - val_loss: 31.5445 - val_mse: 31.4542 - val_mae: 4.4991
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8260 - mse: 32.7346 - mae: 4.4577 - val_loss: 31.2205 - val_mse: 31.1279 - val_mae: 4.4731
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6520 - mse: 32.5582 - mae: 4.4517 - val_loss: 30.3426 - val_mse: 30.2475 - val_mae: 4.4114
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4696 - mse: 32.3731 - mae: 4.4415 - val_loss: 30.4332 - val_mse: 30.3352 - val_mae: 4.4186
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1632 - mse: 32.0638 - mae: 4.4173 - val_loss: 30.4296 - val_mse: 30.3287 - val_mae: 4.4164
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9380 - mse: 31.8354 - mae: 4.4038 - val_loss: 30.0632 - val_mse: 29.9589 - val_mae: 4.3945
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5914 - mse: 31.4857 - mae: 4.3754 - val_loss: 30.0908 - val_mse: 29.9838 - val_mae: 4.3989
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3748 - mse: 31.2664 - mae: 4.3556 - val_loss: 29.9696 - val_mse: 29.8600 - val_mae: 4.3919
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1006 - mse: 30.9897 - mae: 4.3410 - val_loss: 29.7079 - val_mse: 29.5958 - val_mae: 4.3741
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9945 - mse: 30.8813 - mae: 4.3270 - val_loss: 28.4171 - val_mse: 28.3027 - val_mae: 4.2853
bias -0.0059159775
si 0.49590227
rmse 0.05320033
kgeprime [0.65539757]
rmse_95 0.07553065
rmse_99 0.089120835
pearson 0.8446793644254048
pearson_95 0.6591027331224436
pearson_99 0.8079552130946032
rscore 0.7098438200747335
rscore_95 -1.5449693513378038
rscore_99 -7.66360947582249
nse [0.70984382]
nse_95 [-1.54496935]
nse_99 [-7.66360948]
kge [0.73123632]
ext_kge_95 [0.52361097]
ext_kge_99 [0.07101399]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -3.22
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 5.353
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([152797 152821 152845], shape=(3,), dtype=int64) Times out: tf.Tensor(152845, shape=(), dtype=int64)
Times in: tf.Tensor([11837 11861 11885], shape=(3,), dtype=int64) Times out: tf.Tensor(11885, shape=(), dtype=int64)
Times in: tf.Tensor([48863 48887 48911], shape=(3,), dtype=int64) Times out: tf.Tensor(48911, shape=(), dtype=int64)
Times in: tf.Tensor([135383 135407 135431], shape=(3,), dtype=int64) Times out: tf.Tensor(135431, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_559&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_560 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1118 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1119 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_559 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1118 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_559 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1119 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.6765 - mse: 55.6353 - mae: 5.7713 - val_loss: 42.8584 - val_mse: 42.8147 - val_mae: 5.1689
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.3808 - mse: 43.3375 - mae: 5.1238 - val_loss: 35.1623 - val_mse: 35.1167 - val_mae: 4.7397
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1960 - mse: 36.1438 - mae: 4.7075 - val_loss: 32.4890 - val_mse: 32.4296 - val_mae: 4.5703
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3911 - mse: 34.3236 - mae: 4.5780 - val_loss: 31.3887 - val_mse: 31.3137 - val_mae: 4.4928
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4870 - mse: 33.4057 - mae: 4.5152 - val_loss: 31.4948 - val_mse: 31.4079 - val_mae: 4.4986
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1088 - mse: 33.0175 - mae: 4.4857 - val_loss: 30.9330 - val_mse: 30.8375 - val_mae: 4.4571
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8486 - mse: 32.7498 - mae: 4.4671 - val_loss: 31.3267 - val_mse: 31.2241 - val_mae: 4.4872
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6597 - mse: 32.5540 - mae: 4.4519 - val_loss: 30.8157 - val_mse: 30.7069 - val_mae: 4.4529
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4131 - mse: 32.3013 - mae: 4.4363 - val_loss: 30.5879 - val_mse: 30.4730 - val_mae: 4.4379
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2283 - mse: 32.1109 - mae: 4.4225 - val_loss: 31.2695 - val_mse: 31.1489 - val_mae: 4.4879
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0780 - mse: 31.9548 - mae: 4.4107 - val_loss: 31.2856 - val_mse: 31.1597 - val_mae: 4.4924
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8205 - mse: 31.6921 - mae: 4.3937 - val_loss: 30.5868 - val_mse: 30.4559 - val_mae: 4.4393
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7455 - mse: 31.6119 - mae: 4.3880 - val_loss: 29.8033 - val_mse: 29.6671 - val_mae: 4.3841
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.5103 - mse: 31.3718 - mae: 4.3693 - val_loss: 29.3216 - val_mse: 29.1808 - val_mae: 4.3521
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0844 - mse: 30.9418 - mae: 4.3431 - val_loss: 29.6081 - val_mse: 29.4637 - val_mae: 4.3741
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9768 - mse: 30.8309 - mae: 4.3360 - val_loss: 29.0588 - val_mse: 28.9115 - val_mae: 4.3371
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6291 - mse: 30.4806 - mae: 4.3081 - val_loss: 28.9927 - val_mse: 28.8427 - val_mae: 4.3366
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4087 - mse: 30.2575 - mae: 4.2902 - val_loss: 28.9807 - val_mse: 28.8285 - val_mae: 4.3345
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4302 - mse: 30.2771 - mae: 4.2896 - val_loss: 28.4588 - val_mse: 28.3051 - val_mae: 4.2981
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3173 - mse: 30.1626 - mae: 4.2778 - val_loss: 28.2488 - val_mse: 28.0933 - val_mae: 4.2809
bias -0.006537528
si 0.49140564
rmse 0.05300314
kgeprime [0.64637424]
rmse_95 0.07331203
rmse_99 0.08226659
pearson 0.847601698143363
pearson_95 0.6716739023050132
pearson_99 0.8408162267682344
rscore 0.7140500574140793
rscore_95 -1.3384160430428738
rscore_99 -6.429040991408437
nse [0.71405006]
nse_95 [-1.33841604]
nse_99 [-6.42904099]
kge [0.72744729]
ext_kge_95 [0.50979196]
ext_kge_99 [-0.03342932]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -3.22
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 5.353
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([146336 146360 146384], shape=(3,), dtype=int64) Times out: tf.Tensor(146384, shape=(), dtype=int64)
Times in: tf.Tensor([62129 62153 62177], shape=(3,), dtype=int64) Times out: tf.Tensor(62177, shape=(), dtype=int64)
Times in: tf.Tensor([42683 42707 42731], shape=(3,), dtype=int64) Times out: tf.Tensor(42731, shape=(), dtype=int64)
Times in: tf.Tensor([10947 10971 10995], shape=(3,), dtype=int64) Times out: tf.Tensor(10995, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_560&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_561 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1120 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1121 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_560 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1120 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_560 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1121 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.3014 - mse: 43.2435 - mae: 5.0699 - val_loss: 32.2306 - val_mse: 32.1627 - val_mae: 4.5586
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0296 - mse: 33.9555 - mae: 4.5486 - val_loss: 31.6445 - val_mse: 31.5651 - val_mae: 4.5103
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1616 - mse: 33.0782 - mae: 4.4893 - val_loss: 31.2459 - val_mse: 31.1586 - val_mae: 4.4803
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8504 - mse: 32.7593 - mae: 4.4659 - val_loss: 30.7644 - val_mse: 30.6694 - val_mae: 4.4468
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4500 - mse: 32.3508 - mae: 4.4383 - val_loss: 31.2350 - val_mse: 31.1318 - val_mae: 4.4757
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1446 - mse: 32.0373 - mae: 4.4173 - val_loss: 30.3558 - val_mse: 30.2445 - val_mae: 4.4173
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8044 - mse: 31.6889 - mae: 4.3945 - val_loss: 30.2208 - val_mse: 30.1010 - val_mae: 4.4119
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5923 - mse: 31.4687 - mae: 4.3779 - val_loss: 30.5168 - val_mse: 30.3892 - val_mae: 4.4286
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3143 - mse: 31.1831 - mae: 4.3579 - val_loss: 30.3069 - val_mse: 30.1719 - val_mae: 4.4159
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9660 - mse: 30.8274 - mae: 4.3362 - val_loss: 30.5690 - val_mse: 30.4270 - val_mae: 4.4379
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6653 - mse: 30.5203 - mae: 4.3120 - val_loss: 29.9646 - val_mse: 29.8166 - val_mae: 4.3995
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3099 - mse: 30.1598 - mae: 4.2899 - val_loss: 29.1448 - val_mse: 28.9924 - val_mae: 4.3455
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0891 - mse: 29.9352 - mae: 4.2703 - val_loss: 29.3145 - val_mse: 29.1590 - val_mae: 4.3557
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8328 - mse: 29.6756 - mae: 4.2508 - val_loss: 29.5187 - val_mse: 29.3600 - val_mae: 4.3719
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6398 - mse: 29.4801 - mae: 4.2361 - val_loss: 30.0034 - val_mse: 29.8424 - val_mae: 4.4004
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6838 - mse: 29.5219 - mae: 4.2401 - val_loss: 28.9615 - val_mse: 28.7984 - val_mae: 4.3304
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2707 - mse: 29.1068 - mae: 4.2109 - val_loss: 29.2600 - val_mse: 29.0951 - val_mae: 4.3486
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3274 - mse: 29.1617 - mae: 4.2139 - val_loss: 29.9628 - val_mse: 29.7963 - val_mae: 4.3968
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2684 - mse: 29.1011 - mae: 4.2058 - val_loss: 28.3394 - val_mse: 28.1716 - val_mae: 4.2819
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9914 - mse: 28.8228 - mae: 4.1907 - val_loss: 29.0027 - val_mse: 28.8333 - val_mae: 4.3266
bias -0.012653449
si 0.4900984
rmse 0.053696603
kgeprime [0.49699217]
rmse_95 0.069761604
rmse_99 0.081957944
pearson 0.848884677534439
pearson_95 0.6596608936095893
pearson_99 0.8084083232235659
rscore 0.70414138766511
rscore_95 -1.2046961031695957
rscore_99 -6.550164728610782
nse [0.70414139]
nse_95 [-1.2046961]
nse_99 [-6.55016473]
kge [0.61519551]
ext_kge_95 [0.52739458]
ext_kge_99 [0.0504279]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... 0.5726
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... -0.517
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 0.3278
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 0.2673
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 0.7714
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([18109 18133 18157], shape=(3,), dtype=int64) Times out: tf.Tensor(18157, shape=(), dtype=int64)
Times in: tf.Tensor([52052 52076 52100], shape=(3,), dtype=int64) Times out: tf.Tensor(52100, shape=(), dtype=int64)
Times in: tf.Tensor([100213 100237 100261], shape=(3,), dtype=int64) Times out: tf.Tensor(100261, shape=(), dtype=int64)
Times in: tf.Tensor([147331 147355 147379], shape=(3,), dtype=int64) Times out: tf.Tensor(147379, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_561&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_562 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1122 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1123 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_561 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1122 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_561 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1123 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.6032 - mse: 45.5591 - mae: 5.1861 - val_loss: 30.6218 - val_mse: 30.5704 - val_mae: 4.4457
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4742 - mse: 34.4191 - mae: 4.5725 - val_loss: 29.4370 - val_mse: 29.3784 - val_mae: 4.3704
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7927 - mse: 33.7308 - mae: 4.5280 - val_loss: 29.1036 - val_mse: 29.0386 - val_mae: 4.3406
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3860 - mse: 33.3178 - mae: 4.5021 - val_loss: 29.0979 - val_mse: 29.0264 - val_mae: 4.3420
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0846 - mse: 33.0105 - mae: 4.4814 - val_loss: 28.7067 - val_mse: 28.6297 - val_mae: 4.3148
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7507 - mse: 32.6709 - mae: 4.4568 - val_loss: 29.0000 - val_mse: 28.9176 - val_mae: 4.3373
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7538 - mse: 32.6687 - mae: 4.4603 - val_loss: 28.5702 - val_mse: 28.4822 - val_mae: 4.3071
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4755 - mse: 32.3849 - mae: 4.4378 - val_loss: 28.5382 - val_mse: 28.4451 - val_mae: 4.3052
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2147 - mse: 32.1188 - mae: 4.4188 - val_loss: 28.5770 - val_mse: 28.4786 - val_mae: 4.3007
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8862 - mse: 31.7850 - mae: 4.4029 - val_loss: 28.4266 - val_mse: 28.3227 - val_mae: 4.2930
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9728 - mse: 31.8664 - mae: 4.4033 - val_loss: 28.6972 - val_mse: 28.5884 - val_mae: 4.3092
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7219 - mse: 31.6104 - mae: 4.3856 - val_loss: 28.4426 - val_mse: 28.3288 - val_mae: 4.2979
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5837 - mse: 31.4676 - mae: 4.3763 - val_loss: 28.4636 - val_mse: 28.3451 - val_mae: 4.3003
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5684 - mse: 31.4477 - mae: 4.3726 - val_loss: 28.3391 - val_mse: 28.2162 - val_mae: 4.2901
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4306 - mse: 31.3054 - mae: 4.3634 - val_loss: 28.1569 - val_mse: 28.0297 - val_mae: 4.2754
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2536 - mse: 31.1239 - mae: 4.3565 - val_loss: 28.6559 - val_mse: 28.5240 - val_mae: 4.3117
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1460 - mse: 31.0121 - mae: 4.3463 - val_loss: 28.3264 - val_mse: 28.1906 - val_mae: 4.2871
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0266 - mse: 30.8886 - mae: 4.3374 - val_loss: 28.4485 - val_mse: 28.3088 - val_mae: 4.2984
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9783 - mse: 30.8364 - mae: 4.3348 - val_loss: 27.9457 - val_mse: 27.8022 - val_mae: 4.2618
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8251 - mse: 30.6796 - mae: 4.3229 - val_loss: 28.0211 - val_mse: 27.8739 - val_mae: 4.2683
bias -0.006105166
si 0.4970462
rmse 0.052795775
kgeprime [0.65885473]
rmse_95 0.071602434
rmse_99 0.082865655
pearson 0.8450336646311651
pearson_95 0.6305687035244902
pearson_99 0.7859307209723818
rscore 0.7100941380405694
rscore_95 -1.5005796312257536
rscore_99 -6.4295297177695785
nse [0.71009414]
nse_95 [-1.50057963]
nse_99 [-6.42952972]
kge [0.73647281]
ext_kge_95 [0.46801491]
ext_kge_99 [-0.11069553]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -44.18 -43.87
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 2.314
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -3.22
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 5.353
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 10.37
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 3.965
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([32474 32498 32522], shape=(3,), dtype=int64) Times out: tf.Tensor(32522, shape=(), dtype=int64)
Times in: tf.Tensor([47410 47434 47458], shape=(3,), dtype=int64) Times out: tf.Tensor(47458, shape=(), dtype=int64)
Times in: tf.Tensor([129819 129843 129867], shape=(3,), dtype=int64) Times out: tf.Tensor(129867, shape=(), dtype=int64)
Times in: tf.Tensor([16298 16322 16346], shape=(3,), dtype=int64) Times out: tf.Tensor(16346, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_562&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_563 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1124 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1125 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_562 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1124 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_562 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1125 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 49.7409 - mse: 49.6902 - mae: 5.4297 - val_loss: 34.0541 - val_mse: 33.9958 - val_mae: 4.6763
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1041 - mse: 37.0448 - mae: 4.7318 - val_loss: 32.0932 - val_mse: 32.0326 - val_mae: 4.5422
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5754 - mse: 35.5123 - mae: 4.6399 - val_loss: 32.6666 - val_mse: 32.6010 - val_mae: 4.5850
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7738 - mse: 34.7056 - mae: 4.5927 - val_loss: 31.5360 - val_mse: 31.4651 - val_mae: 4.5066
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4361 - mse: 34.3631 - mae: 4.5712 - val_loss: 31.3180 - val_mse: 31.2426 - val_mae: 4.4880
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2405 - mse: 34.1634 - mae: 4.5533 - val_loss: 31.5210 - val_mse: 31.4417 - val_mae: 4.5018
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9694 - mse: 33.8879 - mae: 4.5397 - val_loss: 31.5582 - val_mse: 31.4747 - val_mae: 4.5066
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8358 - mse: 33.7500 - mae: 4.5277 - val_loss: 31.8038 - val_mse: 31.7159 - val_mae: 4.5232
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6776 - mse: 33.5875 - mae: 4.5169 - val_loss: 31.2322 - val_mse: 31.1401 - val_mae: 4.4815
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4001 - mse: 33.3054 - mae: 4.4982 - val_loss: 31.1711 - val_mse: 31.0741 - val_mae: 4.4796
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1173 - mse: 33.0175 - mae: 4.4835 - val_loss: 31.1086 - val_mse: 31.0061 - val_mae: 4.4725
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1334 - mse: 33.0283 - mae: 4.4802 - val_loss: 30.9567 - val_mse: 30.8490 - val_mae: 4.4623
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8118 - mse: 32.7015 - mae: 4.4609 - val_loss: 30.0937 - val_mse: 29.9807 - val_mae: 4.4038
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5945 - mse: 32.4786 - mae: 4.4437 - val_loss: 30.8509 - val_mse: 30.7322 - val_mae: 4.4555
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3349 - mse: 32.2132 - mae: 4.4222 - val_loss: 29.9386 - val_mse: 29.8142 - val_mae: 4.3927
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9211 - mse: 31.7945 - mae: 4.3960 - val_loss: 30.1231 - val_mse: 29.9944 - val_mae: 4.4088
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6512 - mse: 31.5204 - mae: 4.3779 - val_loss: 29.9205 - val_mse: 29.7882 - val_mae: 4.3934
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3583 - mse: 31.2244 - mae: 4.3579 - val_loss: 29.7645 - val_mse: 29.6292 - val_mae: 4.3880
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2123 - mse: 31.0755 - mae: 4.3459 - val_loss: 28.9229 - val_mse: 28.7850 - val_mae: 4.3284
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0714 - mse: 30.9322 - mae: 4.3384 - val_loss: 28.9376 - val_mse: 28.7972 - val_mae: 4.3274
bias -0.011514792
si 0.4934499
rmse 0.053663023
kgeprime [0.52757938]
rmse_95 0.069739856
rmse_99 0.08069469
pearson 0.8464593561040226
pearson_95 0.659968930905135
pearson_99 0.823282833616707
rscore 0.7028031232886809
rscore_95 -1.2147875398294348
rscore_99 -6.234670846822515
nse [0.70280312]
nse_95 [-1.21478754]
nse_99 [-6.23467085]
kge [0.63996328]
ext_kge_95 [0.52477962]
ext_kge_99 [0.08454864]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.58 -10.41 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.4 11.58 ... 2.7 2.346
    uw2             (time, latitude, longitude) float32 111.9 108.3 ... 1.583
    vw2             (time, latitude, longitude) float32 130.0 134.1 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.55 15.57 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([80490 80514 80538], shape=(3,), dtype=int64) Times out: tf.Tensor(80538, shape=(), dtype=int64)
Times in: tf.Tensor([112294 112318 112342], shape=(3,), dtype=int64) Times out: tf.Tensor(112342, shape=(), dtype=int64)
Times in: tf.Tensor([133105 133129 133153], shape=(3,), dtype=int64) Times out: tf.Tensor(133153, shape=(), dtype=int64)
Times in: tf.Tensor([9748 9772 9796], shape=(3,), dtype=int64) Times out: tf.Tensor(9796, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_563&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_564 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1126 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1127 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_563 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1126 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_563 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1127 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.7598 - mse: 43.7080 - mae: 5.0962 - val_loss: 30.6800 - val_mse: 30.6197 - val_mae: 4.4463
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4391 - mse: 33.3728 - mae: 4.5082 - val_loss: 29.5288 - val_mse: 29.4569 - val_mae: 4.3712
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5950 - mse: 32.5182 - mae: 4.4500 - val_loss: 29.0778 - val_mse: 28.9968 - val_mae: 4.3372
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1403 - mse: 32.0558 - mae: 4.4171 - val_loss: 28.8985 - val_mse: 28.8107 - val_mae: 4.3242
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8805 - mse: 31.7895 - mae: 4.3963 - val_loss: 28.2096 - val_mse: 28.1158 - val_mae: 4.2717
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6194 - mse: 31.5225 - mae: 4.3791 - val_loss: 28.3928 - val_mse: 28.2930 - val_mae: 4.2886
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3322 - mse: 31.2294 - mae: 4.3616 - val_loss: 29.2762 - val_mse: 29.1706 - val_mae: 4.3513
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0302 - mse: 30.9215 - mae: 4.3400 - val_loss: 28.7910 - val_mse: 28.6797 - val_mae: 4.3178
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9392 - mse: 30.8249 - mae: 4.3324 - val_loss: 29.0011 - val_mse: 28.8840 - val_mae: 4.3308
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7448 - mse: 30.6248 - mae: 4.3224 - val_loss: 28.3857 - val_mse: 28.2630 - val_mae: 4.2882
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6318 - mse: 30.5062 - mae: 4.3111 - val_loss: 28.0296 - val_mse: 27.9011 - val_mae: 4.2611
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4326 - mse: 30.3015 - mae: 4.3010 - val_loss: 28.5463 - val_mse: 28.4126 - val_mae: 4.2973
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3326 - mse: 30.1962 - mae: 4.2880 - val_loss: 28.1568 - val_mse: 28.0179 - val_mae: 4.2710
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1729 - mse: 30.0315 - mae: 4.2791 - val_loss: 28.4042 - val_mse: 28.2603 - val_mae: 4.2876
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1438 - mse: 29.9975 - mae: 4.2727 - val_loss: 28.1005 - val_mse: 27.9518 - val_mae: 4.2665
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9576 - mse: 29.8067 - mae: 4.2625 - val_loss: 28.4547 - val_mse: 28.3014 - val_mae: 4.2896
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7510 - mse: 29.5956 - mae: 4.2469 - val_loss: 28.4464 - val_mse: 28.2892 - val_mae: 4.2865
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6981 - mse: 29.5388 - mae: 4.2446 - val_loss: 28.1958 - val_mse: 28.0345 - val_mae: 4.2691
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5701 - mse: 29.4068 - mae: 4.2314 - val_loss: 27.6705 - val_mse: 27.5054 - val_mae: 4.2344
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4994 - mse: 29.3327 - mae: 4.2267 - val_loss: 27.5117 - val_mse: 27.3433 - val_mae: 4.2177
bias -0.009807447
si 0.49216923
rmse 0.05229084
kgeprime [0.55506296]
rmse_95 0.06931185
rmse_99 0.08152964
pearson 0.8483192882224289
pearson_95 0.6170161084629568
pearson_99 0.7761434330064024
rscore 0.7093166546418055
rscore_95 -1.450756693741126
rscore_99 -6.842155652256795
nse [0.70931665]
nse_95 [-1.45075669]
nse_99 [-6.84215565]
kge [0.66236311]
ext_kge_95 [0.45666137]
ext_kge_99 [-0.19653517]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... 2.346
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 1.583
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([27071 27095 27119], shape=(3,), dtype=int64) Times out: tf.Tensor(27119, shape=(), dtype=int64)
Times in: tf.Tensor([73657 73681 73705], shape=(3,), dtype=int64) Times out: tf.Tensor(73705, shape=(), dtype=int64)
Times in: tf.Tensor([19775 19799 19823], shape=(3,), dtype=int64) Times out: tf.Tensor(19823, shape=(), dtype=int64)
Times in: tf.Tensor([154421 154445 154469], shape=(3,), dtype=int64) Times out: tf.Tensor(154469, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_564&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_565 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1128 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1129 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_564 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1128 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_564 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1129 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.2775 - mse: 55.2406 - mae: 5.7536 - val_loss: 33.7670 - val_mse: 33.7245 - val_mae: 4.6641
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4399 - mse: 38.3941 - mae: 4.8299 - val_loss: 31.2532 - val_mse: 31.2028 - val_mae: 4.4976
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8463 - mse: 35.7905 - mae: 4.6629 - val_loss: 30.0774 - val_mse: 30.0163 - val_mae: 4.4198
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3042 - mse: 35.2394 - mae: 4.6187 - val_loss: 29.6669 - val_mse: 29.5987 - val_mae: 4.3821
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9204 - mse: 34.8497 - mae: 4.5988 - val_loss: 29.7209 - val_mse: 29.6476 - val_mae: 4.3900
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6528 - mse: 34.5776 - mae: 4.5749 - val_loss: 29.5467 - val_mse: 29.4696 - val_mae: 4.3764
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6282 - mse: 34.5492 - mae: 4.5740 - val_loss: 29.7058 - val_mse: 29.6250 - val_mae: 4.3864
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4283 - mse: 34.3458 - mae: 4.5620 - val_loss: 29.0374 - val_mse: 28.9530 - val_mae: 4.3381
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3004 - mse: 34.2139 - mae: 4.5545 - val_loss: 29.0957 - val_mse: 29.0071 - val_mae: 4.3435
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9965 - mse: 33.9058 - mae: 4.5337 - val_loss: 28.7323 - val_mse: 28.6396 - val_mae: 4.3183
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.0351 - mse: 33.9405 - mae: 4.5351 - val_loss: 28.8016 - val_mse: 28.7054 - val_mae: 4.3239
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8100 - mse: 33.7115 - mae: 4.5205 - val_loss: 28.8522 - val_mse: 28.7517 - val_mae: 4.3267
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7787 - mse: 33.6765 - mae: 4.5144 - val_loss: 29.1368 - val_mse: 29.0330 - val_mae: 4.3500
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5369 - mse: 33.4309 - mae: 4.4988 - val_loss: 28.4500 - val_mse: 28.3423 - val_mae: 4.2994
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3588 - mse: 33.2493 - mae: 4.4946 - val_loss: 28.6166 - val_mse: 28.5054 - val_mae: 4.3140
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2368 - mse: 33.1236 - mae: 4.4830 - val_loss: 28.4698 - val_mse: 28.3550 - val_mae: 4.3009
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1745 - mse: 33.0582 - mae: 4.4784 - val_loss: 28.8831 - val_mse: 28.7652 - val_mae: 4.3347
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2804 - mse: 33.1609 - mae: 4.4814 - val_loss: 28.9550 - val_mse: 28.8337 - val_mae: 4.3389
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8269 - mse: 32.7041 - mae: 4.4588 - val_loss: 29.3379 - val_mse: 29.2139 - val_mae: 4.3649
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7304 - mse: 32.6049 - mae: 4.4450 - val_loss: 28.6194 - val_mse: 28.4926 - val_mae: 4.3148
bias -0.0078060017
si 0.49454668
rmse 0.053378478
kgeprime [0.6121984]
rmse_95 0.07332884
rmse_99 0.08795842
pearson 0.8464990538505777
pearson_95 0.6471869545870943
pearson_99 0.790799973123885
rscore 0.7103500740009017
rscore_95 -1.449809667419148
rscore_99 -6.868639296587878
nse [0.71035007]
nse_95 [-1.44980967]
nse_99 [-6.8686393]
kge [0.70446072]
ext_kge_95 [0.52613391]
ext_kge_99 [0.11493823]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -0.1666
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 0.02849
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([71629 71653 71677], shape=(3,), dtype=int64) Times out: tf.Tensor(71677, shape=(), dtype=int64)
Times in: tf.Tensor([123394 123418 123442], shape=(3,), dtype=int64) Times out: tf.Tensor(123442, shape=(), dtype=int64)
Times in: tf.Tensor([73633 73657 73681], shape=(3,), dtype=int64) Times out: tf.Tensor(73681, shape=(), dtype=int64)
Times in: tf.Tensor([120918 120942 120966], shape=(3,), dtype=int64) Times out: tf.Tensor(120966, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_565&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_566 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1130 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1131 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_565 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1130 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_565 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1131 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.6667 - mse: 48.6170 - mae: 5.3812 - val_loss: 33.2378 - val_mse: 33.1759 - val_mae: 4.6183
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0358 - mse: 34.9671 - mae: 4.6225 - val_loss: 32.1185 - val_mse: 32.0431 - val_mae: 4.5415
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0505 - mse: 33.9700 - mae: 4.5446 - val_loss: 31.6743 - val_mse: 31.5895 - val_mae: 4.5110
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6481 - mse: 33.5607 - mae: 4.5178 - val_loss: 30.9350 - val_mse: 30.8452 - val_mae: 4.4573
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3854 - mse: 33.2929 - mae: 4.4956 - val_loss: 30.8733 - val_mse: 30.7781 - val_mae: 4.4501
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2982 - mse: 33.1999 - mae: 4.4925 - val_loss: 30.7497 - val_mse: 30.6481 - val_mae: 4.4386
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8899 - mse: 32.7849 - mae: 4.4650 - val_loss: 30.7518 - val_mse: 30.6428 - val_mae: 4.4431
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6715 - mse: 32.5591 - mae: 4.4524 - val_loss: 30.6708 - val_mse: 30.5545 - val_mae: 4.4389
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4416 - mse: 32.3220 - mae: 4.4322 - val_loss: 30.3205 - val_mse: 30.1966 - val_mae: 4.4105
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1489 - mse: 32.0214 - mae: 4.4160 - val_loss: 30.8801 - val_mse: 30.7485 - val_mae: 4.4609
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8681 - mse: 31.7329 - mae: 4.3921 - val_loss: 30.4124 - val_mse: 30.2733 - val_mae: 4.4273
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6380 - mse: 31.4960 - mae: 4.3773 - val_loss: 30.5725 - val_mse: 30.4267 - val_mae: 4.4402
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6103 - mse: 31.4620 - mae: 4.3779 - val_loss: 31.2020 - val_mse: 31.0505 - val_mae: 4.4838
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4591 - mse: 31.3052 - mae: 4.3639 - val_loss: 30.3202 - val_mse: 30.1635 - val_mae: 4.4189
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2253 - mse: 31.0664 - mae: 4.3481 - val_loss: 29.6638 - val_mse: 29.5019 - val_mae: 4.3717
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0479 - mse: 30.8838 - mae: 4.3323 - val_loss: 30.2735 - val_mse: 30.1069 - val_mae: 4.4209
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9464 - mse: 30.7780 - mae: 4.3252 - val_loss: 30.8460 - val_mse: 30.6753 - val_mae: 4.4554
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7097 - mse: 30.5371 - mae: 4.3064 - val_loss: 30.0242 - val_mse: 29.8490 - val_mae: 4.3964
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4122 - mse: 30.2355 - mae: 4.2884 - val_loss: 30.1352 - val_mse: 29.9561 - val_mae: 4.4006
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3048 - mse: 30.1241 - mae: 4.2795 - val_loss: 29.3472 - val_mse: 29.1649 - val_mae: 4.3447
bias -0.011662488
si 0.49784365
rmse 0.05400452
kgeprime [0.51472534]
rmse_95 0.07197548
rmse_99 0.07873962
pearson 0.8434660281664358
pearson_95 0.6280108286402423
pearson_99 0.8135963176317542
rscore 0.6972522826690862
rscore_95 -1.4085814473890053
rscore_99 -6.009775330183473
nse [0.69725228]
nse_95 [-1.40858145]
nse_99 [-6.00977533]
kge [0.62935498]
ext_kge_95 [0.45088803]
ext_kge_99 [-0.10775012]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... 2.346
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 1.583
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([58233 58257 58281], shape=(3,), dtype=int64) Times out: tf.Tensor(58281, shape=(), dtype=int64)
Times in: tf.Tensor([38093 38117 38141], shape=(3,), dtype=int64) Times out: tf.Tensor(38141, shape=(), dtype=int64)
Times in: tf.Tensor([139394 139418 139442], shape=(3,), dtype=int64) Times out: tf.Tensor(139442, shape=(), dtype=int64)
Times in: tf.Tensor([47745 47769 47793], shape=(3,), dtype=int64) Times out: tf.Tensor(47793, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_566&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_567 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1132 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1133 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_566 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1132 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_566 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1133 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.0888 - mse: 44.0394 - mae: 5.1239 - val_loss: 31.3089 - val_mse: 31.2492 - val_mae: 4.5000
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7401 - mse: 33.6740 - mae: 4.5323 - val_loss: 30.2019 - val_mse: 30.1300 - val_mae: 4.4267
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8591 - mse: 32.7824 - mae: 4.4746 - val_loss: 30.2316 - val_mse: 30.1506 - val_mae: 4.4223
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2119 - mse: 32.1271 - mae: 4.4262 - val_loss: 29.7317 - val_mse: 29.6434 - val_mae: 4.3864
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9035 - mse: 31.8121 - mae: 4.4052 - val_loss: 29.5305 - val_mse: 29.4357 - val_mae: 4.3738
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5913 - mse: 31.4935 - mae: 4.3827 - val_loss: 28.9972 - val_mse: 28.8961 - val_mae: 4.3362
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1319 - mse: 31.0276 - mae: 4.3478 - val_loss: 29.9697 - val_mse: 29.8619 - val_mae: 4.4013
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7368 - mse: 30.6264 - mae: 4.3198 - val_loss: 28.2541 - val_mse: 28.1411 - val_mae: 4.2853
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3414 - mse: 30.2260 - mae: 4.2920 - val_loss: 27.9580 - val_mse: 27.8402 - val_mae: 4.2621
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0732 - mse: 29.9532 - mae: 4.2724 - val_loss: 28.4395 - val_mse: 28.3175 - val_mae: 4.2927
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8392 - mse: 29.7154 - mae: 4.2536 - val_loss: 28.4553 - val_mse: 28.3295 - val_mae: 4.2947
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7437 - mse: 29.6163 - mae: 4.2483 - val_loss: 27.2112 - val_mse: 27.0822 - val_mae: 4.2029
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5794 - mse: 29.4489 - mae: 4.2336 - val_loss: 26.9796 - val_mse: 26.8475 - val_mae: 4.1893
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4006 - mse: 29.2670 - mae: 4.2251 - val_loss: 26.9850 - val_mse: 26.8501 - val_mae: 4.1872
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2464 - mse: 29.1099 - mae: 4.2114 - val_loss: 27.5571 - val_mse: 27.4193 - val_mae: 4.2275
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3962 - mse: 29.2573 - mae: 4.2207 - val_loss: 27.4775 - val_mse: 27.3374 - val_mae: 4.2175
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1374 - mse: 28.9962 - mae: 4.1976 - val_loss: 28.5071 - val_mse: 28.3648 - val_mae: 4.2902
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1026 - mse: 28.9592 - mae: 4.1992 - val_loss: 27.1928 - val_mse: 27.0487 - val_mae: 4.1964
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9578 - mse: 28.8125 - mae: 4.1841 - val_loss: 27.4485 - val_mse: 27.3021 - val_mae: 4.2117
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8625 - mse: 28.7153 - mae: 4.1820 - val_loss: 26.5087 - val_mse: 26.3604 - val_mae: 4.1472
bias -0.008814382
si 0.47906607
rmse 0.051342398
kgeprime [0.60132493]
rmse_95 0.066275716
rmse_99 0.081039354
pearson 0.8568239292750953
pearson_95 0.6667552312601184
pearson_99 0.7955203094432074
rscore 0.7260332622967651
rscore_95 -1.116295088387337
rscore_99 -6.430030862709365
nse [0.72603326]
nse_95 [-1.11629509]
nse_99 [-6.43003086]
kge [0.69971103]
ext_kge_95 [0.53051756]
ext_kge_99 [-0.12244227]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -0.1666
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 0.02849
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([117975 117999 118023], shape=(3,), dtype=int64) Times out: tf.Tensor(118023, shape=(), dtype=int64)
Times in: tf.Tensor([30341 30365 30389], shape=(3,), dtype=int64) Times out: tf.Tensor(30389, shape=(), dtype=int64)
Times in: tf.Tensor([125483 125507 125531], shape=(3,), dtype=int64) Times out: tf.Tensor(125531, shape=(), dtype=int64)
Times in: tf.Tensor([53166 53190 53214], shape=(3,), dtype=int64) Times out: tf.Tensor(53214, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_567&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_568 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1134 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1135 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_567 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1134 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_567 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1135 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.3462 - mse: 41.2965 - mae: 4.9743 - val_loss: 33.8519 - val_mse: 33.7951 - val_mae: 4.6695
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6921 - mse: 33.6292 - mae: 4.5311 - val_loss: 32.4128 - val_mse: 32.3437 - val_mae: 4.5644
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6506 - mse: 32.5757 - mae: 4.4608 - val_loss: 31.4434 - val_mse: 31.3631 - val_mae: 4.4948
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1291 - mse: 32.0440 - mae: 4.4187 - val_loss: 31.5580 - val_mse: 31.4689 - val_mae: 4.5042
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4505 - mse: 31.3572 - mae: 4.3760 - val_loss: 31.7805 - val_mse: 31.6833 - val_mae: 4.5152
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6999 - mse: 30.5986 - mae: 4.3164 - val_loss: 31.9860 - val_mse: 31.8808 - val_mae: 4.5319
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0445 - mse: 29.9356 - mae: 4.2670 - val_loss: 30.2043 - val_mse: 30.0921 - val_mae: 4.4116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5698 - mse: 29.4546 - mae: 4.2354 - val_loss: 30.9507 - val_mse: 30.8328 - val_mae: 4.4629
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3167 - mse: 29.1964 - mae: 4.2149 - val_loss: 29.6981 - val_mse: 29.5755 - val_mae: 4.3730
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1182 - mse: 28.9936 - mae: 4.1989 - val_loss: 30.7708 - val_mse: 30.6444 - val_mae: 4.4525
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9526 - mse: 28.8241 - mae: 4.1859 - val_loss: 29.0051 - val_mse: 28.8748 - val_mae: 4.3247
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7629 - mse: 28.6305 - mae: 4.1747 - val_loss: 29.4863 - val_mse: 29.3520 - val_mae: 4.3601
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6306 - mse: 28.4945 - mae: 4.1615 - val_loss: 28.7483 - val_mse: 28.6101 - val_mae: 4.3084
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5051 - mse: 28.3650 - mae: 4.1549 - val_loss: 29.5243 - val_mse: 29.3826 - val_mae: 4.3628
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4425 - mse: 28.2990 - mae: 4.1469 - val_loss: 29.4143 - val_mse: 29.2690 - val_mae: 4.3581
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3898 - mse: 28.2426 - mae: 4.1427 - val_loss: 28.6831 - val_mse: 28.5342 - val_mae: 4.3038
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2030 - mse: 28.0522 - mae: 4.1361 - val_loss: 28.4212 - val_mse: 28.2688 - val_mae: 4.2848
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1626 - mse: 28.0085 - mae: 4.1278 - val_loss: 28.6808 - val_mse: 28.5250 - val_mae: 4.3059
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0971 - mse: 27.9397 - mae: 4.1244 - val_loss: 28.9362 - val_mse: 28.7774 - val_mae: 4.3242
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9373 - mse: 27.7768 - mae: 4.1103 - val_loss: 28.4839 - val_mse: 28.3218 - val_mae: 4.2899
bias -0.014724045
si 0.48416245
rmse 0.05321825
kgeprime [0.4555182]
rmse_95 0.063595735
rmse_99 0.07052668
pearson 0.8527174658077594
pearson_95 0.6707629867667261
pearson_99 0.7908189787786729
rscore 0.7043925393763417
rscore_95 -0.9068232599803472
rscore_99 -4.7250291564340285
nse [0.70439254]
nse_95 [-0.90682326]
nse_99 [-4.72502916]
kge [0.57811038]
ext_kge_95 [0.5222165]
ext_kge_99 [-0.01015539]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... 2.346
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 1.583
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([112425 112449 112473], shape=(3,), dtype=int64) Times out: tf.Tensor(112473, shape=(), dtype=int64)
Times in: tf.Tensor([140780 140804 140828], shape=(3,), dtype=int64) Times out: tf.Tensor(140828, shape=(), dtype=int64)
Times in: tf.Tensor([68803 68827 68851], shape=(3,), dtype=int64) Times out: tf.Tensor(68851, shape=(), dtype=int64)
Times in: tf.Tensor([29979 30003 30027], shape=(3,), dtype=int64) Times out: tf.Tensor(30027, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_568&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_569 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1136 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1137 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_568 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1136 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_568 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1137 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.2246 - mse: 44.1712 - mae: 5.1275 - val_loss: 30.8772 - val_mse: 30.8127 - val_mae: 4.4776
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3557 - mse: 33.2839 - mae: 4.5094 - val_loss: 29.2162 - val_mse: 29.1367 - val_mae: 4.3524
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1544 - mse: 32.0686 - mae: 4.4236 - val_loss: 28.8089 - val_mse: 28.7172 - val_mae: 4.3178
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5617 - mse: 31.4652 - mae: 4.3846 - val_loss: 28.4210 - val_mse: 28.3194 - val_mae: 4.2892
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3539 - mse: 31.2484 - mae: 4.3651 - val_loss: 28.1255 - val_mse: 28.0157 - val_mae: 4.2649
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9610 - mse: 30.8477 - mae: 4.3372 - val_loss: 28.0888 - val_mse: 27.9714 - val_mae: 4.2623
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6757 - mse: 30.5544 - mae: 4.3127 - val_loss: 27.8838 - val_mse: 27.7577 - val_mae: 4.2514
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1205 - mse: 29.9904 - mae: 4.2775 - val_loss: 27.3901 - val_mse: 27.2552 - val_mae: 4.2161
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7202 - mse: 29.5818 - mae: 4.2490 - val_loss: 27.2359 - val_mse: 27.0934 - val_mae: 4.2035
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4238 - mse: 29.2783 - mae: 4.2239 - val_loss: 27.1121 - val_mse: 26.9631 - val_mae: 4.1895
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0791 - mse: 28.9278 - mae: 4.2005 - val_loss: 26.5552 - val_mse: 26.4010 - val_mae: 4.1519
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8781 - mse: 28.7218 - mae: 4.1787 - val_loss: 26.2088 - val_mse: 26.0501 - val_mae: 4.1265
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7931 - mse: 28.6326 - mae: 4.1771 - val_loss: 26.4940 - val_mse: 26.3314 - val_mae: 4.1476
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5802 - mse: 28.4161 - mae: 4.1574 - val_loss: 26.0380 - val_mse: 25.8721 - val_mae: 4.1123
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4935 - mse: 28.3262 - mae: 4.1516 - val_loss: 25.7861 - val_mse: 25.6172 - val_mae: 4.0928
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3323 - mse: 28.1623 - mae: 4.1449 - val_loss: 25.6555 - val_mse: 25.4840 - val_mae: 4.0788
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2136 - mse: 28.0411 - mae: 4.1329 - val_loss: 25.8358 - val_mse: 25.6619 - val_mae: 4.0988
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1995 - mse: 28.0246 - mae: 4.1295 - val_loss: 25.3555 - val_mse: 25.1795 - val_mae: 4.0572
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1293 - mse: 27.9525 - mae: 4.1269 - val_loss: 26.0769 - val_mse: 25.8991 - val_mae: 4.1159
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9913 - mse: 27.8127 - mae: 4.1155 - val_loss: 25.7670 - val_mse: 25.5875 - val_mae: 4.0888
bias -0.007099495
si 0.47867435
rmse 0.05058406
kgeprime [0.65390504]
rmse_95 0.06365578
rmse_99 0.0753118
pearson 0.8574020592070157
pearson_95 0.6760539955719178
pearson_99 0.7732218290239917
rscore 0.729289582665799
rscore_95 -1.0425269894360936
rscore_99 -5.71514701434803
nse [0.72928958]
nse_95 [-1.04252699]
nse_99 [-5.71514701]
kge [0.73844326]
ext_kge_95 [0.51889705]
ext_kge_99 [-0.15088314]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.41 -10.25 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.58 11.74 ... 2.346
    uw2             (time, latitude, longitude) float32 108.3 105.0 ... 1.583
    vw2             (time, latitude, longitude) float32 134.1 137.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.57 15.58 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([69330 69354 69378], shape=(3,), dtype=int64) Times out: tf.Tensor(69378, shape=(), dtype=int64)
Times in: tf.Tensor([120233 120257 120281], shape=(3,), dtype=int64) Times out: tf.Tensor(120281, shape=(), dtype=int64)
Times in: tf.Tensor([51289 51313 51337], shape=(3,), dtype=int64) Times out: tf.Tensor(51337, shape=(), dtype=int64)
Times in: tf.Tensor([105519 105543 105567], shape=(3,), dtype=int64) Times out: tf.Tensor(105567, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_569&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_570 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1138 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1139 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_569 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1138 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_569 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1139 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.5138 - mse: 46.4523 - mae: 5.2462 - val_loss: 32.0071 - val_mse: 31.9297 - val_mae: 4.5430
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6817 - mse: 34.5981 - mae: 4.5925 - val_loss: 30.4077 - val_mse: 30.3198 - val_mae: 4.4331
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9361 - mse: 33.8447 - mae: 4.5370 - val_loss: 31.2896 - val_mse: 31.1944 - val_mae: 4.4877
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5287 - mse: 33.4304 - mae: 4.5108 - val_loss: 30.2994 - val_mse: 30.1980 - val_mae: 4.4147
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3149 - mse: 33.2108 - mae: 4.4932 - val_loss: 29.8787 - val_mse: 29.7724 - val_mae: 4.3884
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0753 - mse: 32.9670 - mae: 4.4754 - val_loss: 30.2115 - val_mse: 30.1010 - val_mae: 4.4098
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7991 - mse: 32.6865 - mae: 4.4552 - val_loss: 30.0480 - val_mse: 29.9333 - val_mae: 4.4004
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7156 - mse: 32.5990 - mae: 4.4514 - val_loss: 30.0975 - val_mse: 29.9788 - val_mae: 4.4057
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6360 - mse: 32.5155 - mae: 4.4472 - val_loss: 29.9597 - val_mse: 29.8371 - val_mae: 4.3958
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4239 - mse: 32.2996 - mae: 4.4299 - val_loss: 31.0261 - val_mse: 30.8995 - val_mae: 4.4704
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1904 - mse: 32.0624 - mae: 4.4152 - val_loss: 29.8894 - val_mse: 29.7596 - val_mae: 4.3960
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1498 - mse: 32.0184 - mae: 4.4136 - val_loss: 30.2053 - val_mse: 30.0719 - val_mae: 4.4162
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9266 - mse: 31.7920 - mae: 4.3991 - val_loss: 30.2930 - val_mse: 30.1563 - val_mae: 4.4208
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8285 - mse: 31.6902 - mae: 4.3922 - val_loss: 29.5235 - val_mse: 29.3834 - val_mae: 4.3716
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6554 - mse: 31.5138 - mae: 4.3748 - val_loss: 29.0527 - val_mse: 28.9092 - val_mae: 4.3362
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4169 - mse: 31.2718 - mae: 4.3586 - val_loss: 29.8871 - val_mse: 29.7404 - val_mae: 4.3944
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1996 - mse: 31.0516 - mae: 4.3428 - val_loss: 28.8320 - val_mse: 28.6828 - val_mae: 4.3237
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0272 - mse: 30.8767 - mae: 4.3287 - val_loss: 28.4252 - val_mse: 28.2735 - val_mae: 4.2915
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8298 - mse: 30.6771 - mae: 4.3134 - val_loss: 28.9479 - val_mse: 28.7940 - val_mae: 4.3322
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6915 - mse: 30.5372 - mae: 4.3066 - val_loss: 29.0314 - val_mse: 28.8762 - val_mae: 4.3316
bias -0.012842773
si 0.4837787
rmse 0.05373655
kgeprime [0.50081231]
rmse_95 0.065266505
rmse_99 0.079581045
pearson 0.8535354345003796
pearson_95 0.6812361187959175
pearson_99 0.8458797298450657
rscore 0.7120768378579875
rscore_95 -0.8244879843910791
rscore_99 -5.2250566580350375
nse [0.71207684]
nse_95 [-0.82448798]
nse_99 [-5.22505666]
kge [0.61839855]
ext_kge_95 [0.57546915]
ext_kge_99 [0.0246864]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -0.1666
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 0.02849
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([137631 137655 137679], shape=(3,), dtype=int64) Times out: tf.Tensor(137679, shape=(), dtype=int64)
Times in: tf.Tensor([14669 14693 14717], shape=(3,), dtype=int64) Times out: tf.Tensor(14717, shape=(), dtype=int64)
Times in: tf.Tensor([131959 131983 132007], shape=(3,), dtype=int64) Times out: tf.Tensor(132007, shape=(), dtype=int64)
Times in: tf.Tensor([144566 144590 144614], shape=(3,), dtype=int64) Times out: tf.Tensor(144614, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_570&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_571 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1140 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1141 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_570 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1140 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_570 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1141 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.2929 - mse: 47.2429 - mae: 5.3084 - val_loss: 32.8273 - val_mse: 32.7653 - val_mae: 4.5942
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3718 - mse: 35.3025 - mae: 4.6441 - val_loss: 31.6194 - val_mse: 31.5433 - val_mae: 4.5098
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0322 - mse: 33.9495 - mae: 4.5438 - val_loss: 30.8202 - val_mse: 30.7319 - val_mae: 4.4493
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4784 - mse: 33.3862 - mae: 4.5066 - val_loss: 31.2352 - val_mse: 31.1395 - val_mae: 4.4774
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1491 - mse: 33.0514 - mae: 4.4832 - val_loss: 30.2241 - val_mse: 30.1244 - val_mae: 4.4006
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8567 - mse: 32.7553 - mae: 4.4616 - val_loss: 30.1424 - val_mse: 30.0393 - val_mae: 4.3936
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6623 - mse: 32.5576 - mae: 4.4475 - val_loss: 30.5468 - val_mse: 30.4404 - val_mae: 4.4250
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2835 - mse: 32.1755 - mae: 4.4228 - val_loss: 29.3719 - val_mse: 29.2625 - val_mae: 4.3365
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1138 - mse: 32.0022 - mae: 4.4111 - val_loss: 29.5617 - val_mse: 29.4481 - val_mae: 4.3554
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9399 - mse: 31.8241 - mae: 4.3981 - val_loss: 29.0103 - val_mse: 28.8924 - val_mae: 4.3195
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4087 - mse: 31.2886 - mae: 4.3571 - val_loss: 28.7598 - val_mse: 28.6376 - val_mae: 4.3067
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1599 - mse: 31.0355 - mae: 4.3368 - val_loss: 28.2864 - val_mse: 28.1604 - val_mae: 4.2771
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9687 - mse: 30.8406 - mae: 4.3234 - val_loss: 28.3536 - val_mse: 28.2239 - val_mae: 4.2846
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6557 - mse: 30.5246 - mae: 4.2996 - val_loss: 28.6672 - val_mse: 28.5347 - val_mae: 4.3081
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4858 - mse: 30.3518 - mae: 4.2854 - val_loss: 27.6693 - val_mse: 27.5340 - val_mae: 4.2341
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4842 - mse: 30.3475 - mae: 4.2881 - val_loss: 27.8122 - val_mse: 27.6740 - val_mae: 4.2463
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3196 - mse: 30.1802 - mae: 4.2749 - val_loss: 27.5466 - val_mse: 27.4060 - val_mae: 4.2256
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2096 - mse: 30.0676 - mae: 4.2677 - val_loss: 27.7344 - val_mse: 27.5911 - val_mae: 4.2400
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2268 - mse: 30.0824 - mae: 4.2674 - val_loss: 27.1332 - val_mse: 26.9877 - val_mae: 4.1938
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1052 - mse: 29.9585 - mae: 4.2575 - val_loss: 27.9982 - val_mse: 27.8505 - val_mae: 4.2577
bias -0.010993641
si 0.49366167
rmse 0.052773606
kgeprime [0.54292525]
rmse_95 0.06710619
rmse_99 0.077176884
pearson 0.8464042343033071
pearson_95 0.6902936824417578
pearson_99 0.7794760716994679
rscore 0.7033148388098072
rscore_95 -1.173263325212658
rscore_99 -5.700501639850884
nse [0.70331484]
nse_95 [-1.17326333]
nse_99 [-5.70050164]
kge [0.65190845]
ext_kge_95 [0.54178106]
ext_kge_99 [0.04370973]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.42 -50.11 -49.8 ... -43.87 -43.56
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.11 -9.998 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.88 11.89 ... -0.1666
    uw2             (time, latitude, longitude) float32 102.2 99.97 ... 0.02849
    vw2             (time, latitude, longitude) float32 141.1 141.4 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.6 15.53 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([117467 117491 117515], shape=(3,), dtype=int64) Times out: tf.Tensor(117515, shape=(), dtype=int64)
Times in: tf.Tensor([52703 52727 52751], shape=(3,), dtype=int64) Times out: tf.Tensor(52751, shape=(), dtype=int64)
Times in: tf.Tensor([5797 5821 5845], shape=(3,), dtype=int64) Times out: tf.Tensor(5845, shape=(), dtype=int64)
Times in: tf.Tensor([150502 150526 150550], shape=(3,), dtype=int64) Times out: tf.Tensor(150550, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_571&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_572 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1142 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1143 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_571 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1142 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_571 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1143 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.4604 - mse: 47.4160 - mae: 5.3099 - val_loss: 32.4848 - val_mse: 32.4288 - val_mae: 4.5637
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1775 - mse: 35.1158 - mae: 4.6204 - val_loss: 31.0117 - val_mse: 30.9456 - val_mae: 4.4590
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1799 - mse: 34.1098 - mae: 4.5538 - val_loss: 30.6134 - val_mse: 30.5396 - val_mae: 4.4252
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6516 - mse: 33.5743 - mae: 4.5190 - val_loss: 30.3062 - val_mse: 30.2263 - val_mae: 4.3981
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3685 - mse: 33.2855 - mae: 4.4982 - val_loss: 30.6572 - val_mse: 30.5715 - val_mae: 4.4262
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1916 - mse: 33.1032 - mae: 4.4867 - val_loss: 30.3403 - val_mse: 30.2493 - val_mae: 4.4042
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0124 - mse: 32.9186 - mae: 4.4738 - val_loss: 30.3683 - val_mse: 30.2719 - val_mae: 4.4038
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7820 - mse: 32.6826 - mae: 4.4564 - val_loss: 30.1123 - val_mse: 30.0102 - val_mae: 4.3876
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4865 - mse: 32.3815 - mae: 4.4372 - val_loss: 29.8420 - val_mse: 29.7344 - val_mae: 4.3724
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3133 - mse: 32.2028 - mae: 4.4254 - val_loss: 29.4603 - val_mse: 29.3474 - val_mae: 4.3450
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2808 - mse: 32.1650 - mae: 4.4222 - val_loss: 29.6287 - val_mse: 29.5106 - val_mae: 4.3582
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0392 - mse: 31.9184 - mae: 4.4029 - val_loss: 30.0487 - val_mse: 29.9256 - val_mae: 4.3894
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9844 - mse: 31.8587 - mae: 4.3984 - val_loss: 29.7505 - val_mse: 29.6226 - val_mae: 4.3720
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8063 - mse: 31.6762 - mae: 4.3869 - val_loss: 29.6385 - val_mse: 29.5063 - val_mae: 4.3617
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5465 - mse: 31.4123 - mae: 4.3668 - val_loss: 29.6541 - val_mse: 29.5177 - val_mae: 4.3636
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3372 - mse: 31.1988 - mae: 4.3490 - val_loss: 28.8262 - val_mse: 28.6859 - val_mae: 4.3072
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1611 - mse: 31.0193 - mae: 4.3405 - val_loss: 28.6431 - val_mse: 28.4999 - val_mae: 4.2983
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9383 - mse: 30.7940 - mae: 4.3229 - val_loss: 29.4369 - val_mse: 29.2915 - val_mae: 4.3576
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7087 - mse: 30.5623 - mae: 4.3085 - val_loss: 28.6622 - val_mse: 28.5149 - val_mae: 4.3026
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6054 - mse: 30.4574 - mae: 4.2989 - val_loss: 28.6291 - val_mse: 28.4801 - val_mae: 4.3008
bias -0.008980587
si 0.4999054
rmse 0.05336679
kgeprime [0.58354629]
rmse_95 0.072928995
rmse_99 0.08408462
pearson 0.8420421640598358
pearson_95 0.6951160044915002
pearson_99 0.7791506854809107
rscore 0.7005450228059229
rscore_95 -1.5273365376672419
rscore_99 -7.055006921444045
nse [0.70054502]
nse_95 [-1.52733654]
nse_99 [-7.05500692]
kge [0.6829568]
ext_kge_95 [0.54067825]
ext_kge_99 [0.09225673]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 2.346
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 1.583
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([133411 133435 133459], shape=(3,), dtype=int64) Times out: tf.Tensor(133459, shape=(), dtype=int64)
Times in: tf.Tensor([101798 101822 101846], shape=(3,), dtype=int64) Times out: tf.Tensor(101846, shape=(), dtype=int64)
Times in: tf.Tensor([65637 65661 65685], shape=(3,), dtype=int64) Times out: tf.Tensor(65685, shape=(), dtype=int64)
Times in: tf.Tensor([ 9967  9991 10015], shape=(3,), dtype=int64) Times out: tf.Tensor(10015, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_572&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_573 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1144 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1145 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_572 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1144 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_572 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1145 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.7958 - mse: 45.7449 - mae: 5.2182 - val_loss: 32.1966 - val_mse: 32.1349 - val_mae: 4.5497
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3258 - mse: 34.2577 - mae: 4.5714 - val_loss: 30.7210 - val_mse: 30.6474 - val_mae: 4.4563
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3103 - mse: 33.2327 - mae: 4.4966 - val_loss: 30.6372 - val_mse: 30.5560 - val_mae: 4.4482
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7183 - mse: 32.6347 - mae: 4.4603 - val_loss: 30.1947 - val_mse: 30.1086 - val_mae: 4.4145
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6528 - mse: 32.5651 - mae: 4.4510 - val_loss: 30.1808 - val_mse: 30.0908 - val_mae: 4.4118
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2613 - mse: 32.1700 - mae: 4.4233 - val_loss: 30.9933 - val_mse: 30.9001 - val_mae: 4.4673
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0739 - mse: 31.9793 - mae: 4.4101 - val_loss: 30.3340 - val_mse: 30.2378 - val_mae: 4.4249
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7509 - mse: 31.6529 - mae: 4.3869 - val_loss: 29.2076 - val_mse: 29.1078 - val_mae: 4.3451
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3939 - mse: 31.2920 - mae: 4.3629 - val_loss: 29.6449 - val_mse: 29.5409 - val_mae: 4.3759
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8704 - mse: 30.7642 - mae: 4.3278 - val_loss: 29.4929 - val_mse: 29.3845 - val_mae: 4.3619
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6589 - mse: 30.5487 - mae: 4.3117 - val_loss: 28.4263 - val_mse: 28.3144 - val_mae: 4.2933
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4292 - mse: 30.3159 - mae: 4.2920 - val_loss: 28.4382 - val_mse: 28.3230 - val_mae: 4.2963
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3005 - mse: 30.1839 - mae: 4.2787 - val_loss: 28.9070 - val_mse: 28.7888 - val_mae: 4.3257
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2093 - mse: 30.0896 - mae: 4.2718 - val_loss: 28.0409 - val_mse: 27.9197 - val_mae: 4.2645
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0401 - mse: 29.9175 - mae: 4.2582 - val_loss: 27.7277 - val_mse: 27.6035 - val_mae: 4.2421
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8223 - mse: 29.6967 - mae: 4.2448 - val_loss: 27.7927 - val_mse: 27.6657 - val_mae: 4.2424
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6174 - mse: 29.4891 - mae: 4.2316 - val_loss: 27.0598 - val_mse: 26.9303 - val_mae: 4.1902
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6305 - mse: 29.4997 - mae: 4.2292 - val_loss: 28.2914 - val_mse: 28.1592 - val_mae: 4.2756
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3301 - mse: 29.1967 - mae: 4.2063 - val_loss: 28.2109 - val_mse: 28.0763 - val_mae: 4.2729
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3913 - mse: 29.2555 - mae: 4.2086 - val_loss: 27.6748 - val_mse: 27.5380 - val_mae: 4.2339
bias -0.013071761
si 0.47631687
rmse 0.052476637
kgeprime [0.48474528]
rmse_95 0.06433445
rmse_99 0.07842448
pearson 0.8586806375954803
pearson_95 0.6926929410431573
pearson_99 0.8362991421024017
rscore 0.7195461902948779
rscore_95 -0.8894979494964959
rscore_99 -5.776028823830984
nse [0.71954619]
nse_95 [-0.88949795]
nse_99 [-5.77602882]
kge [0.60628771]
ext_kge_95 [0.57048731]
ext_kge_99 [-0.07884395]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... -0.1666
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.02849
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([103423 103447 103471], shape=(3,), dtype=int64) Times out: tf.Tensor(103471, shape=(), dtype=int64)
Times in: tf.Tensor([61396 61420 61444], shape=(3,), dtype=int64) Times out: tf.Tensor(61444, shape=(), dtype=int64)
Times in: tf.Tensor([88932 88956 88980], shape=(3,), dtype=int64) Times out: tf.Tensor(88980, shape=(), dtype=int64)
Times in: tf.Tensor([131546 131570 131594], shape=(3,), dtype=int64) Times out: tf.Tensor(131594, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_573&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_574 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1146 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1147 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_573 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1146 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_573 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1147 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.7969 - mse: 48.7418 - mae: 5.3651 - val_loss: 30.8048 - val_mse: 30.7321 - val_mae: 4.4403
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4812 - mse: 33.4021 - mae: 4.5060 - val_loss: 29.6331 - val_mse: 29.5492 - val_mae: 4.3608
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6072 - mse: 32.5211 - mae: 4.4438 - val_loss: 29.2646 - val_mse: 29.1764 - val_mae: 4.3323
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3947 - mse: 32.3051 - mae: 4.4288 - val_loss: 29.0285 - val_mse: 28.9376 - val_mae: 4.3120
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1232 - mse: 32.0304 - mae: 4.4145 - val_loss: 28.9086 - val_mse: 28.8139 - val_mae: 4.3037
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9383 - mse: 31.8408 - mae: 4.3983 - val_loss: 28.9799 - val_mse: 28.8800 - val_mae: 4.3068
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6316 - mse: 31.5288 - mae: 4.3766 - val_loss: 28.7594 - val_mse: 28.6536 - val_mae: 4.2953
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4374 - mse: 31.3287 - mae: 4.3647 - val_loss: 28.4408 - val_mse: 28.3292 - val_mae: 4.2722
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2855 - mse: 31.1704 - mae: 4.3495 - val_loss: 28.3975 - val_mse: 28.2795 - val_mae: 4.2690
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0909 - mse: 30.9694 - mae: 4.3382 - val_loss: 28.2292 - val_mse: 28.1049 - val_mae: 4.2563
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8845 - mse: 30.7569 - mae: 4.3220 - val_loss: 28.2016 - val_mse: 28.0711 - val_mae: 4.2589
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6807 - mse: 30.5472 - mae: 4.3114 - val_loss: 28.1996 - val_mse: 28.0635 - val_mae: 4.2627
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4895 - mse: 30.3505 - mae: 4.2972 - val_loss: 28.1003 - val_mse: 27.9586 - val_mae: 4.2561
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4186 - mse: 30.2744 - mae: 4.2875 - val_loss: 28.4548 - val_mse: 28.3080 - val_mae: 4.2855
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1636 - mse: 30.0148 - mae: 4.2713 - val_loss: 27.8559 - val_mse: 27.7051 - val_mae: 4.2405
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0648 - mse: 29.9117 - mae: 4.2684 - val_loss: 27.9930 - val_mse: 27.8378 - val_mae: 4.2521
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0684 - mse: 29.9113 - mae: 4.2617 - val_loss: 28.3583 - val_mse: 28.1996 - val_mae: 4.2806
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8542 - mse: 29.6938 - mae: 4.2469 - val_loss: 27.8306 - val_mse: 27.6689 - val_mae: 4.2403
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6540 - mse: 29.4903 - mae: 4.2344 - val_loss: 27.6008 - val_mse: 27.4358 - val_mae: 4.2254
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6127 - mse: 29.4462 - mae: 4.2280 - val_loss: 27.4945 - val_mse: 27.3269 - val_mae: 4.2154
bias -0.0041721854
si 0.507007
rmse 0.05227518
kgeprime [0.68991284]
rmse_95 0.07997173
rmse_99 0.09058185
pearson 0.8372470372474026
pearson_95 0.6707073362837297
pearson_99 0.6944443156738407
rscore 0.6990466987888688
rscore_95 -2.3253799332960163
rscore_99 -7.961415245406743
nse [0.6990467]
nse_95 [-2.32537993]
nse_99 [-7.96141525]
kge [0.7483627]
ext_kge_95 [0.49019217]
ext_kge_99 [0.11304137]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... -0.1666
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 0.02849
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([64239 64263 64287], shape=(3,), dtype=int64) Times out: tf.Tensor(64287, shape=(), dtype=int64)
Times in: tf.Tensor([139870 139894 139918], shape=(3,), dtype=int64) Times out: tf.Tensor(139918, shape=(), dtype=int64)
Times in: tf.Tensor([64428 64452 64476], shape=(3,), dtype=int64) Times out: tf.Tensor(64476, shape=(), dtype=int64)
Times in: tf.Tensor([133754 133778 133802], shape=(3,), dtype=int64) Times out: tf.Tensor(133802, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_574&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_575 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1148 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1149 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_574 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1148 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_574 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1149 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.6314 - mse: 42.5770 - mae: 5.0473 - val_loss: 31.5837 - val_mse: 31.5206 - val_mae: 4.5054
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4929 - mse: 33.4257 - mae: 4.5156 - val_loss: 30.6711 - val_mse: 30.6001 - val_mae: 4.4399
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4327 - mse: 32.3586 - mae: 4.4385 - val_loss: 29.8420 - val_mse: 29.7644 - val_mae: 4.3763
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8669 - mse: 31.7864 - mae: 4.4010 - val_loss: 29.3597 - val_mse: 29.2769 - val_mae: 4.3337
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5359 - mse: 31.4508 - mae: 4.3769 - val_loss: 29.7795 - val_mse: 29.6921 - val_mae: 4.3714
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3213 - mse: 31.2316 - mae: 4.3610 - val_loss: 29.4597 - val_mse: 29.3677 - val_mae: 4.3481
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9219 - mse: 30.8274 - mae: 4.3301 - val_loss: 30.1853 - val_mse: 30.0882 - val_mae: 4.4030
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3280 - mse: 30.2280 - mae: 4.2866 - val_loss: 28.4413 - val_mse: 28.3384 - val_mae: 4.2811
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8309 - mse: 29.7251 - mae: 4.2446 - val_loss: 28.3421 - val_mse: 28.2337 - val_mae: 4.2768
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3593 - mse: 29.2484 - mae: 4.2195 - val_loss: 27.6413 - val_mse: 27.5281 - val_mae: 4.2286
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1677 - mse: 29.0526 - mae: 4.2044 - val_loss: 27.0201 - val_mse: 26.9034 - val_mae: 4.1820
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8717 - mse: 28.7534 - mae: 4.1809 - val_loss: 27.1495 - val_mse: 27.0299 - val_mae: 4.1913
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7668 - mse: 28.6457 - mae: 4.1709 - val_loss: 26.8586 - val_mse: 26.7364 - val_mae: 4.1724
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5762 - mse: 28.4526 - mae: 4.1598 - val_loss: 27.1088 - val_mse: 26.9843 - val_mae: 4.1887
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5127 - mse: 28.3869 - mae: 4.1508 - val_loss: 26.5331 - val_mse: 26.4063 - val_mae: 4.1468
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3561 - mse: 28.2280 - mae: 4.1390 - val_loss: 26.4278 - val_mse: 26.2987 - val_mae: 4.1364
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3148 - mse: 28.1846 - mae: 4.1356 - val_loss: 26.3729 - val_mse: 26.2418 - val_mae: 4.1297
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3040 - mse: 28.1719 - mae: 4.1368 - val_loss: 26.3927 - val_mse: 26.2598 - val_mae: 4.1304
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1552 - mse: 28.0213 - mae: 4.1248 - val_loss: 26.7888 - val_mse: 26.6541 - val_mae: 4.1617
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0929 - mse: 27.9573 - mae: 4.1218 - val_loss: 26.0549 - val_mse: 25.9184 - val_mae: 4.1006
bias -0.0025141274
si 0.48825452
rmse 0.0509101
kgeprime [0.74038416]
rmse_95 0.07466001
rmse_99 0.0846618
pearson 0.8499999558890879
pearson_95 0.6995797643367314
pearson_99 0.7590221361856835
rscore 0.721821176809992
rscore_95 -1.719163753512725
rscore_99 -7.299448083496737
nse [0.72182118]
nse_95 [-1.71916375]
nse_99 [-7.29944808]
kge [0.77794195]
ext_kge_95 [0.52771924]
ext_kge_99 [0.06243875]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 2.346
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 1.583
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([20612 20636 20660], shape=(3,), dtype=int64) Times out: tf.Tensor(20660, shape=(), dtype=int64)
Times in: tf.Tensor([75630 75654 75678], shape=(3,), dtype=int64) Times out: tf.Tensor(75678, shape=(), dtype=int64)
Times in: tf.Tensor([40285 40309 40333], shape=(3,), dtype=int64) Times out: tf.Tensor(40333, shape=(), dtype=int64)
Times in: tf.Tensor([97133 97157 97181], shape=(3,), dtype=int64) Times out: tf.Tensor(97181, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_575&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_576 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1150 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1151 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_575 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1150 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_575 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1151 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.9959 - mse: 47.9369 - mae: 5.3214 - val_loss: 31.5647 - val_mse: 31.4879 - val_mae: 4.4958
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5877 - mse: 34.5060 - mae: 4.5739 - val_loss: 30.1932 - val_mse: 30.1080 - val_mae: 4.4131
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8703 - mse: 33.7831 - mae: 4.5314 - val_loss: 29.8550 - val_mse: 29.7657 - val_mae: 4.3887
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5572 - mse: 33.4662 - mae: 4.5128 - val_loss: 29.3525 - val_mse: 29.2600 - val_mae: 4.3528
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2353 - mse: 33.1409 - mae: 4.4863 - val_loss: 29.3335 - val_mse: 29.2375 - val_mae: 4.3508
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0484 - mse: 32.9504 - mae: 4.4739 - val_loss: 29.1061 - val_mse: 29.0060 - val_mae: 4.3360
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7455 - mse: 32.6434 - mae: 4.4538 - val_loss: 29.3025 - val_mse: 29.1981 - val_mae: 4.3477
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5103 - mse: 32.4038 - mae: 4.4359 - val_loss: 28.8690 - val_mse: 28.7600 - val_mae: 4.3215
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4656 - mse: 32.3539 - mae: 4.4354 - val_loss: 29.0998 - val_mse: 28.9850 - val_mae: 4.3333
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2286 - mse: 32.1112 - mae: 4.4170 - val_loss: 28.8982 - val_mse: 28.7778 - val_mae: 4.3241
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8639 - mse: 31.7407 - mae: 4.3918 - val_loss: 28.3780 - val_mse: 28.2516 - val_mae: 4.2901
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6263 - mse: 31.4969 - mae: 4.3749 - val_loss: 28.6962 - val_mse: 28.5636 - val_mae: 4.3066
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3318 - mse: 31.1961 - mae: 4.3504 - val_loss: 27.7641 - val_mse: 27.6250 - val_mae: 4.2515
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9276 - mse: 30.7861 - mae: 4.3245 - val_loss: 27.5772 - val_mse: 27.4335 - val_mae: 4.2343
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6287 - mse: 30.4832 - mae: 4.3006 - val_loss: 28.0562 - val_mse: 27.9085 - val_mae: 4.2635
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4979 - mse: 30.3488 - mae: 4.2912 - val_loss: 27.4178 - val_mse: 27.2671 - val_mae: 4.2200
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.3602 - mse: 30.2081 - mae: 4.2829 - val_loss: 26.7683 - val_mse: 26.6149 - val_mae: 4.1700
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2316 - mse: 30.0769 - mae: 4.2742 - val_loss: 27.1828 - val_mse: 27.0271 - val_mae: 4.1997
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2324 - mse: 30.0754 - mae: 4.2711 - val_loss: 26.7606 - val_mse: 26.6023 - val_mae: 4.1680
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0283 - mse: 29.8689 - mae: 4.2569 - val_loss: 26.6453 - val_mse: 26.4850 - val_mae: 4.1641
bias -0.0073164324
si 0.4795581
rmse 0.051463563
kgeprime [0.63685094]
rmse_95 0.06875525
rmse_99 0.08261506
pearson 0.8563574929836129
pearson_95 0.6880518850602951
pearson_99 0.8128572970087796
rscore 0.7278467737595007
rscore_95 -1.1912799174622344
rscore_99 -6.840186797034261
nse [0.72784677]
nse_95 [-1.19127992]
nse_99 [-6.8401868]
kge [0.72520982]
ext_kge_95 [0.55591923]
ext_kge_99 [0.00162377]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... -0.1666
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.02849
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([82870 82894 82918], shape=(3,), dtype=int64) Times out: tf.Tensor(82918, shape=(), dtype=int64)
Times in: tf.Tensor([1057 1081 1105], shape=(3,), dtype=int64) Times out: tf.Tensor(1105, shape=(), dtype=int64)
Times in: tf.Tensor([127971 127995 128019], shape=(3,), dtype=int64) Times out: tf.Tensor(128019, shape=(), dtype=int64)
Times in: tf.Tensor([75877 75901 75925], shape=(3,), dtype=int64) Times out: tf.Tensor(75925, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_576&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_577 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1152 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1153 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_576 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1152 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_576 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1153 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.7257 - mse: 42.6821 - mae: 5.0407 - val_loss: 30.6526 - val_mse: 30.6029 - val_mae: 4.4489
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9250 - mse: 32.8705 - mae: 4.4834 - val_loss: 29.3860 - val_mse: 29.3270 - val_mae: 4.3436
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0630 - mse: 32.0000 - mae: 4.4133 - val_loss: 29.3004 - val_mse: 29.2336 - val_mae: 4.3435
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7487 - mse: 31.6790 - mae: 4.3891 - val_loss: 28.7071 - val_mse: 28.6348 - val_mae: 4.2936
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4573 - mse: 31.3820 - mae: 4.3659 - val_loss: 28.8330 - val_mse: 28.7551 - val_mae: 4.3060
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3108 - mse: 31.2297 - mae: 4.3561 - val_loss: 28.5417 - val_mse: 28.4580 - val_mae: 4.2789
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8258 - mse: 30.7389 - mae: 4.3281 - val_loss: 28.6284 - val_mse: 28.5387 - val_mae: 4.2942
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5787 - mse: 30.4854 - mae: 4.3083 - val_loss: 28.5559 - val_mse: 28.4597 - val_mae: 4.2926
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5584 - mse: 30.4586 - mae: 4.3060 - val_loss: 28.3181 - val_mse: 28.2151 - val_mae: 4.2762
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2898 - mse: 30.1834 - mae: 4.2865 - val_loss: 27.9543 - val_mse: 27.8449 - val_mae: 4.2505
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1021 - mse: 29.9891 - mae: 4.2705 - val_loss: 28.0534 - val_mse: 27.9375 - val_mae: 4.2586
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9806 - mse: 29.8614 - mae: 4.2670 - val_loss: 27.7224 - val_mse: 27.6007 - val_mae: 4.2343
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7446 - mse: 29.6198 - mae: 4.2491 - val_loss: 27.7953 - val_mse: 27.6682 - val_mae: 4.2440
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5068 - mse: 29.3771 - mae: 4.2287 - val_loss: 27.9467 - val_mse: 27.8150 - val_mae: 4.2552
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5126 - mse: 29.3786 - mae: 4.2241 - val_loss: 28.2071 - val_mse: 28.0712 - val_mae: 4.2758
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2660 - mse: 29.1281 - mae: 4.2092 - val_loss: 27.6418 - val_mse: 27.5023 - val_mae: 4.2341
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0703 - mse: 28.9287 - mae: 4.1939 - val_loss: 27.3018 - val_mse: 27.1587 - val_mae: 4.2097
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9303 - mse: 28.7854 - mae: 4.1815 - val_loss: 27.1059 - val_mse: 26.9597 - val_mae: 4.1929
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8131 - mse: 28.6654 - mae: 4.1739 - val_loss: 27.0548 - val_mse: 26.9061 - val_mae: 4.1920
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5439 - mse: 28.3940 - mae: 4.1566 - val_loss: 26.7737 - val_mse: 26.6232 - val_mae: 4.1737
bias -0.0071140854
si 0.49924678
rmse 0.05159763
kgeprime [0.63947399]
rmse_95 0.06835765
rmse_99 0.07859384
pearson 0.8430897304805166
pearson_95 0.6853820973954119
pearson_99 0.7103725991598568
rscore 0.7044675429119435
rscore_95 -1.421826222409452
rscore_99 -6.300350685458891
nse [0.70446754]
nse_95 [-1.42182622]
nse_99 [-6.30035069]
kge [0.72432024]
ext_kge_95 [0.53134142]
ext_kge_99 [0.02236913]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 2.346
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 1.583
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([146623 146647 146671], shape=(3,), dtype=int64) Times out: tf.Tensor(146671, shape=(), dtype=int64)
Times in: tf.Tensor([147460 147484 147508], shape=(3,), dtype=int64) Times out: tf.Tensor(147508, shape=(), dtype=int64)
Times in: tf.Tensor([86784 86808 86832], shape=(3,), dtype=int64) Times out: tf.Tensor(86832, shape=(), dtype=int64)
Times in: tf.Tensor([129455 129479 129503], shape=(3,), dtype=int64) Times out: tf.Tensor(129503, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_577&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_578 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1154 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1155 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_577 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1154 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_577 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1155 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.4842 - mse: 46.4306 - mae: 5.2448 - val_loss: 30.9661 - val_mse: 30.9017 - val_mae: 4.4741
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3250 - mse: 34.2573 - mae: 4.5638 - val_loss: 30.3786 - val_mse: 30.3078 - val_mae: 4.4258
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5979 - mse: 33.5246 - mae: 4.5095 - val_loss: 29.3888 - val_mse: 29.3133 - val_mae: 4.3606
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2398 - mse: 33.1628 - mae: 4.4892 - val_loss: 29.2382 - val_mse: 29.1599 - val_mae: 4.3418
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0502 - mse: 32.9708 - mae: 4.4742 - val_loss: 29.4738 - val_mse: 29.3931 - val_mae: 4.3578
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1026 - mse: 33.0212 - mae: 4.4761 - val_loss: 29.8182 - val_mse: 29.7357 - val_mae: 4.3831
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9073 - mse: 32.8240 - mae: 4.4651 - val_loss: 29.9434 - val_mse: 29.8591 - val_mae: 4.3900
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7395 - mse: 32.6541 - mae: 4.4556 - val_loss: 28.8092 - val_mse: 28.7226 - val_mae: 4.3059
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5791 - mse: 32.4917 - mae: 4.4389 - val_loss: 29.0848 - val_mse: 28.9963 - val_mae: 4.3318
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3046 - mse: 32.2151 - mae: 4.4233 - val_loss: 29.6021 - val_mse: 29.5113 - val_mae: 4.3685
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2798 - mse: 32.1878 - mae: 4.4219 - val_loss: 29.0645 - val_mse: 28.9711 - val_mae: 4.3286
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1557 - mse: 32.0612 - mae: 4.4099 - val_loss: 29.3017 - val_mse: 29.2054 - val_mae: 4.3509
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9990 - mse: 31.9011 - mae: 4.3939 - val_loss: 29.0000 - val_mse: 28.9004 - val_mae: 4.3332
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7689 - mse: 31.6676 - mae: 4.3864 - val_loss: 28.7017 - val_mse: 28.5982 - val_mae: 4.3091
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3564 - mse: 31.2512 - mae: 4.3521 - val_loss: 28.1711 - val_mse: 28.0635 - val_mae: 4.2766
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2172 - mse: 31.1077 - mae: 4.3396 - val_loss: 28.4367 - val_mse: 28.3251 - val_mae: 4.2918
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8875 - mse: 30.7745 - mae: 4.3112 - val_loss: 28.2626 - val_mse: 28.1477 - val_mae: 4.2809
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6244 - mse: 30.5081 - mae: 4.2972 - val_loss: 28.8734 - val_mse: 28.7557 - val_mae: 4.3210
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3985 - mse: 30.2794 - mae: 4.2885 - val_loss: 27.9061 - val_mse: 27.7854 - val_mae: 4.2577
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4212 - mse: 30.2994 - mae: 4.2823 - val_loss: 27.3462 - val_mse: 27.2230 - val_mae: 4.2170
bias -0.008610236
si 0.48543712
rmse 0.052175675
kgeprime [0.58732418]
rmse_95 0.07143887
rmse_99 0.08506727
pearson 0.8527195284276258
pearson_95 0.7023329743134074
pearson_99 0.8021425332553813
rscore 0.7190510775956146
rscore_95 -1.4175920433560272
rscore_99 -7.616635680385649
nse [0.71905108]
nse_95 [-1.41759204]
nse_99 [-7.61663568]
kge [0.68727327]
ext_kge_95 [0.55645365]
ext_kge_99 [0.05116789]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... -0.1666
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.02849
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([103359 103383 103407], shape=(3,), dtype=int64) Times out: tf.Tensor(103407, shape=(), dtype=int64)
Times in: tf.Tensor([49890 49914 49938], shape=(3,), dtype=int64) Times out: tf.Tensor(49938, shape=(), dtype=int64)
Times in: tf.Tensor([115264 115288 115312], shape=(3,), dtype=int64) Times out: tf.Tensor(115312, shape=(), dtype=int64)
Times in: tf.Tensor([124370 124394 124418], shape=(3,), dtype=int64) Times out: tf.Tensor(124418, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_578&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_579 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1156 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1157 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_578 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1156 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_578 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1157 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.7378 - mse: 42.6882 - mae: 5.0537 - val_loss: 29.8996 - val_mse: 29.8393 - val_mae: 4.3852
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4872 - mse: 32.4202 - mae: 4.4461 - val_loss: 28.9356 - val_mse: 28.8626 - val_mae: 4.3191
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2736 - mse: 31.1961 - mae: 4.3635 - val_loss: 28.4422 - val_mse: 28.3609 - val_mae: 4.2786
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9192 - mse: 30.8347 - mae: 4.3357 - val_loss: 28.1916 - val_mse: 28.1048 - val_mae: 4.2443
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6836 - mse: 30.5947 - mae: 4.3172 - val_loss: 28.1549 - val_mse: 28.0643 - val_mae: 4.2407
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3677 - mse: 30.2757 - mae: 4.2915 - val_loss: 28.0270 - val_mse: 27.9338 - val_mae: 4.2321
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2100 - mse: 30.1153 - mae: 4.2797 - val_loss: 27.9598 - val_mse: 27.8638 - val_mae: 4.2245
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0127 - mse: 29.9151 - mae: 4.2675 - val_loss: 27.6259 - val_mse: 27.5270 - val_mae: 4.2137
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6371 - mse: 29.5362 - mae: 4.2381 - val_loss: 27.3802 - val_mse: 27.2777 - val_mae: 4.1974
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2804 - mse: 29.1761 - mae: 4.2082 - val_loss: 26.9750 - val_mse: 26.8696 - val_mae: 4.1753
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9307 - mse: 28.8236 - mae: 4.1797 - val_loss: 26.7935 - val_mse: 26.6853 - val_mae: 4.1593
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6700 - mse: 28.5607 - mae: 4.1625 - val_loss: 26.4982 - val_mse: 26.3882 - val_mae: 4.1465
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4132 - mse: 28.3022 - mae: 4.1378 - val_loss: 26.2385 - val_mse: 26.1270 - val_mae: 4.1216
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2398 - mse: 28.1271 - mae: 4.1295 - val_loss: 26.1040 - val_mse: 25.9905 - val_mae: 4.1136
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1613 - mse: 28.0471 - mae: 4.1161 - val_loss: 26.2328 - val_mse: 26.1182 - val_mae: 4.1263
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0132 - mse: 27.8975 - mae: 4.1120 - val_loss: 25.7653 - val_mse: 25.6491 - val_mae: 4.0849
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8097 - mse: 27.6926 - mae: 4.0961 - val_loss: 25.6590 - val_mse: 25.5415 - val_mae: 4.0755
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7064 - mse: 27.5879 - mae: 4.0881 - val_loss: 25.8631 - val_mse: 25.7440 - val_mae: 4.0943
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7067 - mse: 27.5868 - mae: 4.0900 - val_loss: 25.4601 - val_mse: 25.3396 - val_mae: 4.0612
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6082 - mse: 27.4871 - mae: 4.0786 - val_loss: 25.3651 - val_mse: 25.2434 - val_mae: 4.0514
bias -0.00092266494
si 0.4965057
rmse 0.050242808
kgeprime [0.76924597]
rmse_95 0.07378154
rmse_99 0.08363046
pearson 0.8446942129037918
pearson_95 0.6728533593437216
pearson_99 0.6366948725485739
rscore 0.7133671396449506
rscore_95 -2.029449441381118
rscore_99 -7.472271289288301
nse [0.71336714]
nse_95 [-2.02944944]
nse_99 [-7.47227129]
kge [0.78364972]
ext_kge_95 [0.50520811]
ext_kge_99 [0.04317786]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... -0.1666
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.02849
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([9369 9393 9417], shape=(3,), dtype=int64) Times out: tf.Tensor(9417, shape=(), dtype=int64)
Times in: tf.Tensor([132356 132380 132404], shape=(3,), dtype=int64) Times out: tf.Tensor(132404, shape=(), dtype=int64)
Times in: tf.Tensor([1372 1396 1420], shape=(3,), dtype=int64) Times out: tf.Tensor(1420, shape=(), dtype=int64)
Times in: tf.Tensor([32457 32481 32505], shape=(3,), dtype=int64) Times out: tf.Tensor(32505, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_579&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_580 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1158 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1159 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_579 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1158 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_579 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1159 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.5102 - mse: 46.4578 - mae: 5.2601 - val_loss: 30.7946 - val_mse: 30.7307 - val_mae: 4.4549
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0334 - mse: 33.9638 - mae: 4.5438 - val_loss: 29.8439 - val_mse: 29.7683 - val_mae: 4.3887
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8987 - mse: 32.8174 - mae: 4.4700 - val_loss: 29.1061 - val_mse: 29.0201 - val_mae: 4.3324
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5108 - mse: 32.4209 - mae: 4.4413 - val_loss: 28.8600 - val_mse: 28.7664 - val_mae: 4.3094
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1104 - mse: 32.0141 - mae: 4.4134 - val_loss: 28.9306 - val_mse: 28.8313 - val_mae: 4.3131
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9381 - mse: 31.8364 - mae: 4.3982 - val_loss: 28.6089 - val_mse: 28.5046 - val_mae: 4.2902
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7242 - mse: 31.6175 - mae: 4.3852 - val_loss: 28.3428 - val_mse: 28.2334 - val_mae: 4.2665
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5277 - mse: 31.4158 - mae: 4.3712 - val_loss: 29.2318 - val_mse: 29.1172 - val_mae: 4.3378
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2552 - mse: 31.1382 - mae: 4.3509 - val_loss: 28.2926 - val_mse: 28.1726 - val_mae: 4.2641
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0205 - mse: 30.8978 - mae: 4.3348 - val_loss: 28.5947 - val_mse: 28.4692 - val_mae: 4.2940
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8968 - mse: 30.7685 - mae: 4.3210 - val_loss: 28.4558 - val_mse: 28.3244 - val_mae: 4.2839
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7315 - mse: 30.5976 - mae: 4.3113 - val_loss: 28.0265 - val_mse: 27.8894 - val_mae: 4.2527
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5683 - mse: 30.4290 - mae: 4.3033 - val_loss: 28.2432 - val_mse: 28.1014 - val_mae: 4.2702
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3172 - mse: 30.1730 - mae: 4.2841 - val_loss: 28.1415 - val_mse: 27.9944 - val_mae: 4.2656
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2854 - mse: 30.1362 - mae: 4.2770 - val_loss: 28.3307 - val_mse: 28.1790 - val_mae: 4.2790
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1006 - mse: 29.9469 - mae: 4.2648 - val_loss: 27.6699 - val_mse: 27.5141 - val_mae: 4.2333
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0063 - mse: 29.8486 - mae: 4.2577 - val_loss: 27.6167 - val_mse: 27.4571 - val_mae: 4.2320
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9016 - mse: 29.7404 - mae: 4.2441 - val_loss: 27.2527 - val_mse: 27.0898 - val_mae: 4.2060
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6244 - mse: 29.4601 - mae: 4.2279 - val_loss: 27.4791 - val_mse: 27.3136 - val_mae: 4.2253
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4316 - mse: 29.2648 - mae: 4.2155 - val_loss: 26.9302 - val_mse: 26.7624 - val_mae: 4.1826
bias -0.0060583376
si 0.5018392
rmse 0.051732425
kgeprime [0.63794536]
rmse_95 0.0743886
rmse_99 0.08607287
pearson 0.8409295790163457
pearson_95 0.6917159651551994
pearson_99 0.7045915338470485
rscore 0.7029385674212394
rscore_95 -1.9567204127489495
rscore_99 -8.763160148552691
nse [0.70293857]
nse_95 [-1.95672041]
nse_99 [-8.76316015]
kge [0.71788455]
ext_kge_95 [0.53272129]
ext_kge_99 [0.01988752]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 2.346
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 1.583
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([140773 140797 140821], shape=(3,), dtype=int64) Times out: tf.Tensor(140821, shape=(), dtype=int64)
Times in: tf.Tensor([151371 151395 151419], shape=(3,), dtype=int64) Times out: tf.Tensor(151419, shape=(), dtype=int64)
Times in: tf.Tensor([99769 99793 99817], shape=(3,), dtype=int64) Times out: tf.Tensor(99817, shape=(), dtype=int64)
Times in: tf.Tensor([2164 2188 2212], shape=(3,), dtype=int64) Times out: tf.Tensor(2212, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_580&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_581 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1160 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1161 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_580 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1160 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_580 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1161 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.5336 - mse: 47.4767 - mae: 5.3069 - val_loss: 30.9114 - val_mse: 30.8434 - val_mae: 4.4684
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8122 - mse: 34.7409 - mae: 4.5927 - val_loss: 29.7544 - val_mse: 29.6800 - val_mae: 4.3948
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6837 - mse: 33.6062 - mae: 4.5149 - val_loss: 29.3079 - val_mse: 29.2275 - val_mae: 4.3569
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0449 - mse: 32.9621 - mae: 4.4761 - val_loss: 28.9298 - val_mse: 28.8446 - val_mae: 4.3291
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8444 - mse: 32.7572 - mae: 4.4559 - val_loss: 28.8566 - val_mse: 28.7676 - val_mae: 4.3238
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5169 - mse: 32.4262 - mae: 4.4388 - val_loss: 28.6184 - val_mse: 28.5259 - val_mae: 4.3056
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2279 - mse: 32.1339 - mae: 4.4170 - val_loss: 28.4476 - val_mse: 28.3518 - val_mae: 4.2917
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0785 - mse: 31.9813 - mae: 4.4077 - val_loss: 28.2501 - val_mse: 28.1513 - val_mae: 4.2813
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8937 - mse: 31.7934 - mae: 4.3900 - val_loss: 28.1800 - val_mse: 28.0783 - val_mae: 4.2772
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6952 - mse: 31.5922 - mae: 4.3800 - val_loss: 27.9874 - val_mse: 27.8827 - val_mae: 4.2663
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4712 - mse: 31.3652 - mae: 4.3620 - val_loss: 27.6559 - val_mse: 27.5481 - val_mae: 4.2455
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3193 - mse: 31.2100 - mae: 4.3485 - val_loss: 27.6660 - val_mse: 27.5548 - val_mae: 4.2440
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.9103 - mse: 30.7974 - mae: 4.3213 - val_loss: 27.1996 - val_mse: 27.0850 - val_mae: 4.2074
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7277 - mse: 30.6116 - mae: 4.3098 - val_loss: 26.9750 - val_mse: 26.8573 - val_mae: 4.1902
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6283 - mse: 30.5096 - mae: 4.2985 - val_loss: 26.6154 - val_mse: 26.4955 - val_mae: 4.1653
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.3076 - mse: 30.1868 - mae: 4.2764 - val_loss: 26.6822 - val_mse: 26.5602 - val_mae: 4.1625
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.2030 - mse: 30.0802 - mae: 4.2718 - val_loss: 26.4383 - val_mse: 26.3143 - val_mae: 4.1470
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.0707 - mse: 29.9461 - mae: 4.2584 - val_loss: 26.2340 - val_mse: 26.1082 - val_mae: 4.1314
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.1504 - mse: 30.0239 - mae: 4.2624 - val_loss: 26.4286 - val_mse: 26.3010 - val_mae: 4.1430
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.9696 - mse: 29.8414 - mae: 4.2514 - val_loss: 26.3481 - val_mse: 26.2189 - val_mae: 4.1357
bias -0.0057177423
si 0.48048243
rmse 0.051204383
kgeprime [0.6569575]
rmse_95 0.072198816
rmse_99 0.08619391
pearson 0.8560647187495505
pearson_95 0.6983643585810111
pearson_99 0.8199936960788813
rscore 0.7287800127272249
rscore_95 -1.4616834601822184
rscore_99 -8.26086120988797
nse [0.72878001]
nse_95 [-1.46168346]
nse_99 [-8.26086121]
kge [0.7339751]
ext_kge_95 [0.54076259]
ext_kge_99 [-0.08974078]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -0.4251
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 1.369
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.1808
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 1.875
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 1.434
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([74122 74146 74170], shape=(3,), dtype=int64) Times out: tf.Tensor(74170, shape=(), dtype=int64)
Times in: tf.Tensor([40448 40472 40496], shape=(3,), dtype=int64) Times out: tf.Tensor(40496, shape=(), dtype=int64)
Times in: tf.Tensor([152480 152504 152528], shape=(3,), dtype=int64) Times out: tf.Tensor(152528, shape=(), dtype=int64)
Times in: tf.Tensor([8725 8749 8773], shape=(3,), dtype=int64) Times out: tf.Tensor(8773, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_581&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_582 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1162 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1163 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_581 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1162 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_581 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1163 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.9084 - mse: 40.8584 - mae: 4.9299 - val_loss: 28.8529 - val_mse: 28.7939 - val_mae: 4.3129
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3580 - mse: 31.2946 - mae: 4.3698 - val_loss: 28.1535 - val_mse: 28.0857 - val_mae: 4.2676
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3997 - mse: 30.3266 - mae: 4.2997 - val_loss: 27.8925 - val_mse: 27.8137 - val_mae: 4.2441
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8889 - mse: 29.8051 - mae: 4.2635 - val_loss: 27.2665 - val_mse: 27.1774 - val_mae: 4.1949
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4635 - mse: 29.3696 - mae: 4.2340 - val_loss: 27.0312 - val_mse: 26.9322 - val_mae: 4.1792
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9944 - mse: 28.8909 - mae: 4.1922 - val_loss: 26.7260 - val_mse: 26.6177 - val_mae: 4.1587
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4369 - mse: 28.3245 - mae: 4.1553 - val_loss: 26.7665 - val_mse: 26.6495 - val_mae: 4.1697
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0767 - mse: 27.9567 - mae: 4.1237 - val_loss: 26.3677 - val_mse: 26.2441 - val_mae: 4.1426
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7462 - mse: 27.6196 - mae: 4.0995 - val_loss: 26.1105 - val_mse: 25.9809 - val_mae: 4.1203
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5255 - mse: 27.3938 - mae: 4.0806 - val_loss: 25.9781 - val_mse: 25.8437 - val_mae: 4.1104
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3894 - mse: 27.2532 - mae: 4.0725 - val_loss: 25.6152 - val_mse: 25.4767 - val_mae: 4.0827
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1719 - mse: 27.0318 - mae: 4.0538 - val_loss: 25.6051 - val_mse: 25.4629 - val_mae: 4.0813
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0778 - mse: 26.9339 - mae: 4.0434 - val_loss: 25.4092 - val_mse: 25.2632 - val_mae: 4.0626
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9990 - mse: 26.8516 - mae: 4.0372 - val_loss: 25.1502 - val_mse: 25.0011 - val_mae: 4.0411
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8102 - mse: 26.6599 - mae: 4.0228 - val_loss: 25.7887 - val_mse: 25.6368 - val_mae: 4.0927
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7225 - mse: 26.5692 - mae: 4.0203 - val_loss: 24.9359 - val_mse: 24.7811 - val_mae: 4.0230
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6726 - mse: 26.5167 - mae: 4.0115 - val_loss: 24.8424 - val_mse: 24.6850 - val_mae: 4.0140
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4263 - mse: 26.2679 - mae: 3.9917 - val_loss: 25.4028 - val_mse: 25.2431 - val_mae: 4.0587
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3719 - mse: 26.2112 - mae: 3.9911 - val_loss: 25.0083 - val_mse: 24.8466 - val_mae: 4.0276
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3846 - mse: 26.2222 - mae: 3.9900 - val_loss: 24.8903 - val_mse: 24.7268 - val_mae: 4.0150
bias -0.0047612214
si 0.49734458
rmse 0.049726084
kgeprime [0.69148744]
rmse_95 0.069467954
rmse_99 0.07766018
pearson 0.8444459902970162
pearson_95 0.5685766148448548
pearson_99 0.47305117159624543
rscore 0.7100167102019952
rscore_95 -1.9513415134036203
rscore_99 -6.593295665637606
nse [0.71001671]
nse_95 [-1.95134151]
nse_99 [-6.59329567]
kge [0.75724469]
ext_kge_95 [0.41494795]
ext_kge_99 [0.01748251]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... 0.1688
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... -0.1666
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.02849
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 0.02777
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 0.2372
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([41250 41274 41298], shape=(3,), dtype=int64) Times out: tf.Tensor(41298, shape=(), dtype=int64)
Times in: tf.Tensor([109942 109966 109990], shape=(3,), dtype=int64) Times out: tf.Tensor(109990, shape=(), dtype=int64)
Times in: tf.Tensor([127602 127626 127650], shape=(3,), dtype=int64) Times out: tf.Tensor(127650, shape=(), dtype=int64)
Times in: tf.Tensor([85729 85753 85777], shape=(3,), dtype=int64) Times out: tf.Tensor(85777, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_582&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_583 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1164 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1165 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_582 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1164 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_582 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1165 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.6912 - mse: 41.6363 - mae: 4.9847 - val_loss: 29.5455 - val_mse: 29.4779 - val_mae: 4.3626
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0803 - mse: 32.0068 - mae: 4.4180 - val_loss: 28.7681 - val_mse: 28.6890 - val_mae: 4.3125
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3476 - mse: 31.2636 - mae: 4.3608 - val_loss: 28.7530 - val_mse: 28.6641 - val_mae: 4.3050
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9679 - mse: 30.8755 - mae: 4.3396 - val_loss: 28.5735 - val_mse: 28.4775 - val_mae: 4.2948
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6370 - mse: 30.5380 - mae: 4.3166 - val_loss: 27.7689 - val_mse: 27.6666 - val_mae: 4.2249
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4092 - mse: 30.3042 - mae: 4.2951 - val_loss: 27.9221 - val_mse: 27.8140 - val_mae: 4.2403
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1714 - mse: 30.0604 - mae: 4.2797 - val_loss: 27.8494 - val_mse: 27.7354 - val_mae: 4.2380
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9357 - mse: 29.8189 - mae: 4.2631 - val_loss: 28.0561 - val_mse: 27.9360 - val_mae: 4.2551
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7635 - mse: 29.6412 - mae: 4.2454 - val_loss: 27.6047 - val_mse: 27.4797 - val_mae: 4.2206
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5233 - mse: 29.3957 - mae: 4.2310 - val_loss: 27.8900 - val_mse: 27.7598 - val_mae: 4.2472
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2570 - mse: 29.1244 - mae: 4.2092 - val_loss: 27.6531 - val_mse: 27.5179 - val_mae: 4.2331
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9083 - mse: 28.7709 - mae: 4.1834 - val_loss: 27.4060 - val_mse: 27.2663 - val_mae: 4.2160
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6641 - mse: 28.5226 - mae: 4.1627 - val_loss: 26.6300 - val_mse: 26.4865 - val_mae: 4.1535
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4469 - mse: 28.3021 - mae: 4.1475 - val_loss: 26.7935 - val_mse: 26.6473 - val_mae: 4.1717
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3508 - mse: 28.2034 - mae: 4.1385 - val_loss: 26.2669 - val_mse: 26.1184 - val_mae: 4.1292
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2211 - mse: 28.0716 - mae: 4.1233 - val_loss: 26.7893 - val_mse: 26.6388 - val_mae: 4.1684
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9862 - mse: 27.8350 - mae: 4.1123 - val_loss: 26.0395 - val_mse: 25.8874 - val_mae: 4.1095
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8147 - mse: 27.6616 - mae: 4.0977 - val_loss: 26.1679 - val_mse: 26.0136 - val_mae: 4.1218
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8219 - mse: 27.6669 - mae: 4.0947 - val_loss: 26.0342 - val_mse: 25.8782 - val_mae: 4.1075
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8202 - mse: 27.6635 - mae: 4.0901 - val_loss: 25.9781 - val_mse: 25.8207 - val_mae: 4.1043
bias -0.007277215
si 0.49971384
rmse 0.050814126
kgeprime [0.63396397]
rmse_95 0.0664172
rmse_99 0.07527484
pearson 0.8429738662587168
pearson_95 0.6382272063031718
pearson_99 0.5174879924234862
rscore 0.7036068303481623
rscore_95 -1.576271970900828
rscore_99 -6.469363380286689
nse [0.70360683]
nse_95 [-1.57627197]
nse_99 [-6.46936338]
kge [0.72053403]
ext_kge_95 [0.49210243]
ext_kge_99 [-0.01010447]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -1.258
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 2.346
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 1.583
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 5.503
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 2.662
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([43116 43140 43164], shape=(3,), dtype=int64) Times out: tf.Tensor(43164, shape=(), dtype=int64)
Times in: tf.Tensor([133732 133756 133780], shape=(3,), dtype=int64) Times out: tf.Tensor(133780, shape=(), dtype=int64)
Times in: tf.Tensor([68158 68182 68206], shape=(3,), dtype=int64) Times out: tf.Tensor(68206, shape=(), dtype=int64)
Times in: tf.Tensor([71573 71597 71621], shape=(3,), dtype=int64) Times out: tf.Tensor(71621, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_583&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_584 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1166 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1167 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_583 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1166 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_583 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1167 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.4815 - mse: 50.4163 - mae: 5.4608 - val_loss: 30.8254 - val_mse: 30.7379 - val_mae: 4.4464
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4292 - mse: 35.3361 - mae: 4.6261 - val_loss: 29.5980 - val_mse: 29.5005 - val_mae: 4.3582
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5343 - mse: 34.4338 - mae: 4.5682 - val_loss: 28.8080 - val_mse: 28.7055 - val_mae: 4.3044
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9786 - mse: 33.8744 - mae: 4.5259 - val_loss: 28.6697 - val_mse: 28.5638 - val_mae: 4.2919
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8228 - mse: 33.7159 - mae: 4.5153 - val_loss: 28.8617 - val_mse: 28.7533 - val_mae: 4.3081
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6536 - mse: 33.5440 - mae: 4.5034 - val_loss: 28.2978 - val_mse: 28.1863 - val_mae: 4.2682
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4250 - mse: 33.3118 - mae: 4.4897 - val_loss: 28.2861 - val_mse: 28.1708 - val_mae: 4.2640
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1868 - mse: 33.0697 - mae: 4.4725 - val_loss: 28.4128 - val_mse: 28.2934 - val_mae: 4.2750
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8401 - mse: 32.7186 - mae: 4.4512 - val_loss: 27.9106 - val_mse: 27.7864 - val_mae: 4.2391
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6690 - mse: 32.5428 - mae: 4.4391 - val_loss: 27.6732 - val_mse: 27.5445 - val_mae: 4.2277
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4480 - mse: 32.3171 - mae: 4.4228 - val_loss: 27.5199 - val_mse: 27.3868 - val_mae: 4.2143
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1693 - mse: 32.0339 - mae: 4.4055 - val_loss: 27.4136 - val_mse: 27.2758 - val_mae: 4.2073
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1842 - mse: 32.0443 - mae: 4.4022 - val_loss: 27.7881 - val_mse: 27.6460 - val_mae: 4.2362
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8114 - mse: 31.6675 - mae: 4.3756 - val_loss: 27.4420 - val_mse: 27.2959 - val_mae: 4.2126
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7505 - mse: 31.6025 - mae: 4.3703 - val_loss: 27.0989 - val_mse: 26.9489 - val_mae: 4.1913
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5546 - mse: 31.4033 - mae: 4.3566 - val_loss: 27.2500 - val_mse: 27.0968 - val_mae: 4.1970
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4962 - mse: 31.3415 - mae: 4.3511 - val_loss: 27.2704 - val_mse: 27.1141 - val_mae: 4.2008
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2753 - mse: 31.1176 - mae: 4.3368 - val_loss: 27.6369 - val_mse: 27.4776 - val_mae: 4.2242
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2799 - mse: 31.1193 - mae: 4.3330 - val_loss: 26.9744 - val_mse: 26.8126 - val_mae: 4.1786
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0849 - mse: 30.9218 - mae: 4.3186 - val_loss: 27.1294 - val_mse: 26.9649 - val_mae: 4.1926
bias -0.0096002035
si 0.48412454
rmse 0.05192777
kgeprime [0.56709927]
rmse_95 0.07113038
rmse_99 0.082796164
pearson 0.8533605820405886
pearson_95 0.691757749189676
pearson_99 0.8323337568636792
rscore 0.7184185860197296
rscore_95 -1.4083114665229086
rscore_99 -7.7541056878805215
nse [0.71841859]
nse_95 [-1.40831147]
nse_99 [-7.75410569]
kge [0.67264494]
ext_kge_95 [0.51184056]
ext_kge_99 [-0.25154252]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.87 -43.56
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -0.4251
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 1.369
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 0.1808
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 1.875
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 1.434
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([10084 10108 10132], shape=(3,), dtype=int64) Times out: tf.Tensor(10132, shape=(), dtype=int64)
Times in: tf.Tensor([27371 27395 27419], shape=(3,), dtype=int64) Times out: tf.Tensor(27419, shape=(), dtype=int64)
Times in: tf.Tensor([51714 51738 51762], shape=(3,), dtype=int64) Times out: tf.Tensor(51762, shape=(), dtype=int64)
Times in: tf.Tensor([136059 136083 136107], shape=(3,), dtype=int64) Times out: tf.Tensor(136107, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_584&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_585 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1168 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1169 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_584 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1168 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_584 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1169 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.7052 - mse: 44.6581 - mae: 5.1480 - val_loss: 29.5094 - val_mse: 29.4509 - val_mae: 4.3630
Epoch 2/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.1814 - mse: 32.1174 - mae: 4.4242 - val_loss: 28.6419 - val_mse: 28.5707 - val_mae: 4.3005
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1641 - mse: 31.0881 - mae: 4.3495 - val_loss: 28.4842 - val_mse: 28.4035 - val_mae: 4.2907
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7231 - mse: 30.6392 - mae: 4.3184 - val_loss: 28.5387 - val_mse: 28.4510 - val_mae: 4.2984
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4341 - mse: 30.3433 - mae: 4.2974 - val_loss: 27.8969 - val_mse: 27.8021 - val_mae: 4.2464
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1586 - mse: 30.0610 - mae: 4.2767 - val_loss: 28.5544 - val_mse: 28.4527 - val_mae: 4.3007
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8598 - mse: 29.7552 - mae: 4.2573 - val_loss: 28.4452 - val_mse: 28.3366 - val_mae: 4.2948
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6133 - mse: 29.5018 - mae: 4.2336 - val_loss: 28.5440 - val_mse: 28.4289 - val_mae: 4.3048
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4255 - mse: 29.3076 - mae: 4.2197 - val_loss: 27.6409 - val_mse: 27.5196 - val_mae: 4.2357
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0792 - mse: 28.9552 - mae: 4.1950 - val_loss: 27.7331 - val_mse: 27.6058 - val_mae: 4.2421
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0324 - mse: 28.9026 - mae: 4.1893 - val_loss: 27.7037 - val_mse: 27.5709 - val_mae: 4.2417
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7136 - mse: 28.5788 - mae: 4.1688 - val_loss: 27.5502 - val_mse: 27.4126 - val_mae: 4.2286
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4671 - mse: 28.3277 - mae: 4.1493 - val_loss: 27.0028 - val_mse: 26.8612 - val_mae: 4.1871
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2539 - mse: 28.1106 - mae: 4.1308 - val_loss: 27.6811 - val_mse: 27.5359 - val_mae: 4.2389
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1158 - mse: 27.9694 - mae: 4.1225 - val_loss: 27.2411 - val_mse: 27.0930 - val_mae: 4.2072
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9527 - mse: 27.8037 - mae: 4.1088 - val_loss: 26.8681 - val_mse: 26.7176 - val_mae: 4.1778
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8705 - mse: 27.7193 - mae: 4.1000 - val_loss: 26.1534 - val_mse: 26.0009 - val_mae: 4.1194
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7207 - mse: 27.5673 - mae: 4.0900 - val_loss: 26.2461 - val_mse: 26.0915 - val_mae: 4.1283
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7346 - mse: 27.5791 - mae: 4.0883 - val_loss: 27.2861 - val_mse: 27.1292 - val_mae: 4.2113
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5751 - mse: 27.4173 - mae: 4.0726 - val_loss: 27.2864 - val_mse: 27.1276 - val_mae: 4.2087
bias -0.014721095
si 0.504421
rmse 0.052084144
kgeprime [0.41110103]
rmse_95 0.06456064
rmse_99 0.07688721
pearson 0.8393831692461481
pearson_95 0.6122566412894027
pearson_99 0.46000158346318487
rscore 0.6789026726128551
rscore_95 -1.5541971331219533
rscore_99 -7.203973604306665
nse [0.67890267]
nse_95 [-1.55419713]
nse_99 [-7.2039736]
kge [0.53977789]
ext_kge_95 [0.49857938]
ext_kge_99 [-0.02018132]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -2.758
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 3.506
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 7.607
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 12.29
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 4.461
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([9496 9520 9544], shape=(3,), dtype=int64) Times out: tf.Tensor(9544, shape=(), dtype=int64)
Times in: tf.Tensor([123763 123787 123811], shape=(3,), dtype=int64) Times out: tf.Tensor(123811, shape=(), dtype=int64)
Times in: tf.Tensor([111924 111948 111972], shape=(3,), dtype=int64) Times out: tf.Tensor(111972, shape=(), dtype=int64)
Times in: tf.Tensor([51941 51965 51989], shape=(3,), dtype=int64) Times out: tf.Tensor(51989, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_585&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_586 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1170 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1171 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_585 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1170 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_585 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1171 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.4986 - mse: 46.4425 - mae: 5.2343 - val_loss: 29.7943 - val_mse: 29.7253 - val_mae: 4.3716
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5378 - mse: 33.4661 - mae: 4.5099 - val_loss: 28.7061 - val_mse: 28.6323 - val_mae: 4.2951
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8787 - mse: 32.8028 - mae: 4.4609 - val_loss: 28.3461 - val_mse: 28.2681 - val_mae: 4.2729
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5791 - mse: 32.4997 - mae: 4.4430 - val_loss: 28.2117 - val_mse: 28.1308 - val_mae: 4.2641
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3156 - mse: 32.2329 - mae: 4.4238 - val_loss: 28.1756 - val_mse: 28.0910 - val_mae: 4.2661
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0403 - mse: 31.9536 - mae: 4.4042 - val_loss: 28.0602 - val_mse: 27.9717 - val_mae: 4.2536
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8222 - mse: 31.7312 - mae: 4.3944 - val_loss: 28.0334 - val_mse: 27.9402 - val_mae: 4.2516
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6123 - mse: 31.5161 - mae: 4.3781 - val_loss: 27.6427 - val_mse: 27.5439 - val_mae: 4.2262
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5218 - mse: 31.4202 - mae: 4.3665 - val_loss: 27.5002 - val_mse: 27.3960 - val_mae: 4.2190
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2657 - mse: 31.1585 - mae: 4.3482 - val_loss: 27.5895 - val_mse: 27.4797 - val_mae: 4.2267
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0655 - mse: 30.9527 - mae: 4.3333 - val_loss: 27.3122 - val_mse: 27.1969 - val_mae: 4.2063
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8132 - mse: 30.6952 - mae: 4.3179 - val_loss: 27.2632 - val_mse: 27.1426 - val_mae: 4.2034
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6934 - mse: 30.5701 - mae: 4.3087 - val_loss: 27.1673 - val_mse: 27.0416 - val_mae: 4.1972
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6222 - mse: 30.4940 - mae: 4.2994 - val_loss: 27.2337 - val_mse: 27.1034 - val_mae: 4.2030
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5596 - mse: 30.4270 - mae: 4.2980 - val_loss: 27.3943 - val_mse: 27.2596 - val_mae: 4.2185
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2614 - mse: 30.1246 - mae: 4.2744 - val_loss: 27.1331 - val_mse: 26.9945 - val_mae: 4.2012
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0461 - mse: 29.9057 - mae: 4.2654 - val_loss: 26.9981 - val_mse: 26.8558 - val_mae: 4.1894
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8835 - mse: 29.7392 - mae: 4.2501 - val_loss: 26.8971 - val_mse: 26.7512 - val_mae: 4.1863
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0384 - mse: 29.8906 - mae: 4.2595 - val_loss: 26.7359 - val_mse: 26.5865 - val_mae: 4.1674
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8659 - mse: 29.7149 - mae: 4.2435 - val_loss: 26.8021 - val_mse: 26.6497 - val_mae: 4.1709
bias -0.0052117896
si 0.49238193
rmse 0.05162333
kgeprime [0.67208037]
rmse_95 0.075470224
rmse_99 0.08820638
pearson 0.8478613745965105
pearson_95 0.6883031888704192
pearson_99 0.7814180824853157
rscore 0.7159457984664833
rscore_95 -1.8315836645935866
rscore_99 -9.58341919241671
nse [0.7159458]
nse_95 [-1.83158366]
nse_99 [-9.58341919]
kge [0.74298769]
ext_kge_95 [0.523527]
ext_kge_99 [-0.06948751]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 3.467
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 6.76
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([89598 89622 89646], shape=(3,), dtype=int64) Times out: tf.Tensor(89646, shape=(), dtype=int64)
Times in: tf.Tensor([114390 114414 114438], shape=(3,), dtype=int64) Times out: tf.Tensor(114438, shape=(), dtype=int64)
Times in: tf.Tensor([20289 20313 20337], shape=(3,), dtype=int64) Times out: tf.Tensor(20337, shape=(), dtype=int64)
Times in: tf.Tensor([101190 101214 101238], shape=(3,), dtype=int64) Times out: tf.Tensor(101238, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_586&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_587 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1172 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1173 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_586 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1172 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_586 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1173 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.6878 - mse: 43.6439 - mae: 5.1109 - val_loss: 31.4774 - val_mse: 31.4241 - val_mae: 4.5049
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5683 - mse: 33.5040 - mae: 4.5235 - val_loss: 29.7487 - val_mse: 29.6735 - val_mae: 4.3885
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1134 - mse: 32.0279 - mae: 4.4247 - val_loss: 29.0140 - val_mse: 28.9191 - val_mae: 4.3337
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2831 - mse: 31.1817 - mae: 4.3678 - val_loss: 28.6351 - val_mse: 28.5279 - val_mae: 4.2975
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9063 - mse: 30.7942 - mae: 4.3327 - val_loss: 28.6106 - val_mse: 28.4943 - val_mae: 4.2996
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4316 - mse: 30.3113 - mae: 4.3006 - val_loss: 28.5098 - val_mse: 28.3856 - val_mae: 4.2870
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1331 - mse: 30.0057 - mae: 4.2798 - val_loss: 27.9140 - val_mse: 27.7835 - val_mae: 4.2413
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7465 - mse: 29.6129 - mae: 4.2475 - val_loss: 28.5350 - val_mse: 28.3988 - val_mae: 4.2922
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4026 - mse: 29.2638 - mae: 4.2234 - val_loss: 27.4005 - val_mse: 27.2593 - val_mae: 4.1997
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1340 - mse: 28.9910 - mae: 4.2044 - val_loss: 27.3838 - val_mse: 27.2391 - val_mae: 4.1982
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8681 - mse: 28.7218 - mae: 4.1810 - val_loss: 27.4537 - val_mse: 27.3059 - val_mae: 4.2075
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.7989 - mse: 28.6496 - mae: 4.1776 - val_loss: 27.6053 - val_mse: 27.4547 - val_mae: 4.2184
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.6887 - mse: 28.5368 - mae: 4.1687 - val_loss: 27.2176 - val_mse: 27.0645 - val_mae: 4.1899
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4906 - mse: 28.3362 - mae: 4.1552 - val_loss: 27.7927 - val_mse: 27.6370 - val_mae: 4.2359
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4559 - mse: 28.2989 - mae: 4.1511 - val_loss: 26.4091 - val_mse: 26.2512 - val_mae: 4.1190
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2784 - mse: 28.1192 - mae: 4.1396 - val_loss: 27.3800 - val_mse: 27.2195 - val_mae: 4.2013
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3251 - mse: 28.1633 - mae: 4.1397 - val_loss: 27.7206 - val_mse: 27.5574 - val_mae: 4.2288
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1904 - mse: 28.0259 - mae: 4.1301 - val_loss: 27.2798 - val_mse: 27.1139 - val_mae: 4.1937
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0109 - mse: 27.8436 - mae: 4.1126 - val_loss: 26.4763 - val_mse: 26.3079 - val_mae: 4.1256
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9481 - mse: 27.7783 - mae: 4.1084 - val_loss: 26.6234 - val_mse: 26.4524 - val_mae: 4.1392
bias -0.008231223
si 0.50788915
rmse 0.05143193
kgeprime [0.59160462]
rmse_95 0.068055734
rmse_99 0.08028625
pearson 0.8373794825702954
pearson_95 0.6608270824716757
pearson_99 0.4784378309764373
rscore 0.6930855405157643
rscore_95 -1.6690045176686654
rscore_99 -8.080144564007865
nse [0.69308554]
nse_95 [-1.66900452]
nse_99 [-8.08014456]
kge [0.68813248]
ext_kge_95 [0.53870021]
ext_kge_99 [-0.00602005]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -0.8311
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.6148
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([113917 113941 113965], shape=(3,), dtype=int64) Times out: tf.Tensor(113965, shape=(), dtype=int64)
Times in: tf.Tensor([123769 123793 123817], shape=(3,), dtype=int64) Times out: tf.Tensor(123817, shape=(), dtype=int64)
Times in: tf.Tensor([32014 32038 32062], shape=(3,), dtype=int64) Times out: tf.Tensor(32062, shape=(), dtype=int64)
Times in: tf.Tensor([4664 4688 4712], shape=(3,), dtype=int64) Times out: tf.Tensor(4712, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_587&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_588 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1174 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1175 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_587 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1174 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_587 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1175 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.0778 - mse: 54.0223 - mae: 5.6740 - val_loss: 38.3420 - val_mse: 38.2768 - val_mae: 4.9357
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7661 - mse: 40.6958 - mae: 4.9757 - val_loss: 35.9174 - val_mse: 35.8431 - val_mae: 4.7742
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7057 - mse: 39.6276 - mae: 4.9077 - val_loss: 35.3359 - val_mse: 35.2549 - val_mae: 4.7334
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2987 - mse: 39.2148 - mae: 4.8831 - val_loss: 35.3286 - val_mse: 35.2420 - val_mae: 4.7303
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1239 - mse: 39.0349 - mae: 4.8699 - val_loss: 34.7012 - val_mse: 34.6094 - val_mae: 4.6902
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6194 - mse: 38.5246 - mae: 4.8367 - val_loss: 35.1053 - val_mse: 35.0073 - val_mae: 4.7184
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4218 - mse: 38.3202 - mae: 4.8201 - val_loss: 34.8727 - val_mse: 34.7676 - val_mae: 4.7032
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2734 - mse: 38.1646 - mae: 4.8156 - val_loss: 34.1532 - val_mse: 34.0408 - val_mae: 4.6591
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9534 - mse: 37.8371 - mae: 4.7916 - val_loss: 34.7124 - val_mse: 34.5926 - val_mae: 4.6987
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6547 - mse: 37.5312 - mae: 4.7789 - val_loss: 34.2561 - val_mse: 34.1293 - val_mae: 4.6659
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3782 - mse: 37.2482 - mae: 4.7589 - val_loss: 34.2448 - val_mse: 34.1120 - val_mae: 4.6646
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3054 - mse: 37.1696 - mae: 4.7481 - val_loss: 34.4453 - val_mse: 34.3069 - val_mae: 4.6763
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2455 - mse: 37.1043 - mae: 4.7417 - val_loss: 33.9161 - val_mse: 33.7725 - val_mae: 4.6487
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8290 - mse: 36.6829 - mae: 4.7214 - val_loss: 33.8487 - val_mse: 33.7003 - val_mae: 4.6368
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6493 - mse: 36.4984 - mae: 4.7061 - val_loss: 33.6125 - val_mse: 33.4593 - val_mae: 4.6212
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5533 - mse: 36.3974 - mae: 4.6975 - val_loss: 33.8661 - val_mse: 33.7077 - val_mae: 4.6380
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0778 - mse: 35.9174 - mae: 4.6690 - val_loss: 32.7824 - val_mse: 32.6203 - val_mae: 4.5681
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7868 - mse: 35.6229 - mae: 4.6481 - val_loss: 32.7540 - val_mse: 32.5885 - val_mae: 4.5716
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5968 - mse: 35.4297 - mae: 4.6337 - val_loss: 32.1751 - val_mse: 32.0070 - val_mae: 4.5311
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3458 - mse: 35.1763 - mae: 4.6201 - val_loss: 32.1574 - val_mse: 31.9869 - val_mae: 4.5307
bias -0.008932295
si 0.48507652
rmse 0.056556925
kgeprime [0.60741468]
rmse_95 0.07903008
rmse_99 0.08891452
pearson 0.851697362915833
pearson_95 0.6822517226672701
pearson_99 0.8907289490092263
rscore 0.718288019811041
rscore_95 -1.0735977808066006
rscore_99 -7.234140366288512
nse [0.71828802]
nse_95 [-1.07359778]
nse_99 [-7.23414037]
kge [0.70236912]
ext_kge_95 [0.56789104]
ext_kge_99 [-0.10019087]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -0.8311
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.6148
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([44101 44125 44149], shape=(3,), dtype=int64) Times out: tf.Tensor(44149, shape=(), dtype=int64)
Times in: tf.Tensor([110258 110282 110306], shape=(3,), dtype=int64) Times out: tf.Tensor(110306, shape=(), dtype=int64)
Times in: tf.Tensor([133519 133543 133567], shape=(3,), dtype=int64) Times out: tf.Tensor(133567, shape=(), dtype=int64)
Times in: tf.Tensor([19818 19842 19866], shape=(3,), dtype=int64) Times out: tf.Tensor(19866, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_588&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_589 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1176 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1177 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_588 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1176 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_588 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1177 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 57.6119 - mse: 57.5467 - mae: 5.8734 - val_loss: 40.7045 - val_mse: 40.6267 - val_mae: 5.0722
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.9990 - mse: 42.9144 - mae: 5.1184 - val_loss: 39.0771 - val_mse: 38.9859 - val_mae: 4.9814
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1071 - mse: 40.0099 - mae: 4.9347 - val_loss: 36.3596 - val_mse: 36.2573 - val_mae: 4.8202
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5877 - mse: 38.4813 - mae: 4.8395 - val_loss: 35.4809 - val_mse: 35.3711 - val_mae: 4.7532
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1972 - mse: 38.0843 - mae: 4.8164 - val_loss: 35.2584 - val_mse: 35.1431 - val_mae: 4.7382
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7931 - mse: 37.6756 - mae: 4.7885 - val_loss: 34.9973 - val_mse: 34.8778 - val_mae: 4.7201
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5522 - mse: 37.4307 - mae: 4.7688 - val_loss: 35.4619 - val_mse: 35.3388 - val_mae: 4.7450
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3463 - mse: 37.2208 - mae: 4.7604 - val_loss: 34.7748 - val_mse: 34.6474 - val_mae: 4.7057
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1447 - mse: 37.0152 - mae: 4.7469 - val_loss: 35.2397 - val_mse: 35.1082 - val_mae: 4.7288
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8634 - mse: 36.7295 - mae: 4.7302 - val_loss: 34.9017 - val_mse: 34.7653 - val_mae: 4.7029
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4358 - mse: 36.2964 - mae: 4.6978 - val_loss: 35.1071 - val_mse: 34.9647 - val_mae: 4.7143
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7759 - mse: 35.6310 - mae: 4.6582 - val_loss: 33.4757 - val_mse: 33.3282 - val_mae: 4.6101
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2691 - mse: 35.1193 - mae: 4.6239 - val_loss: 33.4718 - val_mse: 33.3197 - val_mae: 4.6170
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7657 - mse: 34.6118 - mae: 4.5925 - val_loss: 32.7891 - val_mse: 32.6332 - val_mae: 4.5767
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5368 - mse: 34.3793 - mae: 4.5714 - val_loss: 32.5660 - val_mse: 32.4071 - val_mae: 4.5652
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5106 - mse: 34.3500 - mae: 4.5656 - val_loss: 32.3528 - val_mse: 32.1910 - val_mae: 4.5487
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1498 - mse: 33.9863 - mae: 4.5491 - val_loss: 34.2264 - val_mse: 34.0617 - val_mae: 4.6713
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1534 - mse: 33.9874 - mae: 4.5462 - val_loss: 32.9015 - val_mse: 32.7344 - val_mae: 4.5862
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8481 - mse: 33.6796 - mae: 4.5228 - val_loss: 32.5260 - val_mse: 32.3564 - val_mae: 4.5580
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9037 - mse: 33.7329 - mae: 4.5251 - val_loss: 32.0050 - val_mse: 31.8332 - val_mae: 4.5293
bias -0.0116338255
si 0.48245147
rmse 0.05642088
kgeprime [0.56046502]
rmse_95 0.07131806
rmse_99 0.08113757
pearson 0.8534765667712864
pearson_95 0.7207900858145411
pearson_99 0.8962979624562344
rscore 0.7161496923532397
rscore_95 -0.8069704650970115
rscore_99 -6.26615687145175
nse [0.71614969]
nse_95 [-0.80697047]
nse_99 [-6.26615687]
kge [0.6669195]
ext_kge_95 [0.61136297]
ext_kge_99 [0.03821511]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -0.8311
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.6148
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([56440 56464 56488], shape=(3,), dtype=int64) Times out: tf.Tensor(56488, shape=(), dtype=int64)
Times in: tf.Tensor([22102 22126 22150], shape=(3,), dtype=int64) Times out: tf.Tensor(22150, shape=(), dtype=int64)
Times in: tf.Tensor([155246 155270 155294], shape=(3,), dtype=int64) Times out: tf.Tensor(155294, shape=(), dtype=int64)
Times in: tf.Tensor([147928 147952 147976], shape=(3,), dtype=int64) Times out: tf.Tensor(147976, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_589&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_590 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1178 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1179 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_589 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1178 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_589 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1179 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.5771 - mse: 55.5109 - mae: 5.7455 - val_loss: 37.9730 - val_mse: 37.8911 - val_mae: 4.9336
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7552 - mse: 40.6648 - mae: 4.9841 - val_loss: 36.5700 - val_mse: 36.4713 - val_mae: 4.8196
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2272 - mse: 39.1220 - mae: 4.8779 - val_loss: 35.4971 - val_mse: 35.3859 - val_mae: 4.7489
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7130 - mse: 38.5973 - mae: 4.8481 - val_loss: 35.4135 - val_mse: 35.2936 - val_mae: 4.7391
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4848 - mse: 38.3613 - mae: 4.8298 - val_loss: 35.1651 - val_mse: 35.0384 - val_mae: 4.7224
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3392 - mse: 38.2089 - mae: 4.8194 - val_loss: 34.4873 - val_mse: 34.3534 - val_mae: 4.6800
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9578 - mse: 37.8206 - mae: 4.7944 - val_loss: 34.7412 - val_mse: 34.6005 - val_mae: 4.6974
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7923 - mse: 37.6483 - mae: 4.7875 - val_loss: 34.7687 - val_mse: 34.6219 - val_mae: 4.6988
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5390 - mse: 37.3888 - mae: 4.7692 - val_loss: 34.7768 - val_mse: 34.6235 - val_mae: 4.7022
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2924 - mse: 37.1354 - mae: 4.7566 - val_loss: 34.7996 - val_mse: 34.6392 - val_mae: 4.7010
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1280 - mse: 36.9645 - mae: 4.7410 - val_loss: 35.0063 - val_mse: 34.8398 - val_mae: 4.7117
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9658 - mse: 36.7961 - mae: 4.7293 - val_loss: 34.6495 - val_mse: 34.4769 - val_mae: 4.6914
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7145 - mse: 36.5387 - mae: 4.7196 - val_loss: 34.5143 - val_mse: 34.3354 - val_mae: 4.6819
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4767 - mse: 36.2946 - mae: 4.7002 - val_loss: 35.4220 - val_mse: 35.2366 - val_mae: 4.7402
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1146 - mse: 35.9267 - mae: 4.6776 - val_loss: 33.8271 - val_mse: 33.6363 - val_mae: 4.6433
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7588 - mse: 35.5655 - mae: 4.6548 - val_loss: 33.3965 - val_mse: 33.2011 - val_mae: 4.6194
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3454 - mse: 35.1481 - mae: 4.6291 - val_loss: 33.3842 - val_mse: 33.1854 - val_mae: 4.6183
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3868 - mse: 35.1867 - mae: 4.6301 - val_loss: 32.9591 - val_mse: 32.7578 - val_mae: 4.5938
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0586 - mse: 34.8560 - mae: 4.6058 - val_loss: 33.3538 - val_mse: 33.1501 - val_mae: 4.6185
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8028 - mse: 34.5979 - mae: 4.5860 - val_loss: 33.1915 - val_mse: 32.9854 - val_mae: 4.6075
bias -0.011229086
si 0.4902811
rmse 0.057432923
kgeprime [0.56804032]
rmse_95 0.07379614
rmse_99 0.08134623
pearson 0.8484464785855287
pearson_95 0.7165434632537837
pearson_99 0.9030683310463702
rscore 0.7083716356699566
rscore_95 -0.9248864713650444
rscore_99 -6.661170847928114
nse [0.70837164]
nse_95 [-0.92488647]
nse_99 [-6.66117085]
kge [0.67213942]
ext_kge_95 [0.57685011]
ext_kge_99 [-0.24243425]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -2.156
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.01643
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([49227 49251 49275], shape=(3,), dtype=int64) Times out: tf.Tensor(49275, shape=(), dtype=int64)
Times in: tf.Tensor([18692 18716 18740], shape=(3,), dtype=int64) Times out: tf.Tensor(18740, shape=(), dtype=int64)
Times in: tf.Tensor([14664 14688 14712], shape=(3,), dtype=int64) Times out: tf.Tensor(14712, shape=(), dtype=int64)
Times in: tf.Tensor([108676 108700 108724], shape=(3,), dtype=int64) Times out: tf.Tensor(108724, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_590&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_591 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1180 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1181 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_590 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1180 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_590 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1181 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.4770 - mse: 51.4185 - mae: 5.5091 - val_loss: 37.4390 - val_mse: 37.3651 - val_mae: 4.8962
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9873 - mse: 38.9026 - mae: 4.8701 - val_loss: 36.0078 - val_mse: 35.9138 - val_mae: 4.7897
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0590 - mse: 37.9570 - mae: 4.8073 - val_loss: 35.2241 - val_mse: 35.1150 - val_mae: 4.7404
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5212 - mse: 37.4053 - mae: 4.7729 - val_loss: 35.0018 - val_mse: 34.8794 - val_mae: 4.7254
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1131 - mse: 36.9846 - mae: 4.7443 - val_loss: 35.1092 - val_mse: 34.9748 - val_mae: 4.7274
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8419 - mse: 36.7016 - mae: 4.7269 - val_loss: 34.7291 - val_mse: 34.5834 - val_mae: 4.7058
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4106 - mse: 36.2595 - mae: 4.7046 - val_loss: 35.1171 - val_mse: 34.9609 - val_mae: 4.7311
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1297 - mse: 35.9688 - mae: 4.6837 - val_loss: 35.2199 - val_mse: 35.0542 - val_mae: 4.7332
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9921 - mse: 35.8217 - mae: 4.6755 - val_loss: 35.1766 - val_mse: 35.0021 - val_mae: 4.7384
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7142 - mse: 35.5353 - mae: 4.6576 - val_loss: 34.9201 - val_mse: 34.7371 - val_mae: 4.7203
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5169 - mse: 35.3297 - mae: 4.6461 - val_loss: 35.6445 - val_mse: 35.4534 - val_mae: 4.7621
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3256 - mse: 35.1306 - mae: 4.6284 - val_loss: 35.0919 - val_mse: 34.8937 - val_mae: 4.7263
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1500 - mse: 34.9484 - mae: 4.6127 - val_loss: 35.5108 - val_mse: 35.3061 - val_mae: 4.7525
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8170 - mse: 34.6089 - mae: 4.5963 - val_loss: 34.6737 - val_mse: 34.4624 - val_mae: 4.7054
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6181 - mse: 34.4041 - mae: 4.5809 - val_loss: 34.4251 - val_mse: 34.2085 - val_mae: 4.6922
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3651 - mse: 34.1464 - mae: 4.5663 - val_loss: 33.2866 - val_mse: 33.0660 - val_mae: 4.6112
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0153 - mse: 33.7927 - mae: 4.5383 - val_loss: 34.0221 - val_mse: 33.7980 - val_mae: 4.6681
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7545 - mse: 33.5291 - mae: 4.5266 - val_loss: 34.8111 - val_mse: 34.5841 - val_mae: 4.7183
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6443 - mse: 33.4161 - mae: 4.5167 - val_loss: 33.6517 - val_mse: 33.4222 - val_mae: 4.6459
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4427 - mse: 33.2121 - mae: 4.5003 - val_loss: 32.6755 - val_mse: 32.4438 - val_mae: 4.5823
bias -0.009486574
si 0.48874447
rmse 0.056959495
kgeprime [0.61817827]
rmse_95 0.075286984
rmse_99 0.08615637
pearson 0.8500619078823193
pearson_95 0.7401976226908104
pearson_99 0.9072081014678405
rscore 0.7135093056825581
rscore_95 -1.0376233011603921
rscore_99 -7.932747681527172
nse [0.71350931]
nse_95 [-1.0376233]
nse_99 [-7.93274768]
kge [0.71052559]
ext_kge_95 [0.58162808]
ext_kge_99 [-0.27015226]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -2.156
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.01643
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([52774 52798 52822], shape=(3,), dtype=int64) Times out: tf.Tensor(52822, shape=(), dtype=int64)
Times in: tf.Tensor([104158 104182 104206], shape=(3,), dtype=int64) Times out: tf.Tensor(104206, shape=(), dtype=int64)
Times in: tf.Tensor([72338 72362 72386], shape=(3,), dtype=int64) Times out: tf.Tensor(72386, shape=(), dtype=int64)
Times in: tf.Tensor([99679 99703 99727], shape=(3,), dtype=int64) Times out: tf.Tensor(99727, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_591&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_592 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1182 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1183 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_591 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1182 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_591 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1183 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.3932 - mse: 50.3361 - mae: 5.4673 - val_loss: 36.8796 - val_mse: 36.8105 - val_mae: 4.8505
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3756 - mse: 39.3024 - mae: 4.8927 - val_loss: 35.6347 - val_mse: 35.5589 - val_mae: 4.7665
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7488 - mse: 38.6703 - mae: 4.8496 - val_loss: 35.2395 - val_mse: 35.1589 - val_mae: 4.7359
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2581 - mse: 38.1755 - mae: 4.8188 - val_loss: 35.0565 - val_mse: 34.9722 - val_mae: 4.7315
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9828 - mse: 37.8966 - mae: 4.8010 - val_loss: 34.9149 - val_mse: 34.8274 - val_mae: 4.7201
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8320 - mse: 37.7425 - mae: 4.7920 - val_loss: 35.0557 - val_mse: 34.9647 - val_mae: 4.7301
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5522 - mse: 37.4595 - mae: 4.7797 - val_loss: 34.7076 - val_mse: 34.6134 - val_mae: 4.7079
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3344 - mse: 37.2386 - mae: 4.7623 - val_loss: 34.6750 - val_mse: 34.5778 - val_mae: 4.7073
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1629 - mse: 37.0640 - mae: 4.7525 - val_loss: 34.7765 - val_mse: 34.6763 - val_mae: 4.7112
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.9915 - mse: 36.8895 - mae: 4.7436 - val_loss: 34.8460 - val_mse: 34.7428 - val_mae: 4.7154
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8581 - mse: 36.7533 - mae: 4.7306 - val_loss: 34.7117 - val_mse: 34.6060 - val_mae: 4.7069
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5659 - mse: 36.4585 - mae: 4.7164 - val_loss: 34.9265 - val_mse: 34.8176 - val_mae: 4.7200
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3434 - mse: 36.2329 - mae: 4.7002 - val_loss: 34.1838 - val_mse: 34.0716 - val_mae: 4.6756
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9075 - mse: 35.7932 - mae: 4.6704 - val_loss: 33.7057 - val_mse: 33.5894 - val_mae: 4.6386
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5624 - mse: 35.4440 - mae: 4.6473 - val_loss: 33.3014 - val_mse: 33.1814 - val_mae: 4.6078
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0658 - mse: 34.9439 - mae: 4.6160 - val_loss: 33.4063 - val_mse: 33.2829 - val_mae: 4.6133
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8895 - mse: 34.7649 - mae: 4.6001 - val_loss: 32.6237 - val_mse: 32.4978 - val_mae: 4.5685
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6803 - mse: 34.5531 - mae: 4.5843 - val_loss: 32.0932 - val_mse: 31.9650 - val_mae: 4.5374
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4365 - mse: 34.3068 - mae: 4.5691 - val_loss: 31.8386 - val_mse: 31.7081 - val_mae: 4.5214
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.2755 - mse: 34.1437 - mae: 4.5571 - val_loss: 31.8069 - val_mse: 31.6741 - val_mae: 4.5253
bias -0.0026044822
si 0.48985857
rmse 0.056279734
kgeprime [0.7598032]
rmse_95 0.08108397
rmse_99 0.09520555
pearson 0.8490846743624715
pearson_95 0.7385243325315403
pearson_99 0.9103385503840791
rscore 0.7197860023554907
rscore_95 -1.3885185563924187
rscore_99 -10.583591243540457
nse [0.719786]
nse_95 [-1.38851856]
nse_99 [-10.58359124]
kge [0.79358527]
ext_kge_95 [0.59041864]
ext_kge_99 [-0.16325721]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.156
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 0.01643
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([36667 36691 36715], shape=(3,), dtype=int64) Times out: tf.Tensor(36715, shape=(), dtype=int64)
Times in: tf.Tensor([151795 151819 151843], shape=(3,), dtype=int64) Times out: tf.Tensor(151843, shape=(), dtype=int64)
Times in: tf.Tensor([139959 139983 140007], shape=(3,), dtype=int64) Times out: tf.Tensor(140007, shape=(), dtype=int64)
Times in: tf.Tensor([106273 106297 106321], shape=(3,), dtype=int64) Times out: tf.Tensor(106321, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_592&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_593 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1184 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1185 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_592 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1184 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_592 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1185 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.6558 - mse: 53.5946 - mae: 5.6322 - val_loss: 37.4503 - val_mse: 37.3733 - val_mae: 4.9023
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1141 - mse: 40.0301 - mae: 4.9344 - val_loss: 35.6358 - val_mse: 35.5462 - val_mae: 4.7769
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8523 - mse: 38.7594 - mae: 4.8506 - val_loss: 35.6404 - val_mse: 35.5445 - val_mae: 4.7821
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2168 - mse: 38.1180 - mae: 4.8174 - val_loss: 35.4441 - val_mse: 35.3425 - val_mae: 4.7565
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8174 - mse: 37.7128 - mae: 4.7866 - val_loss: 35.0279 - val_mse: 34.9203 - val_mae: 4.7386
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3771 - mse: 37.2662 - mae: 4.7626 - val_loss: 35.0605 - val_mse: 34.9464 - val_mae: 4.7309
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1026 - mse: 36.9849 - mae: 4.7454 - val_loss: 35.3835 - val_mse: 35.2623 - val_mae: 4.7504
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8234 - mse: 36.6984 - mae: 4.7300 - val_loss: 34.9486 - val_mse: 34.8199 - val_mae: 4.7298
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6199 - mse: 36.4874 - mae: 4.7148 - val_loss: 34.8813 - val_mse: 34.7447 - val_mae: 4.7259
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4238 - mse: 36.2835 - mae: 4.7038 - val_loss: 34.4883 - val_mse: 34.3446 - val_mae: 4.6926
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2263 - mse: 36.0789 - mae: 4.6914 - val_loss: 34.2950 - val_mse: 34.1443 - val_mae: 4.6928
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9902 - mse: 35.8357 - mae: 4.6698 - val_loss: 34.5314 - val_mse: 34.3735 - val_mae: 4.7072
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5933 - mse: 35.4318 - mae: 4.6452 - val_loss: 33.8608 - val_mse: 33.6961 - val_mae: 4.6467
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1983 - mse: 35.0302 - mae: 4.6218 - val_loss: 33.3071 - val_mse: 33.1362 - val_mae: 4.6185
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7452 - mse: 34.5719 - mae: 4.5917 - val_loss: 33.4598 - val_mse: 33.2845 - val_mae: 4.6329
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4657 - mse: 34.2883 - mae: 4.5704 - val_loss: 33.4744 - val_mse: 33.2951 - val_mae: 4.6269
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2878 - mse: 34.1068 - mae: 4.5586 - val_loss: 32.3866 - val_mse: 32.2043 - val_mae: 4.5612
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9757 - mse: 33.7918 - mae: 4.5349 - val_loss: 32.2940 - val_mse: 32.1090 - val_mae: 4.5566
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9690 - mse: 33.7824 - mae: 4.5323 - val_loss: 32.3070 - val_mse: 32.1194 - val_mae: 4.5594
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7412 - mse: 33.5520 - mae: 4.5152 - val_loss: 32.7335 - val_mse: 32.5432 - val_mae: 4.5828
bias -0.0104998965
si 0.49061608
rmse 0.05704667
kgeprime [0.60772425]
rmse_95 0.07190735
rmse_99 0.08131768
pearson 0.850490594346107
pearson_95 0.7455960762775938
pearson_99 0.903353133728174
rscore 0.7098508560510043
rscore_95 -0.9504449817133309
rscore_99 -8.045975390194059
nse [0.70985086]
nse_95 [-0.95044498]
nse_99 [-8.04597539]
kge [0.69998486]
ext_kge_95 [0.57140562]
ext_kge_99 [-0.39153728]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.156
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 0.01643
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([74149 74173 74197], shape=(3,), dtype=int64) Times out: tf.Tensor(74197, shape=(), dtype=int64)
Times in: tf.Tensor([154100 154124 154148], shape=(3,), dtype=int64) Times out: tf.Tensor(154148, shape=(), dtype=int64)
Times in: tf.Tensor([38606 38630 38654], shape=(3,), dtype=int64) Times out: tf.Tensor(38654, shape=(), dtype=int64)
Times in: tf.Tensor([3903 3927 3951], shape=(3,), dtype=int64) Times out: tf.Tensor(3951, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_593&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_594 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1186 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1187 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_593 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1186 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_593 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1187 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.0715 - mse: 53.0166 - mae: 5.6176 - val_loss: 37.8875 - val_mse: 37.8222 - val_mae: 4.9126
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0798 - mse: 39.0087 - mae: 4.8756 - val_loss: 35.5244 - val_mse: 35.4481 - val_mae: 4.7547
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7581 - mse: 37.6775 - mae: 4.7902 - val_loss: 35.0118 - val_mse: 34.9271 - val_mae: 4.7189
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3092 - mse: 37.2217 - mae: 4.7597 - val_loss: 34.5805 - val_mse: 34.4906 - val_mae: 4.6901
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7452 - mse: 36.6530 - mae: 4.7227 - val_loss: 34.4354 - val_mse: 34.3410 - val_mae: 4.6778
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4897 - mse: 36.3927 - mae: 4.7020 - val_loss: 34.4523 - val_mse: 34.3527 - val_mae: 4.6783
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7478 - mse: 35.6454 - mae: 4.6562 - val_loss: 33.8650 - val_mse: 33.7597 - val_mae: 4.6429
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2576 - mse: 35.1500 - mae: 4.6233 - val_loss: 32.7866 - val_mse: 32.6766 - val_mae: 4.5771
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7027 - mse: 34.5903 - mae: 4.5873 - val_loss: 32.8115 - val_mse: 32.6971 - val_mae: 4.5764
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3792 - mse: 34.2630 - mae: 4.5619 - val_loss: 32.5182 - val_mse: 32.4000 - val_mae: 4.5550
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0033 - mse: 33.8836 - mae: 4.5407 - val_loss: 32.6648 - val_mse: 32.5431 - val_mae: 4.5700
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0213 - mse: 33.8981 - mae: 4.5382 - val_loss: 32.2819 - val_mse: 32.1571 - val_mae: 4.5361
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6302 - mse: 33.5042 - mae: 4.5161 - val_loss: 33.1748 - val_mse: 33.0472 - val_mae: 4.5914
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6104 - mse: 33.4815 - mae: 4.5131 - val_loss: 32.6183 - val_mse: 32.4879 - val_mae: 4.5575
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3786 - mse: 33.2465 - mae: 4.4933 - val_loss: 32.3855 - val_mse: 32.2517 - val_mae: 4.5462
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2253 - mse: 33.0904 - mae: 4.4864 - val_loss: 32.0785 - val_mse: 31.9418 - val_mae: 4.5222
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1008 - mse: 32.9630 - mae: 4.4744 - val_loss: 31.9152 - val_mse: 31.7758 - val_mae: 4.5119
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1121 - mse: 32.9715 - mae: 4.4780 - val_loss: 32.0013 - val_mse: 31.8594 - val_mae: 4.5246
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9376 - mse: 32.7945 - mae: 4.4620 - val_loss: 31.1774 - val_mse: 31.0329 - val_mae: 4.4661
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7180 - mse: 32.5728 - mae: 4.4531 - val_loss: 32.0065 - val_mse: 31.8597 - val_mae: 4.5229
bias -0.012736647
si 0.487746
rmse 0.05644443
kgeprime [0.52027547]
rmse_95 0.07115538
rmse_99 0.08026434
pearson 0.8505218053906641
pearson_95 0.7319786135694956
pearson_99 0.9008653326173964
rscore 0.7085014565006895
rscore_95 -1.012431853351821
rscore_99 -8.853158837883415
nse [0.70850146]
nse_95 [-1.01243185]
nse_99 [-8.85315884]
kge [0.63413405]
ext_kge_95 [0.56440499]
ext_kge_99 [-0.33141921]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -2.758
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 3.506
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 7.607
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 12.29
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 4.461
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([59389 59413 59437], shape=(3,), dtype=int64) Times out: tf.Tensor(59437, shape=(), dtype=int64)
Times in: tf.Tensor([44565 44589 44613], shape=(3,), dtype=int64) Times out: tf.Tensor(44613, shape=(), dtype=int64)
Times in: tf.Tensor([1626 1650 1674], shape=(3,), dtype=int64) Times out: tf.Tensor(1674, shape=(), dtype=int64)
Times in: tf.Tensor([19436 19460 19484], shape=(3,), dtype=int64) Times out: tf.Tensor(19484, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_594&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_595 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1188 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1189 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_594 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1188 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_594 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1189 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.4831 - mse: 47.4387 - mae: 5.3345 - val_loss: 31.5398 - val_mse: 31.4873 - val_mae: 4.5056
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3883 - mse: 35.3323 - mae: 4.6422 - val_loss: 30.2854 - val_mse: 30.2258 - val_mae: 4.4286
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6084 - mse: 33.5443 - mae: 4.5178 - val_loss: 28.9966 - val_mse: 28.9281 - val_mae: 4.3335
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8306 - mse: 32.7588 - mae: 4.4594 - val_loss: 28.6594 - val_mse: 28.5850 - val_mae: 4.3059
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6528 - mse: 32.5768 - mae: 4.4509 - val_loss: 28.2812 - val_mse: 28.2035 - val_mae: 4.2797
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4834 - mse: 32.4046 - mae: 4.4405 - val_loss: 28.0651 - val_mse: 27.9849 - val_mae: 4.2648
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3179 - mse: 32.2365 - mae: 4.4253 - val_loss: 28.2269 - val_mse: 28.1442 - val_mae: 4.2743
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1086 - mse: 32.0245 - mae: 4.4102 - val_loss: 27.5725 - val_mse: 27.4871 - val_mae: 4.2263
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9122 - mse: 31.8256 - mae: 4.3944 - val_loss: 27.6585 - val_mse: 27.5706 - val_mae: 4.2354
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9466 - mse: 31.8575 - mae: 4.3933 - val_loss: 28.4188 - val_mse: 28.3280 - val_mae: 4.2886
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7424 - mse: 31.6504 - mae: 4.3865 - val_loss: 28.2168 - val_mse: 28.1235 - val_mae: 4.2765
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6554 - mse: 31.5610 - mae: 4.3757 - val_loss: 27.7990 - val_mse: 27.7030 - val_mae: 4.2471
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2400 - mse: 31.1427 - mae: 4.3442 - val_loss: 27.6359 - val_mse: 27.5367 - val_mae: 4.2384
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1857 - mse: 31.0852 - mae: 4.3429 - val_loss: 27.8634 - val_mse: 27.7615 - val_mae: 4.2555
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1533 - mse: 31.0499 - mae: 4.3362 - val_loss: 27.1387 - val_mse: 27.0337 - val_mae: 4.1996
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0043 - mse: 30.8977 - mae: 4.3269 - val_loss: 27.6346 - val_mse: 27.5267 - val_mae: 4.2401
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9860 - mse: 30.8764 - mae: 4.3245 - val_loss: 27.0506 - val_mse: 26.9396 - val_mae: 4.1944
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6404 - mse: 30.5279 - mae: 4.2999 - val_loss: 27.2933 - val_mse: 27.1792 - val_mae: 4.2131
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4946 - mse: 30.3793 - mae: 4.2859 - val_loss: 27.4499 - val_mse: 27.3332 - val_mae: 4.2252
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5822 - mse: 30.4638 - mae: 4.2880 - val_loss: 26.4835 - val_mse: 26.3637 - val_mae: 4.1517
bias -0.007053929
si 0.49012896
rmse 0.051345613
kgeprime [0.63503995]
rmse_95 0.06923154
rmse_99 0.080010064
pearson 0.8494892188059405
pearson_95 0.6806451340721881
pearson_99 0.7737947699572654
rscore 0.7162404793529493
rscore_95 -1.4008494834287446
rscore_99 -8.282451429576472
nse [0.71624048]
nse_95 [-1.40084948]
nse_99 [-8.28245143]
kge [0.72208129]
ext_kge_95 [0.52207697]
ext_kge_99 [-0.14891836]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -2.758
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 3.506
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 7.607
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 12.29
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 4.461
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([122942 122966 122990], shape=(3,), dtype=int64) Times out: tf.Tensor(122990, shape=(), dtype=int64)
Times in: tf.Tensor([18691 18715 18739], shape=(3,), dtype=int64) Times out: tf.Tensor(18739, shape=(), dtype=int64)
Times in: tf.Tensor([35416 35440 35464], shape=(3,), dtype=int64) Times out: tf.Tensor(35464, shape=(), dtype=int64)
Times in: tf.Tensor([111473 111497 111521], shape=(3,), dtype=int64) Times out: tf.Tensor(111521, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_595&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_596 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1190 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1191 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_595 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1190 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_595 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1191 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.1270 - mse: 42.0726 - mae: 5.0028 - val_loss: 29.0580 - val_mse: 28.9921 - val_mae: 4.3343
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5999 - mse: 31.5272 - mae: 4.3892 - val_loss: 27.7103 - val_mse: 27.6310 - val_mae: 4.2226
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7002 - mse: 30.6142 - mae: 4.3158 - val_loss: 26.9142 - val_mse: 26.8223 - val_mae: 4.1637
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7165 - mse: 29.6202 - mae: 4.2456 - val_loss: 26.3256 - val_mse: 26.2253 - val_mae: 4.1211
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1154 - mse: 29.0112 - mae: 4.2008 - val_loss: 25.8004 - val_mse: 25.6927 - val_mae: 4.0853
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5730 - mse: 28.4621 - mae: 4.1544 - val_loss: 25.4267 - val_mse: 25.3130 - val_mae: 4.0575
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2166 - mse: 28.1007 - mae: 4.1268 - val_loss: 25.2760 - val_mse: 25.1580 - val_mae: 4.0463
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9294 - mse: 27.8096 - mae: 4.1062 - val_loss: 24.9144 - val_mse: 24.7930 - val_mae: 4.0192
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7163 - mse: 27.5933 - mae: 4.0916 - val_loss: 24.7412 - val_mse: 24.6165 - val_mae: 4.0090
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5165 - mse: 27.3902 - mae: 4.0759 - val_loss: 24.6392 - val_mse: 24.5116 - val_mae: 3.9972
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3777 - mse: 27.2487 - mae: 4.0642 - val_loss: 24.4397 - val_mse: 24.3093 - val_mae: 3.9828
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2248 - mse: 27.0930 - mae: 4.0511 - val_loss: 24.2228 - val_mse: 24.0895 - val_mae: 3.9630
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1662 - mse: 27.0320 - mae: 4.0406 - val_loss: 24.3069 - val_mse: 24.1716 - val_mae: 3.9725
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0533 - mse: 26.9168 - mae: 4.0376 - val_loss: 24.2799 - val_mse: 24.1422 - val_mae: 3.9694
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8937 - mse: 26.7551 - mae: 4.0246 - val_loss: 24.5407 - val_mse: 24.4008 - val_mae: 3.9860
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8934 - mse: 26.7526 - mae: 4.0232 - val_loss: 24.0484 - val_mse: 23.9068 - val_mae: 3.9462
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7210 - mse: 26.5782 - mae: 4.0152 - val_loss: 24.1782 - val_mse: 24.0345 - val_mae: 3.9583
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6700 - mse: 26.5255 - mae: 4.0062 - val_loss: 23.9405 - val_mse: 23.7950 - val_mae: 3.9365
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4990 - mse: 26.3525 - mae: 3.9904 - val_loss: 24.5406 - val_mse: 24.3931 - val_mae: 3.9833
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5320 - mse: 26.3838 - mae: 3.9958 - val_loss: 23.8906 - val_mse: 23.7416 - val_mae: 3.9293
bias -0.0044783964
si 0.47388816
rmse 0.04872536
kgeprime [0.70505241]
rmse_95 0.06655767
rmse_99 0.08015809
pearson 0.8598336384679782
pearson_95 0.6811189312825006
pearson_99 0.726950048136678
rscore 0.7370921424251377
rscore_95 -1.3810726658770758
rscore_99 -7.533626131201492
nse [0.73709214]
nse_95 [-1.38107267]
nse_99 [-7.53362613]
kge [0.76901541]
ext_kge_95 [0.51558201]
ext_kge_99 [-0.17003275]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 3.467
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 6.76
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([127597 127621 127645], shape=(3,), dtype=int64) Times out: tf.Tensor(127645, shape=(), dtype=int64)
Times in: tf.Tensor([27753 27777 27801], shape=(3,), dtype=int64) Times out: tf.Tensor(27801, shape=(), dtype=int64)
Times in: tf.Tensor([111039 111063 111087], shape=(3,), dtype=int64) Times out: tf.Tensor(111087, shape=(), dtype=int64)
Times in: tf.Tensor([48723 48747 48771], shape=(3,), dtype=int64) Times out: tf.Tensor(48771, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_596&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_597 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1192 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1193 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_596 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1192 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_596 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1193 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.5723 - mse: 40.5061 - mae: 4.9079 - val_loss: 29.3404 - val_mse: 29.2570 - val_mae: 4.3440
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4449 - mse: 31.3509 - mae: 4.3757 - val_loss: 28.1217 - val_mse: 28.0180 - val_mae: 4.2552
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7374 - mse: 30.6278 - mae: 4.3207 - val_loss: 28.2189 - val_mse: 28.1038 - val_mae: 4.2624
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3090 - mse: 30.1902 - mae: 4.2867 - val_loss: 27.4882 - val_mse: 27.3661 - val_mae: 4.2058
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0505 - mse: 29.9257 - mae: 4.2697 - val_loss: 27.3946 - val_mse: 27.2671 - val_mae: 4.1962
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7469 - mse: 29.6166 - mae: 4.2465 - val_loss: 27.3384 - val_mse: 27.2053 - val_mae: 4.1945
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5377 - mse: 29.4019 - mae: 4.2281 - val_loss: 27.2644 - val_mse: 27.1256 - val_mae: 4.1919
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0267 - mse: 28.8852 - mae: 4.1908 - val_loss: 26.5464 - val_mse: 26.4019 - val_mae: 4.1374
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5257 - mse: 28.3787 - mae: 4.1489 - val_loss: 26.6622 - val_mse: 26.5127 - val_mae: 4.1495
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2393 - mse: 28.0872 - mae: 4.1259 - val_loss: 26.5481 - val_mse: 26.3940 - val_mae: 4.1465
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9537 - mse: 27.7975 - mae: 4.1075 - val_loss: 26.1780 - val_mse: 26.0200 - val_mae: 4.1178
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7838 - mse: 27.6245 - mae: 4.0967 - val_loss: 26.4613 - val_mse: 26.3004 - val_mae: 4.1420
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7205 - mse: 27.5581 - mae: 4.0877 - val_loss: 25.5233 - val_mse: 25.3595 - val_mae: 4.0663
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3819 - mse: 27.2170 - mae: 4.0632 - val_loss: 25.6259 - val_mse: 25.4601 - val_mae: 4.0735
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2701 - mse: 27.1031 - mae: 4.0524 - val_loss: 25.3078 - val_mse: 25.1397 - val_mae: 4.0493
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1284 - mse: 26.9592 - mae: 4.0417 - val_loss: 25.8255 - val_mse: 25.6552 - val_mae: 4.0902
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1056 - mse: 26.9341 - mae: 4.0392 - val_loss: 25.3498 - val_mse: 25.1773 - val_mae: 4.0499
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0331 - mse: 26.8596 - mae: 4.0336 - val_loss: 25.5450 - val_mse: 25.3704 - val_mae: 4.0674
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 26.8658 - mse: 26.6904 - mae: 4.0183 - val_loss: 25.0931 - val_mse: 24.9165 - val_mae: 4.0315
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9001 - mse: 26.7226 - mae: 4.0208 - val_loss: 25.8965 - val_mse: 25.7181 - val_mae: 4.0940
bias -0.013014759
si 0.47785813
rmse 0.050713032
kgeprime [0.48202413]
rmse_95 0.062462226
rmse_99 0.075283624
pearson 0.8572413477085049
pearson_95 0.6740340567656382
pearson_99 0.7312669226039283
rscore 0.7161554634236729
rscore_95 -1.0834067274965857
rscore_99 -6.703603985934258
nse [0.71615546]
nse_95 [-1.08340673]
nse_99 [-6.70360399]
kge [0.60277257]
ext_kge_95 [0.5426918]
ext_kge_99 [-0.04066195]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.2 -10.02 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.43 11.57 ... 3.467
    uw2             (time, latitude, longitude) float32 104.0 100.4 ... 6.76
    vw2             (time, latitude, longitude) float32 130.6 133.8 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.32 15.3 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([141849 141873 141897], shape=(3,), dtype=int64) Times out: tf.Tensor(141897, shape=(), dtype=int64)
Times in: tf.Tensor([37858 37882 37906], shape=(3,), dtype=int64) Times out: tf.Tensor(37906, shape=(), dtype=int64)
Times in: tf.Tensor([121761 121785 121809], shape=(3,), dtype=int64) Times out: tf.Tensor(121809, shape=(), dtype=int64)
Times in: tf.Tensor([63939 63963 63987], shape=(3,), dtype=int64) Times out: tf.Tensor(63987, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_597&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_598 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1194 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1195 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_597 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1194 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_597 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1195 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.8241 - mse: 43.7748 - mae: 5.0891 - val_loss: 29.3070 - val_mse: 29.2485 - val_mae: 4.3396
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3027 - mse: 33.2409 - mae: 4.4949 - val_loss: 28.4930 - val_mse: 28.4286 - val_mae: 4.2849
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8636 - mse: 32.7974 - mae: 4.4584 - val_loss: 28.1580 - val_mse: 28.0903 - val_mae: 4.2617
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5921 - mse: 32.5231 - mae: 4.4459 - val_loss: 28.0070 - val_mse: 27.9367 - val_mae: 4.2549
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5272 - mse: 32.4556 - mae: 4.4347 - val_loss: 27.7020 - val_mse: 27.6288 - val_mae: 4.2257
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2523 - mse: 32.1772 - mae: 4.4210 - val_loss: 27.7440 - val_mse: 27.6672 - val_mae: 4.2304
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0550 - mse: 31.9762 - mae: 4.4023 - val_loss: 27.5787 - val_mse: 27.4978 - val_mae: 4.2194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7418 - mse: 31.6588 - mae: 4.3844 - val_loss: 27.4759 - val_mse: 27.3910 - val_mae: 4.2114
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8240 - mse: 31.7370 - mae: 4.3894 - val_loss: 27.3918 - val_mse: 27.3025 - val_mae: 4.2046
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6002 - mse: 31.5083 - mae: 4.3747 - val_loss: 27.4708 - val_mse: 27.3766 - val_mae: 4.2133
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5378 - mse: 31.4410 - mae: 4.3669 - val_loss: 27.3688 - val_mse: 27.2698 - val_mae: 4.2035
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3891 - mse: 31.2875 - mae: 4.3563 - val_loss: 27.3393 - val_mse: 27.2351 - val_mae: 4.2021
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2965 - mse: 31.1897 - mae: 4.3470 - val_loss: 27.1256 - val_mse: 27.0165 - val_mae: 4.1871
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1182 - mse: 31.0065 - mae: 4.3347 - val_loss: 27.7073 - val_mse: 27.5932 - val_mae: 4.2337
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9452 - mse: 30.8285 - mae: 4.3225 - val_loss: 26.9951 - val_mse: 26.8759 - val_mae: 4.1778
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6880 - mse: 30.5665 - mae: 4.3018 - val_loss: 27.0945 - val_mse: 26.9706 - val_mae: 4.1862
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6024 - mse: 30.4763 - mae: 4.2997 - val_loss: 27.1992 - val_mse: 27.0706 - val_mae: 4.1947
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.3795 - mse: 30.2486 - mae: 4.2799 - val_loss: 26.4925 - val_mse: 26.3597 - val_mae: 4.1399
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3415 - mse: 30.2065 - mae: 4.2725 - val_loss: 26.9340 - val_mse: 26.7975 - val_mae: 4.1778
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1384 - mse: 30.0001 - mae: 4.2574 - val_loss: 26.4630 - val_mse: 26.3231 - val_mae: 4.1476
bias -0.005505145
si 0.49540514
rmse 0.05130599
kgeprime [0.67020353]
rmse_95 0.07281767
rmse_99 0.08649079
pearson 0.8455526180991637
pearson_95 0.664909962590044
pearson_99 0.76507365929739
rscore 0.7115792906027036
rscore_95 -1.7813230167444365
rscore_99 -9.543577924279749
nse [0.71157929]
nse_95 [-1.78132302]
nse_99 [-9.54357792]
kge [0.74322853]
ext_kge_95 [0.51928132]
ext_kge_99 [-0.05094793]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 3.467
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 6.76
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([103909 103933 103957], shape=(3,), dtype=int64) Times out: tf.Tensor(103957, shape=(), dtype=int64)
Times in: tf.Tensor([104915 104939 104963], shape=(3,), dtype=int64) Times out: tf.Tensor(104963, shape=(), dtype=int64)
Times in: tf.Tensor([3525 3549 3573], shape=(3,), dtype=int64) Times out: tf.Tensor(3573, shape=(), dtype=int64)
Times in: tf.Tensor([36825 36849 36873], shape=(3,), dtype=int64) Times out: tf.Tensor(36873, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_598&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_599 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1196 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1197 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_598 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1196 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_598 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1197 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.4203 - mse: 42.3596 - mae: 5.0354 - val_loss: 30.2434 - val_mse: 30.1697 - val_mae: 4.4170
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9408 - mse: 32.8574 - mae: 4.4845 - val_loss: 29.2489 - val_mse: 29.1561 - val_mae: 4.3472
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8334 - mse: 31.7313 - mae: 4.4002 - val_loss: 29.9843 - val_mse: 29.8736 - val_mae: 4.3935
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1240 - mse: 31.0061 - mae: 4.3503 - val_loss: 28.7121 - val_mse: 28.5884 - val_mae: 4.3009
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6772 - mse: 30.5479 - mae: 4.3186 - val_loss: 28.1355 - val_mse: 28.0013 - val_mae: 4.2589
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2257 - mse: 30.0864 - mae: 4.2830 - val_loss: 28.1182 - val_mse: 27.9744 - val_mae: 4.2599
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6449 - mse: 29.4962 - mae: 4.2413 - val_loss: 27.9020 - val_mse: 27.7493 - val_mae: 4.2504
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3603 - mse: 29.2034 - mae: 4.2177 - val_loss: 27.8391 - val_mse: 27.6784 - val_mae: 4.2488
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9631 - mse: 28.7984 - mae: 4.1895 - val_loss: 27.2855 - val_mse: 27.1171 - val_mae: 4.2113
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7003 - mse: 28.5279 - mae: 4.1667 - val_loss: 27.8272 - val_mse: 27.6516 - val_mae: 4.2496
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4122 - mse: 28.2326 - mae: 4.1430 - val_loss: 27.1654 - val_mse: 26.9826 - val_mae: 4.2001
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2857 - mse: 28.0994 - mae: 4.1320 - val_loss: 27.3680 - val_mse: 27.1789 - val_mae: 4.2118
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2289 - mse: 28.0368 - mae: 4.1281 - val_loss: 27.1075 - val_mse: 26.9128 - val_mae: 4.1940
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1028 - mse: 27.9051 - mae: 4.1161 - val_loss: 26.4331 - val_mse: 26.2330 - val_mae: 4.1393
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8785 - mse: 27.6760 - mae: 4.0979 - val_loss: 27.3413 - val_mse: 27.1368 - val_mae: 4.2093
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8783 - mse: 27.6716 - mae: 4.0972 - val_loss: 27.0634 - val_mse: 26.8549 - val_mae: 4.1874
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6904 - mse: 27.4799 - mae: 4.0834 - val_loss: 26.8203 - val_mse: 26.6080 - val_mae: 4.1685
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5508 - mse: 27.3368 - mae: 4.0783 - val_loss: 26.4412 - val_mse: 26.2257 - val_mae: 4.1386
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5997 - mse: 27.3822 - mae: 4.0800 - val_loss: 25.9985 - val_mse: 25.7795 - val_mae: 4.1031
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3998 - mse: 27.1788 - mae: 4.0627 - val_loss: 26.4485 - val_mse: 26.2261 - val_mae: 4.1414
bias -0.011192442
si 0.4812953
rmse 0.051211398
kgeprime [0.53803251]
rmse_95 0.064493515
rmse_99 0.0800002
pearson 0.8548995212407262
pearson_95 0.6645579954016438
pearson_99 0.7561230223249362
rscore 0.7172839594042182
rscore_95 -1.0820106841255757
rscore_99 -8.597607803153695
nse [0.71728396]
nse_95 [-1.08201068]
nse_99 [-8.5976078]
kge [0.64914142]
ext_kge_95 [0.56348699]
ext_kge_99 [-0.18815125]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 3.467
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 6.76
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([31708 31732 31756], shape=(3,), dtype=int64) Times out: tf.Tensor(31756, shape=(), dtype=int64)
Times in: tf.Tensor([65243 65267 65291], shape=(3,), dtype=int64) Times out: tf.Tensor(65291, shape=(), dtype=int64)
Times in: tf.Tensor([14959 14983 15007], shape=(3,), dtype=int64) Times out: tf.Tensor(15007, shape=(), dtype=int64)
Times in: tf.Tensor([10059 10083 10107], shape=(3,), dtype=int64) Times out: tf.Tensor(10107, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_599&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_600 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1198 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1199 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_599 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1198 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_599 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1199 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.5025 - mse: 43.4492 - mae: 5.0930 - val_loss: 31.3961 - val_mse: 31.3296 - val_mae: 4.5031
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8354 - mse: 33.7588 - mae: 4.5435 - val_loss: 30.0800 - val_mse: 29.9928 - val_mae: 4.4035
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8272 - mse: 32.7316 - mae: 4.4760 - val_loss: 29.9407 - val_mse: 29.8363 - val_mae: 4.3953
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2098 - mse: 32.0975 - mae: 4.4316 - val_loss: 29.3327 - val_mse: 29.2122 - val_mae: 4.3524
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8700 - mse: 31.7432 - mae: 4.4068 - val_loss: 29.8243 - val_mse: 29.6906 - val_mae: 4.3929
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6035 - mse: 31.4643 - mae: 4.3810 - val_loss: 29.0620 - val_mse: 28.9167 - val_mae: 4.3355
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2907 - mse: 31.1404 - mae: 4.3646 - val_loss: 29.3332 - val_mse: 29.1769 - val_mae: 4.3548
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0199 - mse: 30.8590 - mae: 4.3417 - val_loss: 29.3126 - val_mse: 29.1461 - val_mae: 4.3572
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8273 - mse: 30.6569 - mae: 4.3314 - val_loss: 28.8545 - val_mse: 28.6790 - val_mae: 4.3232
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5932 - mse: 30.4140 - mae: 4.3095 - val_loss: 28.9672 - val_mse: 28.7832 - val_mae: 4.3306
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2412 - mse: 30.0543 - mae: 4.2817 - val_loss: 29.6626 - val_mse: 29.4720 - val_mae: 4.3816
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8555 - mse: 29.6627 - mae: 4.2565 - val_loss: 28.2606 - val_mse: 28.0647 - val_mae: 4.2773
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7567 - mse: 29.5591 - mae: 4.2487 - val_loss: 28.0134 - val_mse: 27.8134 - val_mae: 4.2608
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5802 - mse: 29.3787 - mae: 4.2342 - val_loss: 28.6591 - val_mse: 28.4558 - val_mae: 4.3084
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4736 - mse: 29.2687 - mae: 4.2270 - val_loss: 27.6397 - val_mse: 27.4329 - val_mae: 4.2298
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3368 - mse: 29.1290 - mae: 4.2135 - val_loss: 27.5623 - val_mse: 27.3531 - val_mae: 4.2229
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2730 - mse: 29.0630 - mae: 4.2090 - val_loss: 28.2503 - val_mse: 28.0388 - val_mae: 4.2754
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1326 - mse: 28.9202 - mae: 4.1980 - val_loss: 27.4160 - val_mse: 27.2026 - val_mae: 4.2091
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0974 - mse: 28.8830 - mae: 4.1952 - val_loss: 27.8608 - val_mse: 27.6454 - val_mae: 4.2442
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9630 - mse: 28.7468 - mae: 4.1804 - val_loss: 27.3466 - val_mse: 27.1296 - val_mae: 4.2011
bias -0.0072343075
si 0.49273646
rmse 0.052086048
kgeprime [0.6327415]
rmse_95 0.06855576
rmse_99 0.08391745
pearson 0.8473644072639748
pearson_95 0.6868178211071071
pearson_99 0.7596180693714633
rscore 0.7124077898288217
rscore_95 -1.2162266895806888
rscore_99 -9.792669655555054
nse [0.71240779]
nse_95 [-1.21622669]
nse_99 [-9.79266966]
kge [0.71997972]
ext_kge_95 [0.57202942]
ext_kge_99 [-0.25083962]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.02 -9.86 ... -2.6
    vgrd10m         (time, latitude, longitude) float32 11.57 11.66 ... 3.467
    uw2             (time, latitude, longitude) float32 100.4 97.21 ... 6.76
    vw2             (time, latitude, longitude) float32 133.8 135.9 ... 12.02
    wind_magnitude  (time, latitude, longitude) float32 15.3 15.27 ... 4.334
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([99567 99591 99615], shape=(3,), dtype=int64) Times out: tf.Tensor(99615, shape=(), dtype=int64)
Times in: tf.Tensor([16782 16806 16830], shape=(3,), dtype=int64) Times out: tf.Tensor(16830, shape=(), dtype=int64)
Times in: tf.Tensor([102720 102744 102768], shape=(3,), dtype=int64) Times out: tf.Tensor(102768, shape=(), dtype=int64)
Times in: tf.Tensor([134549 134573 134597], shape=(3,), dtype=int64) Times out: tf.Tensor(134597, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_600&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_601 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1200 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1201 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_600 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1200 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_600 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1201 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.0239 - mse: 42.9694 - mae: 5.0634 - val_loss: 30.7731 - val_mse: 30.7068 - val_mae: 4.4676
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6135 - mse: 33.5393 - mae: 4.5319 - val_loss: 29.7688 - val_mse: 29.6868 - val_mae: 4.3851
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6118 - mse: 32.5239 - mae: 4.4595 - val_loss: 29.3733 - val_mse: 29.2800 - val_mae: 4.3485
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1380 - mse: 32.0399 - mae: 4.4248 - val_loss: 29.1576 - val_mse: 29.0548 - val_mae: 4.3356
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7218 - mse: 31.6145 - mae: 4.3937 - val_loss: 28.8071 - val_mse: 28.6955 - val_mae: 4.3136
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2983 - mse: 31.1821 - mae: 4.3662 - val_loss: 28.9019 - val_mse: 28.7811 - val_mae: 4.3251
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1399 - mse: 31.0152 - mae: 4.3524 - val_loss: 28.8294 - val_mse: 28.7001 - val_mae: 4.3204
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8664 - mse: 30.7336 - mae: 4.3319 - val_loss: 28.6147 - val_mse: 28.4780 - val_mae: 4.3026
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5845 - mse: 30.4438 - mae: 4.3136 - val_loss: 28.4410 - val_mse: 28.2958 - val_mae: 4.2920
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2378 - mse: 30.0896 - mae: 4.2863 - val_loss: 28.2828 - val_mse: 28.1308 - val_mae: 4.2831
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8809 - mse: 29.7259 - mae: 4.2550 - val_loss: 27.8881 - val_mse: 27.7299 - val_mae: 4.2492
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6111 - mse: 29.4505 - mae: 4.2387 - val_loss: 27.7727 - val_mse: 27.6094 - val_mae: 4.2424
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3785 - mse: 29.2131 - mae: 4.2218 - val_loss: 27.5784 - val_mse: 27.4107 - val_mae: 4.2302
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2431 - mse: 29.0738 - mae: 4.2107 - val_loss: 27.5993 - val_mse: 27.4279 - val_mae: 4.2298
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9431 - mse: 28.7701 - mae: 4.1912 - val_loss: 28.1357 - val_mse: 27.9610 - val_mae: 4.2690
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8653 - mse: 28.6893 - mae: 4.1831 - val_loss: 27.3015 - val_mse: 27.1241 - val_mae: 4.2073
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8507 - mse: 28.6720 - mae: 4.1782 - val_loss: 26.8864 - val_mse: 26.7063 - val_mae: 4.1750
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7308 - mse: 28.5497 - mae: 4.1708 - val_loss: 26.7612 - val_mse: 26.5788 - val_mae: 4.1624
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6052 - mse: 28.4220 - mae: 4.1591 - val_loss: 26.7928 - val_mse: 26.6085 - val_mae: 4.1640
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5684 - mse: 28.3834 - mae: 4.1506 - val_loss: 26.8174 - val_mse: 26.6312 - val_mae: 4.1636
bias -0.005593557
si 0.4955337
rmse 0.051605422
kgeprime [0.6857219]
rmse_95 0.0675082
rmse_99 0.08247923
pearson 0.8460328876862244
pearson_95 0.6613374210659148
pearson_99 0.7158680736985218
rscore 0.7113256725832735
rscore_95 -1.2638399689161721
rscore_99 -9.22901036922125
nse [0.71132567]
nse_95 [-1.26383997]
nse_99 [-9.22901037]
kge [0.75621994]
ext_kge_95 [0.53723503]
ext_kge_99 [-0.32504345]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.789 -9.74 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.62 11.53 ... -0.8311
    uw2             (time, latitude, longitude) float32 95.83 94.87 ... 0.6148
    vw2             (time, latitude, longitude) float32 135.0 132.9 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.19 15.09 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([123820 123844 123868], shape=(3,), dtype=int64) Times out: tf.Tensor(123868, shape=(), dtype=int64)
Times in: tf.Tensor([107174 107198 107222], shape=(3,), dtype=int64) Times out: tf.Tensor(107222, shape=(), dtype=int64)
Times in: tf.Tensor([54160 54184 54208], shape=(3,), dtype=int64) Times out: tf.Tensor(54208, shape=(), dtype=int64)
Times in: tf.Tensor([106001 106025 106049], shape=(3,), dtype=int64) Times out: tf.Tensor(106049, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_601&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_602 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1202 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1203 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_601 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1202 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_601 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1203 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 64.1627 - mse: 64.1198 - mae: 6.1766 - val_loss: 43.2652 - val_mse: 43.2117 - val_mae: 5.2277
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.2755 - mse: 46.2169 - mae: 5.2892 - val_loss: 38.8816 - val_mse: 38.8176 - val_mae: 4.9626
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.3130 - mse: 44.2442 - mae: 5.1701 - val_loss: 38.0604 - val_mse: 37.9871 - val_mae: 4.9027
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.6309 - mse: 43.5540 - mae: 5.1312 - val_loss: 37.9940 - val_mse: 37.9129 - val_mae: 4.8945
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.5294 - mse: 43.4448 - mae: 5.1176 - val_loss: 37.1555 - val_mse: 37.0667 - val_mae: 4.8494
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.9555 - mse: 42.8629 - mae: 5.0906 - val_loss: 36.6988 - val_mse: 36.6018 - val_mae: 4.8178
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.5763 - mse: 42.4758 - mae: 5.0679 - val_loss: 36.9955 - val_mse: 36.8905 - val_mae: 4.8379
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.3385 - mse: 42.2296 - mae: 5.0547 - val_loss: 36.3936 - val_mse: 36.2804 - val_mae: 4.8060
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1325 - mse: 42.0159 - mae: 5.0355 - val_loss: 36.3433 - val_mse: 36.2222 - val_mae: 4.8021
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.9506 - mse: 41.8262 - mae: 5.0301 - val_loss: 36.5835 - val_mse: 36.4551 - val_mae: 4.8175
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.7889 - mse: 41.6574 - mae: 5.0206 - val_loss: 37.1248 - val_mse: 36.9895 - val_mae: 4.8530
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.4627 - mse: 41.3246 - mae: 4.9939 - val_loss: 36.6288 - val_mse: 36.4872 - val_mae: 4.8208
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.3870 - mse: 41.2429 - mae: 4.9932 - val_loss: 36.4587 - val_mse: 36.3114 - val_mae: 4.8118
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.1169 - mse: 40.9672 - mae: 4.9770 - val_loss: 36.3692 - val_mse: 36.2166 - val_mae: 4.8060
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.0496 - mse: 40.8945 - mae: 4.9687 - val_loss: 36.8321 - val_mse: 36.6740 - val_mae: 4.8388
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.1185 - mse: 40.9585 - mae: 4.9715 - val_loss: 38.0605 - val_mse: 37.8980 - val_mae: 4.9109
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.8715 - mse: 40.7070 - mae: 4.9559 - val_loss: 38.7160 - val_mse: 38.5490 - val_mae: 4.9540
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.6892 - mse: 40.5207 - mae: 4.9460 - val_loss: 36.9539 - val_mse: 36.7831 - val_mae: 4.8465
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.4917 - mse: 40.3195 - mae: 4.9317 - val_loss: 37.3861 - val_mse: 37.2120 - val_mae: 4.8765
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.6338 - mse: 40.4584 - mae: 4.9437 - val_loss: 36.4104 - val_mse: 36.2330 - val_mae: 4.8144
bias -0.011297905
si 0.49949336
rmse 0.06019391
kgeprime [0.55516904]
rmse_95 0.0855533
rmse_99 0.10168967
pearson 0.8417746851742142
pearson_95 0.6578673233998025
pearson_99 0.8275106783767484
rscore 0.6979235889820123
rscore_95 -1.2197808340317349
rscore_99 -10.188134827711567
nse [0.69792359]
nse_95 [-1.21978083]
nse_99 [-10.18813483]
kge [0.6611969]
ext_kge_95 [0.53422276]
ext_kge_99 [-0.49751947]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.6 165.9 166.2 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.74 -9.708 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.53 11.38 ... -0.8311
    uw2             (time, latitude, longitude) float32 94.87 94.24 ... 0.6148
    vw2             (time, latitude, longitude) float32 132.9 129.5 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.09 14.96 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([22151 22175 22199], shape=(3,), dtype=int64) Times out: tf.Tensor(22199, shape=(), dtype=int64)
Times in: tf.Tensor([94496 94520 94544], shape=(3,), dtype=int64) Times out: tf.Tensor(94544, shape=(), dtype=int64)
Times in: tf.Tensor([26457 26481 26505], shape=(3,), dtype=int64) Times out: tf.Tensor(26505, shape=(), dtype=int64)
Times in: tf.Tensor([133904 133928 133952], shape=(3,), dtype=int64) Times out: tf.Tensor(133952, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_602&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_603 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1204 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1205 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_602 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1204 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_602 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1205 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 64.3668 - mse: 64.3176 - mae: 6.2067 - val_loss: 43.9702 - val_mse: 43.9123 - val_mae: 5.2767
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.4889 - mse: 47.4224 - mae: 5.3870 - val_loss: 41.6983 - val_mse: 41.6253 - val_mae: 5.1365
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.3362 - mse: 44.2558 - mae: 5.1938 - val_loss: 39.2078 - val_mse: 39.1212 - val_mae: 4.9960
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.8348 - mse: 42.7427 - mae: 5.1007 - val_loss: 38.6439 - val_mse: 38.5472 - val_mae: 4.9411
Epoch 5/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.2755 - mse: 42.1749 - mae: 5.0627 - val_loss: 38.4260 - val_mse: 38.3222 - val_mae: 4.9222
Epoch 6/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.8336 - mse: 41.7265 - mae: 5.0342 - val_loss: 38.6130 - val_mse: 38.5029 - val_mae: 4.9318
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6094 - mse: 41.4962 - mae: 5.0203 - val_loss: 38.1891 - val_mse: 38.0728 - val_mae: 4.9062
Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.3039 - mse: 41.1845 - mae: 5.0021 - val_loss: 37.5501 - val_mse: 37.4280 - val_mae: 4.8731
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.8146 - mse: 40.6889 - mae: 4.9760 - val_loss: 37.3442 - val_mse: 37.2159 - val_mae: 4.8588
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.7847 - mse: 40.6526 - mae: 4.9750 - val_loss: 37.9384 - val_mse: 37.8030 - val_mae: 4.8926
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.2054 - mse: 40.0665 - mae: 4.9381 - val_loss: 37.0188 - val_mse: 36.8767 - val_mae: 4.8312
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.7872 - mse: 39.6418 - mae: 4.9105 - val_loss: 37.1773 - val_mse: 37.0288 - val_mae: 4.8363
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1902 - mse: 39.0384 - mae: 4.8713 - val_loss: 35.6877 - val_mse: 35.5332 - val_mae: 4.7531
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5113 - mse: 38.3543 - mae: 4.8262 - val_loss: 36.5367 - val_mse: 36.3776 - val_mae: 4.8036
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.2870 - mse: 38.1255 - mae: 4.8145 - val_loss: 35.0874 - val_mse: 34.9239 - val_mae: 4.7175
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.9806 - mse: 37.8150 - mae: 4.7920 - val_loss: 35.2547 - val_mse: 35.0873 - val_mae: 4.7300
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8682 - mse: 37.6986 - mae: 4.7852 - val_loss: 35.1437 - val_mse: 34.9722 - val_mae: 4.7254
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5698 - mse: 37.3965 - mae: 4.7678 - val_loss: 34.6165 - val_mse: 34.4418 - val_mae: 4.6960
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5130 - mse: 37.3364 - mae: 4.7615 - val_loss: 33.8177 - val_mse: 33.6398 - val_mae: 4.6461
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2278 - mse: 37.0481 - mae: 4.7418 - val_loss: 34.0477 - val_mse: 33.8665 - val_mae: 4.6571
bias -0.008348561
si 0.47916865
rmse 0.058194924
kgeprime [0.63513268]
rmse_95 0.08031022
rmse_99 0.09391181
pearson 0.8553754987894009
pearson_95 0.6843926268479765
pearson_99 0.795369805374174
rscore 0.7260070470028508
rscore_95 -0.9075859342323964
rscore_99 -8.934263803442796
nse [0.72600705]
nse_95 [-0.90758593]
nse_99 [-8.9342638]
kge [0.72323342]
ext_kge_95 [0.58326774]
ext_kge_99 [-0.36205197]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.156
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 0.01643
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([5370 5394 5418], shape=(3,), dtype=int64) Times out: tf.Tensor(5418, shape=(), dtype=int64)
Times in: tf.Tensor([59245 59269 59293], shape=(3,), dtype=int64) Times out: tf.Tensor(59293, shape=(), dtype=int64)
Times in: tf.Tensor([25034 25058 25082], shape=(3,), dtype=int64) Times out: tf.Tensor(25082, shape=(), dtype=int64)
Times in: tf.Tensor([71545 71569 71593], shape=(3,), dtype=int64) Times out: tf.Tensor(71593, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_603&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_604 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1206 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1207 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_603 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1206 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_603 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1207 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.0708 - mse: 55.0172 - mae: 5.7072 - val_loss: 38.2034 - val_mse: 38.1344 - val_mae: 4.9451
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3913 - mse: 40.3134 - mae: 4.9536 - val_loss: 36.0720 - val_mse: 35.9858 - val_mae: 4.7955
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2934 - mse: 39.2019 - mae: 4.8853 - val_loss: 35.5631 - val_mse: 35.4664 - val_mae: 4.7606
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6822 - mse: 38.5811 - mae: 4.8464 - val_loss: 35.2596 - val_mse: 35.1543 - val_mae: 4.7426
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2391 - mse: 38.1293 - mae: 4.8184 - val_loss: 34.8762 - val_mse: 34.7619 - val_mae: 4.7185
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0660 - mse: 37.9473 - mae: 4.8069 - val_loss: 35.0326 - val_mse: 34.9100 - val_mae: 4.7352
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7890 - mse: 37.6620 - mae: 4.7919 - val_loss: 35.4187 - val_mse: 35.2875 - val_mae: 4.7546
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4451 - mse: 37.3093 - mae: 4.7729 - val_loss: 35.6170 - val_mse: 35.4772 - val_mae: 4.7681
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1736 - mse: 37.0295 - mae: 4.7533 - val_loss: 34.6225 - val_mse: 34.4747 - val_mae: 4.7075
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9896 - mse: 36.8378 - mae: 4.7418 - val_loss: 35.1224 - val_mse: 34.9669 - val_mae: 4.7418
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7766 - mse: 36.6171 - mae: 4.7273 - val_loss: 34.6270 - val_mse: 34.4640 - val_mae: 4.7078
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4363 - mse: 36.2695 - mae: 4.7075 - val_loss: 34.3555 - val_mse: 34.1853 - val_mae: 4.6928
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2580 - mse: 36.0840 - mae: 4.6921 - val_loss: 33.9236 - val_mse: 33.7460 - val_mae: 4.6575
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9938 - mse: 35.8131 - mae: 4.6745 - val_loss: 34.8522 - val_mse: 34.6688 - val_mae: 4.7211
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6120 - mse: 35.4260 - mae: 4.6467 - val_loss: 33.7679 - val_mse: 33.5798 - val_mae: 4.6500
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3083 - mse: 35.1180 - mae: 4.6261 - val_loss: 33.3713 - val_mse: 33.1791 - val_mae: 4.6323
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0016 - mse: 34.8076 - mae: 4.6021 - val_loss: 32.9154 - val_mse: 32.7201 - val_mae: 4.6020
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9105 - mse: 34.7138 - mae: 4.5968 - val_loss: 32.7445 - val_mse: 32.5464 - val_mae: 4.5893
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7236 - mse: 34.5241 - mae: 4.5853 - val_loss: 32.2907 - val_mse: 32.0902 - val_mae: 4.5567
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8180 - mse: 34.6162 - mae: 4.5875 - val_loss: 32.2177 - val_mse: 32.0149 - val_mae: 4.5514
bias -0.0042293346
si 0.49320543
rmse 0.056581706
kgeprime [0.70808109]
rmse_95 0.08320286
rmse_99 0.096230276
pearson 0.8467676724268228
pearson_95 0.7425777946662698
pearson_99 0.9298006339012832
rscore 0.7154236908236129
rscore_95 -1.6156866172870488
rscore_99 -12.557952533491884
nse [0.71542369]
nse_95 [-1.61568662]
nse_99 [-12.55795253]
kge [0.76276284]
ext_kge_95 [0.5495673]
ext_kge_99 [-0.53306818]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.156
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 0.01643
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([93327 93351 93375], shape=(3,), dtype=int64) Times out: tf.Tensor(93375, shape=(), dtype=int64)
Times in: tf.Tensor([29228 29252 29276], shape=(3,), dtype=int64) Times out: tf.Tensor(29276, shape=(), dtype=int64)
Times in: tf.Tensor([27992 28016 28040], shape=(3,), dtype=int64) Times out: tf.Tensor(28040, shape=(), dtype=int64)
Times in: tf.Tensor([126221 126245 126269], shape=(3,), dtype=int64) Times out: tf.Tensor(126269, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_604&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_605 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1208 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1209 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_604 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1208 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_604 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1209 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.8062 - mse: 55.7573 - mae: 5.7513 - val_loss: 39.1620 - val_mse: 39.1004 - val_mae: 5.0015
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.8694 - mse: 41.7990 - mae: 5.0375 - val_loss: 36.9879 - val_mse: 36.9087 - val_mae: 4.8498
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.4976 - mse: 40.4116 - mae: 4.9508 - val_loss: 36.0565 - val_mse: 35.9647 - val_mae: 4.7881
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.9232 - mse: 39.8265 - mae: 4.9177 - val_loss: 35.5136 - val_mse: 35.4122 - val_mae: 4.7505
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3450 - mse: 39.2387 - mae: 4.8829 - val_loss: 35.9666 - val_mse: 35.8558 - val_mae: 4.7835
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2107 - mse: 39.0950 - mae: 4.8740 - val_loss: 35.2928 - val_mse: 35.1725 - val_mae: 4.7404
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9088 - mse: 38.7840 - mae: 4.8557 - val_loss: 34.9775 - val_mse: 34.8485 - val_mae: 4.7216
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4984 - mse: 38.3650 - mae: 4.8304 - val_loss: 35.6488 - val_mse: 35.5112 - val_mae: 4.7641
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5085 - mse: 38.3665 - mae: 4.8262 - val_loss: 35.7790 - val_mse: 35.6332 - val_mae: 4.7720
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2524 - mse: 38.1023 - mae: 4.8141 - val_loss: 35.1933 - val_mse: 35.0394 - val_mae: 4.7386
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9192 - mse: 37.7617 - mae: 4.7938 - val_loss: 35.6388 - val_mse: 35.4778 - val_mae: 4.7672
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7041 - mse: 37.5395 - mae: 4.7787 - val_loss: 35.2563 - val_mse: 35.0886 - val_mae: 4.7420
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7306 - mse: 37.5598 - mae: 4.7758 - val_loss: 36.0830 - val_mse: 35.9090 - val_mae: 4.7935
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4262 - mse: 37.2492 - mae: 4.7580 - val_loss: 35.8031 - val_mse: 35.6232 - val_mae: 4.7796
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3269 - mse: 37.1442 - mae: 4.7544 - val_loss: 36.2537 - val_mse: 36.0682 - val_mae: 4.8078
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2429 - mse: 37.0547 - mae: 4.7479 - val_loss: 34.7782 - val_mse: 34.5878 - val_mae: 4.7109
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8991 - mse: 36.7062 - mae: 4.7271 - val_loss: 35.8490 - val_mse: 35.6537 - val_mae: 4.7866
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9513 - mse: 36.7534 - mae: 4.7264 - val_loss: 36.3738 - val_mse: 36.1738 - val_mae: 4.8209
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8228 - mse: 36.6204 - mae: 4.7181 - val_loss: 35.5226 - val_mse: 35.3181 - val_mae: 4.7644
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6427 - mse: 36.4359 - mae: 4.7152 - val_loss: 34.6337 - val_mse: 34.4249 - val_mae: 4.7008
bias -0.0076427623
si 0.5053889
rmse 0.05867272
kgeprime [0.62696102]
rmse_95 0.08640697
rmse_99 0.10245881
pearson 0.8384853406601225
pearson_95 0.717163343452802
pearson_99 0.8888702658501234
rscore 0.6979242941620564
rscore_95 -1.7562444201773237
rscore_99 -14.172070925195511
nse [0.69792429]
nse_95 [-1.75624442]
nse_99 [-14.17207093]
kge [0.71224567]
ext_kge_95 [0.5187531]
ext_kge_99 [-0.69883251]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 171.9 172.2 172.5
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 0.1282
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.156
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 0.01643
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 4.647
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.159
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([124440 124464 124488], shape=(3,), dtype=int64) Times out: tf.Tensor(124488, shape=(), dtype=int64)
Times in: tf.Tensor([4490 4514 4538], shape=(3,), dtype=int64) Times out: tf.Tensor(4538, shape=(), dtype=int64)
Times in: tf.Tensor([58662 58686 58710], shape=(3,), dtype=int64) Times out: tf.Tensor(58710, shape=(), dtype=int64)
Times in: tf.Tensor([149162 149186 149210], shape=(3,), dtype=int64) Times out: tf.Tensor(149210, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_605&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_606 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1210 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1211 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_605 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1210 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_605 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1211 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.2346 - mse: 55.1875 - mae: 5.7190 - val_loss: 38.6201 - val_mse: 38.5662 - val_mae: 4.9815
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.3669 - mse: 41.3084 - mae: 5.0118 - val_loss: 37.1543 - val_mse: 37.0913 - val_mae: 4.8721
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3816 - mse: 40.3153 - mae: 4.9473 - val_loss: 36.5577 - val_mse: 36.4889 - val_mae: 4.8219
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8291 - mse: 39.7579 - mae: 4.9131 - val_loss: 35.7192 - val_mse: 35.6457 - val_mae: 4.7646
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5589 - mse: 39.4827 - mae: 4.8938 - val_loss: 36.4554 - val_mse: 36.3763 - val_mae: 4.8154
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4705 - mse: 39.3888 - mae: 4.8893 - val_loss: 36.1809 - val_mse: 36.0963 - val_mae: 4.7929
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1171 - mse: 39.0299 - mae: 4.8700 - val_loss: 35.4345 - val_mse: 35.3447 - val_mae: 4.7503
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8542 - mse: 38.7617 - mae: 4.8524 - val_loss: 35.7727 - val_mse: 35.6777 - val_mae: 4.7711
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6762 - mse: 38.5787 - mae: 4.8470 - val_loss: 35.0451 - val_mse: 34.9448 - val_mae: 4.7276
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5542 - mse: 38.4512 - mae: 4.8368 - val_loss: 36.2314 - val_mse: 36.1257 - val_mae: 4.7994
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4175 - mse: 38.3095 - mae: 4.8290 - val_loss: 35.9750 - val_mse: 35.8646 - val_mae: 4.7823
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2918 - mse: 38.1792 - mae: 4.8188 - val_loss: 35.4606 - val_mse: 35.3459 - val_mae: 4.7523
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1840 - mse: 38.0670 - mae: 4.8098 - val_loss: 35.1695 - val_mse: 35.0502 - val_mae: 4.7324
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0469 - mse: 37.9252 - mae: 4.8030 - val_loss: 35.9613 - val_mse: 35.8373 - val_mae: 4.7791
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7882 - mse: 37.6618 - mae: 4.7845 - val_loss: 34.8222 - val_mse: 34.6934 - val_mae: 4.7069
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2456 - mse: 37.1143 - mae: 4.7478 - val_loss: 35.1227 - val_mse: 34.9891 - val_mae: 4.7248
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9428 - mse: 36.8070 - mae: 4.7300 - val_loss: 34.3774 - val_mse: 34.2396 - val_mae: 4.6818
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7952 - mse: 36.6559 - mae: 4.7194 - val_loss: 34.6068 - val_mse: 34.4660 - val_mae: 4.6998
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5413 - mse: 36.3990 - mae: 4.6991 - val_loss: 34.1213 - val_mse: 33.9776 - val_mae: 4.6657
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3891 - mse: 36.2441 - mae: 4.6931 - val_loss: 33.4103 - val_mse: 33.2639 - val_mae: 4.6244
bias -0.009526689
si 0.49663225
rmse 0.057674866
kgeprime [0.5994127]
rmse_95 0.07729198
rmse_99 0.08950636
pearson 0.8448664655643727
pearson_95 0.7300793408189469
pearson_99 0.8951664668926277
rscore 0.7054390258857566
rscore_95 -1.2698204009040635
rscore_99 -11.205131297276324
nse [0.70543903]
nse_95 [-1.2698204]
nse_99 [-11.2051313]
kge [0.69572961]
ext_kge_95 [0.53997356]
ext_kge_99 [-0.56570187]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.747
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 1.056
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([129354 129378 129402], shape=(3,), dtype=int64) Times out: tf.Tensor(129402, shape=(), dtype=int64)
Times in: tf.Tensor([131651 131675 131699], shape=(3,), dtype=int64) Times out: tf.Tensor(131699, shape=(), dtype=int64)
Times in: tf.Tensor([80870 80894 80918], shape=(3,), dtype=int64) Times out: tf.Tensor(80918, shape=(), dtype=int64)
Times in: tf.Tensor([14714 14738 14762], shape=(3,), dtype=int64) Times out: tf.Tensor(14762, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_606&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_607 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1212 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1213 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_606 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1212 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_606 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1213 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.5985 - mse: 54.5477 - mae: 5.6988 - val_loss: 38.4604 - val_mse: 38.3974 - val_mae: 4.9633
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6006 - mse: 41.5305 - mae: 5.0237 - val_loss: 36.2275 - val_mse: 36.1512 - val_mae: 4.8034
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2724 - mse: 40.1917 - mae: 4.9355 - val_loss: 35.3475 - val_mse: 35.2630 - val_mae: 4.7470
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6723 - mse: 39.5844 - mae: 4.9038 - val_loss: 35.4368 - val_mse: 35.3460 - val_mae: 4.7492
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4289 - mse: 39.3355 - mae: 4.8883 - val_loss: 35.0183 - val_mse: 34.9225 - val_mae: 4.7219
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3534 - mse: 39.2549 - mae: 4.8769 - val_loss: 35.0753 - val_mse: 34.9744 - val_mae: 4.7293
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0699 - mse: 38.9661 - mae: 4.8636 - val_loss: 34.6487 - val_mse: 34.5425 - val_mae: 4.6996
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8723 - mse: 38.7635 - mae: 4.8518 - val_loss: 34.5080 - val_mse: 34.3968 - val_mae: 4.6950
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6912 - mse: 38.5774 - mae: 4.8418 - val_loss: 35.4114 - val_mse: 35.2950 - val_mae: 4.7499
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5405 - mse: 38.4219 - mae: 4.8298 - val_loss: 34.5415 - val_mse: 34.4208 - val_mae: 4.6958
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4031 - mse: 38.2797 - mae: 4.8256 - val_loss: 34.9939 - val_mse: 34.8679 - val_mae: 4.7267
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2634 - mse: 38.1350 - mae: 4.8161 - val_loss: 35.1622 - val_mse: 35.0315 - val_mae: 4.7364
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0477 - mse: 37.9144 - mae: 4.8008 - val_loss: 34.9872 - val_mse: 34.8517 - val_mae: 4.7243
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8761 - mse: 37.7383 - mae: 4.7895 - val_loss: 34.9834 - val_mse: 34.8436 - val_mae: 4.7233
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9221 - mse: 37.7801 - mae: 4.7875 - val_loss: 35.3012 - val_mse: 35.1571 - val_mae: 4.7420
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6182 - mse: 37.4719 - mae: 4.7754 - val_loss: 35.5939 - val_mse: 35.4452 - val_mae: 4.7598
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6844 - mse: 37.5335 - mae: 4.7759 - val_loss: 34.3060 - val_mse: 34.1530 - val_mae: 4.6764
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3408 - mse: 37.1855 - mae: 4.7565 - val_loss: 34.6027 - val_mse: 34.4453 - val_mae: 4.6942
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0975 - mse: 36.9375 - mae: 4.7368 - val_loss: 33.8628 - val_mse: 33.7005 - val_mae: 4.6449
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7478 - mse: 36.5834 - mae: 4.7167 - val_loss: 34.0302 - val_mse: 33.8637 - val_mae: 4.6573
bias -0.011805781
si 0.50365984
rmse 0.058192525
kgeprime [0.53228848]
rmse_95 0.078485385
rmse_99 0.09418154
pearson 0.8400016477145887
pearson_95 0.7172680768683538
pearson_99 0.8900603398518236
rscore 0.692913155948454
rscore_95 -1.4861831580755327
rscore_99 -14.235006442497104
nse [0.69291316]
nse_95 [-1.48618316]
nse_99 [-14.23500644]
kge [0.64277755]
ext_kge_95 [0.55387608]
ext_kge_99 [-0.5718583]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.747
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 1.056
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([66471 66495 66519], shape=(3,), dtype=int64) Times out: tf.Tensor(66519, shape=(), dtype=int64)
Times in: tf.Tensor([95689 95713 95737], shape=(3,), dtype=int64) Times out: tf.Tensor(95737, shape=(), dtype=int64)
Times in: tf.Tensor([83919 83943 83967], shape=(3,), dtype=int64) Times out: tf.Tensor(83967, shape=(), dtype=int64)
Times in: tf.Tensor([48417 48441 48465], shape=(3,), dtype=int64) Times out: tf.Tensor(48465, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_607&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_608 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1214 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1215 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_607 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1214 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_607 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1215 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.4776 - mse: 47.4106 - mae: 5.3257 - val_loss: 36.0787 - val_mse: 35.9982 - val_mae: 4.8280
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8890 - mse: 37.7992 - mae: 4.8031 - val_loss: 35.2756 - val_mse: 35.1762 - val_mae: 4.7638
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4620 - mse: 36.3548 - mae: 4.7042 - val_loss: 34.4062 - val_mse: 34.2918 - val_mae: 4.6977
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6494 - mse: 35.5294 - mae: 4.6564 - val_loss: 36.9750 - val_mse: 36.8493 - val_mae: 4.8566
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0416 - mse: 34.9112 - mae: 4.6109 - val_loss: 34.1177 - val_mse: 33.9825 - val_mae: 4.6733
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7762 - mse: 34.6368 - mae: 4.5928 - val_loss: 34.0293 - val_mse: 33.8852 - val_mae: 4.6702
Epoch 7/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.2728 - mse: 34.1239 - mae: 4.5603 - val_loss: 34.1184 - val_mse: 33.9650 - val_mae: 4.6718
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6552 - mse: 33.4979 - mae: 4.5180 - val_loss: 32.8175 - val_mse: 32.6562 - val_mae: 4.5964
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1797 - mse: 33.0147 - mae: 4.4902 - val_loss: 32.7619 - val_mse: 32.5931 - val_mae: 4.5823
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6985 - mse: 32.5269 - mae: 4.4538 - val_loss: 31.8323 - val_mse: 31.6579 - val_mae: 4.5237
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.3440 - mse: 32.1672 - mae: 4.4343 - val_loss: 32.7222 - val_mse: 32.5428 - val_mae: 4.5763
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.1503 - mse: 31.9688 - mae: 4.4192 - val_loss: 31.5900 - val_mse: 31.4061 - val_mae: 4.5005
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.9885 - mse: 31.8024 - mae: 4.4012 - val_loss: 31.8225 - val_mse: 31.6339 - val_mae: 4.5145
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.8046 - mse: 31.6142 - mae: 4.3911 - val_loss: 31.4274 - val_mse: 31.2346 - val_mae: 4.4874
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.7383 - mse: 31.5441 - mae: 4.3814 - val_loss: 30.8831 - val_mse: 30.6870 - val_mae: 4.4544
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.4864 - mse: 31.2888 - mae: 4.3640 - val_loss: 31.5190 - val_mse: 31.3198 - val_mae: 4.4990
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.4254 - mse: 31.2247 - mae: 4.3628 - val_loss: 31.9860 - val_mse: 31.7835 - val_mae: 4.5287
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.2431 - mse: 31.0393 - mae: 4.3493 - val_loss: 30.9392 - val_mse: 30.7344 - val_mae: 4.4566
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.0937 - mse: 30.8874 - mae: 4.3406 - val_loss: 31.2275 - val_mse: 31.0199 - val_mae: 4.4839
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.1897 - mse: 30.9807 - mae: 4.3417 - val_loss: 31.2842 - val_mse: 31.0740 - val_mae: 4.4839
bias -0.00903492
si 0.49804807
rmse 0.055744074
kgeprime [0.62121787]
rmse_95 0.07107833
rmse_99 0.07997626
pearson 0.8457009709734812
pearson_95 0.7197826405384327
pearson_99 0.8655911495977877
rscore 0.7048895800321546
rscore_95 -1.2077595706730762
rscore_99 -11.77920257276165
nse [0.70488958]
nse_95 [-1.20775957]
nse_99 [-11.77920257]
kge [0.71108962]
ext_kge_95 [0.54776106]
ext_kge_99 [-0.61840274]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 2.572
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 4.861
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([33427 33451 33475], shape=(3,), dtype=int64) Times out: tf.Tensor(33475, shape=(), dtype=int64)
Times in: tf.Tensor([108427 108451 108475], shape=(3,), dtype=int64) Times out: tf.Tensor(108475, shape=(), dtype=int64)
Times in: tf.Tensor([40537 40561 40585], shape=(3,), dtype=int64) Times out: tf.Tensor(40585, shape=(), dtype=int64)
Times in: tf.Tensor([74050 74074 74098], shape=(3,), dtype=int64) Times out: tf.Tensor(74098, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_608&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_609 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1216 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1217 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_608 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1216 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_608 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1217 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.7355 - mse: 48.6678 - mae: 5.3915 - val_loss: 35.4402 - val_mse: 35.3582 - val_mae: 4.7557
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8922 - mse: 37.8015 - mae: 4.8192 - val_loss: 33.6939 - val_mse: 33.5950 - val_mae: 4.6354
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8183 - mse: 36.7133 - mae: 4.7385 - val_loss: 33.6637 - val_mse: 33.5525 - val_mae: 4.6264
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3905 - mse: 36.2740 - mae: 4.7075 - val_loss: 32.8764 - val_mse: 32.7539 - val_mae: 4.5789
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9486 - mse: 35.8208 - mae: 4.6785 - val_loss: 33.3059 - val_mse: 33.1725 - val_mae: 4.6092
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5552 - mse: 35.4170 - mae: 4.6570 - val_loss: 32.5493 - val_mse: 32.4058 - val_mae: 4.5637
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4520 - mse: 35.3038 - mae: 4.6466 - val_loss: 32.3716 - val_mse: 32.2178 - val_mae: 4.5489
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9831 - mse: 34.8249 - mae: 4.6180 - val_loss: 32.3671 - val_mse: 32.2036 - val_mae: 4.5488
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7354 - mse: 34.5674 - mae: 4.5965 - val_loss: 32.2570 - val_mse: 32.0841 - val_mae: 4.5494
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5620 - mse: 34.3850 - mae: 4.5868 - val_loss: 33.2519 - val_mse: 33.0705 - val_mae: 4.6180
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3272 - mse: 34.1423 - mae: 4.5713 - val_loss: 32.3240 - val_mse: 32.1351 - val_mae: 4.5551
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2479 - mse: 34.0553 - mae: 4.5654 - val_loss: 32.5065 - val_mse: 32.3102 - val_mae: 4.5653
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8607 - mse: 33.6611 - mae: 4.5341 - val_loss: 31.8863 - val_mse: 31.6832 - val_mae: 4.5247
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6310 - mse: 33.4247 - mae: 4.5182 - val_loss: 31.7224 - val_mse: 31.5127 - val_mae: 4.5119
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1782 - mse: 32.9661 - mae: 4.4844 - val_loss: 31.1860 - val_mse: 30.9712 - val_mae: 4.4756
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9308 - mse: 32.7143 - mae: 4.4686 - val_loss: 31.4179 - val_mse: 31.1991 - val_mae: 4.4904
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7274 - mse: 32.5072 - mae: 4.4517 - val_loss: 30.9419 - val_mse: 30.7201 - val_mae: 4.4607
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4769 - mse: 32.2538 - mae: 4.4342 - val_loss: 30.3211 - val_mse: 30.0966 - val_mae: 4.4130
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3021 - mse: 32.0765 - mae: 4.4259 - val_loss: 31.1343 - val_mse: 30.9077 - val_mae: 4.4710
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0650 - mse: 31.8373 - mae: 4.4073 - val_loss: 30.5587 - val_mse: 30.3300 - val_mae: 4.4308
bias -0.009652651
si 0.4808927
rmse 0.055072647
kgeprime [0.59940949]
rmse_95 0.0734443
rmse_99 0.090460114
pearson 0.8541947801736263
pearson_95 0.7155910668129406
pearson_99 0.7688153412309906
rscore 0.7210398312080577
rscore_95 -0.8645016715575535
rscore_99 -8.542233317481195
nse [0.72103983]
nse_95 [-0.86450167]
nse_99 [-8.54223332]
kge [0.69771849]
ext_kge_95 [0.59355494]
ext_kge_99 [-0.40950907]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 2.572
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 4.861
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([27242 27266 27290], shape=(3,), dtype=int64) Times out: tf.Tensor(27290, shape=(), dtype=int64)
Times in: tf.Tensor([47314 47338 47362], shape=(3,), dtype=int64) Times out: tf.Tensor(47362, shape=(), dtype=int64)
Times in: tf.Tensor([101440 101464 101488], shape=(3,), dtype=int64) Times out: tf.Tensor(101488, shape=(), dtype=int64)
Times in: tf.Tensor([30820 30844 30868], shape=(3,), dtype=int64) Times out: tf.Tensor(30868, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_609&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_610 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1218 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1219 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_609 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1218 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_609 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1219 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 56.8328 - mse: 56.7817 - mae: 5.8519 - val_loss: 39.1812 - val_mse: 39.1225 - val_mae: 4.9847
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.9681 - mse: 42.9056 - mae: 5.1318 - val_loss: 38.0295 - val_mse: 37.9620 - val_mae: 4.9245
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.9358 - mse: 39.8610 - mae: 4.9411 - val_loss: 35.9440 - val_mse: 35.8622 - val_mae: 4.7873
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4301 - mse: 38.3415 - mae: 4.8426 - val_loss: 34.1922 - val_mse: 34.0977 - val_mae: 4.6759
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6563 - mse: 37.5560 - mae: 4.7986 - val_loss: 34.5876 - val_mse: 34.4821 - val_mae: 4.6978
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1691 - mse: 37.0590 - mae: 4.7598 - val_loss: 33.9402 - val_mse: 33.8260 - val_mae: 4.6538
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7994 - mse: 36.6808 - mae: 4.7406 - val_loss: 34.6817 - val_mse: 34.5589 - val_mae: 4.7107
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2163 - mse: 36.0894 - mae: 4.6970 - val_loss: 33.5611 - val_mse: 33.4302 - val_mae: 4.6364
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8701 - mse: 35.7355 - mae: 4.6730 - val_loss: 32.5428 - val_mse: 32.4047 - val_mae: 4.5711
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2487 - mse: 35.1072 - mae: 4.6341 - val_loss: 32.0689 - val_mse: 31.9245 - val_mae: 4.5371
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8787 - mse: 34.7314 - mae: 4.6028 - val_loss: 32.8663 - val_mse: 32.7169 - val_mae: 4.5954
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7669 - mse: 34.6150 - mae: 4.5948 - val_loss: 32.7741 - val_mse: 32.6203 - val_mae: 4.5882
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.3044 - mse: 34.1485 - mae: 4.5618 - val_loss: 32.1152 - val_mse: 31.9575 - val_mae: 4.5383
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3880 - mse: 34.2284 - mae: 4.5646 - val_loss: 31.4587 - val_mse: 31.2977 - val_mae: 4.4943
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0209 - mse: 33.8580 - mae: 4.5388 - val_loss: 31.7416 - val_mse: 31.5776 - val_mae: 4.5123
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9396 - mse: 33.7736 - mae: 4.5335 - val_loss: 31.9310 - val_mse: 31.7633 - val_mae: 4.5270
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7588 - mse: 33.5893 - mae: 4.5202 - val_loss: 31.6859 - val_mse: 31.5149 - val_mae: 4.5074
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6348 - mse: 33.4618 - mae: 4.5139 - val_loss: 30.9970 - val_mse: 30.8227 - val_mae: 4.4619
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4203 - mse: 33.2441 - mae: 4.4982 - val_loss: 30.8688 - val_mse: 30.6910 - val_mae: 4.4556
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3518 - mse: 33.1725 - mae: 4.4931 - val_loss: 31.1633 - val_mse: 30.9828 - val_mae: 4.4741
bias -0.011248826
si 0.4821973
rmse 0.055662148
kgeprime [0.56945199]
rmse_95 0.06990199
rmse_99 0.091966905
pearson 0.8535330694213148
pearson_95 0.7119263447598493
pearson_99 0.718193887110917
rscore 0.7166082352715024
rscore_95 -0.7047023441976736
rscore_99 -8.798197869746847
nse [0.71660824]
nse_95 [-0.70470234]
nse_99 [-8.79819787]
kge [0.67390512]
ext_kge_95 [0.62248722]
ext_kge_99 [-0.33749722]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 2.572
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 4.861
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([106903 106927 106951], shape=(3,), dtype=int64) Times out: tf.Tensor(106951, shape=(), dtype=int64)
Times in: tf.Tensor([99293 99317 99341], shape=(3,), dtype=int64) Times out: tf.Tensor(99341, shape=(), dtype=int64)
Times in: tf.Tensor([80063 80087 80111], shape=(3,), dtype=int64) Times out: tf.Tensor(80111, shape=(), dtype=int64)
Times in: tf.Tensor([146974 146998 147022], shape=(3,), dtype=int64) Times out: tf.Tensor(147022, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_610&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_611 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1220 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1221 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_610 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1220 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_610 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1221 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.9561 - mse: 58.9205 - mae: 5.9105 - val_loss: 38.0980 - val_mse: 38.0536 - val_mae: 4.9123
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7310 - mse: 40.6810 - mae: 4.9816 - val_loss: 35.9092 - val_mse: 35.8545 - val_mae: 4.7724
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5219 - mse: 39.4635 - mae: 4.9075 - val_loss: 34.8243 - val_mse: 34.7623 - val_mae: 4.6991
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2151 - mse: 39.1491 - mae: 4.8808 - val_loss: 34.3420 - val_mse: 34.2721 - val_mae: 4.6694
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6862 - mse: 38.6121 - mae: 4.8480 - val_loss: 34.3880 - val_mse: 34.3096 - val_mae: 4.6744
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3078 - mse: 38.2250 - mae: 4.8242 - val_loss: 33.9186 - val_mse: 33.8312 - val_mae: 4.6469
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0599 - mse: 37.9679 - mae: 4.8109 - val_loss: 35.2352 - val_mse: 35.1382 - val_mae: 4.7382
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6791 - mse: 37.5775 - mae: 4.7841 - val_loss: 34.5609 - val_mse: 34.4545 - val_mae: 4.6973
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4006 - mse: 37.2894 - mae: 4.7631 - val_loss: 34.7404 - val_mse: 34.6246 - val_mae: 4.7096
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1280 - mse: 37.0076 - mae: 4.7450 - val_loss: 33.7697 - val_mse: 33.6449 - val_mae: 4.6452
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6664 - mse: 36.5374 - mae: 4.7183 - val_loss: 33.9266 - val_mse: 33.7935 - val_mae: 4.6596
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5026 - mse: 36.3654 - mae: 4.7020 - val_loss: 33.1250 - val_mse: 32.9838 - val_mae: 4.6048
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8961 - mse: 35.7514 - mae: 4.6646 - val_loss: 33.3963 - val_mse: 33.2482 - val_mae: 4.6283
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6817 - mse: 35.5308 - mae: 4.6502 - val_loss: 32.5655 - val_mse: 32.4120 - val_mae: 4.5721
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5200 - mse: 35.3641 - mae: 4.6347 - val_loss: 32.2345 - val_mse: 32.0764 - val_mae: 4.5488
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2361 - mse: 35.0760 - mae: 4.6152 - val_loss: 31.9461 - val_mse: 31.7844 - val_mae: 4.5301
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1974 - mse: 35.0342 - mae: 4.6122 - val_loss: 31.9176 - val_mse: 31.7529 - val_mae: 4.5286
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0461 - mse: 34.8797 - mae: 4.5962 - val_loss: 32.8920 - val_mse: 32.7240 - val_mae: 4.5924
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8693 - mse: 34.7001 - mae: 4.5919 - val_loss: 31.5161 - val_mse: 31.3452 - val_mae: 4.4958
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7177 - mse: 34.5457 - mae: 4.5813 - val_loss: 31.5659 - val_mse: 31.3926 - val_mae: 4.4951
bias -0.011230097
si 0.48006985
rmse 0.056029085
kgeprime [0.54761393]
rmse_95 0.07836112
rmse_99 0.095982954
pearson 0.8549211486917174
pearson_95 0.7147247821707992
pearson_99 0.7123308799076842
rscore 0.7187334563024693
rscore_95 -1.0758256379124451
rscore_99 -9.17749690134391
nse [0.71873346]
nse_95 [-1.07582564]
nse_99 [-9.1774969]
kge [0.65739761]
ext_kge_95 [0.60275376]
ext_kge_99 [-0.24926401]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 0.9486
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 2.554
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([25325 25349 25373], shape=(3,), dtype=int64) Times out: tf.Tensor(25373, shape=(), dtype=int64)
Times in: tf.Tensor([108083 108107 108131], shape=(3,), dtype=int64) Times out: tf.Tensor(108131, shape=(), dtype=int64)
Times in: tf.Tensor([34255 34279 34303], shape=(3,), dtype=int64) Times out: tf.Tensor(34303, shape=(), dtype=int64)
Times in: tf.Tensor([134626 134650 134674], shape=(3,), dtype=int64) Times out: tf.Tensor(134674, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_611&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_612 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1222 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1223 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_611 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1222 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_611 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1223 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.0632 - mse: 52.0153 - mae: 5.5746 - val_loss: 37.5806 - val_mse: 37.5220 - val_mae: 4.8888
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1502 - mse: 40.0844 - mae: 4.9507 - val_loss: 35.3631 - val_mse: 35.2901 - val_mae: 4.7441
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1612 - mse: 39.0827 - mae: 4.8847 - val_loss: 35.0571 - val_mse: 34.9726 - val_mae: 4.7251
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5868 - mse: 38.4967 - mae: 4.8467 - val_loss: 34.2273 - val_mse: 34.1309 - val_mae: 4.6695
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1248 - mse: 38.0227 - mae: 4.8149 - val_loss: 35.9095 - val_mse: 35.8018 - val_mae: 4.7851
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8510 - mse: 37.7374 - mae: 4.7971 - val_loss: 34.9173 - val_mse: 34.7979 - val_mae: 4.7161
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5893 - mse: 37.4643 - mae: 4.7779 - val_loss: 34.3422 - val_mse: 34.2114 - val_mae: 4.6884
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1527 - mse: 37.0166 - mae: 4.7496 - val_loss: 33.6828 - val_mse: 33.5411 - val_mae: 4.6442
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8010 - mse: 36.6541 - mae: 4.7196 - val_loss: 34.1738 - val_mse: 34.0217 - val_mae: 4.6730
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1967 - mse: 36.0400 - mae: 4.6838 - val_loss: 33.1321 - val_mse: 32.9707 - val_mae: 4.6056
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6718 - mse: 35.5067 - mae: 4.6457 - val_loss: 32.9408 - val_mse: 32.7722 - val_mae: 4.6014
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3786 - mse: 35.2067 - mae: 4.6252 - val_loss: 33.2966 - val_mse: 33.1217 - val_mae: 4.6215
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2645 - mse: 35.0873 - mae: 4.6145 - val_loss: 33.1625 - val_mse: 32.9829 - val_mae: 4.6164
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7505 - mse: 34.5686 - mae: 4.5868 - val_loss: 32.7982 - val_mse: 32.6142 - val_mae: 4.5924
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6441 - mse: 34.4580 - mae: 4.5712 - val_loss: 32.2693 - val_mse: 32.0815 - val_mae: 4.5545
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5012 - mse: 34.3115 - mae: 4.5621 - val_loss: 32.3229 - val_mse: 32.1317 - val_mae: 4.5570
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3904 - mse: 34.1975 - mae: 4.5566 - val_loss: 32.0620 - val_mse: 31.8674 - val_mae: 4.5387
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2342 - mse: 34.0378 - mae: 4.5447 - val_loss: 32.2620 - val_mse: 32.0639 - val_mae: 4.5498
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2001 - mse: 34.0007 - mae: 4.5458 - val_loss: 31.8719 - val_mse: 31.6712 - val_mae: 4.5284
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1074 - mse: 33.9056 - mae: 4.5363 - val_loss: 31.9562 - val_mse: 31.7533 - val_mae: 4.5337
bias -0.0118644675
si 0.4760317
rmse 0.056350082
kgeprime [0.56680207]
rmse_95 0.07069263
rmse_99 0.08827499
pearson 0.8570094821582361
pearson_95 0.7219103089213061
pearson_99 0.7458366850714232
rscore 0.7218317102129586
rscore_95 -0.6356195518685566
rscore_99 -8.00587070040264
nse [0.72183171]
nse_95 [-0.63561955]
nse_99 [-8.0058707]
kge [0.6721983]
ext_kge_95 [0.62453569]
ext_kge_99 [-0.38448944]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.86 -9.789 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.66 11.62 ... 0.9486
    uw2             (time, latitude, longitude) float32 97.21 95.83 ... 2.554
    vw2             (time, latitude, longitude) float32 135.9 135.0 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 15.27 15.19 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([139066 139090 139114], shape=(3,), dtype=int64) Times out: tf.Tensor(139114, shape=(), dtype=int64)
Times in: tf.Tensor([143073 143097 143121], shape=(3,), dtype=int64) Times out: tf.Tensor(143121, shape=(), dtype=int64)
Times in: tf.Tensor([97051 97075 97099], shape=(3,), dtype=int64) Times out: tf.Tensor(97099, shape=(), dtype=int64)
Times in: tf.Tensor([65967 65991 66015], shape=(3,), dtype=int64) Times out: tf.Tensor(66015, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_612&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_613 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1224 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1225 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_612 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1224 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_612 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1225 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 61.4704 - mse: 61.4057 - mae: 6.0425 - val_loss: 39.8862 - val_mse: 39.8073 - val_mae: 5.0394
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.1843 - mse: 43.0983 - mae: 5.1309 - val_loss: 37.7899 - val_mse: 37.6965 - val_mae: 4.9112
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.5827 - mse: 41.4824 - mae: 5.0295 - val_loss: 36.3627 - val_mse: 36.2561 - val_mae: 4.8016
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.8018 - mse: 40.6902 - mae: 4.9781 - val_loss: 37.0253 - val_mse: 36.9088 - val_mae: 4.8444
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.5537 - mse: 40.4336 - mae: 4.9593 - val_loss: 36.8415 - val_mse: 36.7176 - val_mae: 4.8270
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2168 - mse: 40.0894 - mae: 4.9411 - val_loss: 36.7046 - val_mse: 36.5735 - val_mae: 4.8205
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8998 - mse: 39.7652 - mae: 4.9145 - val_loss: 36.8842 - val_mse: 36.7458 - val_mae: 4.8338
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5638 - mse: 39.4220 - mae: 4.8987 - val_loss: 36.7729 - val_mse: 36.6271 - val_mae: 4.8296
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2256 - mse: 39.0766 - mae: 4.8772 - val_loss: 36.3039 - val_mse: 36.1512 - val_mae: 4.8043
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1126 - mse: 38.9558 - mae: 4.8673 - val_loss: 36.2863 - val_mse: 36.1251 - val_mae: 4.8035
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.7293 - mse: 38.5646 - mae: 4.8426 - val_loss: 35.6147 - val_mse: 35.4457 - val_mae: 4.7624
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.5638 - mse: 38.3913 - mae: 4.8319 - val_loss: 35.9881 - val_mse: 35.8120 - val_mae: 4.7867
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3238 - mse: 38.1443 - mae: 4.8189 - val_loss: 37.4844 - val_mse: 37.3009 - val_mae: 4.8858
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1525 - mse: 37.9656 - mae: 4.8059 - val_loss: 36.7665 - val_mse: 36.5759 - val_mae: 4.8417
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1266 - mse: 37.9331 - mae: 4.8013 - val_loss: 35.7015 - val_mse: 35.5049 - val_mae: 4.7738
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9177 - mse: 37.7185 - mae: 4.7892 - val_loss: 37.2013 - val_mse: 36.9990 - val_mae: 4.8691
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.8739 - mse: 37.6693 - mae: 4.7803 - val_loss: 37.0681 - val_mse: 36.8610 - val_mae: 4.8611
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.5898 - mse: 37.3803 - mae: 4.7657 - val_loss: 37.0717 - val_mse: 36.8595 - val_mae: 4.8588
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.3098 - mse: 37.0956 - mae: 4.7438 - val_loss: 35.0395 - val_mse: 34.8228 - val_mae: 4.7368
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.9986 - mse: 36.7804 - mae: 4.7279 - val_loss: 34.4145 - val_mse: 34.1949 - val_mae: 4.6988
bias -0.01333672
si 0.48630664
rmse 0.0584764
kgeprime [0.53158288]
rmse_95 0.07430265
rmse_99 0.08839695
pearson 0.8500646096887846
pearson_95 0.6938145595174187
pearson_99 0.7316708088377933
rscore 0.7070831364341928
rscore_95 -0.770135260013584
rscore_99 -7.625446318427972
nse [0.70708314]
nse_95 [-0.77013526]
nse_99 [-7.62544632]
kge [0.64274686]
ext_kge_95 [0.59150056]
ext_kge_99 [-0.31774017]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.789 -9.74 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.62 11.53 ... 0.9486
    uw2             (time, latitude, longitude) float32 95.83 94.87 ... 2.554
    vw2             (time, latitude, longitude) float32 135.0 132.9 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 15.19 15.09 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([17051 17075 17099], shape=(3,), dtype=int64) Times out: tf.Tensor(17099, shape=(), dtype=int64)
Times in: tf.Tensor([68542 68566 68590], shape=(3,), dtype=int64) Times out: tf.Tensor(68590, shape=(), dtype=int64)
Times in: tf.Tensor([57316 57340 57364], shape=(3,), dtype=int64) Times out: tf.Tensor(57364, shape=(), dtype=int64)
Times in: tf.Tensor([53262 53286 53310], shape=(3,), dtype=int64) Times out: tf.Tensor(53310, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_613&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_614 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1226 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1227 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_613 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1226 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_613 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1227 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 57.3340 - mse: 57.2781 - mae: 5.8419 - val_loss: 40.1047 - val_mse: 40.0387 - val_mae: 5.0685
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.9259 - mse: 42.8555 - mae: 5.1206 - val_loss: 38.6571 - val_mse: 38.5823 - val_mae: 4.9731
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.1461 - mse: 41.0678 - mae: 5.0036 - val_loss: 37.7138 - val_mse: 37.6321 - val_mae: 4.8975
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.6402 - mse: 40.5558 - mae: 4.9738 - val_loss: 38.2376 - val_mse: 38.1510 - val_mae: 4.9203
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3390 - mse: 40.2506 - mae: 4.9473 - val_loss: 37.7192 - val_mse: 37.6289 - val_mae: 4.8932
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.9743 - mse: 39.8822 - mae: 4.9317 - val_loss: 37.2875 - val_mse: 37.1932 - val_mae: 4.8604
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7065 - mse: 39.6102 - mae: 4.9147 - val_loss: 37.8049 - val_mse: 37.7062 - val_mae: 4.8917
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5383 - mse: 39.4374 - mae: 4.8972 - val_loss: 36.8768 - val_mse: 36.7738 - val_mae: 4.8316
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1654 - mse: 39.0598 - mae: 4.8717 - val_loss: 37.4832 - val_mse: 37.3753 - val_mae: 4.8699
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8762 - mse: 38.7656 - mae: 4.8538 - val_loss: 36.1203 - val_mse: 36.0071 - val_mae: 4.7892
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.3839 - mse: 38.2679 - mae: 4.8285 - val_loss: 36.0934 - val_mse: 35.9744 - val_mae: 4.7837
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8221 - mse: 37.6998 - mae: 4.7871 - val_loss: 36.9502 - val_mse: 36.8251 - val_mae: 4.8321
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0891 - mse: 36.9615 - mae: 4.7427 - val_loss: 34.6558 - val_mse: 34.5260 - val_mae: 4.6934
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7404 - mse: 36.6084 - mae: 4.7153 - val_loss: 34.7668 - val_mse: 34.6328 - val_mae: 4.7047
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1647 - mse: 36.0292 - mae: 4.6785 - val_loss: 34.1483 - val_mse: 34.0112 - val_mae: 4.6642
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1174 - mse: 35.9786 - mae: 4.6785 - val_loss: 34.4136 - val_mse: 34.2736 - val_mae: 4.6824
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8034 - mse: 35.6620 - mae: 4.6490 - val_loss: 34.0033 - val_mse: 33.8606 - val_mae: 4.6577
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6699 - mse: 35.5262 - mae: 4.6453 - val_loss: 33.6702 - val_mse: 33.5257 - val_mae: 4.6373
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4770 - mse: 35.3313 - mae: 4.6336 - val_loss: 34.0208 - val_mse: 33.8740 - val_mae: 4.6562
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3452 - mse: 35.1973 - mae: 4.6224 - val_loss: 33.3596 - val_mse: 33.2107 - val_mae: 4.6150
bias -0.012253955
si 0.47690758
rmse 0.057628714
kgeprime [0.56459099]
rmse_95 0.07040614
rmse_99 0.07898261
pearson 0.8564462651551197
pearson_95 0.7182138007310055
pearson_99 0.7511429727946848
rscore 0.7204697819854845
rscore_95 -0.5543825582975404
rscore_99 -6.299973969442793
nse [0.72046978]
nse_95 [-0.55438256]
nse_99 [-6.29997397]
kge [0.67016728]
ext_kge_95 [0.61595134]
ext_kge_99 [-0.29126751]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.789 -9.74 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.62 11.53 ... 0.9486
    uw2             (time, latitude, longitude) float32 95.83 94.87 ... 2.554
    vw2             (time, latitude, longitude) float32 135.0 132.9 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 15.19 15.09 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([58832 58856 58880], shape=(3,), dtype=int64) Times out: tf.Tensor(58880, shape=(), dtype=int64)
Times in: tf.Tensor([50631 50655 50679], shape=(3,), dtype=int64) Times out: tf.Tensor(50679, shape=(), dtype=int64)
Times in: tf.Tensor([82580 82604 82628], shape=(3,), dtype=int64) Times out: tf.Tensor(82628, shape=(), dtype=int64)
Times in: tf.Tensor([4026 4050 4074], shape=(3,), dtype=int64) Times out: tf.Tensor(4074, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_614&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_615 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1228 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1229 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_614 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1228 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_614 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1229 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 60.9459 - mse: 60.8913 - mae: 6.0036 - val_loss: 40.9520 - val_mse: 40.8801 - val_mae: 5.0984
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.4634 - mse: 43.3824 - mae: 5.1412 - val_loss: 38.9554 - val_mse: 38.8661 - val_mae: 4.9790
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1396 - mse: 42.0434 - mae: 5.0568 - val_loss: 37.8297 - val_mse: 37.7273 - val_mae: 4.8937
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.4908 - mse: 41.3822 - mae: 5.0180 - val_loss: 36.9205 - val_mse: 36.8062 - val_mae: 4.8398
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.0579 - mse: 40.9377 - mae: 4.9873 - val_loss: 36.9708 - val_mse: 36.8453 - val_mae: 4.8413
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.5213 - mse: 40.3900 - mae: 4.9588 - val_loss: 36.8360 - val_mse: 36.6991 - val_mae: 4.8388
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1598 - mse: 40.0170 - mae: 4.9344 - val_loss: 37.2315 - val_mse: 37.0832 - val_mae: 4.8573
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8715 - mse: 39.7172 - mae: 4.9206 - val_loss: 36.3202 - val_mse: 36.1603 - val_mae: 4.8056
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5051 - mse: 39.3392 - mae: 4.8940 - val_loss: 36.7335 - val_mse: 36.5624 - val_mae: 4.8290
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3237 - mse: 39.1469 - mae: 4.8837 - val_loss: 36.7629 - val_mse: 36.5807 - val_mae: 4.8310
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8865 - mse: 38.6986 - mae: 4.8584 - val_loss: 37.0173 - val_mse: 36.8245 - val_mae: 4.8582
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6438 - mse: 38.4466 - mae: 4.8392 - val_loss: 36.3377 - val_mse: 36.1363 - val_mae: 4.8127
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3289 - mse: 38.1229 - mae: 4.8157 - val_loss: 36.1498 - val_mse: 35.9397 - val_mae: 4.7947
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8054 - mse: 37.5914 - mae: 4.7849 - val_loss: 34.6807 - val_mse: 34.4636 - val_mae: 4.7056
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6015 - mse: 37.3816 - mae: 4.7609 - val_loss: 36.2239 - val_mse: 36.0017 - val_mae: 4.8090
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2447 - mse: 37.0202 - mae: 4.7451 - val_loss: 34.4023 - val_mse: 34.1766 - val_mae: 4.6929
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0260 - mse: 36.7979 - mae: 4.7348 - val_loss: 35.0370 - val_mse: 34.8074 - val_mae: 4.7314
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9936 - mse: 36.7623 - mae: 4.7264 - val_loss: 34.1698 - val_mse: 33.9375 - val_mae: 4.6751
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6619 - mse: 36.4280 - mae: 4.7080 - val_loss: 35.1096 - val_mse: 34.8748 - val_mae: 4.7411
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4031 - mse: 36.1670 - mae: 4.6920 - val_loss: 34.4074 - val_mse: 34.1703 - val_mae: 4.6944
bias -0.011200451
si 0.48169798
rmse 0.058455396
kgeprime [0.60634438]
rmse_95 0.07291375
rmse_99 0.086124636
pearson 0.8547416136430459
pearson_95 0.6865799323868457
pearson_99 0.7751765768166883
rscore 0.7175105005948454
rscore_95 -0.6373447668470029
rscore_99 -7.668332239286196
nse [0.7175105]
nse_95 [-0.63734477]
nse_99 [-7.66833224]
kge [0.70027691]
ext_kge_95 [0.57203169]
ext_kge_99 [-0.55276395]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.789 -9.74 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.62 11.53 ... 0.9486
    uw2             (time, latitude, longitude) float32 95.83 94.87 ... 2.554
    vw2             (time, latitude, longitude) float32 135.0 132.9 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 15.19 15.09 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([39798 39822 39846], shape=(3,), dtype=int64) Times out: tf.Tensor(39846, shape=(), dtype=int64)
Times in: tf.Tensor([118102 118126 118150], shape=(3,), dtype=int64) Times out: tf.Tensor(118150, shape=(), dtype=int64)
Times in: tf.Tensor([2717 2741 2765], shape=(3,), dtype=int64) Times out: tf.Tensor(2765, shape=(), dtype=int64)
Times in: tf.Tensor([124191 124215 124239], shape=(3,), dtype=int64) Times out: tf.Tensor(124239, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_615&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_616 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1230 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1231 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_615 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1230 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_615 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1231 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.5561 - mse: 58.5095 - mae: 5.9159 - val_loss: 41.2115 - val_mse: 41.1552 - val_mae: 5.1358
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.8116 - mse: 43.7483 - mae: 5.1735 - val_loss: 39.2462 - val_mse: 39.1752 - val_mae: 4.9966
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1724 - mse: 42.0948 - mae: 5.0642 - val_loss: 38.5062 - val_mse: 38.4225 - val_mae: 4.9352
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.3794 - mse: 41.2910 - mae: 5.0171 - val_loss: 38.3102 - val_mse: 38.2172 - val_mae: 4.9204
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9909 - mse: 40.8939 - mae: 4.9908 - val_loss: 37.9878 - val_mse: 37.8867 - val_mae: 4.9033
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.5276 - mse: 40.4220 - mae: 4.9670 - val_loss: 37.9993 - val_mse: 37.8895 - val_mae: 4.9019
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2460 - mse: 40.1312 - mae: 4.9471 - val_loss: 38.7125 - val_mse: 38.5934 - val_mae: 4.9450
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.9329 - mse: 39.8088 - mae: 4.9246 - val_loss: 38.6316 - val_mse: 38.5032 - val_mae: 4.9417
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5887 - mse: 39.4552 - mae: 4.9036 - val_loss: 38.1566 - val_mse: 38.0186 - val_mae: 4.9203
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1918 - mse: 39.0490 - mae: 4.8804 - val_loss: 38.1143 - val_mse: 37.9673 - val_mae: 4.9168
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8884 - mse: 38.7369 - mae: 4.8588 - val_loss: 37.5919 - val_mse: 37.4366 - val_mae: 4.8832
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3776 - mse: 38.2181 - mae: 4.8254 - val_loss: 37.0113 - val_mse: 36.8477 - val_mae: 4.8523
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0789 - mse: 37.9115 - mae: 4.8062 - val_loss: 36.6349 - val_mse: 36.4641 - val_mae: 4.8243
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4822 - mse: 37.3081 - mae: 4.7641 - val_loss: 36.2562 - val_mse: 36.0792 - val_mae: 4.7996
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9892 - mse: 36.8092 - mae: 4.7297 - val_loss: 34.8517 - val_mse: 34.6689 - val_mae: 4.7202
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6108 - mse: 36.4253 - mae: 4.7028 - val_loss: 34.4305 - val_mse: 34.2430 - val_mae: 4.6955
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3556 - mse: 36.1657 - mae: 4.6914 - val_loss: 34.5580 - val_mse: 34.3661 - val_mae: 4.7013
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1052 - mse: 35.9113 - mae: 4.6745 - val_loss: 33.6770 - val_mse: 33.4814 - val_mae: 4.6534
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8206 - mse: 35.6231 - mae: 4.6536 - val_loss: 34.0371 - val_mse: 33.8384 - val_mae: 4.6741
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7508 - mse: 35.5506 - mae: 4.6510 - val_loss: 33.3749 - val_mse: 33.1734 - val_mae: 4.6312
bias -0.006672339
si 0.47598317
rmse 0.057596326
kgeprime [0.69251591]
rmse_95 0.0782446
rmse_99 0.089354746
pearson 0.857365596233111
pearson_95 0.6851407128169785
pearson_99 0.7331004794722847
rscore 0.730908393465528
rscore_95 -0.8394263940453492
rscore_99 -8.852512646383545
nse [0.73090839]
nse_95 [-0.83942639]
nse_99 [-8.85251265]
kge [0.76432998]
ext_kge_95 [0.56965437]
ext_kge_99 [-0.56784084]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.789 -9.74 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.62 11.53 ... -0.8311
    uw2             (time, latitude, longitude) float32 95.83 94.87 ... 0.6148
    vw2             (time, latitude, longitude) float32 135.0 132.9 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 15.19 15.09 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([45507 45531 45555], shape=(3,), dtype=int64) Times out: tf.Tensor(45555, shape=(), dtype=int64)
Times in: tf.Tensor([84288 84312 84336], shape=(3,), dtype=int64) Times out: tf.Tensor(84336, shape=(), dtype=int64)
Times in: tf.Tensor([90373 90397 90421], shape=(3,), dtype=int64) Times out: tf.Tensor(90421, shape=(), dtype=int64)
Times in: tf.Tensor([94492 94516 94540], shape=(3,), dtype=int64) Times out: tf.Tensor(94540, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_616&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_617 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1232 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1233 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_616 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1232 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_616 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1233 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 74.5076 - mse: 74.4624 - mae: 6.6214 - val_loss: 45.1969 - val_mse: 45.1419 - val_mae: 5.3153
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 52.4550 - mse: 52.3956 - mae: 5.6139 - val_loss: 42.1186 - val_mse: 42.0544 - val_mae: 5.1629
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 50.6171 - mse: 50.5480 - mae: 5.5024 - val_loss: 40.6744 - val_mse: 40.6013 - val_mae: 5.0620
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 49.7301 - mse: 49.6528 - mae: 5.4502 - val_loss: 40.1765 - val_mse: 40.0955 - val_mae: 5.0315
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 49.2352 - mse: 49.1496 - mae: 5.4237 - val_loss: 39.8429 - val_mse: 39.7529 - val_mae: 5.0101
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 48.6646 - mse: 48.5700 - mae: 5.3987 - val_loss: 39.4919 - val_mse: 39.3923 - val_mae: 4.9886
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 48.4843 - mse: 48.3796 - mae: 5.3898 - val_loss: 39.4993 - val_mse: 39.3896 - val_mae: 4.9949
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.7318 - mse: 47.6171 - mae: 5.3539 - val_loss: 39.2289 - val_mse: 39.1093 - val_mae: 4.9821
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.5032 - mse: 47.3784 - mae: 5.3356 - val_loss: 39.2366 - val_mse: 39.1072 - val_mae: 4.9810
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.3398 - mse: 47.2055 - mae: 5.3202 - val_loss: 39.5793 - val_mse: 39.4404 - val_mae: 5.0056
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.9729 - mse: 46.8294 - mae: 5.2978 - val_loss: 38.7586 - val_mse: 38.6108 - val_mae: 4.9571
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.8398 - mse: 46.6879 - mae: 5.2990 - val_loss: 38.6329 - val_mse: 38.4770 - val_mae: 4.9559
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.7066 - mse: 46.5469 - mae: 5.2850 - val_loss: 38.7842 - val_mse: 38.6209 - val_mae: 4.9614
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.2793 - mse: 46.1125 - mae: 5.2634 - val_loss: 38.9660 - val_mse: 38.7961 - val_mae: 4.9785
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.1158 - mse: 45.9427 - mae: 5.2524 - val_loss: 39.0735 - val_mse: 38.8973 - val_mae: 4.9797
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.8520 - mse: 45.6730 - mae: 5.2376 - val_loss: 38.4424 - val_mse: 38.2607 - val_mae: 4.9412
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.6395 - mse: 45.4551 - mae: 5.2251 - val_loss: 39.0820 - val_mse: 38.8953 - val_mae: 4.9813
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.3869 - mse: 45.1978 - mae: 5.2113 - val_loss: 38.4595 - val_mse: 38.2680 - val_mae: 4.9451
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.4372 - mse: 45.2434 - mae: 5.2121 - val_loss: 38.6412 - val_mse: 38.4455 - val_mae: 4.9552
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.1696 - mse: 44.9717 - mae: 5.1980 - val_loss: 38.5216 - val_mse: 38.3217 - val_mae: 4.9562
bias -0.0071578464
si 0.49448955
rmse 0.061904553
kgeprime [0.66843218]
rmse_95 0.09315072
rmse_99 0.11435208
pearson 0.8443715088208722
pearson_95 0.6509517156002703
pearson_99 0.6409130789476865
rscore 0.7088346411365776
rscore_95 -1.4474734595865342
rscore_99 -18.369150512114494
nse [0.70883464]
nse_95 [-1.44747346]
nse_99 [-18.36915051]
kge [0.74278259]
ext_kge_95 [0.52533601]
ext_kge_99 [-1.20625718]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 165.9 166.2 166.6 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.708 -9.678 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 11.38 11.16 ... -2.747
    uw2             (time, latitude, longitude) float32 94.24 93.66 ... 1.056
    vw2             (time, latitude, longitude) float32 129.5 124.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.96 14.77 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([135396 135420 135444], shape=(3,), dtype=int64) Times out: tf.Tensor(135444, shape=(), dtype=int64)
Times in: tf.Tensor([77016 77040 77064], shape=(3,), dtype=int64) Times out: tf.Tensor(77064, shape=(), dtype=int64)
Times in: tf.Tensor([69808 69832 69856], shape=(3,), dtype=int64) Times out: tf.Tensor(69856, shape=(), dtype=int64)
Times in: tf.Tensor([92944 92968 92992], shape=(3,), dtype=int64) Times out: tf.Tensor(92992, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_617&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_618 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1234 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1235 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_617 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1234 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_617 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1235 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 59.2379 - mse: 59.1875 - mae: 5.9714 - val_loss: 40.9123 - val_mse: 40.8480 - val_mae: 5.0821
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.1398 - mse: 43.0653 - mae: 5.1311 - val_loss: 41.1346 - val_mse: 41.0480 - val_mae: 5.1096
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7068 - mse: 40.6092 - mae: 4.9775 - val_loss: 38.2775 - val_mse: 38.1690 - val_mae: 4.9319
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1349 - mse: 39.0173 - mae: 4.8755 - val_loss: 36.9008 - val_mse: 36.7745 - val_mae: 4.8392
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3794 - mse: 38.2479 - mae: 4.8240 - val_loss: 37.5716 - val_mse: 37.4349 - val_mae: 4.8767
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9549 - mse: 37.8151 - mae: 4.7948 - val_loss: 37.4297 - val_mse: 37.2863 - val_mae: 4.8650
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6258 - mse: 37.4798 - mae: 4.7734 - val_loss: 36.8049 - val_mse: 36.6563 - val_mae: 4.8255
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3659 - mse: 37.2151 - mae: 4.7586 - val_loss: 35.9676 - val_mse: 35.8143 - val_mae: 4.7752
Epoch 9/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.2303 - mse: 37.0748 - mae: 4.7473 - val_loss: 36.7055 - val_mse: 36.5477 - val_mae: 4.8239
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9480 - mse: 36.7878 - mae: 4.7317 - val_loss: 36.1276 - val_mse: 35.9647 - val_mae: 4.7920
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5554 - mse: 36.3901 - mae: 4.7051 - val_loss: 38.2126 - val_mse: 38.0443 - val_mae: 4.9210
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0227 - mse: 35.8517 - mae: 4.6730 - val_loss: 36.6890 - val_mse: 36.5152 - val_mae: 4.8254
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6785 - mse: 35.5026 - mae: 4.6470 - val_loss: 36.8807 - val_mse: 36.7024 - val_mae: 4.8421
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2773 - mse: 35.0974 - mae: 4.6195 - val_loss: 36.3944 - val_mse: 36.2126 - val_mae: 4.8141
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1941 - mse: 35.0107 - mae: 4.6152 - val_loss: 35.8901 - val_mse: 35.7049 - val_mae: 4.7847
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0938 - mse: 34.9071 - mae: 4.6103 - val_loss: 33.9609 - val_mse: 33.7727 - val_mae: 4.6587
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9440 - mse: 34.7544 - mae: 4.6013 - val_loss: 35.7146 - val_mse: 35.5232 - val_mae: 4.7722
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8054 - mse: 34.6126 - mae: 4.5905 - val_loss: 35.2693 - val_mse: 35.0752 - val_mae: 4.7428
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7558 - mse: 34.5603 - mae: 4.5871 - val_loss: 35.7537 - val_mse: 35.5563 - val_mae: 4.7743
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.5495 - mse: 34.3511 - mae: 4.5694 - val_loss: 35.8764 - val_mse: 35.6763 - val_mae: 4.7829
bias -0.019188017
si 0.503706
rmse 0.059729606
kgeprime [0.37156744]
rmse_95 0.06645974
rmse_99 0.079412915
pearson 0.8410306043432776
pearson_95 0.7162808028126405
pearson_99 0.9003711873477278
rscore 0.6719042068492853
rscore_95 -0.8714469623222088
rscore_99 -10.73752504087254
nse [0.67190421]
nse_95 [-0.87144696]
nse_99 [-10.73752504]
kge [0.49845073]
ext_kge_95 [0.56311368]
ext_kge_99 [-0.59407043]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -50.11 -49.8 -49.49 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.678 -9.618 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 11.16 10.93 ... -2.747
    uw2             (time, latitude, longitude) float32 93.66 92.51 ... 1.056
    vw2             (time, latitude, longitude) float32 124.5 119.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.77 14.56 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([128236 128260 128284], shape=(3,), dtype=int64) Times out: tf.Tensor(128284, shape=(), dtype=int64)
Times in: tf.Tensor([144425 144449 144473], shape=(3,), dtype=int64) Times out: tf.Tensor(144473, shape=(), dtype=int64)
Times in: tf.Tensor([78426 78450 78474], shape=(3,), dtype=int64) Times out: tf.Tensor(78474, shape=(), dtype=int64)
Times in: tf.Tensor([69322 69346 69370], shape=(3,), dtype=int64) Times out: tf.Tensor(69370, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_618&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_619 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1236 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1237 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_618 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1236 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_618 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1237 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.2613 - mse: 50.1885 - mae: 5.4605 - val_loss: 36.9108 - val_mse: 36.8209 - val_mae: 4.8635
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8174 - mse: 37.7174 - mae: 4.7958 - val_loss: 35.4173 - val_mse: 35.3068 - val_mae: 4.7594
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8135 - mse: 36.6949 - mae: 4.7320 - val_loss: 34.6206 - val_mse: 34.4939 - val_mae: 4.6976
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1058 - mse: 35.9727 - mae: 4.6857 - val_loss: 33.9785 - val_mse: 33.8387 - val_mae: 4.6580
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7826 - mse: 35.6373 - mae: 4.6640 - val_loss: 34.4239 - val_mse: 34.2729 - val_mae: 4.6817
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4314 - mse: 35.2754 - mae: 4.6426 - val_loss: 34.3032 - val_mse: 34.1421 - val_mae: 4.6761
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1767 - mse: 35.0109 - mae: 4.6259 - val_loss: 34.9529 - val_mse: 34.7817 - val_mae: 4.7181
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8529 - mse: 34.6770 - mae: 4.5976 - val_loss: 34.1722 - val_mse: 33.9910 - val_mae: 4.6669
Epoch 9/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.2928 - mse: 34.1073 - mae: 4.5624 - val_loss: 34.4344 - val_mse: 34.2443 - val_mae: 4.6874
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9120 - mse: 33.7181 - mae: 4.5379 - val_loss: 33.1844 - val_mse: 32.9866 - val_mae: 4.6121
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7047 - mse: 33.5038 - mae: 4.5219 - val_loss: 33.8249 - val_mse: 33.6208 - val_mae: 4.6583
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3605 - mse: 33.1541 - mae: 4.4965 - val_loss: 33.6752 - val_mse: 33.4660 - val_mae: 4.6509
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2855 - mse: 33.0738 - mae: 4.4921 - val_loss: 33.0533 - val_mse: 32.8389 - val_mae: 4.6071
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1801 - mse: 32.9640 - mae: 4.4777 - val_loss: 32.4654 - val_mse: 32.2469 - val_mae: 4.5756
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9672 - mse: 32.7467 - mae: 4.4685 - val_loss: 33.0593 - val_mse: 32.8370 - val_mae: 4.6058
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8283 - mse: 32.6041 - mae: 4.4553 - val_loss: 32.9019 - val_mse: 32.6758 - val_mae: 4.5952
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7806 - mse: 32.5528 - mae: 4.4564 - val_loss: 32.6582 - val_mse: 32.4283 - val_mae: 4.5786
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6815 - mse: 32.4501 - mae: 4.4498 - val_loss: 32.2329 - val_mse: 31.9995 - val_mae: 4.5504
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5365 - mse: 32.3014 - mae: 4.4395 - val_loss: 32.3441 - val_mse: 32.1073 - val_mae: 4.5619
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4766 - mse: 32.2381 - mae: 4.4284 - val_loss: 32.4904 - val_mse: 32.2501 - val_mae: 4.5654
bias -0.011691855
si 0.4986935
rmse 0.05678923
kgeprime [0.54712821]
rmse_95 0.0712158
rmse_99 0.08123627
pearson 0.844548068462633
pearson_95 0.7184187112572453
pearson_99 0.88761709627962
rscore 0.699388500362369
rscore_95 -1.155444831328019
rscore_99 -11.745398393387555
nse [0.6993885]
nse_95 [-1.15544483]
nse_99 [-11.74539839]
kge [0.65373617]
ext_kge_95 [0.49955625]
ext_kge_99 [-0.90241635]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.58 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.42 11.37 ... 2.572
    uw2             (time, latitude, longitude) float32 92.35 91.77 ... 4.861
    vw2             (time, latitude, longitude) float32 130.4 129.2 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 14.92 14.87 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([97544 97568 97592], shape=(3,), dtype=int64) Times out: tf.Tensor(97592, shape=(), dtype=int64)
Times in: tf.Tensor([39380 39404 39428], shape=(3,), dtype=int64) Times out: tf.Tensor(39428, shape=(), dtype=int64)
Times in: tf.Tensor([104159 104183 104207], shape=(3,), dtype=int64) Times out: tf.Tensor(104207, shape=(), dtype=int64)
Times in: tf.Tensor([109443 109467 109491], shape=(3,), dtype=int64) Times out: tf.Tensor(109491, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_619&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_620 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1238 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1239 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_619 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1238 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_619 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1239 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.8695 - mse: 53.8163 - mae: 5.6490 - val_loss: 37.0727 - val_mse: 37.0074 - val_mae: 4.8687
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7551 - mse: 40.6837 - mae: 4.9814 - val_loss: 35.3896 - val_mse: 35.3127 - val_mae: 4.7436
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6773 - mse: 39.5950 - mae: 4.9104 - val_loss: 35.3473 - val_mse: 35.2600 - val_mae: 4.7476
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2523 - mse: 39.1606 - mae: 4.8877 - val_loss: 34.6467 - val_mse: 34.5504 - val_mae: 4.6971
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6202 - mse: 38.5195 - mae: 4.8438 - val_loss: 34.3746 - val_mse: 34.2695 - val_mae: 4.6856
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4067 - mse: 38.2970 - mae: 4.8297 - val_loss: 34.3210 - val_mse: 34.2069 - val_mae: 4.6767
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9197 - mse: 37.8011 - mae: 4.7966 - val_loss: 34.2378 - val_mse: 34.1151 - val_mae: 4.6762
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7603 - mse: 37.6334 - mae: 4.7871 - val_loss: 34.3007 - val_mse: 34.1699 - val_mae: 4.6806
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4104 - mse: 37.2756 - mae: 4.7685 - val_loss: 33.6907 - val_mse: 33.5523 - val_mae: 4.6415
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3695 - mse: 37.2271 - mae: 4.7638 - val_loss: 34.0190 - val_mse: 33.8732 - val_mae: 4.6606
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0441 - mse: 36.8946 - mae: 4.7433 - val_loss: 34.2230 - val_mse: 34.0699 - val_mae: 4.6798
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8717 - mse: 36.7149 - mae: 4.7291 - val_loss: 33.6182 - val_mse: 33.4584 - val_mae: 4.6390
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7980 - mse: 36.6348 - mae: 4.7242 - val_loss: 33.4987 - val_mse: 33.3324 - val_mae: 4.6301
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3903 - mse: 36.2210 - mae: 4.6994 - val_loss: 33.7345 - val_mse: 33.5622 - val_mae: 4.6467
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3032 - mse: 36.1281 - mae: 4.6922 - val_loss: 33.5217 - val_mse: 33.3442 - val_mae: 4.6334
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2399 - mse: 36.0594 - mae: 4.6868 - val_loss: 33.0169 - val_mse: 32.8338 - val_mae: 4.5958
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9356 - mse: 35.7496 - mae: 4.6671 - val_loss: 33.4821 - val_mse: 33.2937 - val_mae: 4.6297
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7237 - mse: 35.5327 - mae: 4.6493 - val_loss: 33.0148 - val_mse: 32.8216 - val_mae: 4.5932
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4112 - mse: 35.2156 - mae: 4.6289 - val_loss: 33.2122 - val_mse: 33.0147 - val_mae: 4.6150
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1019 - mse: 34.9023 - mae: 4.6080 - val_loss: 32.5409 - val_mse: 32.3399 - val_mae: 4.5658
bias -0.009911549
si 0.48328134
rmse 0.056868218
kgeprime [0.60594766]
rmse_95 0.076431386
rmse_99 0.09449134
pearson 0.8524935478076064
pearson_95 0.7207475305097039
pearson_99 0.7589558862179666
rscore 0.7178639453971357
rscore_95 -0.7764692702008538
rscore_99 -7.045306996125621
nse [0.71786395]
nse_95 [-0.77646927]
nse_99 [-7.045307]
kge [0.70223748]
ext_kge_95 [0.62539191]
ext_kge_99 [-0.05678347]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.2 171.6 171.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.58 -9.58 ... -1.598
    vgrd10m         (time, latitude, longitude) float32 11.37 11.28 ... 0.9486
    uw2             (time, latitude, longitude) float32 91.77 91.77 ... 2.554
    vw2             (time, latitude, longitude) float32 129.2 127.2 ... 0.8998
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.8 ... 1.858
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([122406 122430 122454], shape=(3,), dtype=int64) Times out: tf.Tensor(122454, shape=(), dtype=int64)
Times in: tf.Tensor([22992 23016 23040], shape=(3,), dtype=int64) Times out: tf.Tensor(23040, shape=(), dtype=int64)
Times in: tf.Tensor([21101 21125 21149], shape=(3,), dtype=int64) Times out: tf.Tensor(21149, shape=(), dtype=int64)
Times in: tf.Tensor([148583 148607 148631], shape=(3,), dtype=int64) Times out: tf.Tensor(148631, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_620&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_621 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1240 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1241 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_620 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1240 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_620 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1241 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 64.8657 - mse: 64.8114 - mae: 6.2113 - val_loss: 42.4300 - val_mse: 42.3649 - val_mae: 5.1815
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.9742 - mse: 44.9033 - mae: 5.2388 - val_loss: 40.2564 - val_mse: 40.1792 - val_mae: 5.0468
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.9413 - mse: 42.8577 - mae: 5.1201 - val_loss: 38.8111 - val_mse: 38.7219 - val_mae: 4.9559
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1010 - mse: 42.0067 - mae: 5.0647 - val_loss: 38.2689 - val_mse: 38.1702 - val_mae: 4.9183
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.5528 - mse: 41.4499 - mae: 5.0283 - val_loss: 38.3165 - val_mse: 38.2099 - val_mae: 4.9148
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.1263 - mse: 41.0160 - mae: 5.0027 - val_loss: 38.2616 - val_mse: 38.1480 - val_mae: 4.9155
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9241 - mse: 40.8071 - mae: 4.9865 - val_loss: 37.3032 - val_mse: 37.1831 - val_mae: 4.8624
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3398 - mse: 40.2163 - mae: 4.9512 - val_loss: 37.5501 - val_mse: 37.4232 - val_mae: 4.8563
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7167 - mse: 39.5861 - mae: 4.9101 - val_loss: 36.2003 - val_mse: 36.0662 - val_mae: 4.7801
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9266 - mse: 38.7892 - mae: 4.8579 - val_loss: 37.3871 - val_mse: 37.2466 - val_mae: 4.8547
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2465 - mse: 38.1034 - mae: 4.8179 - val_loss: 34.5206 - val_mse: 34.3754 - val_mae: 4.6809
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9038 - mse: 37.7566 - mae: 4.7918 - val_loss: 34.9236 - val_mse: 34.7747 - val_mae: 4.7055
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6121 - mse: 37.4613 - mae: 4.7742 - val_loss: 34.9545 - val_mse: 34.8023 - val_mae: 4.7100
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2315 - mse: 37.0778 - mae: 4.7525 - val_loss: 34.4468 - val_mse: 34.2918 - val_mae: 4.6847
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0151 - mse: 36.8588 - mae: 4.7325 - val_loss: 34.3516 - val_mse: 34.1941 - val_mae: 4.6767
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9947 - mse: 36.8359 - mae: 4.7320 - val_loss: 34.1738 - val_mse: 34.0138 - val_mae: 4.6665
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7114 - mse: 36.5501 - mae: 4.7136 - val_loss: 34.3596 - val_mse: 34.1974 - val_mae: 4.6775
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6017 - mse: 36.4382 - mae: 4.7033 - val_loss: 33.9141 - val_mse: 33.7494 - val_mae: 4.6472
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.5256 - mse: 36.3600 - mae: 4.7013 - val_loss: 33.4892 - val_mse: 33.3228 - val_mae: 4.6207
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4969 - mse: 36.3295 - mae: 4.6979 - val_loss: 33.6925 - val_mse: 33.5243 - val_mae: 4.6304
bias -0.011490606
si 0.47075236
rmse 0.057900213
kgeprime [0.58152065]
rmse_95 0.07679969
rmse_99 0.0893294
pearson 0.8602185715757168
pearson_95 0.702866800401495
pearson_99 0.6653583249435938
rscore 0.7292906825902636
rscore_95 -0.7928981961434827
rscore_99 -9.425244326227817
nse [0.72929068]
nse_95 [-0.7928982]
nse_99 [-9.42524433]
kge [0.68502357]
ext_kge_95 [0.58035869]
ext_kge_99 [-0.65502012]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.58 -9.58 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.37 11.28 ... -0.8311
    uw2             (time, latitude, longitude) float32 91.77 91.77 ... 0.6148
    vw2             (time, latitude, longitude) float32 129.2 127.2 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.8 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([19608 19632 19656], shape=(3,), dtype=int64) Times out: tf.Tensor(19656, shape=(), dtype=int64)
Times in: tf.Tensor([12263 12287 12311], shape=(3,), dtype=int64) Times out: tf.Tensor(12311, shape=(), dtype=int64)
Times in: tf.Tensor([154134 154158 154182], shape=(3,), dtype=int64) Times out: tf.Tensor(154182, shape=(), dtype=int64)
Times in: tf.Tensor([43269 43293 43317], shape=(3,), dtype=int64) Times out: tf.Tensor(43317, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_621&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_622 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1242 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1243 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_621 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1242 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_621 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1243 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.2839 - mse: 58.2254 - mae: 5.8821 - val_loss: 40.9251 - val_mse: 40.8490 - val_mae: 5.0998
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.2150 - mse: 43.1282 - mae: 5.1365 - val_loss: 39.3031 - val_mse: 39.2067 - val_mae: 4.9909
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1107 - mse: 42.0057 - mae: 5.0654 - val_loss: 38.8702 - val_mse: 38.7572 - val_mae: 4.9453
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6008 - mse: 41.4802 - mae: 5.0300 - val_loss: 38.6990 - val_mse: 38.5705 - val_mae: 4.9406
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9460 - mse: 40.8104 - mae: 4.9930 - val_loss: 38.2517 - val_mse: 38.1082 - val_mae: 4.9104
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.6147 - mse: 40.4638 - mae: 4.9661 - val_loss: 38.5663 - val_mse: 38.4080 - val_mae: 4.9407
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.0286 - mse: 39.8630 - mae: 4.9332 - val_loss: 37.4418 - val_mse: 37.2694 - val_mae: 4.8704
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6907 - mse: 39.5111 - mae: 4.9105 - val_loss: 37.1636 - val_mse: 36.9771 - val_mae: 4.8545
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0355 - mse: 38.8422 - mae: 4.8727 - val_loss: 36.6557 - val_mse: 36.4558 - val_mae: 4.8183
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2239 - mse: 38.0177 - mae: 4.8186 - val_loss: 36.5709 - val_mse: 36.3592 - val_mae: 4.8075
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6293 - mse: 37.4127 - mae: 4.7788 - val_loss: 35.7059 - val_mse: 35.4848 - val_mae: 4.7676
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2010 - mse: 36.9760 - mae: 4.7500 - val_loss: 34.8920 - val_mse: 34.6636 - val_mae: 4.7253
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9088 - mse: 36.6766 - mae: 4.7320 - val_loss: 34.4962 - val_mse: 34.2610 - val_mae: 4.6997
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4355 - mse: 36.1972 - mae: 4.6975 - val_loss: 34.5441 - val_mse: 34.3032 - val_mae: 4.6954
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1682 - mse: 35.9252 - mae: 4.6799 - val_loss: 34.0985 - val_mse: 33.8535 - val_mae: 4.6651
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0575 - mse: 35.8107 - mae: 4.6764 - val_loss: 33.8526 - val_mse: 33.6043 - val_mae: 4.6477
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9177 - mse: 35.6678 - mae: 4.6608 - val_loss: 33.7249 - val_mse: 33.4739 - val_mae: 4.6550
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6541 - mse: 35.4017 - mae: 4.6458 - val_loss: 33.9194 - val_mse: 33.6664 - val_mae: 4.6567
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6641 - mse: 35.4100 - mae: 4.6450 - val_loss: 33.7864 - val_mse: 33.5313 - val_mae: 4.6401
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4091 - mse: 35.1532 - mae: 4.6305 - val_loss: 33.4474 - val_mse: 33.1904 - val_mae: 4.6264
bias -0.0058369427
si 0.46885908
rmse 0.05761112
kgeprime [0.71508903]
rmse_95 0.079393655
rmse_99 0.08988514
pearson 0.8614923677659999
pearson_95 0.709367477530815
pearson_99 0.667429677987904
rscore 0.7391066457026327
rscore_95 -0.8540904537735212
rscore_99 -10.342848178605582
nse [0.73910665]
nse_95 [-0.85409045]
nse_99 [-10.34284818]
kge [0.77941312]
ext_kge_95 [0.55831722]
ext_kge_99 [-0.78857682]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.3 165.6 165.9 ... 171.6 171.9 172.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.58 -9.58 ... -0.7841
    vgrd10m         (time, latitude, longitude) float32 11.37 11.28 ... -0.8311
    uw2             (time, latitude, longitude) float32 91.77 91.77 ... 0.6148
    vw2             (time, latitude, longitude) float32 129.2 127.2 ... 0.6907
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.8 ... 1.143
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([27598 27622 27646], shape=(3,), dtype=int64) Times out: tf.Tensor(27646, shape=(), dtype=int64)
Times in: tf.Tensor([109130 109154 109178], shape=(3,), dtype=int64) Times out: tf.Tensor(109178, shape=(), dtype=int64)
Times in: tf.Tensor([7314 7338 7362], shape=(3,), dtype=int64) Times out: tf.Tensor(7362, shape=(), dtype=int64)
Times in: tf.Tensor([74428 74452 74476], shape=(3,), dtype=int64) Times out: tf.Tensor(74476, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_622&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_623 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1244 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1245 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_622 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1244 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_622 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1245 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 68.3559 - mse: 68.3141 - mae: 6.3771 - val_loss: 44.6118 - val_mse: 44.5613 - val_mae: 5.3334
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 49.6391 - mse: 49.5837 - mae: 5.4935 - val_loss: 42.8293 - val_mse: 42.7680 - val_mae: 5.2186
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.8649 - mse: 47.7986 - mae: 5.3918 - val_loss: 41.5955 - val_mse: 41.5250 - val_mae: 5.1163
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.1514 - mse: 47.0779 - mae: 5.3437 - val_loss: 40.3780 - val_mse: 40.3010 - val_mae: 5.0502
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.9499 - mse: 46.8700 - mae: 5.3316 - val_loss: 40.9086 - val_mse: 40.8257 - val_mae: 5.0838
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.5839 - mse: 46.4988 - mae: 5.3118 - val_loss: 40.2567 - val_mse: 40.1693 - val_mae: 5.0468
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.4104 - mse: 46.3202 - mae: 5.2967 - val_loss: 40.1926 - val_mse: 40.0998 - val_mae: 5.0408
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.1186 - mse: 46.0234 - mae: 5.2808 - val_loss: 40.3983 - val_mse: 40.3007 - val_mae: 5.0556
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.7681 - mse: 45.6681 - mae: 5.2634 - val_loss: 40.4192 - val_mse: 40.3164 - val_mae: 5.0494
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.7586 - mse: 45.6532 - mae: 5.2573 - val_loss: 40.3426 - val_mse: 40.2348 - val_mae: 5.0465
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.3970 - mse: 45.2868 - mae: 5.2408 - val_loss: 39.8340 - val_mse: 39.7213 - val_mae: 5.0196
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.2306 - mse: 45.1154 - mae: 5.2300 - val_loss: 39.7053 - val_mse: 39.5877 - val_mae: 5.0164
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.1793 - mse: 45.0591 - mae: 5.2265 - val_loss: 39.3881 - val_mse: 39.2652 - val_mae: 5.0003
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.9300 - mse: 44.8040 - mae: 5.2101 - val_loss: 39.2991 - val_mse: 39.1700 - val_mae: 5.0012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.4403 - mse: 44.3082 - mae: 5.1819 - val_loss: 40.2354 - val_mse: 40.1003 - val_mae: 5.0400
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.1349 - mse: 43.9967 - mae: 5.1567 - val_loss: 38.9394 - val_mse: 38.7981 - val_mae: 4.9649
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.6953 - mse: 43.5509 - mae: 5.1416 - val_loss: 38.0650 - val_mse: 37.9176 - val_mae: 4.9193
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.2086 - mse: 43.0587 - mae: 5.1077 - val_loss: 37.8390 - val_mse: 37.6864 - val_mae: 4.9090
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.8548 - mse: 42.6999 - mae: 5.0824 - val_loss: 38.2080 - val_mse: 38.0509 - val_mae: 4.9257
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.5219 - mse: 42.3628 - mae: 5.0663 - val_loss: 37.6682 - val_mse: 37.5070 - val_mae: 4.8993
bias -0.009988331
si 0.48564693
rmse 0.06124298
kgeprime [0.62356463]
rmse_95 0.083468564
rmse_99 0.09852752
pearson 0.8505259575003148
pearson_95 0.6779587074108134
pearson_99 0.615345012800554
rscore 0.7152404053027432
rscore_95 -1.00628632453521
rscore_99 -14.078175991222379
nse [0.71524041]
nse_95 [-1.00628632]
nse_99 [-14.07817599]
kge [0.71488643]
ext_kge_95 [0.55437214]
ext_kge_99 [-0.96991484]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.747
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 1.056
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([106563 106587 106611], shape=(3,), dtype=int64) Times out: tf.Tensor(106611, shape=(), dtype=int64)
Times in: tf.Tensor([51257 51281 51305], shape=(3,), dtype=int64) Times out: tf.Tensor(51305, shape=(), dtype=int64)
Times in: tf.Tensor([134660 134684 134708], shape=(3,), dtype=int64) Times out: tf.Tensor(134708, shape=(), dtype=int64)
Times in: tf.Tensor([94171 94195 94219], shape=(3,), dtype=int64) Times out: tf.Tensor(94219, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_623&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_624 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1246 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1247 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_623 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1246 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_623 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1247 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.6366 - mse: 53.5660 - mae: 5.6424 - val_loss: 37.9295 - val_mse: 37.8415 - val_mae: 4.9293
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5469 - mse: 39.4504 - mae: 4.8991 - val_loss: 36.3683 - val_mse: 36.2633 - val_mae: 4.8056
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2253 - mse: 38.1127 - mae: 4.8189 - val_loss: 35.9897 - val_mse: 35.8699 - val_mae: 4.7776
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7332 - mse: 37.6076 - mae: 4.7855 - val_loss: 36.0225 - val_mse: 35.8910 - val_mae: 4.7853
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2471 - mse: 37.1097 - mae: 4.7569 - val_loss: 35.5712 - val_mse: 35.4275 - val_mae: 4.7639
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8748 - mse: 36.7252 - mae: 4.7344 - val_loss: 36.2187 - val_mse: 36.0634 - val_mae: 4.7897
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6601 - mse: 36.4997 - mae: 4.7198 - val_loss: 35.5550 - val_mse: 35.3890 - val_mae: 4.7532
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2687 - mse: 36.0975 - mae: 4.6958 - val_loss: 36.2213 - val_mse: 36.0447 - val_mae: 4.7934
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1735 - mse: 35.9921 - mae: 4.6846 - val_loss: 36.6140 - val_mse: 36.4278 - val_mae: 4.8179
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6379 - mse: 35.4476 - mae: 4.6495 - val_loss: 34.8954 - val_mse: 34.7007 - val_mae: 4.7116
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5195 - mse: 35.3207 - mae: 4.6431 - val_loss: 35.0952 - val_mse: 34.8925 - val_mae: 4.7283
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.1100 - mse: 34.9039 - mae: 4.6121 - val_loss: 34.8089 - val_mse: 34.5993 - val_mae: 4.7156
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7850 - mse: 34.5725 - mae: 4.5897 - val_loss: 34.8061 - val_mse: 34.5910 - val_mae: 4.7182
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.4700 - mse: 34.2526 - mae: 4.5682 - val_loss: 34.0872 - val_mse: 33.8677 - val_mae: 4.6713
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.3115 - mse: 34.0901 - mae: 4.5569 - val_loss: 33.7494 - val_mse: 33.5258 - val_mae: 4.6461
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.0629 - mse: 33.8379 - mae: 4.5386 - val_loss: 33.9115 - val_mse: 33.6847 - val_mae: 4.6513
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.1996 - mse: 33.9711 - mae: 4.5434 - val_loss: 33.8411 - val_mse: 33.6110 - val_mae: 4.6460
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.9251 - mse: 33.6935 - mae: 4.5292 - val_loss: 33.6742 - val_mse: 33.4412 - val_mae: 4.6364
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6923 - mse: 33.4578 - mae: 4.5085 - val_loss: 33.2119 - val_mse: 32.9757 - val_mae: 4.6145
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6618 - mse: 33.4248 - mae: 4.5062 - val_loss: 32.6852 - val_mse: 32.4470 - val_mae: 4.5722
bias -0.0082118185
si 0.49603465
rmse 0.05696225
kgeprime [0.63943757]
rmse_95 0.07607267
rmse_99 0.088247515
pearson 0.8463637078270493
pearson_95 0.7180901382818836
pearson_99 0.8716335264846241
rscore 0.7089246731619857
rscore_95 -1.3182568544316333
rscore_99 -13.590040246313277
nse [0.70892467]
nse_95 [-1.31825685]
nse_99 [-13.59004025]
kge [0.72534791]
ext_kge_95 [0.52877816]
ext_kge_99 [-0.81699778]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.747
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 1.056
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([132385 132409 132433], shape=(3,), dtype=int64) Times out: tf.Tensor(132433, shape=(), dtype=int64)
Times in: tf.Tensor([49674 49698 49722], shape=(3,), dtype=int64) Times out: tf.Tensor(49722, shape=(), dtype=int64)
Times in: tf.Tensor([135473 135497 135521], shape=(3,), dtype=int64) Times out: tf.Tensor(135521, shape=(), dtype=int64)
Times in: tf.Tensor([25016 25040 25064], shape=(3,), dtype=int64) Times out: tf.Tensor(25064, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_624&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_625 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1248 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1249 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_624 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1248 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_624 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1249 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.3535 - mse: 51.2951 - mae: 5.5365 - val_loss: 38.6607 - val_mse: 38.5889 - val_mae: 4.9683
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2587 - mse: 40.1777 - mae: 4.9480 - val_loss: 36.9666 - val_mse: 36.8757 - val_mae: 4.8449
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7284 - mse: 38.6296 - mae: 4.8547 - val_loss: 36.1158 - val_mse: 36.0097 - val_mae: 4.7914
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0570 - mse: 37.9449 - mae: 4.8053 - val_loss: 35.9070 - val_mse: 35.7890 - val_mae: 4.7728
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5310 - mse: 37.4079 - mae: 4.7727 - val_loss: 35.3903 - val_mse: 35.2624 - val_mae: 4.7413
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2737 - mse: 37.1414 - mae: 4.7562 - val_loss: 35.0075 - val_mse: 34.8708 - val_mae: 4.7155
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7006 - mse: 36.5590 - mae: 4.7206 - val_loss: 35.0374 - val_mse: 34.8911 - val_mae: 4.7198
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0025 - mse: 35.8524 - mae: 4.6729 - val_loss: 34.4005 - val_mse: 34.2465 - val_mae: 4.6809
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6374 - mse: 35.4800 - mae: 4.6504 - val_loss: 33.7811 - val_mse: 33.6205 - val_mae: 4.6476
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3172 - mse: 35.1538 - mae: 4.6291 - val_loss: 33.3527 - val_mse: 33.1864 - val_mae: 4.6174
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0789 - mse: 34.9102 - mae: 4.6137 - val_loss: 33.4817 - val_mse: 33.3106 - val_mae: 4.6330
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8693 - mse: 34.6958 - mae: 4.6019 - val_loss: 34.1047 - val_mse: 33.9287 - val_mae: 4.6636
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7157 - mse: 34.5378 - mae: 4.5873 - val_loss: 33.6858 - val_mse: 33.5058 - val_mae: 4.6361
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5723 - mse: 34.3903 - mae: 4.5769 - val_loss: 34.0719 - val_mse: 33.8879 - val_mae: 4.6624
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4166 - mse: 34.2308 - mae: 4.5715 - val_loss: 33.1777 - val_mse: 32.9901 - val_mae: 4.5977
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4161 - mse: 34.2268 - mae: 4.5662 - val_loss: 33.1010 - val_mse: 32.9100 - val_mae: 4.5971
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2244 - mse: 34.0316 - mae: 4.5561 - val_loss: 33.4674 - val_mse: 33.2730 - val_mae: 4.6185
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1689 - mse: 33.9729 - mae: 4.5486 - val_loss: 32.9047 - val_mse: 32.7068 - val_mae: 4.5828
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0020 - mse: 33.8026 - mae: 4.5379 - val_loss: 32.9662 - val_mse: 32.7651 - val_mae: 4.5870
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8174 - mse: 33.6147 - mae: 4.5252 - val_loss: 32.2659 - val_mse: 32.0615 - val_mae: 4.5397
bias -0.0064032394
si 0.49648115
rmse 0.056622893
kgeprime [0.65997101]
rmse_95 0.080581054
rmse_99 0.08990654
pearson 0.845440826504708
pearson_95 0.7162943473894144
pearson_99 0.7836620331021943
rscore 0.7110318057484756
rscore_95 -1.6517637213536638
rscore_99 -13.709729875954162
nse [0.71103181]
nse_95 [-1.65176372]
nse_99 [-13.70972988]
kge [0.73678215]
ext_kge_95 [0.52686298]
ext_kge_99 [-0.61544162]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.2 172.5 172.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.028
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.747
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 1.056
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.548
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 2.933
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([135047 135071 135095], shape=(3,), dtype=int64) Times out: tf.Tensor(135095, shape=(), dtype=int64)
Times in: tf.Tensor([82480 82504 82528], shape=(3,), dtype=int64) Times out: tf.Tensor(82528, shape=(), dtype=int64)
Times in: tf.Tensor([56833 56857 56881], shape=(3,), dtype=int64) Times out: tf.Tensor(56881, shape=(), dtype=int64)
Times in: tf.Tensor([54092 54116 54140], shape=(3,), dtype=int64) Times out: tf.Tensor(54140, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_625&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_626 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1250 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1251 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_625 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1250 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_625 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1251 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.5446 - mse: 54.4793 - mae: 5.6878 - val_loss: 37.5256 - val_mse: 37.4420 - val_mae: 4.9068
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3885 - mse: 40.2963 - mae: 4.9461 - val_loss: 35.7718 - val_mse: 35.6714 - val_mae: 4.7784
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9630 - mse: 38.8569 - mae: 4.8552 - val_loss: 35.0894 - val_mse: 34.9778 - val_mae: 4.7259
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4497 - mse: 38.3337 - mae: 4.8250 - val_loss: 34.4709 - val_mse: 34.3500 - val_mae: 4.6771
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9452 - mse: 37.8207 - mae: 4.7957 - val_loss: 35.2295 - val_mse: 35.1011 - val_mae: 4.7281
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7455 - mse: 37.6139 - mae: 4.7781 - val_loss: 34.1029 - val_mse: 33.9682 - val_mae: 4.6517
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5181 - mse: 37.3800 - mae: 4.7717 - val_loss: 33.8494 - val_mse: 33.7081 - val_mae: 4.6421
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4021 - mse: 37.2577 - mae: 4.7586 - val_loss: 34.1899 - val_mse: 34.0421 - val_mae: 4.6594
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1313 - mse: 36.9809 - mae: 4.7448 - val_loss: 34.4280 - val_mse: 34.2745 - val_mae: 4.6750
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9530 - mse: 36.7965 - mae: 4.7311 - val_loss: 34.0441 - val_mse: 33.8843 - val_mae: 4.6487
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5204 - mse: 36.3578 - mae: 4.7031 - val_loss: 33.6215 - val_mse: 33.4562 - val_mae: 4.6210
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0805 - mse: 35.9127 - mae: 4.6767 - val_loss: 34.2169 - val_mse: 34.0470 - val_mae: 4.6606
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7359 - mse: 35.5639 - mae: 4.6519 - val_loss: 32.6607 - val_mse: 32.4870 - val_mae: 4.5631
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5657 - mse: 35.3901 - mae: 4.6389 - val_loss: 33.2184 - val_mse: 33.0409 - val_mae: 4.6000
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3962 - mse: 35.2173 - mae: 4.6274 - val_loss: 33.6908 - val_mse: 33.5104 - val_mae: 4.6328
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2167 - mse: 35.0351 - mae: 4.6145 - val_loss: 32.4580 - val_mse: 32.2750 - val_mae: 4.5497
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2563 - mse: 35.0720 - mae: 4.6179 - val_loss: 32.4572 - val_mse: 32.2718 - val_mae: 4.5529
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1367 - mse: 34.9501 - mae: 4.6068 - val_loss: 32.8586 - val_mse: 32.6705 - val_mae: 4.5808
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9855 - mse: 34.7966 - mae: 4.6003 - val_loss: 32.1749 - val_mse: 31.9849 - val_mae: 4.5308
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9351 - mse: 34.7442 - mae: 4.5947 - val_loss: 32.5335 - val_mse: 32.3413 - val_mae: 4.5575
bias -0.00860982
si 0.5045033
rmse 0.05686938
kgeprime [0.60907916]
rmse_95 0.07686968
rmse_99 0.083578475
pearson 0.8403856857070188
pearson_95 0.7071151525395182
pearson_99 0.7724456519951203
rscore 0.6988986430416961
rscore_95 -1.5658073436239208
rscore_99 -12.851281745886924
nse [0.69889864]
nse_95 [-1.56580734]
nse_99 [-12.85128175]
kge [0.70180841]
ext_kge_95 [0.4959842]
ext_kge_99 [-0.67931513]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.779
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 3.077
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([21895 21919 21943], shape=(3,), dtype=int64) Times out: tf.Tensor(21943, shape=(), dtype=int64)
Times in: tf.Tensor([107267 107291 107315], shape=(3,), dtype=int64) Times out: tf.Tensor(107315, shape=(), dtype=int64)
Times in: tf.Tensor([121167 121191 121215], shape=(3,), dtype=int64) Times out: tf.Tensor(121215, shape=(), dtype=int64)
Times in: tf.Tensor([3096 3120 3144], shape=(3,), dtype=int64) Times out: tf.Tensor(3144, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_626&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_627 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1252 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1253 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_626 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1252 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_626 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1253 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.6210 - mse: 48.5661 - mae: 5.3874 - val_loss: 35.6617 - val_mse: 35.5969 - val_mae: 4.7731
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3168 - mse: 37.2435 - mae: 4.7665 - val_loss: 34.3379 - val_mse: 34.2557 - val_mae: 4.6835
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9578 - mse: 35.8676 - mae: 4.6751 - val_loss: 33.7843 - val_mse: 33.6872 - val_mae: 4.6388
Epoch 4/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.2738 - mse: 35.1710 - mae: 4.6267 - val_loss: 32.9016 - val_mse: 32.7939 - val_mae: 4.5862
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8543 - mse: 34.7416 - mae: 4.6040 - val_loss: 33.9850 - val_mse: 33.8680 - val_mae: 4.6547
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5209 - mse: 34.4003 - mae: 4.5796 - val_loss: 33.2085 - val_mse: 33.0840 - val_mae: 4.6064
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3245 - mse: 34.1963 - mae: 4.5687 - val_loss: 33.1955 - val_mse: 33.0638 - val_mae: 4.6049
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2686 - mse: 34.1335 - mae: 4.5636 - val_loss: 33.4024 - val_mse: 33.2637 - val_mae: 4.6157
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0658 - mse: 33.9237 - mae: 4.5509 - val_loss: 33.1488 - val_mse: 33.0036 - val_mae: 4.6022
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8489 - mse: 33.7007 - mae: 4.5349 - val_loss: 35.1274 - val_mse: 34.9763 - val_mae: 4.7289
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7824 - mse: 33.6281 - mae: 4.5329 - val_loss: 33.1251 - val_mse: 32.9679 - val_mae: 4.6002
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6109 - mse: 33.4506 - mae: 4.5192 - val_loss: 32.5786 - val_mse: 32.4150 - val_mae: 4.5632
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1940 - mse: 33.0275 - mae: 4.4911 - val_loss: 33.1487 - val_mse: 32.9792 - val_mae: 4.6021
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0217 - mse: 32.8499 - mae: 4.4791 - val_loss: 32.3205 - val_mse: 32.1466 - val_mae: 4.5438
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7024 - mse: 32.5264 - mae: 4.4503 - val_loss: 32.8582 - val_mse: 32.6805 - val_mae: 4.5871
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4119 - mse: 32.2324 - mae: 4.4344 - val_loss: 32.6339 - val_mse: 32.4529 - val_mae: 4.5688
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2377 - mse: 32.0553 - mae: 4.4250 - val_loss: 33.3005 - val_mse: 33.1167 - val_mae: 4.6182
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1429 - mse: 31.9579 - mae: 4.4161 - val_loss: 31.8453 - val_mse: 31.6594 - val_mae: 4.5206
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0459 - mse: 31.8587 - mae: 4.4083 - val_loss: 31.0596 - val_mse: 30.8716 - val_mae: 4.4665
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9867 - mse: 31.7973 - mae: 4.4057 - val_loss: 31.4589 - val_mse: 31.2686 - val_mae: 4.4939
bias -0.011089324
si 0.5069349
rmse 0.0559183
kgeprime [0.5465512]
rmse_95 0.072642006
rmse_99 0.08533069
pearson 0.8394643882074433
pearson_95 0.686318006555876
pearson_99 0.8463274890322903
rscore 0.6913653602257608
rscore_95 -1.5216446616973163
rscore_99 -15.522423239839338
nse [0.69136536]
nse_95 [-1.52164466]
nse_99 [-15.52242324]
kge [0.65276389]
ext_kge_95 [0.51700249]
ext_kge_99 [-0.73937947]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.58 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.42 11.37 ... 2.572
    uw2             (time, latitude, longitude) float32 92.35 91.77 ... 4.861
    vw2             (time, latitude, longitude) float32 130.4 129.2 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 14.92 14.87 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([15394 15418 15442], shape=(3,), dtype=int64) Times out: tf.Tensor(15442, shape=(), dtype=int64)
Times in: tf.Tensor([118467 118491 118515], shape=(3,), dtype=int64) Times out: tf.Tensor(118515, shape=(), dtype=int64)
Times in: tf.Tensor([79220 79244 79268], shape=(3,), dtype=int64) Times out: tf.Tensor(79268, shape=(), dtype=int64)
Times in: tf.Tensor([98889 98913 98937], shape=(3,), dtype=int64) Times out: tf.Tensor(98937, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_627&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_628 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1254 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1255 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_627 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1254 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_627 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1255 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.3714 - mse: 58.3146 - mae: 5.8713 - val_loss: 37.2239 - val_mse: 37.1538 - val_mae: 4.8629
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.7749 - mse: 41.7012 - mae: 5.0322 - val_loss: 36.5583 - val_mse: 36.4799 - val_mae: 4.8190
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1385 - mse: 40.0553 - mae: 4.9339 - val_loss: 35.2121 - val_mse: 35.1239 - val_mae: 4.7323
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2693 - mse: 39.1765 - mae: 4.8758 - val_loss: 35.2404 - val_mse: 35.1429 - val_mae: 4.7321
Epoch 5/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.0648 - mse: 38.9623 - mae: 4.8622 - val_loss: 34.3698 - val_mse: 34.2621 - val_mae: 4.6778
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6483 - mse: 38.5362 - mae: 4.8375 - val_loss: 33.8730 - val_mse: 33.7560 - val_mae: 4.6443
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2901 - mse: 38.1683 - mae: 4.8128 - val_loss: 34.2649 - val_mse: 34.1382 - val_mae: 4.6724
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0224 - mse: 37.8913 - mae: 4.7953 - val_loss: 33.8582 - val_mse: 33.7231 - val_mae: 4.6518
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6626 - mse: 37.5234 - mae: 4.7714 - val_loss: 34.4974 - val_mse: 34.3541 - val_mae: 4.6883
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4683 - mse: 37.3214 - mae: 4.7607 - val_loss: 33.5141 - val_mse: 33.3634 - val_mae: 4.6252
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3106 - mse: 37.1566 - mae: 4.7475 - val_loss: 33.4612 - val_mse: 33.3036 - val_mae: 4.6218
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0231 - mse: 36.8620 - mae: 4.7288 - val_loss: 33.7216 - val_mse: 33.5573 - val_mae: 4.6437
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9304 - mse: 36.7629 - mae: 4.7229 - val_loss: 34.2952 - val_mse: 34.1248 - val_mae: 4.6890
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8021 - mse: 36.6289 - mae: 4.7126 - val_loss: 34.1529 - val_mse: 33.9763 - val_mae: 4.6727
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4698 - mse: 36.2909 - mae: 4.6905 - val_loss: 34.4174 - val_mse: 34.2353 - val_mae: 4.6898
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.4194 - mse: 36.2353 - mae: 4.6892 - val_loss: 33.7903 - val_mse: 33.6038 - val_mae: 4.6494
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1814 - mse: 35.9926 - mae: 4.6744 - val_loss: 33.5617 - val_mse: 33.3703 - val_mae: 4.6344
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2557 - mse: 36.0621 - mae: 4.6780 - val_loss: 33.2742 - val_mse: 33.0784 - val_mae: 4.6155
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8701 - mse: 35.6724 - mae: 4.6536 - val_loss: 33.4238 - val_mse: 33.2238 - val_mae: 4.6224
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9195 - mse: 35.7176 - mae: 4.6557 - val_loss: 33.9562 - val_mse: 33.7521 - val_mae: 4.6588
bias -0.012287189
si 0.49004382
rmse 0.058096513
kgeprime [0.55616532]
rmse_95 0.07716564
rmse_99 0.09170134
pearson 0.8482127908358161
pearson_95 0.6812413087561388
pearson_99 0.7223622355965252
rscore 0.7053711011279946
rscore_95 -0.8816557645041467
rscore_99 -7.862907477598364
nse [0.7053711]
nse_95 [-0.88165576]
nse_99 [-7.86290748]
kge [0.66172722]
ext_kge_95 [0.5776696]
ext_kge_99 [-0.41664673]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.779
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 3.077
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([44737 44761 44785], shape=(3,), dtype=int64) Times out: tf.Tensor(44785, shape=(), dtype=int64)
Times in: tf.Tensor([130563 130587 130611], shape=(3,), dtype=int64) Times out: tf.Tensor(130611, shape=(), dtype=int64)
Times in: tf.Tensor([32732 32756 32780], shape=(3,), dtype=int64) Times out: tf.Tensor(32780, shape=(), dtype=int64)
Times in: tf.Tensor([4399 4423 4447], shape=(3,), dtype=int64) Times out: tf.Tensor(4447, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_628&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_629 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1256 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1257 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_628 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1256 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_628 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1257 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.1940 - mse: 51.1280 - mae: 5.4951 - val_loss: 36.9701 - val_mse: 36.8864 - val_mae: 4.8656
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4795 - mse: 38.3878 - mae: 4.8334 - val_loss: 35.2470 - val_mse: 35.1480 - val_mae: 4.7392
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4258 - mse: 37.3209 - mae: 4.7609 - val_loss: 34.3532 - val_mse: 34.2437 - val_mae: 4.6685
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8456 - mse: 36.7317 - mae: 4.7272 - val_loss: 34.1655 - val_mse: 34.0483 - val_mae: 4.6536
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5277 - mse: 36.4063 - mae: 4.7101 - val_loss: 33.9076 - val_mse: 33.7827 - val_mae: 4.6408
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2145 - mse: 36.0852 - mae: 4.6903 - val_loss: 34.3668 - val_mse: 34.2339 - val_mae: 4.6725
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8755 - mse: 35.7384 - mae: 4.6681 - val_loss: 34.5736 - val_mse: 34.4331 - val_mae: 4.6882
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7873 - mse: 35.6428 - mae: 4.6596 - val_loss: 33.8496 - val_mse: 33.7019 - val_mae: 4.6391
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3629 - mse: 35.2109 - mae: 4.6346 - val_loss: 34.0707 - val_mse: 33.9154 - val_mae: 4.6575
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2486 - mse: 35.0894 - mae: 4.6284 - val_loss: 33.3827 - val_mse: 33.2202 - val_mae: 4.6130
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1518 - mse: 34.9853 - mae: 4.6191 - val_loss: 33.2569 - val_mse: 33.0869 - val_mae: 4.6049
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8601 - mse: 34.6861 - mae: 4.5960 - val_loss: 33.8287 - val_mse: 33.6515 - val_mae: 4.6464
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7189 - mse: 34.5379 - mae: 4.5930 - val_loss: 33.7388 - val_mse: 33.5547 - val_mae: 4.6380
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.6004 - mse: 34.4125 - mae: 4.5866 - val_loss: 33.6067 - val_mse: 33.4154 - val_mae: 4.6250
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.1922 - mse: 33.9970 - mae: 4.5548 - val_loss: 33.1908 - val_mse: 32.9921 - val_mae: 4.6005
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.8744 - mse: 33.6723 - mae: 4.5300 - val_loss: 32.6291 - val_mse: 32.4238 - val_mae: 4.5630
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.6007 - mse: 33.3927 - mae: 4.5105 - val_loss: 32.6809 - val_mse: 32.4705 - val_mae: 4.5670
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.3585 - mse: 33.1457 - mae: 4.4948 - val_loss: 32.5601 - val_mse: 32.3456 - val_mae: 4.5609
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.2535 - mse: 33.0370 - mae: 4.4879 - val_loss: 31.8748 - val_mse: 31.6568 - val_mae: 4.5140
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.9687 - mse: 32.7486 - mae: 4.4712 - val_loss: 32.1956 - val_mse: 31.9741 - val_mae: 4.5417
bias -0.008622036
si 0.5079748
rmse 0.056545675
kgeprime [0.59699637]
rmse_95 0.08050411
rmse_99 0.09385954
pearson 0.8380271197434357
pearson_95 0.6912034473984728
pearson_99 0.8430680788239331
rscore 0.6950653389782886
rscore_95 -1.9984915193286685
rscore_99 -18.253660563941256
nse [0.69506534]
nse_95 [-1.99849152]
nse_99 [-18.25366056]
kge [0.69209303]
ext_kge_95 [0.52263986]
ext_kge_99 [-0.59552182]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.779
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 3.077
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([140893 140917 140941], shape=(3,), dtype=int64) Times out: tf.Tensor(140941, shape=(), dtype=int64)
Times in: tf.Tensor([56037 56061 56085], shape=(3,), dtype=int64) Times out: tf.Tensor(56085, shape=(), dtype=int64)
Times in: tf.Tensor([12891 12915 12939], shape=(3,), dtype=int64) Times out: tf.Tensor(12939, shape=(), dtype=int64)
Times in: tf.Tensor([52027 52051 52075], shape=(3,), dtype=int64) Times out: tf.Tensor(52075, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_629&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_630 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1258 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1259 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_629 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1258 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_629 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1259 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.0496 - mse: 52.9871 - mae: 5.6199 - val_loss: 36.6446 - val_mse: 36.5682 - val_mae: 4.8299
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9171 - mse: 38.8346 - mae: 4.8662 - val_loss: 35.4188 - val_mse: 35.3283 - val_mae: 4.7479
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6913 - mse: 36.5941 - mae: 4.7220 - val_loss: 34.0740 - val_mse: 33.9699 - val_mae: 4.6623
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0355 - mse: 35.9258 - mae: 4.6727 - val_loss: 34.4617 - val_mse: 34.3465 - val_mae: 4.6836
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4094 - mse: 35.2896 - mae: 4.6333 - val_loss: 33.8294 - val_mse: 33.7048 - val_mae: 4.6409
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1386 - mse: 35.0095 - mae: 4.6161 - val_loss: 33.0833 - val_mse: 32.9495 - val_mae: 4.5991
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8494 - mse: 34.7115 - mae: 4.6008 - val_loss: 33.7217 - val_mse: 33.5794 - val_mae: 4.6366
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4961 - mse: 34.3489 - mae: 4.5809 - val_loss: 33.5359 - val_mse: 33.3837 - val_mae: 4.6252
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3784 - mse: 34.2217 - mae: 4.5708 - val_loss: 33.6436 - val_mse: 33.4821 - val_mae: 4.6329
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9240 - mse: 33.7576 - mae: 4.5380 - val_loss: 32.7478 - val_mse: 32.5772 - val_mae: 4.5716
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3694 - mse: 33.1947 - mae: 4.4985 - val_loss: 32.6527 - val_mse: 32.4741 - val_mae: 4.5653
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0334 - mse: 32.8515 - mae: 4.4768 - val_loss: 32.2677 - val_mse: 32.0828 - val_mae: 4.5412
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6063 - mse: 32.4188 - mae: 4.4491 - val_loss: 31.2755 - val_mse: 31.0855 - val_mae: 4.4819
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5043 - mse: 32.3118 - mae: 4.4393 - val_loss: 31.5402 - val_mse: 31.3455 - val_mae: 4.4965
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1811 - mse: 31.9846 - mae: 4.4194 - val_loss: 32.2625 - val_mse: 32.0646 - val_mae: 4.5385
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1710 - mse: 31.9714 - mae: 4.4107 - val_loss: 31.0570 - val_mse: 30.8560 - val_mae: 4.4609
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9651 - mse: 31.7626 - mae: 4.4013 - val_loss: 30.8155 - val_mse: 30.6118 - val_mae: 4.4392
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7375 - mse: 31.5323 - mae: 4.3861 - val_loss: 29.8891 - val_mse: 29.6829 - val_mae: 4.3777
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7538 - mse: 31.5462 - mae: 4.3808 - val_loss: 31.0648 - val_mse: 30.8563 - val_mae: 4.4608
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6135 - mse: 31.4042 - mae: 4.3768 - val_loss: 30.2750 - val_mse: 30.0648 - val_mae: 4.4055
bias -0.008366508
si 0.49940187
rmse 0.05483139
kgeprime [0.60903129]
rmse_95 0.07481897
rmse_99 0.08692068
pearson 0.8443382358464756
pearson_95 0.6829483684892559
pearson_99 0.8244053987212017
rscore 0.7057610390353733
rscore_95 -1.647128152897221
rscore_99 -16.272092986902383
nse [0.70576104]
nse_95 [-1.64712815]
nse_99 [-16.27209299]
kge [0.70270475]
ext_kge_95 [0.50475843]
ext_kge_99 [-0.74719554]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.58 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.42 11.37 ... 2.572
    uw2             (time, latitude, longitude) float32 92.35 91.77 ... 4.861
    vw2             (time, latitude, longitude) float32 130.4 129.2 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 14.92 14.87 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([6644 6668 6692], shape=(3,), dtype=int64) Times out: tf.Tensor(6692, shape=(), dtype=int64)
Times in: tf.Tensor([110227 110251 110275], shape=(3,), dtype=int64) Times out: tf.Tensor(110275, shape=(), dtype=int64)
Times in: tf.Tensor([55470 55494 55518], shape=(3,), dtype=int64) Times out: tf.Tensor(55518, shape=(), dtype=int64)
Times in: tf.Tensor([85490 85514 85538], shape=(3,), dtype=int64) Times out: tf.Tensor(85538, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_630&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_631 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1260 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1261 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_630 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1260 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_630 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1261 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.7953 - mse: 52.7426 - mae: 5.5962 - val_loss: 37.9512 - val_mse: 37.8867 - val_mae: 4.9010
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2451 - mse: 39.1758 - mae: 4.8868 - val_loss: 35.4554 - val_mse: 35.3823 - val_mae: 4.7561
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2190 - mse: 38.1435 - mae: 4.8178 - val_loss: 36.2543 - val_mse: 36.1757 - val_mae: 4.8041
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7676 - mse: 37.6873 - mae: 4.7852 - val_loss: 35.7208 - val_mse: 35.6384 - val_mae: 4.7597
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3745 - mse: 37.2907 - mae: 4.7645 - val_loss: 34.8814 - val_mse: 34.7956 - val_mae: 4.7079
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3486 - mse: 37.2621 - mae: 4.7576 - val_loss: 34.8995 - val_mse: 34.8114 - val_mae: 4.7104
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1526 - mse: 37.0637 - mae: 4.7478 - val_loss: 35.0654 - val_mse: 34.9748 - val_mae: 4.7148
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9538 - mse: 36.8624 - mae: 4.7322 - val_loss: 34.4617 - val_mse: 34.3687 - val_mae: 4.6767
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8235 - mse: 36.7297 - mae: 4.7185 - val_loss: 35.2861 - val_mse: 35.1908 - val_mae: 4.7357
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5245 - mse: 36.4283 - mae: 4.7049 - val_loss: 34.2999 - val_mse: 34.2022 - val_mae: 4.6708
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4650 - mse: 36.3660 - mae: 4.6960 - val_loss: 35.0301 - val_mse: 34.9295 - val_mae: 4.7172
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3575 - mse: 36.2559 - mae: 4.6926 - val_loss: 34.4505 - val_mse: 34.3471 - val_mae: 4.6825
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1421 - mse: 36.0377 - mae: 4.6743 - val_loss: 33.6657 - val_mse: 33.5593 - val_mae: 4.6379
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8747 - mse: 35.7670 - mae: 4.6609 - val_loss: 33.6412 - val_mse: 33.5313 - val_mae: 4.6315
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5894 - mse: 35.4778 - mae: 4.6364 - val_loss: 33.7100 - val_mse: 33.5961 - val_mae: 4.6432
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2710 - mse: 35.1551 - mae: 4.6130 - val_loss: 32.7202 - val_mse: 32.6016 - val_mae: 4.5748
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9857 - mse: 34.8651 - mae: 4.5970 - val_loss: 33.3146 - val_mse: 33.1912 - val_mae: 4.6196
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5384 - mse: 34.4133 - mae: 4.5728 - val_loss: 31.9841 - val_mse: 31.8566 - val_mae: 4.5310
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3190 - mse: 34.1903 - mae: 4.5506 - val_loss: 32.7599 - val_mse: 32.6293 - val_mae: 4.5929
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2134 - mse: 34.0816 - mae: 4.5455 - val_loss: 32.2933 - val_mse: 32.1597 - val_mae: 4.5499
bias -0.010981954
si 0.48167452
rmse 0.056709528
kgeprime [0.58568968]
rmse_95 0.07330107
rmse_99 0.08418012
pearson 0.8536871236236673
pearson_95 0.7313838790299473
pearson_99 0.7817290265735881
rscore 0.7176390427102703
rscore_95 -0.7689866533918477
rscore_99 -7.109795314365215
nse [0.71763904]
nse_95 [-0.76898665]
nse_99 [-7.10979531]
kge [0.68652076]
ext_kge_95 [0.63091701]
ext_kge_99 [-0.18615678]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.2 166.6 166.9 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.539 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.93 10.7 ... -2.779
    uw2             (time, latitude, longitude) float32 92.35 91.0 ... 3.077
    vw2             (time, latitude, longitude) float32 119.5 114.5 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.55 14.33 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([132355 132379 132403], shape=(3,), dtype=int64) Times out: tf.Tensor(132403, shape=(), dtype=int64)
Times in: tf.Tensor([20473 20497 20521], shape=(3,), dtype=int64) Times out: tf.Tensor(20521, shape=(), dtype=int64)
Times in: tf.Tensor([76971 76995 77019], shape=(3,), dtype=int64) Times out: tf.Tensor(77019, shape=(), dtype=int64)
Times in: tf.Tensor([133206 133230 133254], shape=(3,), dtype=int64) Times out: tf.Tensor(133254, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_631&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_632 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1262 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1263 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_631 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1262 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_631 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1263 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.7640 - mse: 51.7041 - mae: 5.5640 - val_loss: 37.5818 - val_mse: 37.5101 - val_mae: 4.8982
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6702 - mse: 39.5926 - mae: 4.9124 - val_loss: 36.3805 - val_mse: 36.2970 - val_mae: 4.8206
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0239 - mse: 37.9347 - mae: 4.8136 - val_loss: 35.7807 - val_mse: 35.6860 - val_mae: 4.7690
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3406 - mse: 37.2413 - mae: 4.7629 - val_loss: 35.0266 - val_mse: 34.9232 - val_mae: 4.7226
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8361 - mse: 36.7291 - mae: 4.7278 - val_loss: 34.7926 - val_mse: 34.6825 - val_mae: 4.7064
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4432 - mse: 36.3299 - mae: 4.7024 - val_loss: 34.7817 - val_mse: 34.6655 - val_mae: 4.7034
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9376 - mse: 35.8183 - mae: 4.6687 - val_loss: 34.4230 - val_mse: 34.3003 - val_mae: 4.6733
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3789 - mse: 35.2525 - mae: 4.6350 - val_loss: 33.2510 - val_mse: 33.1211 - val_mae: 4.6024
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7516 - mse: 34.6183 - mae: 4.5906 - val_loss: 33.3497 - val_mse: 33.2130 - val_mae: 4.6088
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2229 - mse: 34.0836 - mae: 4.5529 - val_loss: 32.9260 - val_mse: 32.7841 - val_mae: 4.5889
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9199 - mse: 33.7756 - mae: 4.5308 - val_loss: 32.6742 - val_mse: 32.5278 - val_mae: 4.5660
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5919 - mse: 33.4435 - mae: 4.5141 - val_loss: 31.7219 - val_mse: 31.5716 - val_mae: 4.5114
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5476 - mse: 33.3956 - mae: 4.5071 - val_loss: 32.4359 - val_mse: 32.2823 - val_mae: 4.5509
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4494 - mse: 33.2942 - mae: 4.5000 - val_loss: 32.3073 - val_mse: 32.1505 - val_mae: 4.5472
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2474 - mse: 33.0890 - mae: 4.4878 - val_loss: 31.3868 - val_mse: 31.2267 - val_mae: 4.4884
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1182 - mse: 32.9566 - mae: 4.4821 - val_loss: 31.4120 - val_mse: 31.2491 - val_mae: 4.4917
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0449 - mse: 32.8808 - mae: 4.4747 - val_loss: 31.3453 - val_mse: 31.1799 - val_mae: 4.4815
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0218 - mse: 32.8550 - mae: 4.4721 - val_loss: 32.2819 - val_mse: 32.1135 - val_mae: 4.5410
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7061 - mse: 32.5362 - mae: 4.4516 - val_loss: 31.5545 - val_mse: 31.3832 - val_mae: 4.4955
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8831 - mse: 32.7104 - mae: 4.4652 - val_loss: 31.5649 - val_mse: 31.3907 - val_mae: 4.4925
bias -0.008534463
si 0.4999119
rmse 0.056027424
kgeprime [0.60319873]
rmse_95 0.075631104
rmse_99 0.084914275
pearson 0.843730737104893
pearson_95 0.6977940472140196
pearson_99 0.761254604319256
rscore 0.7049770298680469
rscore_95 -1.609294405921105
rscore_99 -13.595593758262009
nse [0.70497703]
nse_95 [-1.60929441]
nse_99 [-13.59559376]
kge [0.69799567]
ext_kge_95 [0.530087]
ext_kge_99 [-0.414854]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -2.779
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 3.077
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([138996 139020 139044], shape=(3,), dtype=int64) Times out: tf.Tensor(139044, shape=(), dtype=int64)
Times in: tf.Tensor([37722 37746 37770], shape=(3,), dtype=int64) Times out: tf.Tensor(37770, shape=(), dtype=int64)
Times in: tf.Tensor([120919 120943 120967], shape=(3,), dtype=int64) Times out: tf.Tensor(120967, shape=(), dtype=int64)
Times in: tf.Tensor([128369 128393 128417], shape=(3,), dtype=int64) Times out: tf.Tensor(128417, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_632&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_633 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1264 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1265 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_632 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1264 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_632 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1265 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.0051 - mse: 49.9538 - mae: 5.4335 - val_loss: 36.0726 - val_mse: 36.0079 - val_mae: 4.7993
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3996 - mse: 37.3264 - mae: 4.7672 - val_loss: 34.6218 - val_mse: 34.5403 - val_mae: 4.7020
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3173 - mse: 36.2296 - mae: 4.6948 - val_loss: 33.7896 - val_mse: 33.6960 - val_mae: 4.6394
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8308 - mse: 35.7325 - mae: 4.6652 - val_loss: 33.7905 - val_mse: 33.6877 - val_mae: 4.6435
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4723 - mse: 35.3651 - mae: 4.6405 - val_loss: 34.6236 - val_mse: 34.5114 - val_mae: 4.6885
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1059 - mse: 34.9893 - mae: 4.6159 - val_loss: 33.6856 - val_mse: 33.5644 - val_mae: 4.6324
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8401 - mse: 34.7146 - mae: 4.6001 - val_loss: 34.0723 - val_mse: 33.9422 - val_mae: 4.6519
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6283 - mse: 34.4939 - mae: 4.5854 - val_loss: 33.8403 - val_mse: 33.7015 - val_mae: 4.6448
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3347 - mse: 34.1918 - mae: 4.5611 - val_loss: 33.9030 - val_mse: 33.7556 - val_mae: 4.6461
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1798 - mse: 34.0280 - mae: 4.5525 - val_loss: 33.6111 - val_mse: 33.4546 - val_mae: 4.6207
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8715 - mse: 33.7110 - mae: 4.5327 - val_loss: 33.2630 - val_mse: 33.0986 - val_mae: 4.6046
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7588 - mse: 33.5906 - mae: 4.5267 - val_loss: 34.2490 - val_mse: 34.0767 - val_mae: 4.6679
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5398 - mse: 33.3640 - mae: 4.5104 - val_loss: 33.8528 - val_mse: 33.6734 - val_mae: 4.6382
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3914 - mse: 33.2086 - mae: 4.4979 - val_loss: 33.0093 - val_mse: 32.8229 - val_mae: 4.5797
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1612 - mse: 32.9715 - mae: 4.4785 - val_loss: 32.7918 - val_mse: 32.5990 - val_mae: 4.5788
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8277 - mse: 32.6324 - mae: 4.4561 - val_loss: 32.5451 - val_mse: 32.3475 - val_mae: 4.5586
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5511 - mse: 32.3510 - mae: 4.4404 - val_loss: 32.1540 - val_mse: 31.9518 - val_mae: 4.5346
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3869 - mse: 32.1830 - mae: 4.4252 - val_loss: 32.5202 - val_mse: 32.3147 - val_mae: 4.5584
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1415 - mse: 31.9341 - mae: 4.4103 - val_loss: 31.5105 - val_mse: 31.3014 - val_mae: 4.4855
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9571 - mse: 31.7462 - mae: 4.3966 - val_loss: 32.1240 - val_mse: 31.9115 - val_mae: 4.5411
bias -0.009342751
si 0.51121324
rmse 0.056490228
kgeprime [0.60614527]
rmse_95 0.07062551
rmse_99 0.079949185
pearson 0.8386597871431583
pearson_95 0.6918513058342534
pearson_99 0.7214862557453022
rscore 0.6907970181530839
rscore_95 -1.3565328938942356
rscore_99 -12.231508585696368
nse [0.69079702]
nse_95 [-1.35653289]
nse_99 [-12.23150859]
kge [0.69735131]
ext_kge_95 [0.51297726]
ext_kge_99 [-0.64898363]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 2.572
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 4.861
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([46805 46829 46853], shape=(3,), dtype=int64) Times out: tf.Tensor(46853, shape=(), dtype=int64)
Times in: tf.Tensor([109130 109154 109178], shape=(3,), dtype=int64) Times out: tf.Tensor(109178, shape=(), dtype=int64)
Times in: tf.Tensor([105707 105731 105755], shape=(3,), dtype=int64) Times out: tf.Tensor(105755, shape=(), dtype=int64)
Times in: tf.Tensor([58344 58368 58392], shape=(3,), dtype=int64) Times out: tf.Tensor(58392, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_633&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_634 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1266 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1267 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_633 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1266 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_633 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1267 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.8109 - mse: 58.7665 - mae: 5.9401 - val_loss: 46.3877 - val_mse: 46.3383 - val_mae: 5.3860
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.7484 - mse: 44.6971 - mae: 5.2158 - val_loss: 37.6291 - val_mse: 37.5741 - val_mae: 4.8911
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8283 - mse: 39.7681 - mae: 4.9264 - val_loss: 38.5621 - val_mse: 38.4967 - val_mae: 4.9639
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2428 - mse: 38.1728 - mae: 4.8151 - val_loss: 36.4913 - val_mse: 36.4162 - val_mae: 4.8288
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4221 - mse: 37.3429 - mae: 4.7570 - val_loss: 34.9548 - val_mse: 34.8715 - val_mae: 4.7197
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9213 - mse: 36.8346 - mae: 4.7131 - val_loss: 34.2247 - val_mse: 34.1342 - val_mae: 4.6679
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0657 - mse: 35.9717 - mae: 4.6569 - val_loss: 34.2523 - val_mse: 34.1549 - val_mae: 4.6746
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4225 - mse: 35.3222 - mae: 4.6125 - val_loss: 34.2931 - val_mse: 34.1898 - val_mae: 4.6791
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8890 - mse: 34.7830 - mae: 4.5750 - val_loss: 33.9024 - val_mse: 33.7936 - val_mae: 4.6561
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4258 - mse: 34.3146 - mae: 4.5422 - val_loss: 32.4587 - val_mse: 32.3448 - val_mae: 4.5609
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0932 - mse: 33.9771 - mae: 4.5192 - val_loss: 30.8060 - val_mse: 30.6876 - val_mae: 4.4516
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7820 - mse: 33.6614 - mae: 4.4965 - val_loss: 32.9007 - val_mse: 32.7779 - val_mae: 4.5901
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.5303 - mse: 33.4057 - mae: 4.4844 - val_loss: 31.9676 - val_mse: 31.8410 - val_mae: 4.5294
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2387 - mse: 33.1103 - mae: 4.4630 - val_loss: 31.6059 - val_mse: 31.4756 - val_mae: 4.5076
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1157 - mse: 32.9837 - mae: 4.4504 - val_loss: 30.8351 - val_mse: 30.7015 - val_mae: 4.4586
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8318 - mse: 32.6965 - mae: 4.4292 - val_loss: 32.2786 - val_mse: 32.1416 - val_mae: 4.5533
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6221 - mse: 32.4840 - mae: 4.4217 - val_loss: 30.4412 - val_mse: 30.3018 - val_mae: 4.4276
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.6967 - mse: 32.5558 - mae: 4.4292 - val_loss: 30.3661 - val_mse: 30.2239 - val_mae: 4.4277
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5219 - mse: 32.3785 - mae: 4.4112 - val_loss: 29.9602 - val_mse: 29.8155 - val_mae: 4.3977
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3202 - mse: 32.1744 - mae: 4.4007 - val_loss: 30.7140 - val_mse: 30.5671 - val_mae: 4.4467
bias -0.013514606
si 0.47042838
rmse 0.055287562
kgeprime [0.51778759]
rmse_95 0.065506406
rmse_99 0.07877883
pearson 0.8608262768613195
pearson_95 0.7391032325875371
pearson_99 0.7555284040824972
rscore 0.724556684560087
rscore_95 -0.48307794887429667
rscore_99 -6.5494280380478305
nse [0.72455668]
nse_95 [-0.48307795]
nse_99 [-6.54942804]
kge [0.63302485]
ext_kge_95 [0.66728652]
ext_kge_99 [-0.11887318]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 165.0 165.3 165.6 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.61 -9.58 ... -2.205
    vgrd10m         (time, latitude, longitude) float32 11.42 11.37 ... 2.572
    uw2             (time, latitude, longitude) float32 92.35 91.77 ... 4.861
    vw2             (time, latitude, longitude) float32 130.4 129.2 ... 6.617
    wind_magnitude  (time, latitude, longitude) float32 14.92 14.87 ... 3.388
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([102021 102045 102069], shape=(3,), dtype=int64) Times out: tf.Tensor(102069, shape=(), dtype=int64)
Times in: tf.Tensor([106661 106685 106709], shape=(3,), dtype=int64) Times out: tf.Tensor(106709, shape=(), dtype=int64)
Times in: tf.Tensor([39734 39758 39782], shape=(3,), dtype=int64) Times out: tf.Tensor(39782, shape=(), dtype=int64)
Times in: tf.Tensor([70544 70568 70592], shape=(3,), dtype=int64) Times out: tf.Tensor(70592, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_634&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_635 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1268 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1269 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_634 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1268 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_634 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1269 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.4049 - mse: 50.3538 - mae: 5.4746 - val_loss: 37.6417 - val_mse: 37.5833 - val_mae: 4.8864
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6024 - mse: 38.5401 - mae: 4.8476 - val_loss: 35.4346 - val_mse: 35.3691 - val_mae: 4.7278
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6408 - mse: 37.5714 - mae: 4.7833 - val_loss: 35.1360 - val_mse: 35.0632 - val_mae: 4.7246
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0377 - mse: 36.9616 - mae: 4.7409 - val_loss: 34.2343 - val_mse: 34.1550 - val_mae: 4.6661
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6372 - mse: 36.5549 - mae: 4.7133 - val_loss: 35.6665 - val_mse: 35.5814 - val_mae: 4.7681
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3177 - mse: 36.2298 - mae: 4.6957 - val_loss: 33.6143 - val_mse: 33.5237 - val_mae: 4.6242
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9852 - mse: 35.8920 - mae: 4.6668 - val_loss: 34.9411 - val_mse: 34.8454 - val_mae: 4.7185
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7065 - mse: 35.6083 - mae: 4.6493 - val_loss: 34.6777 - val_mse: 34.5770 - val_mae: 4.6982
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6189 - mse: 35.5159 - mae: 4.6400 - val_loss: 33.4301 - val_mse: 33.3247 - val_mae: 4.6160
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.2136 - mse: 35.1059 - mae: 4.6162 - val_loss: 32.4864 - val_mse: 32.3761 - val_mae: 4.5524
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.7472 - mse: 34.6343 - mae: 4.5832 - val_loss: 32.3357 - val_mse: 32.2201 - val_mae: 4.5429
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.1198 - mse: 34.0017 - mae: 4.5427 - val_loss: 31.5163 - val_mse: 31.3958 - val_mae: 4.4885
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.6811 - mse: 33.5583 - mae: 4.5077 - val_loss: 32.2583 - val_mse: 32.1330 - val_mae: 4.5449
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4833 - mse: 33.3563 - mae: 4.4930 - val_loss: 31.3698 - val_mse: 31.2408 - val_mae: 4.4879
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3137 - mse: 33.1831 - mae: 4.4781 - val_loss: 30.0313 - val_mse: 29.8990 - val_mae: 4.3889
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0432 - mse: 32.9093 - mae: 4.4628 - val_loss: 30.9618 - val_mse: 30.8261 - val_mae: 4.4599
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9211 - mse: 32.7840 - mae: 4.4524 - val_loss: 30.6686 - val_mse: 30.5302 - val_mae: 4.4387
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.7857 - mse: 32.6462 - mae: 4.4481 - val_loss: 30.1633 - val_mse: 30.0226 - val_mae: 4.3976
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7258 - mse: 32.5840 - mae: 4.4415 - val_loss: 29.4907 - val_mse: 29.3481 - val_mae: 4.3557
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6944 - mse: 32.5506 - mae: 4.4368 - val_loss: 30.4323 - val_mse: 30.2874 - val_mae: 4.4208
bias -0.011783447
si 0.46604604
rmse 0.05503399
kgeprime [0.55084232]
rmse_95 0.07033965
rmse_99 0.082147
pearson 0.8637258001402837
pearson_95 0.7254006403245274
pearson_99 0.7850166415275012
rscore 0.7333911202159474
rscore_95 -0.6645456801895735
rscore_99 -7.185764413038406
nse [0.73339112]
nse_95 [-0.66454568]
nse_99 [-7.18576441]
kge [0.66170019]
ext_kge_95 [0.61780555]
ext_kge_99 [-0.41431914]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -2.779
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 3.077
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([111652 111676 111700], shape=(3,), dtype=int64) Times out: tf.Tensor(111700, shape=(), dtype=int64)
Times in: tf.Tensor([89895 89919 89943], shape=(3,), dtype=int64) Times out: tf.Tensor(89943, shape=(), dtype=int64)
Times in: tf.Tensor([38849 38873 38897], shape=(3,), dtype=int64) Times out: tf.Tensor(38897, shape=(), dtype=int64)
Times in: tf.Tensor([28185 28209 28233], shape=(3,), dtype=int64) Times out: tf.Tensor(28233, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_635&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_636 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1270 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1271 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_635 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1270 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_635 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1271 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.7523 - mse: 51.6999 - mae: 5.5450 - val_loss: 38.2423 - val_mse: 38.1795 - val_mae: 4.9402
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2214 - mse: 39.1524 - mae: 4.8789 - val_loss: 36.1646 - val_mse: 36.0901 - val_mae: 4.7982
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1568 - mse: 38.0784 - mae: 4.8142 - val_loss: 36.0810 - val_mse: 35.9991 - val_mae: 4.7879
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6739 - mse: 37.5887 - mae: 4.7811 - val_loss: 35.1958 - val_mse: 35.1072 - val_mae: 4.7337
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3721 - mse: 37.2810 - mae: 4.7588 - val_loss: 35.2929 - val_mse: 35.1988 - val_mae: 4.7406
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8534 - mse: 36.7563 - mae: 4.7298 - val_loss: 35.9275 - val_mse: 35.8268 - val_mae: 4.7823
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5674 - mse: 36.4635 - mae: 4.7156 - val_loss: 35.6553 - val_mse: 35.5477 - val_mae: 4.7633
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2022 - mse: 36.0907 - mae: 4.6915 - val_loss: 34.2372 - val_mse: 34.1216 - val_mae: 4.6708
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7208 - mse: 35.6011 - mae: 4.6552 - val_loss: 35.2572 - val_mse: 35.1334 - val_mae: 4.7424
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3066 - mse: 35.1792 - mae: 4.6276 - val_loss: 33.4058 - val_mse: 33.2751 - val_mae: 4.6271
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0469 - mse: 34.9130 - mae: 4.6154 - val_loss: 33.5406 - val_mse: 33.4040 - val_mae: 4.6367
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8747 - mse: 34.7352 - mae: 4.6011 - val_loss: 33.9743 - val_mse: 33.8322 - val_mae: 4.6600
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3343 - mse: 34.1898 - mae: 4.5635 - val_loss: 33.2586 - val_mse: 33.1115 - val_mae: 4.6131
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2905 - mse: 34.1408 - mae: 4.5623 - val_loss: 33.6670 - val_mse: 33.5146 - val_mae: 4.6360
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2759 - mse: 34.1214 - mae: 4.5602 - val_loss: 32.7612 - val_mse: 32.6044 - val_mae: 4.5841
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0076 - mse: 33.8486 - mae: 4.5442 - val_loss: 32.7037 - val_mse: 32.5424 - val_mae: 4.5715
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8770 - mse: 33.7132 - mae: 4.5312 - val_loss: 32.4791 - val_mse: 32.3131 - val_mae: 4.5630
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8476 - mse: 33.6791 - mae: 4.5304 - val_loss: 32.5244 - val_mse: 32.3535 - val_mae: 4.5612
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5534 - mse: 33.3801 - mae: 4.5113 - val_loss: 31.9987 - val_mse: 31.8233 - val_mae: 4.5380
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4730 - mse: 33.2954 - mae: 4.5045 - val_loss: 32.7053 - val_mse: 32.5253 - val_mae: 4.5784
bias -0.009476752
si 0.5059851
rmse 0.057030946
kgeprime [0.60480075]
rmse_95 0.07231455
rmse_99 0.08208043
pearson 0.8413145807428999
pearson_95 0.6917951050869291
pearson_99 0.7257292551691436
rscore 0.6966279101093418
rscore_95 -1.3677534818325494
rscore_99 -12.188225033387452
nse [0.69662791]
nse_95 [-1.36775348]
nse_99 [-12.18822503]
kge [0.69770321]
ext_kge_95 [0.51794882]
ext_kge_99 [-0.5879406]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.56 -43.24
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.754
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -2.779
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 3.077
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 7.726
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 3.287
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([6737 6761 6785], shape=(3,), dtype=int64) Times out: tf.Tensor(6785, shape=(), dtype=int64)
Times in: tf.Tensor([101302 101326 101350], shape=(3,), dtype=int64) Times out: tf.Tensor(101350, shape=(), dtype=int64)
Times in: tf.Tensor([56805 56829 56853], shape=(3,), dtype=int64) Times out: tf.Tensor(56853, shape=(), dtype=int64)
Times in: tf.Tensor([141368 141392 141416], shape=(3,), dtype=int64) Times out: tf.Tensor(141416, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_636&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_637 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1272 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1273 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_636 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1272 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_636 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1273 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.7202 - mse: 50.6702 - mae: 5.4831 - val_loss: 37.0903 - val_mse: 37.0281 - val_mae: 4.8397
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1924 - mse: 39.1246 - mae: 4.8716 - val_loss: 35.9266 - val_mse: 35.8539 - val_mae: 4.7543
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2662 - mse: 38.1896 - mae: 4.8111 - val_loss: 35.6495 - val_mse: 35.5696 - val_mae: 4.7355
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8966 - mse: 37.8137 - mae: 4.7924 - val_loss: 34.3760 - val_mse: 34.2904 - val_mae: 4.6543
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5625 - mse: 37.4741 - mae: 4.7690 - val_loss: 34.1145 - val_mse: 34.0237 - val_mae: 4.6411
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3500 - mse: 37.2565 - mae: 4.7564 - val_loss: 34.7351 - val_mse: 34.6391 - val_mae: 4.6796
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0693 - mse: 36.9706 - mae: 4.7358 - val_loss: 34.4576 - val_mse: 34.3564 - val_mae: 4.6618
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8490 - mse: 36.7454 - mae: 4.7251 - val_loss: 34.2644 - val_mse: 34.1583 - val_mae: 4.6491
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4892 - mse: 36.3807 - mae: 4.6988 - val_loss: 34.7013 - val_mse: 34.5905 - val_mae: 4.6781
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3567 - mse: 36.2435 - mae: 4.6913 - val_loss: 34.5551 - val_mse: 34.4399 - val_mae: 4.6665
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1845 - mse: 36.0671 - mae: 4.6821 - val_loss: 34.2177 - val_mse: 34.0982 - val_mae: 4.6454
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.1483 - mse: 36.0266 - mae: 4.6735 - val_loss: 34.2331 - val_mse: 34.1091 - val_mae: 4.6483
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9182 - mse: 35.7921 - mae: 4.6590 - val_loss: 34.2461 - val_mse: 34.1180 - val_mae: 4.6516
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7814 - mse: 35.6513 - mae: 4.6528 - val_loss: 34.3774 - val_mse: 34.2452 - val_mae: 4.6616
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5890 - mse: 35.4548 - mae: 4.6410 - val_loss: 34.0012 - val_mse: 33.8651 - val_mae: 4.6403
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4505 - mse: 35.3122 - mae: 4.6295 - val_loss: 34.1708 - val_mse: 34.0304 - val_mae: 4.6479
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3475 - mse: 35.2049 - mae: 4.6253 - val_loss: 33.8302 - val_mse: 33.6858 - val_mae: 4.6300
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1787 - mse: 35.0319 - mae: 4.6118 - val_loss: 34.3109 - val_mse: 34.1620 - val_mae: 4.6573
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9557 - mse: 34.8049 - mae: 4.6066 - val_loss: 34.8872 - val_mse: 34.7341 - val_mae: 4.6957
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7925 - mse: 34.6375 - mae: 4.5895 - val_loss: 33.9174 - val_mse: 33.7605 - val_mae: 4.6362
bias -0.015110372
si 0.51463455
rmse 0.058103796
kgeprime [0.42405239]
rmse_95 0.07541815
rmse_99 0.08891657
pearson 0.8340165373568948
pearson_95 0.6736696912191643
pearson_99 0.6789412820351262
rscore 0.6734933679320281
rscore_95 -1.7231263479882557
rscore_99 -14.784942826079494
nse [0.67349337]
nse_95 [-1.72312635]
nse_99 [-14.78494283]
kge [0.55064867]
ext_kge_95 [0.51095827]
ext_kge_99 [-0.76587725]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 1.797
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.01
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([120713 120737 120761], shape=(3,), dtype=int64) Times out: tf.Tensor(120761, shape=(), dtype=int64)
Times in: tf.Tensor([48852 48876 48900], shape=(3,), dtype=int64) Times out: tf.Tensor(48900, shape=(), dtype=int64)
Times in: tf.Tensor([85759 85783 85807], shape=(3,), dtype=int64) Times out: tf.Tensor(85807, shape=(), dtype=int64)
Times in: tf.Tensor([30152 30176 30200], shape=(3,), dtype=int64) Times out: tf.Tensor(30200, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_637&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_638 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1274 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1275 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_637 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1274 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_637 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1275 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.9765 - mse: 44.9329 - mae: 5.1638 - val_loss: 31.4858 - val_mse: 31.4326 - val_mae: 4.4828
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9274 - mse: 33.8676 - mae: 4.5441 - val_loss: 29.7285 - val_mse: 29.6625 - val_mae: 4.3679
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8073 - mse: 32.7366 - mae: 4.4616 - val_loss: 28.9524 - val_mse: 28.8773 - val_mae: 4.3116
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4412 - mse: 32.3619 - mae: 4.4342 - val_loss: 29.1430 - val_mse: 29.0594 - val_mae: 4.3264
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0913 - mse: 32.0036 - mae: 4.4117 - val_loss: 29.2253 - val_mse: 29.1334 - val_mae: 4.3340
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8394 - mse: 31.7437 - mae: 4.3961 - val_loss: 28.7898 - val_mse: 28.6895 - val_mae: 4.3050
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5811 - mse: 31.4768 - mae: 4.3737 - val_loss: 28.5982 - val_mse: 28.4893 - val_mae: 4.2894
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3966 - mse: 31.2837 - mae: 4.3611 - val_loss: 28.9760 - val_mse: 28.8584 - val_mae: 4.3201
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2348 - mse: 31.1132 - mae: 4.3444 - val_loss: 28.9278 - val_mse: 28.8015 - val_mae: 4.3209
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8492 - mse: 30.7189 - mae: 4.3218 - val_loss: 29.4007 - val_mse: 29.2661 - val_mae: 4.3575
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7186 - mse: 30.5801 - mae: 4.3095 - val_loss: 28.4792 - val_mse: 28.3366 - val_mae: 4.2896
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6568 - mse: 30.5105 - mae: 4.3058 - val_loss: 28.1476 - val_mse: 27.9974 - val_mae: 4.2677
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2234 - mse: 30.0695 - mae: 4.2736 - val_loss: 27.9593 - val_mse: 27.8015 - val_mae: 4.2529
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9998 - mse: 29.8386 - mae: 4.2531 - val_loss: 27.3014 - val_mse: 27.1367 - val_mae: 4.2098
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7002 - mse: 29.5325 - mae: 4.2329 - val_loss: 27.3936 - val_mse: 27.2229 - val_mae: 4.2157
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4847 - mse: 29.3115 - mae: 4.2218 - val_loss: 27.0213 - val_mse: 26.8458 - val_mae: 4.1857
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3877 - mse: 29.2101 - mae: 4.2093 - val_loss: 26.7291 - val_mse: 26.5494 - val_mae: 4.1633
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3036 - mse: 29.1220 - mae: 4.2021 - val_loss: 26.2992 - val_mse: 26.1160 - val_mae: 4.1229
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1349 - mse: 28.9500 - mae: 4.1930 - val_loss: 26.5780 - val_mse: 26.3918 - val_mae: 4.1456
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0528 - mse: 28.8651 - mae: 4.1846 - val_loss: 26.0498 - val_mse: 25.8607 - val_mae: 4.1060
bias -0.0073589087
si 0.47216034
rmse 0.050853405
kgeprime [0.63499237]
rmse_95 0.06783716
rmse_99 0.083196945
pearson 0.8606701084012152
pearson_95 0.7128981850133516
pearson_99 0.7981201644493757
rscore 0.7350818045549816
rscore_95 -1.0411351349675622
rscore_99 -8.887545100252376
nse [0.7350818]
nse_95 [-1.04113513]
nse_99 [-8.8875451]
kge [0.72433328]
ext_kge_95 [0.59590225]
ext_kge_99 [-0.27124548]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 1.797
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.01
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([34508 34532 34556], shape=(3,), dtype=int64) Times out: tf.Tensor(34556, shape=(), dtype=int64)
Times in: tf.Tensor([154212 154236 154260], shape=(3,), dtype=int64) Times out: tf.Tensor(154260, shape=(), dtype=int64)
Times in: tf.Tensor([147580 147604 147628], shape=(3,), dtype=int64) Times out: tf.Tensor(147628, shape=(), dtype=int64)
Times in: tf.Tensor([58681 58705 58729], shape=(3,), dtype=int64) Times out: tf.Tensor(58729, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_638&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_639 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1276 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1277 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_638 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1276 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_638 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1277 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.2488 - mse: 48.1998 - mae: 5.3540 - val_loss: 31.6182 - val_mse: 31.5606 - val_mae: 4.5022
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1109 - mse: 35.0500 - mae: 4.6191 - val_loss: 30.1600 - val_mse: 30.0955 - val_mae: 4.4030
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7458 - mse: 33.6776 - mae: 4.5231 - val_loss: 29.6491 - val_mse: 29.5772 - val_mae: 4.3691
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2291 - mse: 33.1533 - mae: 4.4915 - val_loss: 29.2046 - val_mse: 29.1250 - val_mae: 4.3382
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9527 - mse: 32.8696 - mae: 4.4689 - val_loss: 29.2029 - val_mse: 29.1163 - val_mae: 4.3374
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7642 - mse: 32.6744 - mae: 4.4567 - val_loss: 29.2735 - val_mse: 29.1801 - val_mae: 4.3485
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4738 - mse: 32.3773 - mae: 4.4365 - val_loss: 29.2471 - val_mse: 29.1471 - val_mae: 4.3432
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3767 - mse: 32.2733 - mae: 4.4274 - val_loss: 28.8805 - val_mse: 28.7735 - val_mae: 4.3205
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1162 - mse: 32.0058 - mae: 4.4067 - val_loss: 28.7073 - val_mse: 28.5934 - val_mae: 4.3128
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8316 - mse: 31.7143 - mae: 4.3864 - val_loss: 28.5678 - val_mse: 28.4471 - val_mae: 4.3087
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7930 - mse: 31.6695 - mae: 4.3817 - val_loss: 28.4784 - val_mse: 28.3515 - val_mae: 4.2968
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5438 - mse: 31.4141 - mae: 4.3625 - val_loss: 28.9566 - val_mse: 28.8238 - val_mae: 4.3324
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4356 - mse: 31.2999 - mae: 4.3571 - val_loss: 28.0245 - val_mse: 27.8859 - val_mae: 4.2667
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2585 - mse: 31.1174 - mae: 4.3456 - val_loss: 28.4633 - val_mse: 28.3195 - val_mae: 4.2934
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0935 - mse: 30.9471 - mae: 4.3321 - val_loss: 28.1118 - val_mse: 27.9628 - val_mae: 4.2685
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0329 - mse: 30.8813 - mae: 4.3238 - val_loss: 27.7695 - val_mse: 27.6153 - val_mae: 4.2416
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9387 - mse: 30.7822 - mae: 4.3193 - val_loss: 27.9228 - val_mse: 27.7640 - val_mae: 4.2537
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8066 - mse: 30.6455 - mae: 4.3066 - val_loss: 27.5501 - val_mse: 27.3863 - val_mae: 4.2149
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4665 - mse: 30.3005 - mae: 4.2825 - val_loss: 27.6019 - val_mse: 27.4337 - val_mae: 4.2215
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1650 - mse: 29.9948 - mae: 4.2659 - val_loss: 26.9160 - val_mse: 26.7441 - val_mae: 4.1745
bias -0.004769439
si 0.47989553
rmse 0.051714707
kgeprime [0.70390171]
rmse_95 0.070666075
rmse_99 0.08524717
pearson 0.8555333465901183
pearson_95 0.7105471168496126
pearson_99 0.8142333610752085
rscore 0.7296027919514964
rscore_95 -1.105527037508335
rscore_99 -9.491565656034611
nse [0.72960279]
nse_95 [-1.10552704]
nse_99 [-9.49156566]
kge [0.76742958]
ext_kge_95 [0.58680813]
ext_kge_99 [-0.3976736]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 2.66
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.64
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([84035 84059 84083], shape=(3,), dtype=int64) Times out: tf.Tensor(84083, shape=(), dtype=int64)
Times in: tf.Tensor([13327 13351 13375], shape=(3,), dtype=int64) Times out: tf.Tensor(13375, shape=(), dtype=int64)
Times in: tf.Tensor([31881 31905 31929], shape=(3,), dtype=int64) Times out: tf.Tensor(31929, shape=(), dtype=int64)
Times in: tf.Tensor([111650 111674 111698], shape=(3,), dtype=int64) Times out: tf.Tensor(111698, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_639&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_640 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1278 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1279 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_639 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1278 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_639 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1279 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.7103 - mse: 43.6539 - mae: 5.1048 - val_loss: 31.7144 - val_mse: 31.6469 - val_mae: 4.5107
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2570 - mse: 34.1805 - mae: 4.5687 - val_loss: 30.3391 - val_mse: 30.2541 - val_mae: 4.4222
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9818 - mse: 32.8899 - mae: 4.4757 - val_loss: 29.3256 - val_mse: 29.2275 - val_mae: 4.3408
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9947 - mse: 31.8913 - mae: 4.4065 - val_loss: 28.6913 - val_mse: 28.5828 - val_mae: 4.2913
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3252 - mse: 31.2124 - mae: 4.3577 - val_loss: 28.2304 - val_mse: 28.1133 - val_mae: 4.2663
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9463 - mse: 30.8256 - mae: 4.3225 - val_loss: 27.7024 - val_mse: 27.5781 - val_mae: 4.2262
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6006 - mse: 30.4727 - mae: 4.3023 - val_loss: 27.3462 - val_mse: 27.2150 - val_mae: 4.2036
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2561 - mse: 30.1217 - mae: 4.2730 - val_loss: 27.1381 - val_mse: 27.0005 - val_mae: 4.1877
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9945 - mse: 29.8539 - mae: 4.2496 - val_loss: 27.1197 - val_mse: 26.9761 - val_mae: 4.1873
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6677 - mse: 29.5214 - mae: 4.2296 - val_loss: 26.5023 - val_mse: 26.3534 - val_mae: 4.1449
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4624 - mse: 29.3108 - mae: 4.2119 - val_loss: 26.4748 - val_mse: 26.3208 - val_mae: 4.1417
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1893 - mse: 29.0330 - mae: 4.1937 - val_loss: 26.1837 - val_mse: 26.0254 - val_mae: 4.1216
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1086 - mse: 28.9482 - mae: 4.1891 - val_loss: 26.7487 - val_mse: 26.5865 - val_mae: 4.1666
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9629 - mse: 28.7989 - mae: 4.1777 - val_loss: 26.1485 - val_mse: 25.9829 - val_mae: 4.1122
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9080 - mse: 28.7406 - mae: 4.1737 - val_loss: 25.9221 - val_mse: 25.7530 - val_mae: 4.0985
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8022 - mse: 28.6317 - mae: 4.1640 - val_loss: 26.1249 - val_mse: 25.9530 - val_mae: 4.1079
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7725 - mse: 28.5992 - mae: 4.1601 - val_loss: 25.8492 - val_mse: 25.6746 - val_mae: 4.0852
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7293 - mse: 28.5537 - mae: 4.1572 - val_loss: 25.9292 - val_mse: 25.7525 - val_mae: 4.0957
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6046 - mse: 28.4268 - mae: 4.1488 - val_loss: 25.8307 - val_mse: 25.6519 - val_mae: 4.0880
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5748 - mse: 28.3944 - mae: 4.1486 - val_loss: 25.5798 - val_mse: 25.3983 - val_mae: 4.0669
bias -0.0011255784
si 0.4660248
rmse 0.050396755
kgeprime [0.78498569]
rmse_95 0.069950655
rmse_99 0.08656964
pearson 0.8642923434887982
pearson_95 0.7330651446083098
pearson_99 0.7695978523766464
rscore 0.7468430443417553
rscore_95 -0.9963623393259664
rscore_99 -9.464058614806946
nse [0.74684304]
nse_95 [-0.99636234]
nse_99 [-9.46405861]
kge [0.80210171]
ext_kge_95 [0.6028112]
ext_kge_99 [-0.39314532]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 2.66
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.64
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([44889 44913 44937], shape=(3,), dtype=int64) Times out: tf.Tensor(44937, shape=(), dtype=int64)
Times in: tf.Tensor([65333 65357 65381], shape=(3,), dtype=int64) Times out: tf.Tensor(65381, shape=(), dtype=int64)
Times in: tf.Tensor([101032 101056 101080], shape=(3,), dtype=int64) Times out: tf.Tensor(101080, shape=(), dtype=int64)
Times in: tf.Tensor([72639 72663 72687], shape=(3,), dtype=int64) Times out: tf.Tensor(72687, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_640&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_641 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1280 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1281 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_640 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1280 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_640 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1281 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.5333 - mse: 47.4811 - mae: 5.3140 - val_loss: 32.5576 - val_mse: 32.4950 - val_mae: 4.5600
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2667 - mse: 35.1965 - mae: 4.6338 - val_loss: 30.7528 - val_mse: 30.6761 - val_mae: 4.4419
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0411 - mse: 33.9580 - mae: 4.5477 - val_loss: 30.1947 - val_mse: 30.1060 - val_mae: 4.4019
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6123 - mse: 33.5183 - mae: 4.5152 - val_loss: 29.7926 - val_mse: 29.6939 - val_mae: 4.3659
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2236 - mse: 33.1205 - mae: 4.4864 - val_loss: 29.7885 - val_mse: 29.6811 - val_mae: 4.3764
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9210 - mse: 32.8092 - mae: 4.4660 - val_loss: 29.8733 - val_mse: 29.7573 - val_mae: 4.3890
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5621 - mse: 32.4418 - mae: 4.4387 - val_loss: 29.1761 - val_mse: 29.0522 - val_mae: 4.3298
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3579 - mse: 32.2295 - mae: 4.4250 - val_loss: 29.0020 - val_mse: 28.8698 - val_mae: 4.3225
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2666 - mse: 32.1303 - mae: 4.4176 - val_loss: 30.2586 - val_mse: 30.1190 - val_mae: 4.4302
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0654 - mse: 31.9221 - mae: 4.4008 - val_loss: 29.2340 - val_mse: 29.0876 - val_mae: 4.3442
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9464 - mse: 31.7967 - mae: 4.3948 - val_loss: 29.1298 - val_mse: 28.9770 - val_mae: 4.3426
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7575 - mse: 31.6015 - mae: 4.3805 - val_loss: 28.7980 - val_mse: 28.6391 - val_mae: 4.3173
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3802 - mse: 31.2181 - mae: 4.3586 - val_loss: 28.7042 - val_mse: 28.5392 - val_mae: 4.3038
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2738 - mse: 31.1057 - mae: 4.3481 - val_loss: 29.0057 - val_mse: 28.8350 - val_mae: 4.3363
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0018 - mse: 30.8287 - mae: 4.3293 - val_loss: 27.9927 - val_mse: 27.8174 - val_mae: 4.2573
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6578 - mse: 30.4802 - mae: 4.3062 - val_loss: 28.0636 - val_mse: 27.8842 - val_mae: 4.2668
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6209 - mse: 30.4398 - mae: 4.3013 - val_loss: 28.4061 - val_mse: 28.2235 - val_mae: 4.2931
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.3138 - mse: 30.1297 - mae: 4.2795 - val_loss: 27.3842 - val_mse: 27.1990 - val_mae: 4.2154
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.2700 - mse: 30.0832 - mae: 4.2745 - val_loss: 27.6486 - val_mse: 27.4604 - val_mae: 4.2333
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.1960 - mse: 30.0066 - mae: 4.2735 - val_loss: 27.5226 - val_mse: 27.3322 - val_mae: 4.2234
bias -0.008223281
si 0.47384718
rmse 0.052280236
kgeprime [0.63263381]
rmse_95 0.06896344
rmse_99 0.085376345
pearson 0.8592238797738143
pearson_95 0.7328130377180472
pearson_99 0.7912963559361789
rscore 0.731487174217984
rscore_95 -0.8771653770983654
rscore_99 -8.889752345244958
nse [0.73148717]
nse_95 [-0.87716538]
nse_99 [-8.88975235]
kge [0.72351278]
ext_kge_95 [0.62441719]
ext_kge_99 [-0.30648638]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 2.66
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.64
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([67599 67623 67647], shape=(3,), dtype=int64) Times out: tf.Tensor(67647, shape=(), dtype=int64)
Times in: tf.Tensor([61436 61460 61484], shape=(3,), dtype=int64) Times out: tf.Tensor(61484, shape=(), dtype=int64)
Times in: tf.Tensor([97727 97751 97775], shape=(3,), dtype=int64) Times out: tf.Tensor(97775, shape=(), dtype=int64)
Times in: tf.Tensor([51467 51491 51515], shape=(3,), dtype=int64) Times out: tf.Tensor(51515, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_641&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_642 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1282 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1283 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_641 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1282 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_641 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1283 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.0147 - mse: 51.9698 - mae: 5.5436 - val_loss: 33.6472 - val_mse: 33.5924 - val_mae: 4.6282
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1141 - mse: 37.0543 - mae: 4.7477 - val_loss: 31.8480 - val_mse: 31.7829 - val_mae: 4.5128
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9935 - mse: 35.9243 - mae: 4.6713 - val_loss: 32.5014 - val_mse: 32.4278 - val_mae: 4.5587
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6012 - mse: 35.5242 - mae: 4.6406 - val_loss: 31.2743 - val_mse: 31.1932 - val_mae: 4.4754
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2388 - mse: 35.1540 - mae: 4.6196 - val_loss: 30.6921 - val_mse: 30.6028 - val_mae: 4.4323
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0017 - mse: 34.9080 - mae: 4.5985 - val_loss: 30.7868 - val_mse: 30.6881 - val_mae: 4.4454
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6624 - mse: 34.5591 - mae: 4.5816 - val_loss: 30.3622 - val_mse: 30.2537 - val_mae: 4.4170
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3618 - mse: 34.2487 - mae: 4.5565 - val_loss: 30.3705 - val_mse: 30.2522 - val_mae: 4.4220
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2200 - mse: 34.0969 - mae: 4.5428 - val_loss: 30.1167 - val_mse: 29.9886 - val_mae: 4.4076
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0032 - mse: 33.8706 - mae: 4.5278 - val_loss: 30.1888 - val_mse: 30.0513 - val_mae: 4.4183
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7523 - mse: 33.6108 - mae: 4.5131 - val_loss: 29.5367 - val_mse: 29.3908 - val_mae: 4.3669
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4633 - mse: 33.3135 - mae: 4.4900 - val_loss: 30.9797 - val_mse: 30.8260 - val_mae: 4.4734
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3393 - mse: 33.1822 - mae: 4.4857 - val_loss: 30.1041 - val_mse: 29.9435 - val_mae: 4.4084
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1583 - mse: 32.9947 - mae: 4.4715 - val_loss: 30.1083 - val_mse: 29.9416 - val_mae: 4.4115
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2172 - mse: 33.0479 - mae: 4.4754 - val_loss: 29.3593 - val_mse: 29.1874 - val_mae: 4.3548
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0559 - mse: 32.8818 - mae: 4.4625 - val_loss: 29.6931 - val_mse: 29.5167 - val_mae: 4.3797
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9551 - mse: 32.7766 - mae: 4.4529 - val_loss: 30.3337 - val_mse: 30.1530 - val_mae: 4.4245
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7806 - mse: 32.5982 - mae: 4.4418 - val_loss: 29.5347 - val_mse: 29.3505 - val_mae: 4.3698
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6494 - mse: 32.4635 - mae: 4.4315 - val_loss: 29.7399 - val_mse: 29.5522 - val_mae: 4.3824
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3130 - mse: 32.1239 - mae: 4.4082 - val_loss: 29.3568 - val_mse: 29.1664 - val_mae: 4.3542
bias -0.012280611
si 0.47835433
rmse 0.054005947
kgeprime [0.5293681]
rmse_95 0.068087496
rmse_99 0.08045977
pearson 0.8560734799774116
pearson_95 0.7074113770379035
pearson_99 0.7311860115890176
rscore 0.7182911098438997
rscore_95 -0.7676050082654409
rscore_99 -7.304837724376398
nse [0.71829111]
nse_95 [-0.76760501]
nse_99 [-7.30483772]
kge [0.64246216]
ext_kge_95 [0.59528503]
ext_kge_99 [-0.36103466]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 2.66
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.64
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([102647 102671 102695], shape=(3,), dtype=int64) Times out: tf.Tensor(102695, shape=(), dtype=int64)
Times in: tf.Tensor([49476 49500 49524], shape=(3,), dtype=int64) Times out: tf.Tensor(49524, shape=(), dtype=int64)
Times in: tf.Tensor([115459 115483 115507], shape=(3,), dtype=int64) Times out: tf.Tensor(115507, shape=(), dtype=int64)
Times in: tf.Tensor([94906 94930 94954], shape=(3,), dtype=int64) Times out: tf.Tensor(94954, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_642&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_643 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1284 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1285 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_642 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1284 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_642 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1285 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.0837 - mse: 52.0179 - mae: 5.5648 - val_loss: 35.0057 - val_mse: 34.9238 - val_mae: 4.7197
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1932 - mse: 37.1035 - mae: 4.7587 - val_loss: 32.8840 - val_mse: 32.7864 - val_mae: 4.5878
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3590 - mse: 35.2532 - mae: 4.6371 - val_loss: 32.6682 - val_mse: 32.5542 - val_mae: 4.5713
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5437 - mse: 34.4229 - mae: 4.5815 - val_loss: 31.3537 - val_mse: 31.2266 - val_mae: 4.4710
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0483 - mse: 33.9158 - mae: 4.5428 - val_loss: 32.6283 - val_mse: 32.4905 - val_mae: 4.5637
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8342 - mse: 33.6919 - mae: 4.5245 - val_loss: 31.1841 - val_mse: 31.0375 - val_mae: 4.4679
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5162 - mse: 33.3650 - mae: 4.5052 - val_loss: 31.1168 - val_mse: 30.9614 - val_mae: 4.4609
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1848 - mse: 33.0247 - mae: 4.4823 - val_loss: 30.9904 - val_mse: 30.8261 - val_mae: 4.4478
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9365 - mse: 32.7677 - mae: 4.4615 - val_loss: 30.7976 - val_mse: 30.6242 - val_mae: 4.4405
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5885 - mse: 32.4110 - mae: 4.4385 - val_loss: 29.9863 - val_mse: 29.8047 - val_mae: 4.3922
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1469 - mse: 31.9616 - mae: 4.4085 - val_loss: 29.6510 - val_mse: 29.4622 - val_mae: 4.3704
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8495 - mse: 31.6578 - mae: 4.3879 - val_loss: 30.0176 - val_mse: 29.8229 - val_mae: 4.3983
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5512 - mse: 31.3542 - mae: 4.3600 - val_loss: 29.6427 - val_mse: 29.4433 - val_mae: 4.3769
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5031 - mse: 31.3015 - mae: 4.3604 - val_loss: 29.6787 - val_mse: 29.4749 - val_mae: 4.3745
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2405 - mse: 31.0347 - mae: 4.3429 - val_loss: 29.0768 - val_mse: 28.8692 - val_mae: 4.3350
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0070 - mse: 30.7979 - mae: 4.3250 - val_loss: 28.7824 - val_mse: 28.5716 - val_mae: 4.3008
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9491 - mse: 30.7373 - mae: 4.3159 - val_loss: 29.1943 - val_mse: 28.9806 - val_mae: 4.3367
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8511 - mse: 30.6361 - mae: 4.3111 - val_loss: 28.9172 - val_mse: 28.7004 - val_mae: 4.3169
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7138 - mse: 30.4957 - mae: 4.3025 - val_loss: 28.4669 - val_mse: 28.2475 - val_mae: 4.2776
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4925 - mse: 30.2717 - mae: 4.2827 - val_loss: 28.6273 - val_mse: 28.4047 - val_mae: 4.2855
bias -0.009386819
si 0.47271103
rmse 0.053296022
kgeprime [0.59564558]
rmse_95 0.07074457
rmse_99 0.08340379
pearson 0.8596874023943005
pearson_95 0.7346234632955144
pearson_99 0.723106479582324
rscore 0.730556271758512
rscore_95 -0.8551195659084265
rscore_99 -7.786433547187
nse [0.73055627]
nse_95 [-0.85511957]
nse_99 [-7.78643355]
kge [0.69574739]
ext_kge_95 [0.62508194]
ext_kge_99 [-0.22835561]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 2.66
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.64
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([5444 5468 5492], shape=(3,), dtype=int64) Times out: tf.Tensor(5492, shape=(), dtype=int64)
Times in: tf.Tensor([33144 33168 33192], shape=(3,), dtype=int64) Times out: tf.Tensor(33192, shape=(), dtype=int64)
Times in: tf.Tensor([95149 95173 95197], shape=(3,), dtype=int64) Times out: tf.Tensor(95197, shape=(), dtype=int64)
Times in: tf.Tensor([30163 30187 30211], shape=(3,), dtype=int64) Times out: tf.Tensor(30211, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_643&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_644 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1286 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1287 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_643 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1286 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_643 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1287 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.7998 - mse: 47.7460 - mae: 5.3252 - val_loss: 35.1783 - val_mse: 35.1128 - val_mae: 4.7401
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9414 - mse: 35.8678 - mae: 4.6804 - val_loss: 34.2190 - val_mse: 34.1383 - val_mae: 4.6777
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0450 - mse: 34.9575 - mae: 4.6122 - val_loss: 32.2513 - val_mse: 32.1574 - val_mae: 4.5387
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5780 - mse: 34.4786 - mae: 4.5787 - val_loss: 34.4481 - val_mse: 34.3435 - val_mae: 4.6874
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1833 - mse: 34.0741 - mae: 4.5528 - val_loss: 33.6506 - val_mse: 33.5371 - val_mae: 4.6364
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6740 - mse: 33.5562 - mae: 4.5206 - val_loss: 32.0066 - val_mse: 31.8850 - val_mae: 4.5277
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4169 - mse: 33.2915 - mae: 4.5001 - val_loss: 31.7964 - val_mse: 31.6677 - val_mae: 4.5158
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2831 - mse: 33.1507 - mae: 4.4934 - val_loss: 32.5386 - val_mse: 32.4031 - val_mae: 4.5743
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0286 - mse: 32.8899 - mae: 4.4753 - val_loss: 32.8457 - val_mse: 32.7042 - val_mae: 4.5920
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8536 - mse: 32.7089 - mae: 4.4651 - val_loss: 33.2604 - val_mse: 33.1128 - val_mae: 4.6210
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5899 - mse: 32.4394 - mae: 4.4482 - val_loss: 32.9969 - val_mse: 32.8438 - val_mae: 4.6019
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5642 - mse: 32.4084 - mae: 4.4395 - val_loss: 32.7245 - val_mse: 32.5663 - val_mae: 4.5832
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2634 - mse: 32.1023 - mae: 4.4195 - val_loss: 31.4293 - val_mse: 31.2657 - val_mae: 4.4920
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9177 - mse: 31.7516 - mae: 4.3910 - val_loss: 30.8426 - val_mse: 30.6746 - val_mae: 4.4548
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6637 - mse: 31.4933 - mae: 4.3753 - val_loss: 31.2749 - val_mse: 31.1025 - val_mae: 4.4825
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4845 - mse: 31.3102 - mae: 4.3641 - val_loss: 30.9885 - val_mse: 30.8126 - val_mae: 4.4652
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2185 - mse: 31.0411 - mae: 4.3413 - val_loss: 31.1920 - val_mse: 31.0132 - val_mae: 4.4826
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0486 - mse: 30.8681 - mae: 4.3308 - val_loss: 30.3635 - val_mse: 30.1818 - val_mae: 4.4233
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9875 - mse: 30.8044 - mae: 4.3240 - val_loss: 29.9560 - val_mse: 29.7716 - val_mae: 4.3864
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7102 - mse: 30.5242 - mae: 4.3047 - val_loss: 28.7471 - val_mse: 28.5602 - val_mae: 4.3001
bias -0.0071230233
si 0.47329062
rmse 0.05344174
kgeprime [0.66064807]
rmse_95 0.07255595
rmse_99 0.086133555
pearson 0.8591702675189347
pearson_95 0.7371277464342415
pearson_99 0.7556258441184828
rscore 0.7334084483848733
rscore_95 -0.9172412360916025
rscore_99 -8.558175361432246
nse [0.73340845]
nse_95 [-0.91724124]
nse_99 [-8.55817536]
kge [0.74269899]
ext_kge_95 [0.6156594]
ext_kge_99 [-0.36337056]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.448
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 3.053
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.89
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 9.321
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.605
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([15396 15420 15444], shape=(3,), dtype=int64) Times out: tf.Tensor(15444, shape=(), dtype=int64)
Times in: tf.Tensor([4184 4208 4232], shape=(3,), dtype=int64) Times out: tf.Tensor(4232, shape=(), dtype=int64)
Times in: tf.Tensor([46197 46221 46245], shape=(3,), dtype=int64) Times out: tf.Tensor(46245, shape=(), dtype=int64)
Times in: tf.Tensor([122411 122435 122459], shape=(3,), dtype=int64) Times out: tf.Tensor(122459, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_644&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_645 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1288 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1289 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_644 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1288 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_644 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1289 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 57.4380 - mse: 57.3877 - mae: 5.8368 - val_loss: 36.3487 - val_mse: 36.2853 - val_mae: 4.7994
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2354 - mse: 40.1654 - mae: 4.9414 - val_loss: 34.2352 - val_mse: 34.1600 - val_mae: 4.6659
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8889 - mse: 38.8092 - mae: 4.8467 - val_loss: 33.8175 - val_mse: 33.7345 - val_mae: 4.6328
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3720 - mse: 38.2866 - mae: 4.8135 - val_loss: 33.7057 - val_mse: 33.6186 - val_mae: 4.6165
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0745 - mse: 37.9857 - mae: 4.7946 - val_loss: 33.4713 - val_mse: 33.3815 - val_mae: 4.6020
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8105 - mse: 37.7194 - mae: 4.7757 - val_loss: 32.7796 - val_mse: 32.6878 - val_mae: 4.5566
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4188 - mse: 37.3253 - mae: 4.7479 - val_loss: 32.9472 - val_mse: 32.8528 - val_mae: 4.5733
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4692 - mse: 37.3735 - mae: 4.7504 - val_loss: 32.8492 - val_mse: 32.7527 - val_mae: 4.5625
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2130 - mse: 37.1150 - mae: 4.7362 - val_loss: 32.9149 - val_mse: 32.8159 - val_mae: 4.5696
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1876 - mse: 37.0874 - mae: 4.7337 - val_loss: 32.5009 - val_mse: 32.3997 - val_mae: 4.5409
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0312 - mse: 36.9286 - mae: 4.7225 - val_loss: 32.6267 - val_mse: 32.5231 - val_mae: 4.5562
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9211 - mse: 36.8162 - mae: 4.7195 - val_loss: 32.3853 - val_mse: 32.2793 - val_mae: 4.5380
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7301 - mse: 36.6229 - mae: 4.7036 - val_loss: 32.0201 - val_mse: 31.9119 - val_mae: 4.5198
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5767 - mse: 36.4671 - mae: 4.6959 - val_loss: 31.8964 - val_mse: 31.7859 - val_mae: 4.5080
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3782 - mse: 36.2664 - mae: 4.6740 - val_loss: 32.3983 - val_mse: 32.2855 - val_mae: 4.5525
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2229 - mse: 36.1088 - mae: 4.6710 - val_loss: 32.2814 - val_mse: 32.1664 - val_mae: 4.5417
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1585 - mse: 36.0425 - mae: 4.6677 - val_loss: 32.4394 - val_mse: 32.3224 - val_mae: 4.5583
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2699 - mse: 36.1517 - mae: 4.6726 - val_loss: 32.0774 - val_mse: 31.9582 - val_mae: 4.5333
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1767 - mse: 36.0564 - mae: 4.6615 - val_loss: 31.6131 - val_mse: 31.4920 - val_mae: 4.4940
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8722 - mse: 35.7500 - mae: 4.6458 - val_loss: 31.5912 - val_mse: 31.4679 - val_mae: 4.4983
bias -0.005791008
si 0.4939262
rmse 0.056096278
kgeprime [0.66733668]
rmse_95 0.08235298
rmse_99 0.093331225
pearson 0.8453976455333281
pearson_95 0.7175718064640871
pearson_99 0.7332548785657736
rscore 0.7115577362179317
rscore_95 -1.4186603558313622
rscore_99 -10.23115441570917
nse [0.71155774]
nse_95 [-1.41866036]
nse_99 [-10.23115442]
kge [0.7383068]
ext_kge_95 [0.58490062]
ext_kge_99 [-0.30814637]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.448
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 3.053
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.89
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 9.321
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.605
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([99915 99939 99963], shape=(3,), dtype=int64) Times out: tf.Tensor(99963, shape=(), dtype=int64)
Times in: tf.Tensor([22200 22224 22248], shape=(3,), dtype=int64) Times out: tf.Tensor(22248, shape=(), dtype=int64)
Times in: tf.Tensor([51868 51892 51916], shape=(3,), dtype=int64) Times out: tf.Tensor(51916, shape=(), dtype=int64)
Times in: tf.Tensor([89470 89494 89518], shape=(3,), dtype=int64) Times out: tf.Tensor(89518, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_645&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_646 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1290 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1291 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_645 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1290 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_645 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1291 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.8594 - mse: 48.8062 - mae: 5.4082 - val_loss: 36.0012 - val_mse: 35.9403 - val_mae: 4.7978
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4598 - mse: 38.3952 - mae: 4.8391 - val_loss: 34.5412 - val_mse: 34.4727 - val_mae: 4.6891
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4821 - mse: 37.4101 - mae: 4.7722 - val_loss: 33.9697 - val_mse: 33.8945 - val_mae: 4.6521
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8361 - mse: 36.7580 - mae: 4.7262 - val_loss: 33.0684 - val_mse: 32.9879 - val_mae: 4.5891
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6049 - mse: 36.5219 - mae: 4.7084 - val_loss: 33.0950 - val_mse: 33.0101 - val_mae: 4.5883
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3374 - mse: 36.2502 - mae: 4.6976 - val_loss: 33.4642 - val_mse: 33.3748 - val_mae: 4.6138
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0015 - mse: 35.9097 - mae: 4.6710 - val_loss: 32.8982 - val_mse: 32.8039 - val_mae: 4.5785
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6877 - mse: 35.5908 - mae: 4.6452 - val_loss: 32.4551 - val_mse: 32.3557 - val_mae: 4.5468
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3410 - mse: 35.2383 - mae: 4.6202 - val_loss: 32.4123 - val_mse: 32.3064 - val_mae: 4.5489
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6259 - mse: 34.5167 - mae: 4.5769 - val_loss: 31.7911 - val_mse: 31.6787 - val_mae: 4.5165
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0509 - mse: 33.9357 - mae: 4.5343 - val_loss: 30.6206 - val_mse: 30.5024 - val_mae: 4.4400
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4915 - mse: 33.3708 - mae: 4.4938 - val_loss: 30.1214 - val_mse: 29.9982 - val_mae: 4.4072
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3569 - mse: 33.2313 - mae: 4.4816 - val_loss: 30.0814 - val_mse: 29.9537 - val_mae: 4.4085
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1311 - mse: 33.0013 - mae: 4.4675 - val_loss: 29.9990 - val_mse: 29.8673 - val_mae: 4.4028
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9583 - mse: 32.8245 - mae: 4.4562 - val_loss: 29.6076 - val_mse: 29.4720 - val_mae: 4.3711
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8266 - mse: 32.6892 - mae: 4.4474 - val_loss: 29.5547 - val_mse: 29.4157 - val_mae: 4.3686
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7239 - mse: 32.5832 - mae: 4.4395 - val_loss: 29.2186 - val_mse: 29.0762 - val_mae: 4.3546
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5131 - mse: 32.3693 - mae: 4.4260 - val_loss: 29.7381 - val_mse: 29.5927 - val_mae: 4.3926
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4985 - mse: 32.3518 - mae: 4.4227 - val_loss: 29.4068 - val_mse: 29.2587 - val_mae: 4.3655
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3977 - mse: 32.2484 - mae: 4.4147 - val_loss: 28.7521 - val_mse: 28.6017 - val_mae: 4.3201
bias -0.0012545418
si 0.46855912
rmse 0.053480547
kgeprime [0.7789304]
rmse_95 0.07840914
rmse_99 0.09213761
pearson 0.8620252251658163
pearson_95 0.7341337961167603
pearson_99 0.7588819107708696
rscore 0.7428748711201139
rscore_95 -1.1425423088622422
rscore_99 -9.73475280709927
nse [0.74287487]
nse_95 [-1.14254231]
nse_99 [-9.73475281]
kge [0.79677045]
ext_kge_95 [0.62568117]
ext_kge_99 [-0.19425889]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.222
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -1.814
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 1.493
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 3.29
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 2.187
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([77899 77923 77947], shape=(3,), dtype=int64) Times out: tf.Tensor(77947, shape=(), dtype=int64)
Times in: tf.Tensor([94677 94701 94725], shape=(3,), dtype=int64) Times out: tf.Tensor(94725, shape=(), dtype=int64)
Times in: tf.Tensor([78170 78194 78218], shape=(3,), dtype=int64) Times out: tf.Tensor(78218, shape=(), dtype=int64)
Times in: tf.Tensor([36473 36497 36521], shape=(3,), dtype=int64) Times out: tf.Tensor(36521, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_646&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_647 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1292 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1293 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_646 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1292 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_646 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1293 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.6272 - mse: 52.5835 - mae: 5.5908 - val_loss: 38.8821 - val_mse: 38.8302 - val_mae: 4.9600
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7927 - mse: 40.7356 - mae: 4.9728 - val_loss: 36.0915 - val_mse: 36.0297 - val_mae: 4.7809
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4612 - mse: 39.3954 - mae: 4.8911 - val_loss: 36.2890 - val_mse: 36.2205 - val_mae: 4.7840
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0225 - mse: 38.9521 - mae: 4.8621 - val_loss: 35.6439 - val_mse: 35.5719 - val_mae: 4.7422
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7373 - mse: 38.6637 - mae: 4.8418 - val_loss: 36.4183 - val_mse: 36.3436 - val_mae: 4.7882
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5704 - mse: 38.4945 - mae: 4.8339 - val_loss: 34.8399 - val_mse: 34.7631 - val_mae: 4.6899
Epoch 7/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.3512 - mse: 38.2730 - mae: 4.8157 - val_loss: 35.0094 - val_mse: 34.9302 - val_mae: 4.6983
Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.1069 - mse: 38.0264 - mae: 4.8061 - val_loss: 35.7101 - val_mse: 35.6286 - val_mae: 4.7414
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9891 - mse: 37.9061 - mae: 4.8011 - val_loss: 35.8454 - val_mse: 35.7612 - val_mae: 4.7517
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7583 - mse: 37.6730 - mae: 4.7837 - val_loss: 34.5595 - val_mse: 34.4732 - val_mae: 4.6710
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.6585 - mse: 37.5708 - mae: 4.7766 - val_loss: 35.1846 - val_mse: 35.0959 - val_mae: 4.7055
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4747 - mse: 37.3849 - mae: 4.7659 - val_loss: 34.8715 - val_mse: 34.7807 - val_mae: 4.6876
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.3569 - mse: 37.2650 - mae: 4.7533 - val_loss: 35.2173 - val_mse: 35.1245 - val_mae: 4.7080
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.2881 - mse: 37.1941 - mae: 4.7559 - val_loss: 35.7695 - val_mse: 35.6746 - val_mae: 4.7467
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.1665 - mse: 37.0705 - mae: 4.7431 - val_loss: 35.0556 - val_mse: 34.9588 - val_mae: 4.7030
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.0829 - mse: 36.9850 - mae: 4.7404 - val_loss: 36.4400 - val_mse: 36.3413 - val_mae: 4.7932
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.8674 - mse: 36.7676 - mae: 4.7282 - val_loss: 35.7256 - val_mse: 35.6250 - val_mae: 4.7425
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.8184 - mse: 36.7166 - mae: 4.7190 - val_loss: 35.4852 - val_mse: 35.3825 - val_mae: 4.7305
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.6616 - mse: 36.5578 - mae: 4.7123 - val_loss: 35.9784 - val_mse: 35.8736 - val_mae: 4.7599
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.5941 - mse: 36.4881 - mae: 4.7058 - val_loss: 35.0937 - val_mse: 34.9866 - val_mae: 4.7078
bias -0.01325348
si 0.522506
rmse 0.059149463
kgeprime [0.47725676]
rmse_95 0.07910434
rmse_99 0.092077084
pearson 0.82833705826727
pearson_95 0.6529127202661823
pearson_99 0.6094517467017745
rscore 0.6692523268310177
rscore_95 -1.9158779093524685
rscore_99 -14.727810161350689
nse [0.66925233]
nse_95 [-1.91587791]
nse_99 [-14.72781016]
kge [0.59545414]
ext_kge_95 [0.50336515]
ext_kge_99 [-0.53688159]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 1.797
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.01
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([23916 23940 23964], shape=(3,), dtype=int64) Times out: tf.Tensor(23964, shape=(), dtype=int64)
Times in: tf.Tensor([112912 112936 112960], shape=(3,), dtype=int64) Times out: tf.Tensor(112960, shape=(), dtype=int64)
Times in: tf.Tensor([43989 44013 44037], shape=(3,), dtype=int64) Times out: tf.Tensor(44037, shape=(), dtype=int64)
Times in: tf.Tensor([75175 75199 75223], shape=(3,), dtype=int64) Times out: tf.Tensor(75223, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_647&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_648 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1294 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1295 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_647 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1294 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_647 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1295 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.2434 - mse: 43.1972 - mae: 5.0729 - val_loss: 31.0559 - val_mse: 31.0010 - val_mae: 4.4669
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1746 - mse: 34.1131 - mae: 4.5617 - val_loss: 30.6684 - val_mse: 30.6001 - val_mae: 4.4394
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9447 - mse: 32.8713 - mae: 4.4751 - val_loss: 29.0805 - val_mse: 29.0026 - val_mae: 4.3232
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4423 - mse: 32.3612 - mae: 4.4325 - val_loss: 28.5376 - val_mse: 28.4535 - val_mae: 4.2817
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2760 - mse: 32.1895 - mae: 4.4184 - val_loss: 28.6078 - val_mse: 28.5187 - val_mae: 4.2911
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9799 - mse: 31.8884 - mae: 4.4016 - val_loss: 28.4903 - val_mse: 28.3965 - val_mae: 4.2843
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8476 - mse: 31.7516 - mae: 4.3941 - val_loss: 29.4807 - val_mse: 29.3824 - val_mae: 4.3609
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6403 - mse: 31.5398 - mae: 4.3758 - val_loss: 28.0051 - val_mse: 27.9023 - val_mae: 4.2513
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4245 - mse: 31.3194 - mae: 4.3585 - val_loss: 28.3042 - val_mse: 28.1968 - val_mae: 4.2738
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1681 - mse: 31.0583 - mae: 4.3426 - val_loss: 27.9463 - val_mse: 27.8340 - val_mae: 4.2508
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0799 - mse: 30.9654 - mae: 4.3342 - val_loss: 27.9120 - val_mse: 27.7952 - val_mae: 4.2421
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9478 - mse: 30.8286 - mae: 4.3201 - val_loss: 27.5810 - val_mse: 27.4597 - val_mae: 4.2180
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8291 - mse: 30.7056 - mae: 4.3153 - val_loss: 27.5735 - val_mse: 27.4476 - val_mae: 4.2167
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7431 - mse: 30.6153 - mae: 4.3095 - val_loss: 28.3039 - val_mse: 28.1740 - val_mae: 4.2779
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5529 - mse: 30.4208 - mae: 4.2996 - val_loss: 27.7618 - val_mse: 27.6274 - val_mae: 4.2384
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4783 - mse: 30.3419 - mae: 4.2867 - val_loss: 27.8990 - val_mse: 27.7604 - val_mae: 4.2412
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3288 - mse: 30.1882 - mae: 4.2774 - val_loss: 28.0239 - val_mse: 27.8812 - val_mae: 4.2508
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0696 - mse: 29.9249 - mae: 4.2591 - val_loss: 27.2872 - val_mse: 27.1401 - val_mae: 4.1961
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8275 - mse: 29.6786 - mae: 4.2412 - val_loss: 27.1415 - val_mse: 26.9906 - val_mae: 4.1895
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5935 - mse: 29.4412 - mae: 4.2256 - val_loss: 27.8624 - val_mse: 27.7084 - val_mae: 4.2460
bias -0.012250277
si 0.48019263
rmse 0.052638803
kgeprime [0.534921]
rmse_95 0.06263734
rmse_99 0.07466535
pearson 0.856132164552093
pearson_95 0.6950970534360463
pearson_99 0.7944888480195366
rscore 0.7164252770426227
rscore_95 -0.7314793256581709
rscore_99 -7.446083892460223
nse [0.71642528]
nse_95 [-0.73147933]
nse_99 [-7.44608389]
kge [0.64390322]
ext_kge_95 [0.58404681]
ext_kge_99 [-0.33319512]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.6 170.9 171.2
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.412
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 2.66
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.64
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 7.075
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.326
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([125045 125069 125093], shape=(3,), dtype=int64) Times out: tf.Tensor(125093, shape=(), dtype=int64)
Times in: tf.Tensor([139108 139132 139156], shape=(3,), dtype=int64) Times out: tf.Tensor(139156, shape=(), dtype=int64)
Times in: tf.Tensor([126363 126387 126411], shape=(3,), dtype=int64) Times out: tf.Tensor(126411, shape=(), dtype=int64)
Times in: tf.Tensor([45460 45484 45508], shape=(3,), dtype=int64) Times out: tf.Tensor(45508, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_648&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_649 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1296 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1297 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_648 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1296 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_648 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1297 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 51.5899 - mse: 51.5369 - mae: 5.5395 - val_loss: 34.6924 - val_mse: 34.6293 - val_mae: 4.7051
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1311 - mse: 38.0631 - mae: 4.8195 - val_loss: 33.1006 - val_mse: 33.0280 - val_mae: 4.5906
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7490 - mse: 36.6714 - mae: 4.7221 - val_loss: 32.3130 - val_mse: 32.2311 - val_mae: 4.5331
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0896 - mse: 36.0043 - mae: 4.6802 - val_loss: 32.1381 - val_mse: 32.0501 - val_mae: 4.5243
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7410 - mse: 35.6502 - mae: 4.6527 - val_loss: 31.6283 - val_mse: 31.5354 - val_mae: 4.4858
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6062 - mse: 35.5103 - mae: 4.6420 - val_loss: 31.6865 - val_mse: 31.5883 - val_mae: 4.4942
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2537 - mse: 35.1528 - mae: 4.6191 - val_loss: 31.3406 - val_mse: 31.2378 - val_mae: 4.4715
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9777 - mse: 34.8724 - mae: 4.5985 - val_loss: 31.8378 - val_mse: 31.7303 - val_mae: 4.5117
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8952 - mse: 34.7849 - mae: 4.5937 - val_loss: 31.3217 - val_mse: 31.2093 - val_mae: 4.4752
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6036 - mse: 34.4888 - mae: 4.5747 - val_loss: 31.0299 - val_mse: 30.9133 - val_mae: 4.4539
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5877 - mse: 34.4684 - mae: 4.5703 - val_loss: 31.0732 - val_mse: 30.9519 - val_mae: 4.4589
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3968 - mse: 34.2731 - mae: 4.5565 - val_loss: 30.8669 - val_mse: 30.7414 - val_mae: 4.4417
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2945 - mse: 34.1668 - mae: 4.5501 - val_loss: 30.7850 - val_mse: 30.6555 - val_mae: 4.4416
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0165 - mse: 33.8849 - mae: 4.5306 - val_loss: 30.3318 - val_mse: 30.1987 - val_mae: 4.4075
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7826 - mse: 33.6472 - mae: 4.5134 - val_loss: 30.4604 - val_mse: 30.3231 - val_mae: 4.4234
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5337 - mse: 33.3943 - mae: 4.4976 - val_loss: 29.7689 - val_mse: 29.6278 - val_mae: 4.3703
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0347 - mse: 32.8918 - mae: 4.4594 - val_loss: 29.4251 - val_mse: 29.2807 - val_mae: 4.3529
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8260 - mse: 32.6801 - mae: 4.4495 - val_loss: 29.2986 - val_mse: 29.1516 - val_mae: 4.3404
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7842 - mse: 32.6356 - mae: 4.4401 - val_loss: 28.8952 - val_mse: 28.7455 - val_mae: 4.3122
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4857 - mse: 32.3345 - mae: 4.4222 - val_loss: 28.6117 - val_mse: 28.4594 - val_mae: 4.2895
bias -0.00574328
si 0.47450572
rmse 0.053347398
kgeprime [0.66467459]
rmse_95 0.07829211
rmse_99 0.09167558
pearson 0.8589447460227724
pearson_95 0.7258608177419926
pearson_99 0.7358502404797523
rscore 0.7335805688905761
rscore_95 -1.3124405219109598
rscore_99 -10.39507968911111
nse [0.73358057]
nse_95 [-1.31244052]
nse_99 [-10.39507969]
kge [0.73817203]
ext_kge_95 [0.60559335]
ext_kge_99 [-0.30463223]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.7 165.0 165.3 ... 170.9 171.2 171.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.749 -9.61 ... -3.448
    vgrd10m         (time, latitude, longitude) float32 11.37 11.42 ... 3.053
    uw2             (time, latitude, longitude) float32 95.03 92.35 ... 11.89
    vw2             (time, latitude, longitude) float32 129.2 130.4 ... 9.321
    wind_magnitude  (time, latitude, longitude) float32 14.98 14.92 ... 4.605
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([115015 115039 115063], shape=(3,), dtype=int64) Times out: tf.Tensor(115063, shape=(), dtype=int64)
Times in: tf.Tensor([24117 24141 24165], shape=(3,), dtype=int64) Times out: tf.Tensor(24165, shape=(), dtype=int64)
Times in: tf.Tensor([145294 145318 145342], shape=(3,), dtype=int64) Times out: tf.Tensor(145342, shape=(), dtype=int64)
Times in: tf.Tensor([150131 150155 150179], shape=(3,), dtype=int64) Times out: tf.Tensor(150179, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_649&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_650 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1298 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1299 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_649 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1298 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_649 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1299 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.1034 - mse: 54.0537 - mae: 5.6802 - val_loss: 38.0148 - val_mse: 37.9544 - val_mae: 4.9176
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.6314 - mse: 40.5667 - mae: 4.9654 - val_loss: 36.2174 - val_mse: 36.1480 - val_mae: 4.8100
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1399 - mse: 38.0657 - mae: 4.8090 - val_loss: 34.7149 - val_mse: 34.6364 - val_mae: 4.7066
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0231 - mse: 36.9411 - mae: 4.7335 - val_loss: 34.7099 - val_mse: 34.6243 - val_mae: 4.7086
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3305 - mse: 36.2416 - mae: 4.6930 - val_loss: 33.6075 - val_mse: 33.5150 - val_mae: 4.6335
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9624 - mse: 35.8667 - mae: 4.6685 - val_loss: 33.0166 - val_mse: 32.9177 - val_mae: 4.5957
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6596 - mse: 35.5576 - mae: 4.6434 - val_loss: 33.1986 - val_mse: 33.0934 - val_mae: 4.6057
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3353 - mse: 35.2274 - mae: 4.6261 - val_loss: 34.0881 - val_mse: 33.9772 - val_mae: 4.6697
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9912 - mse: 34.8778 - mae: 4.6031 - val_loss: 33.4054 - val_mse: 33.2890 - val_mae: 4.6248
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8856 - mse: 34.7671 - mae: 4.5874 - val_loss: 32.1292 - val_mse: 32.0083 - val_mae: 4.5325
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6590 - mse: 34.5361 - mae: 4.5777 - val_loss: 31.9092 - val_mse: 31.7840 - val_mae: 4.5196
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4630 - mse: 34.3360 - mae: 4.5603 - val_loss: 32.9820 - val_mse: 32.8531 - val_mae: 4.5971
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3625 - mse: 34.2317 - mae: 4.5552 - val_loss: 32.7040 - val_mse: 32.5711 - val_mae: 4.5754
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1473 - mse: 34.0127 - mae: 4.5413 - val_loss: 31.8122 - val_mse: 31.6757 - val_mae: 4.5121
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8428 - mse: 33.7044 - mae: 4.5186 - val_loss: 32.2673 - val_mse: 32.1268 - val_mae: 4.5412
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4481 - mse: 33.3059 - mae: 4.4926 - val_loss: 31.3153 - val_mse: 31.1712 - val_mae: 4.4828
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2196 - mse: 33.0739 - mae: 4.4709 - val_loss: 30.9670 - val_mse: 30.8194 - val_mae: 4.4598
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9241 - mse: 32.7753 - mae: 4.4528 - val_loss: 30.6805 - val_mse: 30.5302 - val_mae: 4.4359
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6249 - mse: 32.4735 - mae: 4.4273 - val_loss: 30.8322 - val_mse: 30.6794 - val_mae: 4.4505
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4925 - mse: 32.3383 - mae: 4.4168 - val_loss: 29.4281 - val_mse: 29.2727 - val_mae: 4.3532
bias -0.008286731
si 0.47298503
rmse 0.054104276
kgeprime [0.6205806]
rmse_95 0.07393548
rmse_99 0.08559362
pearson 0.8594175053785695
pearson_95 0.725704692358518
pearson_99 0.7253232512649437
rscore 0.7319378897552198
rscore_95 -0.9918018575294694
rscore_99 -8.891572169478977
nse [0.73193789]
nse_95 [-0.99180186]
nse_99 [-8.89157217]
kge [0.71314266]
ext_kge_95 [0.61023934]
ext_kge_99 [-0.41148343]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.222
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -1.814
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 1.493
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 3.29
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 2.187
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([133603 133627 133651], shape=(3,), dtype=int64) Times out: tf.Tensor(133651, shape=(), dtype=int64)
Times in: tf.Tensor([7354 7378 7402], shape=(3,), dtype=int64) Times out: tf.Tensor(7402, shape=(), dtype=int64)
Times in: tf.Tensor([139526 139550 139574], shape=(3,), dtype=int64) Times out: tf.Tensor(139574, shape=(), dtype=int64)
Times in: tf.Tensor([133730 133754 133778], shape=(3,), dtype=int64) Times out: tf.Tensor(133778, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_650&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_651 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1300 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1301 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_650 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1300 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_650 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1301 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.1046 - mse: 54.0536 - mae: 5.6838 - val_loss: 39.5988 - val_mse: 39.5368 - val_mae: 5.0068
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6165 - mse: 41.5483 - mae: 5.0246 - val_loss: 38.1054 - val_mse: 38.0306 - val_mae: 4.9064
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3857 - mse: 39.3053 - mae: 4.8886 - val_loss: 35.8481 - val_mse: 35.7630 - val_mae: 4.7539
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6315 - mse: 38.5426 - mae: 4.8384 - val_loss: 35.2791 - val_mse: 35.1865 - val_mae: 4.7242
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.1795 - mse: 38.0839 - mae: 4.8094 - val_loss: 35.2618 - val_mse: 35.1631 - val_mae: 4.7243
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8398 - mse: 37.7379 - mae: 4.7909 - val_loss: 36.0321 - val_mse: 35.9272 - val_mae: 4.7730
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5818 - mse: 37.4740 - mae: 4.7732 - val_loss: 35.0470 - val_mse: 34.9363 - val_mae: 4.7102
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3740 - mse: 37.2603 - mae: 4.7607 - val_loss: 36.1730 - val_mse: 36.0560 - val_mae: 4.7787
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0115 - mse: 36.8916 - mae: 4.7368 - val_loss: 35.3464 - val_mse: 35.2237 - val_mae: 4.7229
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8520 - mse: 36.7264 - mae: 4.7248 - val_loss: 34.4820 - val_mse: 34.3535 - val_mae: 4.6706
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6178 - mse: 36.4865 - mae: 4.7139 - val_loss: 34.8137 - val_mse: 34.6793 - val_mae: 4.6867
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2368 - mse: 36.0993 - mae: 4.6868 - val_loss: 34.4677 - val_mse: 34.3268 - val_mae: 4.6632
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8842 - mse: 35.7406 - mae: 4.6623 - val_loss: 34.5309 - val_mse: 34.3843 - val_mae: 4.6670
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5235 - mse: 35.3747 - mae: 4.6446 - val_loss: 33.8533 - val_mse: 33.7020 - val_mae: 4.6265
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3734 - mse: 35.2199 - mae: 4.6298 - val_loss: 33.8356 - val_mse: 33.6799 - val_mae: 4.6261
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0397 - mse: 34.8821 - mae: 4.6066 - val_loss: 33.7719 - val_mse: 33.6123 - val_mae: 4.6247
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9650 - mse: 34.8036 - mae: 4.6017 - val_loss: 33.8260 - val_mse: 33.6628 - val_mae: 4.6260
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7128 - mse: 34.5481 - mae: 4.5848 - val_loss: 33.4548 - val_mse: 33.2883 - val_mae: 4.6076
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6604 - mse: 34.4925 - mae: 4.5773 - val_loss: 32.9620 - val_mse: 32.7923 - val_mae: 4.5685
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5491 - mse: 34.3779 - mae: 4.5746 - val_loss: 33.1925 - val_mse: 33.0197 - val_mae: 4.5836
bias -0.011378058
si 0.5062992
rmse 0.057462744
kgeprime [0.52629656]
rmse_95 0.07581908
rmse_99 0.084987484
pearson 0.8393605265362724
pearson_95 0.6762559255723122
pearson_99 0.6289830436814514
rscore 0.6924667128970279
rscore_95 -1.7031288572988745
rscore_99 -13.077439677047684
nse [0.69246671]
nse_95 [-1.70312886]
nse_99 [-13.07743968]
kge [0.63801753]
ext_kge_95 [0.51957588]
ext_kge_99 [-0.54258142]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.222
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -1.814
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 1.493
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 3.29
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 2.187
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([7659 7683 7707], shape=(3,), dtype=int64) Times out: tf.Tensor(7707, shape=(), dtype=int64)
Times in: tf.Tensor([64922 64946 64970], shape=(3,), dtype=int64) Times out: tf.Tensor(64970, shape=(), dtype=int64)
Times in: tf.Tensor([93773 93797 93821], shape=(3,), dtype=int64) Times out: tf.Tensor(93821, shape=(), dtype=int64)
Times in: tf.Tensor([101652 101676 101700], shape=(3,), dtype=int64) Times out: tf.Tensor(101700, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_651&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_652 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1302 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1303 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_651 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1302 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_651 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1303 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.4350 - mse: 52.3936 - mae: 5.5858 - val_loss: 38.5759 - val_mse: 38.5271 - val_mae: 4.9474
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.5708 - mse: 40.5177 - mae: 4.9636 - val_loss: 37.0844 - val_mse: 37.0276 - val_mae: 4.8405
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.3870 - mse: 39.3266 - mae: 4.8906 - val_loss: 36.7203 - val_mse: 36.6563 - val_mae: 4.8234
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8735 - mse: 38.8061 - mae: 4.8590 - val_loss: 36.5025 - val_mse: 36.4315 - val_mae: 4.8008
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3042 - mse: 38.2300 - mae: 4.8187 - val_loss: 34.9844 - val_mse: 34.9072 - val_mae: 4.7042
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8714 - mse: 37.7912 - mae: 4.7949 - val_loss: 36.1663 - val_mse: 36.0827 - val_mae: 4.7779
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6511 - mse: 37.5642 - mae: 4.7797 - val_loss: 35.3820 - val_mse: 35.2918 - val_mae: 4.7326
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1729 - mse: 37.0796 - mae: 4.7489 - val_loss: 34.9684 - val_mse: 34.8718 - val_mae: 4.6997
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8905 - mse: 36.7905 - mae: 4.7243 - val_loss: 34.4570 - val_mse: 34.3535 - val_mae: 4.6717
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4146 - mse: 36.3082 - mae: 4.6922 - val_loss: 34.0960 - val_mse: 33.9868 - val_mae: 4.6497
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9326 - mse: 35.8206 - mae: 4.6615 - val_loss: 33.5398 - val_mse: 33.4249 - val_mae: 4.6152
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7390 - mse: 35.6217 - mae: 4.6532 - val_loss: 34.0840 - val_mse: 33.9639 - val_mae: 4.6497
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5116 - mse: 35.3896 - mae: 4.6323 - val_loss: 33.7468 - val_mse: 33.6223 - val_mae: 4.6295
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3624 - mse: 35.2357 - mae: 4.6249 - val_loss: 32.3367 - val_mse: 32.2074 - val_mae: 4.5407
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1552 - mse: 35.0240 - mae: 4.6092 - val_loss: 33.0620 - val_mse: 32.9285 - val_mae: 4.5897
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0281 - mse: 34.8924 - mae: 4.6051 - val_loss: 32.9514 - val_mse: 32.8137 - val_mae: 4.5811
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7241 - mse: 34.5843 - mae: 4.5814 - val_loss: 32.5600 - val_mse: 32.4180 - val_mae: 4.5585
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7044 - mse: 34.5605 - mae: 4.5767 - val_loss: 32.8699 - val_mse: 32.7237 - val_mae: 4.5780
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5037 - mse: 34.3558 - mae: 4.5686 - val_loss: 32.1409 - val_mse: 31.9910 - val_mae: 4.5318
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5179 - mse: 34.3662 - mae: 4.5676 - val_loss: 33.0942 - val_mse: 32.9405 - val_mae: 4.5930
bias -0.012948472
si 0.50472575
rmse 0.057393845
kgeprime [0.49482491]
rmse_95 0.0702081
rmse_99 0.076870926
pearson 0.8408683458145013
pearson_95 0.6879491021244315
pearson_99 0.6193115664483004
rscore 0.6911594528850925
rscore_95 -1.3044850934910683
rscore_99 -10.06927613069634
nse [0.69115945]
nse_95 [-1.30448509]
nse_99 [-10.06927613]
kge [0.6115309]
ext_kge_95 [0.52345018]
ext_kge_99 [-0.46703393]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.939 -9.749 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.27 11.37 ... 1.797
    uw2             (time, latitude, longitude) float32 98.78 95.03 ... 11.01
    vw2             (time, latitude, longitude) float32 127.0 129.2 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 15.03 14.98 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([139410 139434 139458], shape=(3,), dtype=int64) Times out: tf.Tensor(139458, shape=(), dtype=int64)
Times in: tf.Tensor([87416 87440 87464], shape=(3,), dtype=int64) Times out: tf.Tensor(87464, shape=(), dtype=int64)
Times in: tf.Tensor([92901 92925 92949], shape=(3,), dtype=int64) Times out: tf.Tensor(92949, shape=(), dtype=int64)
Times in: tf.Tensor([60243 60267 60291], shape=(3,), dtype=int64) Times out: tf.Tensor(60291, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_652&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_653 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1304 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1305 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_652 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1304 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_652 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1305 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.7340 - mse: 47.6834 - mae: 5.3139 - val_loss: 31.0918 - val_mse: 31.0304 - val_mae: 4.4581
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4590 - mse: 35.3936 - mae: 4.6380 - val_loss: 29.7030 - val_mse: 29.6345 - val_mae: 4.3618
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6619 - mse: 34.5910 - mae: 4.5833 - val_loss: 29.3037 - val_mse: 29.2309 - val_mae: 4.3301
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4260 - mse: 34.3520 - mae: 4.5668 - val_loss: 29.3513 - val_mse: 29.2766 - val_mae: 4.3377
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2740 - mse: 34.1980 - mae: 4.5518 - val_loss: 28.9389 - val_mse: 28.8620 - val_mae: 4.3102
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0402 - mse: 33.9615 - mae: 4.5350 - val_loss: 28.6722 - val_mse: 28.5916 - val_mae: 4.2896
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7318 - mse: 33.6490 - mae: 4.5137 - val_loss: 28.6441 - val_mse: 28.5591 - val_mae: 4.2912
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4583 - mse: 33.3705 - mae: 4.4915 - val_loss: 29.1085 - val_mse: 29.0181 - val_mae: 4.3281
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0675 - mse: 32.9742 - mae: 4.4673 - val_loss: 28.3424 - val_mse: 28.2464 - val_mae: 4.2703
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9961 - mse: 32.8969 - mae: 4.4588 - val_loss: 28.1549 - val_mse: 28.0527 - val_mae: 4.2594
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7755 - mse: 32.6702 - mae: 4.4493 - val_loss: 28.6540 - val_mse: 28.5457 - val_mae: 4.3035
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6326 - mse: 32.5213 - mae: 4.4328 - val_loss: 28.2241 - val_mse: 28.1099 - val_mae: 4.2708
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3276 - mse: 32.2106 - mae: 4.4127 - val_loss: 28.0864 - val_mse: 27.9662 - val_mae: 4.2591
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2139 - mse: 32.0911 - mae: 4.4010 - val_loss: 28.0676 - val_mse: 27.9419 - val_mae: 4.2600
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.9217 - mse: 31.7936 - mae: 4.3776 - val_loss: 27.5663 - val_mse: 27.4355 - val_mae: 4.2174
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8053 - mse: 31.6721 - mae: 4.3685 - val_loss: 27.2338 - val_mse: 27.0982 - val_mae: 4.1982
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5579 - mse: 31.4199 - mae: 4.3512 - val_loss: 27.1363 - val_mse: 26.9960 - val_mae: 4.1959
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2095 - mse: 31.0674 - mae: 4.3264 - val_loss: 27.4658 - val_mse: 27.3215 - val_mae: 4.2210
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0648 - mse: 30.9189 - mae: 4.3177 - val_loss: 27.5341 - val_mse: 27.3864 - val_mae: 4.2261
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9722 - mse: 30.8230 - mae: 4.3124 - val_loss: 26.6459 - val_mse: 26.4953 - val_mae: 4.1523
bias -0.008014908
si 0.47705382
rmse 0.051473577
kgeprime [0.6059934]
rmse_95 0.07236756
rmse_99 0.08369875
pearson 0.8580439090565429
pearson_95 0.7109822699458251
pearson_99 0.760970773679856
rscore 0.7289940007217908
rscore_95 -1.342600394687849
rscore_99 -9.445512995145707
nse [0.728994]
nse_95 [-1.34260039]
nse_99 [-9.445513]
kge [0.70179496]
ext_kge_95 [0.57910153]
ext_kge_99 [-0.20741489]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.5 172.8 173.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 1.222
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -1.814
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 1.493
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 3.29
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 2.187
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([76646 76670 76694], shape=(3,), dtype=int64) Times out: tf.Tensor(76694, shape=(), dtype=int64)
Times in: tf.Tensor([55834 55858 55882], shape=(3,), dtype=int64) Times out: tf.Tensor(55882, shape=(), dtype=int64)
Times in: tf.Tensor([124394 124418 124442], shape=(3,), dtype=int64) Times out: tf.Tensor(124442, shape=(), dtype=int64)
Times in: tf.Tensor([89494 89518 89542], shape=(3,), dtype=int64) Times out: tf.Tensor(89542, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_653&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_654 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1306 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1307 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_653 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1306 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_653 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1307 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 57.0172 - mse: 56.9607 - mae: 5.8380 - val_loss: 40.8149 - val_mse: 40.7475 - val_mae: 5.0707
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.1175 - mse: 43.0451 - mae: 5.1110 - val_loss: 38.9225 - val_mse: 38.8447 - val_mae: 4.9367
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6062 - mse: 41.5236 - mae: 5.0145 - val_loss: 39.4083 - val_mse: 39.3212 - val_mae: 4.9758
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.0829 - mse: 39.9927 - mae: 4.9210 - val_loss: 37.4422 - val_mse: 37.3483 - val_mae: 4.8550
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1224 - mse: 39.0256 - mae: 4.8603 - val_loss: 36.6147 - val_mse: 36.5146 - val_mae: 4.7925
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7108 - mse: 38.6081 - mae: 4.8405 - val_loss: 36.4962 - val_mse: 36.3908 - val_mae: 4.7937
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4724 - mse: 38.3647 - mae: 4.8232 - val_loss: 36.8539 - val_mse: 36.7441 - val_mae: 4.8150
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9939 - mse: 37.8815 - mae: 4.7953 - val_loss: 36.4891 - val_mse: 36.3738 - val_mae: 4.7903
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7214 - mse: 37.6034 - mae: 4.7794 - val_loss: 36.8522 - val_mse: 36.7312 - val_mae: 4.8082
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0588 - mse: 36.9354 - mae: 4.7350 - val_loss: 35.7054 - val_mse: 35.5795 - val_mae: 4.7361
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5890 - mse: 36.4613 - mae: 4.7086 - val_loss: 35.9818 - val_mse: 35.8521 - val_mae: 4.7569
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3139 - mse: 36.1824 - mae: 4.6838 - val_loss: 35.2510 - val_mse: 35.1176 - val_mae: 4.7105
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0900 - mse: 35.9549 - mae: 4.6719 - val_loss: 36.1182 - val_mse: 35.9814 - val_mae: 4.7664
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8288 - mse: 35.6907 - mae: 4.6529 - val_loss: 36.6268 - val_mse: 36.4872 - val_mae: 4.8028
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5800 - mse: 35.4392 - mae: 4.6341 - val_loss: 34.2808 - val_mse: 34.1386 - val_mae: 4.6564
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3501 - mse: 35.2067 - mae: 4.6207 - val_loss: 35.2669 - val_mse: 35.1219 - val_mae: 4.7216
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3039 - mse: 35.1579 - mae: 4.6170 - val_loss: 33.9949 - val_mse: 33.8473 - val_mae: 4.6384
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1982 - mse: 35.0496 - mae: 4.6101 - val_loss: 34.7046 - val_mse: 34.5550 - val_mae: 4.6863
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9517 - mse: 34.8011 - mae: 4.5928 - val_loss: 34.5101 - val_mse: 34.3582 - val_mae: 4.6728
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9054 - mse: 34.7523 - mae: 4.5934 - val_loss: 34.6564 - val_mse: 34.5019 - val_mae: 4.6834
bias -0.017758895
si 0.4993536
rmse 0.058738362
kgeprime [0.38329751]
rmse_95 0.06871698
rmse_99 0.0761087
pearson 0.8440062849774875
pearson_95 0.6722318447091578
pearson_99 0.5757372720694132
rscore 0.6833978122598652
rscore_95 -1.2315234850611354
rscore_99 -11.074009726625489
nse [0.68339781]
nse_95 [-1.23152349]
nse_99 [-11.07400973]
kge [0.51405598]
ext_kge_95 [0.52233671]
ext_kge_99 [-0.59776929]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.8 -49.49 -49.18 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.539 -9.42 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.7 10.47 ... -1.613
    uw2             (time, latitude, longitude) float32 91.0 88.73 ... 6.584
    vw2             (time, latitude, longitude) float32 114.5 109.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 14.33 14.08 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([60312 60336 60360], shape=(3,), dtype=int64) Times out: tf.Tensor(60360, shape=(), dtype=int64)
Times in: tf.Tensor([89082 89106 89130], shape=(3,), dtype=int64) Times out: tf.Tensor(89130, shape=(), dtype=int64)
Times in: tf.Tensor([20083 20107 20131], shape=(3,), dtype=int64) Times out: tf.Tensor(20131, shape=(), dtype=int64)
Times in: tf.Tensor([81454 81478 81502], shape=(3,), dtype=int64) Times out: tf.Tensor(81502, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_654&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_655 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1308 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1309 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_654 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1308 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_654 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1309 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 52.8285 - mse: 52.7735 - mae: 5.6017 - val_loss: 38.8000 - val_mse: 38.7310 - val_mae: 4.9783
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2465 - mse: 40.1693 - mae: 4.9468 - val_loss: 37.0177 - val_mse: 36.9324 - val_mae: 4.8509
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9432 - mse: 38.8520 - mae: 4.8602 - val_loss: 36.6187 - val_mse: 36.5219 - val_mae: 4.8031
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4416 - mse: 38.3412 - mae: 4.8281 - val_loss: 35.3609 - val_mse: 35.2568 - val_mae: 4.7323
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9276 - mse: 37.8209 - mae: 4.7971 - val_loss: 35.7572 - val_mse: 35.6475 - val_mae: 4.7583
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7666 - mse: 37.6544 - mae: 4.7860 - val_loss: 35.3237 - val_mse: 35.2084 - val_mae: 4.7321
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5370 - mse: 37.4196 - mae: 4.7693 - val_loss: 34.8328 - val_mse: 34.7128 - val_mae: 4.6972
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1416 - mse: 37.0192 - mae: 4.7488 - val_loss: 35.1999 - val_mse: 35.0747 - val_mae: 4.7225
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9704 - mse: 36.8422 - mae: 4.7375 - val_loss: 34.6715 - val_mse: 34.5398 - val_mae: 4.6894
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5584 - mse: 36.4240 - mae: 4.7137 - val_loss: 34.4519 - val_mse: 34.3143 - val_mae: 4.6706
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1395 - mse: 35.9998 - mae: 4.6852 - val_loss: 33.4252 - val_mse: 33.2829 - val_mae: 4.6042
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7920 - mse: 35.6480 - mae: 4.6538 - val_loss: 33.6623 - val_mse: 33.5162 - val_mae: 4.6268
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4590 - mse: 35.3112 - mae: 4.6401 - val_loss: 33.9432 - val_mse: 33.7931 - val_mae: 4.6459
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4149 - mse: 35.2634 - mae: 4.6320 - val_loss: 33.6934 - val_mse: 33.5402 - val_mae: 4.6343
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2080 - mse: 35.0533 - mae: 4.6247 - val_loss: 34.3203 - val_mse: 34.1636 - val_mae: 4.6699
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0059 - mse: 34.8479 - mae: 4.6030 - val_loss: 33.5008 - val_mse: 33.3411 - val_mae: 4.6149
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9919 - mse: 34.8310 - mae: 4.6036 - val_loss: 33.1820 - val_mse: 33.0194 - val_mae: 4.5967
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7786 - mse: 34.6146 - mae: 4.5896 - val_loss: 32.8870 - val_mse: 32.7215 - val_mae: 4.5813
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6891 - mse: 34.5223 - mae: 4.5895 - val_loss: 33.3391 - val_mse: 33.1704 - val_mae: 4.6129
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8417 - mse: 34.6719 - mae: 4.5935 - val_loss: 33.8924 - val_mse: 33.7212 - val_mae: 4.6481
bias -0.012631995
si 0.5097798
rmse 0.058069963
kgeprime [0.52156743]
rmse_95 0.07062957
rmse_99 0.07973257
pearson 0.839153374726979
pearson_95 0.6832950910222946
pearson_99 0.5840781816970645
rscore 0.6865414422486046
rscore_95 -1.3635523431194274
rscore_99 -11.212759649947618
nse [0.68654144]
nse_95 [-1.36355234]
nse_99 [-11.21275965]
kge [0.62988305]
ext_kge_95 [0.50984874]
ext_kge_99 [-0.58100463]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 0.9614
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 13.08
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([67340 67364 67388], shape=(3,), dtype=int64) Times out: tf.Tensor(67388, shape=(), dtype=int64)
Times in: tf.Tensor([124262 124286 124310], shape=(3,), dtype=int64) Times out: tf.Tensor(124310, shape=(), dtype=int64)
Times in: tf.Tensor([38876 38900 38924], shape=(3,), dtype=int64) Times out: tf.Tensor(38924, shape=(), dtype=int64)
Times in: tf.Tensor([135412 135436 135460], shape=(3,), dtype=int64) Times out: tf.Tensor(135460, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_655&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_656 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1310 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1311 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_655 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1310 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_655 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1311 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.4591 - mse: 39.4070 - mae: 4.8547 - val_loss: 26.9587 - val_mse: 26.8968 - val_mae: 4.1685
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2488 - mse: 30.1780 - mae: 4.2927 - val_loss: 26.7891 - val_mse: 26.7099 - val_mae: 4.1566
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2522 - mse: 29.1665 - mae: 4.2182 - val_loss: 26.2975 - val_mse: 26.2059 - val_mae: 4.1155
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7917 - mse: 28.6962 - mae: 4.1800 - val_loss: 25.2161 - val_mse: 25.1167 - val_mae: 4.0314
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5130 - mse: 28.4105 - mae: 4.1554 - val_loss: 25.0769 - val_mse: 24.9712 - val_mae: 4.0206
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0720 - mse: 27.9636 - mae: 4.1222 - val_loss: 24.5661 - val_mse: 24.4548 - val_mae: 3.9767
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6733 - mse: 27.5594 - mae: 4.0913 - val_loss: 24.2323 - val_mse: 24.1160 - val_mae: 3.9526
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2647 - mse: 27.1460 - mae: 4.0608 - val_loss: 24.1467 - val_mse: 24.0259 - val_mae: 3.9499
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0842 - mse: 26.9610 - mae: 4.0438 - val_loss: 24.2993 - val_mse: 24.1739 - val_mae: 3.9632
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8162 - mse: 26.6890 - mae: 4.0271 - val_loss: 23.3962 - val_mse: 23.2672 - val_mae: 3.8865
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6072 - mse: 26.4763 - mae: 4.0090 - val_loss: 23.6906 - val_mse: 23.5583 - val_mae: 3.9126
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5554 - mse: 26.4212 - mae: 4.0046 - val_loss: 22.9626 - val_mse: 22.8269 - val_mae: 3.8484
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3836 - mse: 26.2465 - mae: 3.9897 - val_loss: 23.1732 - val_mse: 23.0347 - val_mae: 3.8649
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2617 - mse: 26.1216 - mae: 3.9789 - val_loss: 22.9641 - val_mse: 22.8229 - val_mae: 3.8488
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0478 - mse: 25.9052 - mae: 3.9643 - val_loss: 23.0836 - val_mse: 22.9399 - val_mae: 3.8585
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0934 - mse: 25.9487 - mae: 3.9641 - val_loss: 23.3930 - val_mse: 23.2469 - val_mae: 3.8830
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0495 - mse: 25.9026 - mae: 3.9634 - val_loss: 22.5952 - val_mse: 22.4476 - val_mae: 3.8157
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0153 - mse: 25.8667 - mae: 3.9571 - val_loss: 22.5152 - val_mse: 22.3658 - val_mae: 3.8091
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9465 - mse: 25.7961 - mae: 3.9507 - val_loss: 22.5630 - val_mse: 22.4118 - val_mae: 3.8121
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7951 - mse: 25.6430 - mae: 3.9422 - val_loss: 22.6159 - val_mse: 22.4629 - val_mae: 3.8171
bias -0.0062773805
si 0.46892983
rmse 0.047395043
kgeprime [0.66230556]
rmse_95 0.059630204
rmse_99 0.07550001
pearson 0.8636423663110498
pearson_95 0.6040125515504143
pearson_99 0.5426264165999647
rscore 0.7413091051875236
rscore_95 -1.175306562402759
rscore_99 -8.755425357121528
nse [0.74130911]
nse_95 [-1.17530656]
nse_99 [-8.75542536]
kge [0.74538272]
ext_kge_95 [0.48379072]
ext_kge_99 [-0.34540478]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 0.9614
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 13.08
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([150262 150286 150310], shape=(3,), dtype=int64) Times out: tf.Tensor(150310, shape=(), dtype=int64)
Times in: tf.Tensor([14725 14749 14773], shape=(3,), dtype=int64) Times out: tf.Tensor(14773, shape=(), dtype=int64)
Times in: tf.Tensor([80512 80536 80560], shape=(3,), dtype=int64) Times out: tf.Tensor(80560, shape=(), dtype=int64)
Times in: tf.Tensor([35069 35093 35117], shape=(3,), dtype=int64) Times out: tf.Tensor(35117, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_656&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_657 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1312 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1313 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_656 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1312 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_656 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1313 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.6443 - mse: 42.5935 - mae: 5.0229 - val_loss: 28.1740 - val_mse: 28.1132 - val_mae: 4.2439
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5505 - mse: 31.4843 - mae: 4.3794 - val_loss: 26.4495 - val_mse: 26.3779 - val_mae: 4.1292
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6297 - mse: 30.5540 - mae: 4.3113 - val_loss: 27.1138 - val_mse: 27.0348 - val_mae: 4.1738
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2496 - mse: 30.1681 - mae: 4.2803 - val_loss: 26.0572 - val_mse: 25.9735 - val_mae: 4.0962
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9157 - mse: 29.8296 - mae: 4.2563 - val_loss: 25.8248 - val_mse: 25.7367 - val_mae: 4.0784
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7337 - mse: 29.6434 - mae: 4.2437 - val_loss: 26.2616 - val_mse: 26.1693 - val_mae: 4.1096
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3938 - mse: 29.2990 - mae: 4.2195 - val_loss: 25.8276 - val_mse: 25.7305 - val_mae: 4.0751
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3252 - mse: 29.2258 - mae: 4.2085 - val_loss: 25.6441 - val_mse: 25.5425 - val_mae: 4.0613
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0565 - mse: 28.9524 - mae: 4.1917 - val_loss: 25.7085 - val_mse: 25.6021 - val_mae: 4.0678
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9715 - mse: 28.8625 - mae: 4.1832 - val_loss: 26.5564 - val_mse: 26.4449 - val_mae: 4.1348
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9151 - mse: 28.8010 - mae: 4.1761 - val_loss: 25.7670 - val_mse: 25.6507 - val_mae: 4.0755
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6771 - mse: 28.5580 - mae: 4.1609 - val_loss: 25.6768 - val_mse: 25.5551 - val_mae: 4.0691
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5352 - mse: 28.4104 - mae: 4.1469 - val_loss: 25.6482 - val_mse: 25.5208 - val_mae: 4.0687
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2573 - mse: 28.1270 - mae: 4.1322 - val_loss: 24.7305 - val_mse: 24.5975 - val_mae: 3.9985
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1712 - mse: 28.0352 - mae: 4.1247 - val_loss: 24.8486 - val_mse: 24.7101 - val_mae: 4.0115
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0054 - mse: 27.8642 - mae: 4.1138 - val_loss: 25.7510 - val_mse: 25.6072 - val_mae: 4.0852
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9047 - mse: 27.7585 - mae: 4.1026 - val_loss: 24.6194 - val_mse: 24.4708 - val_mae: 3.9887
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5742 - mse: 27.4238 - mae: 4.0833 - val_loss: 24.5504 - val_mse: 24.3980 - val_mae: 3.9835
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3403 - mse: 27.1860 - mae: 4.0637 - val_loss: 23.9897 - val_mse: 23.8337 - val_mae: 3.9365
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3404 - mse: 27.1829 - mae: 4.0592 - val_loss: 23.7491 - val_mse: 23.5903 - val_mae: 3.9131
bias -0.008185582
si 0.47528973
rmse 0.048569877
kgeprime [0.60784595]
rmse_95 0.061406262
rmse_99 0.07455722
pearson 0.8594712486956492
pearson_95 0.5931697506072099
pearson_99 0.6223416963049774
rscore 0.7310296001517128
rscore_95 -1.2878221588533352
rscore_99 -8.31899992057675
nse [0.7310296]
nse_95 [-1.28782216]
nse_99 [-8.31899992]
kge [0.70517856]
ext_kge_95 [0.47164705]
ext_kge_99 [-0.19870123]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 1.143
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 11.95
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([17305 17329 17353], shape=(3,), dtype=int64) Times out: tf.Tensor(17353, shape=(), dtype=int64)
Times in: tf.Tensor([18255 18279 18303], shape=(3,), dtype=int64) Times out: tf.Tensor(18303, shape=(), dtype=int64)
Times in: tf.Tensor([114792 114816 114840], shape=(3,), dtype=int64) Times out: tf.Tensor(114840, shape=(), dtype=int64)
Times in: tf.Tensor([144685 144709 144733], shape=(3,), dtype=int64) Times out: tf.Tensor(144733, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_657&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_658 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1314 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1315 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_657 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1314 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_657 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1315 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.6262 - mse: 45.5802 - mae: 5.1960 - val_loss: 30.8125 - val_mse: 30.7566 - val_mae: 4.4470
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6299 - mse: 33.5704 - mae: 4.5018 - val_loss: 31.4822 - val_mse: 31.4190 - val_mae: 4.5002
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8562 - mse: 31.7901 - mae: 4.3894 - val_loss: 27.3023 - val_mse: 27.2335 - val_mae: 4.1990
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2357 - mse: 31.1643 - mae: 4.3447 - val_loss: 27.1315 - val_mse: 27.0577 - val_mae: 4.1892
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8748 - mse: 30.7986 - mae: 4.3197 - val_loss: 26.4596 - val_mse: 26.3812 - val_mae: 4.1356
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5680 - mse: 30.4871 - mae: 4.3031 - val_loss: 26.7628 - val_mse: 26.6794 - val_mae: 4.1567
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2908 - mse: 30.2053 - mae: 4.2842 - val_loss: 27.5606 - val_mse: 27.4729 - val_mae: 4.2180
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1400 - mse: 30.0501 - mae: 4.2681 - val_loss: 26.5467 - val_mse: 26.4546 - val_mae: 4.1412
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9285 - mse: 29.8340 - mae: 4.2504 - val_loss: 25.6912 - val_mse: 25.5946 - val_mae: 4.0764
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6857 - mse: 29.5864 - mae: 4.2357 - val_loss: 26.5946 - val_mse: 26.4932 - val_mae: 4.1468
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4987 - mse: 29.3946 - mae: 4.2172 - val_loss: 25.8563 - val_mse: 25.7500 - val_mae: 4.0918
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1334 - mse: 29.0247 - mae: 4.1924 - val_loss: 24.8474 - val_mse: 24.7365 - val_mae: 4.0115
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0412 - mse: 28.9284 - mae: 4.1798 - val_loss: 24.7322 - val_mse: 24.6174 - val_mae: 4.0058
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5204 - mse: 28.4041 - mae: 4.1478 - val_loss: 24.5007 - val_mse: 24.3830 - val_mae: 3.9884
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4048 - mse: 28.2854 - mae: 4.1362 - val_loss: 24.1738 - val_mse: 24.0530 - val_mae: 3.9630
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4962 - mse: 28.3739 - mae: 4.1415 - val_loss: 24.3971 - val_mse: 24.2737 - val_mae: 3.9795
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2150 - mse: 28.0902 - mae: 4.1243 - val_loss: 24.4401 - val_mse: 24.3143 - val_mae: 3.9851
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0528 - mse: 27.9259 - mae: 4.1102 - val_loss: 24.6310 - val_mse: 24.5032 - val_mae: 4.0008
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1373 - mse: 28.0084 - mae: 4.1185 - val_loss: 24.2545 - val_mse: 24.1249 - val_mae: 3.9690
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9866 - mse: 27.8559 - mae: 4.1037 - val_loss: 24.5366 - val_mse: 24.4051 - val_mae: 3.9893
bias -0.012178919
si 0.47272077
rmse 0.04940151
kgeprime [0.50738259]
rmse_95 0.058012694
rmse_99 0.07226538
pearson 0.8610707870247986
pearson_95 0.594992026945929
pearson_99 0.6638862589845694
rscore 0.7245821959698525
rscore_95 -0.9855660255574112
rscore_99 -7.447764884635358
nse [0.7245822]
nse_95 [-0.98556603]
nse_99 [-7.44776488]
kge [0.62332581]
ext_kge_95 [0.49985666]
ext_kge_99 [-0.15600699]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 1.143
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 11.95
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([25165 25189 25213], shape=(3,), dtype=int64) Times out: tf.Tensor(25213, shape=(), dtype=int64)
Times in: tf.Tensor([55107 55131 55155], shape=(3,), dtype=int64) Times out: tf.Tensor(55155, shape=(), dtype=int64)
Times in: tf.Tensor([66513 66537 66561], shape=(3,), dtype=int64) Times out: tf.Tensor(66561, shape=(), dtype=int64)
Times in: tf.Tensor([85369 85393 85417], shape=(3,), dtype=int64) Times out: tf.Tensor(85417, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_658&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_659 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1316 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1317 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_658 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1316 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_658 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1317 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.0309 - mse: 41.9879 - mae: 5.0132 - val_loss: 29.7915 - val_mse: 29.7414 - val_mae: 4.3661
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9207 - mse: 31.8641 - mae: 4.4062 - val_loss: 27.7169 - val_mse: 27.6531 - val_mae: 4.2263
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5616 - mse: 30.4914 - mae: 4.3092 - val_loss: 27.4448 - val_mse: 27.3693 - val_mae: 4.2055
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8288 - mse: 29.7487 - mae: 4.2559 - val_loss: 26.6583 - val_mse: 26.5745 - val_mae: 4.1434
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5412 - mse: 29.4536 - mae: 4.2283 - val_loss: 26.6446 - val_mse: 26.5540 - val_mae: 4.1433
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1494 - mse: 29.0553 - mae: 4.2039 - val_loss: 27.6906 - val_mse: 27.5938 - val_mae: 4.2231
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6877 - mse: 28.5876 - mae: 4.1666 - val_loss: 25.1546 - val_mse: 25.0521 - val_mae: 4.0302
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3455 - mse: 28.2395 - mae: 4.1405 - val_loss: 26.0736 - val_mse: 25.9650 - val_mae: 4.1042
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7868 - mse: 27.6750 - mae: 4.1023 - val_loss: 25.6910 - val_mse: 25.5771 - val_mae: 4.0758
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4463 - mse: 27.3299 - mae: 4.0743 - val_loss: 24.6990 - val_mse: 24.5809 - val_mae: 3.9985
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2375 - mse: 27.1174 - mae: 4.0540 - val_loss: 24.8581 - val_mse: 24.7367 - val_mae: 4.0168
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9962 - mse: 26.8729 - mae: 4.0353 - val_loss: 24.4225 - val_mse: 24.2981 - val_mae: 3.9818
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8099 - mse: 26.6837 - mae: 4.0171 - val_loss: 24.3806 - val_mse: 24.2535 - val_mae: 3.9739
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7167 - mse: 26.5879 - mae: 4.0135 - val_loss: 24.2335 - val_mse: 24.1039 - val_mae: 3.9608
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6244 - mse: 26.4932 - mae: 4.0084 - val_loss: 23.4475 - val_mse: 23.3158 - val_mae: 3.8963
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4464 - mse: 26.3132 - mae: 3.9921 - val_loss: 25.0869 - val_mse: 24.9528 - val_mae: 4.0318
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4013 - mse: 26.2659 - mae: 3.9898 - val_loss: 24.2712 - val_mse: 24.1353 - val_mae: 3.9706
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3758 - mse: 26.2387 - mae: 3.9837 - val_loss: 24.5634 - val_mse: 24.4257 - val_mae: 3.9917
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2257 - mse: 26.0868 - mae: 3.9716 - val_loss: 24.6005 - val_mse: 24.4609 - val_mae: 3.9966
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1184 - mse: 25.9777 - mae: 3.9656 - val_loss: 23.7263 - val_mse: 23.5852 - val_mae: 3.9261
bias -0.009481786
si 0.468304
rmse 0.04856462
kgeprime [0.59532545]
rmse_95 0.058289547
rmse_99 0.075591795
pearson 0.8642265195278875
pearson_95 0.6070353698148037
pearson_99 0.6576617139812462
rscore 0.7359192903234072
rscore_95 -0.9676647528191511
rscore_99 -8.94277992356144
nse [0.73591929]
nse_95 [-0.96766475]
nse_99 [-8.94277992]
kge [0.69466812]
ext_kge_95 [0.50424422]
ext_kge_99 [-0.412197]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.143
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.95
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([23600 23624 23648], shape=(3,), dtype=int64) Times out: tf.Tensor(23648, shape=(), dtype=int64)
Times in: tf.Tensor([73967 73991 74015], shape=(3,), dtype=int64) Times out: tf.Tensor(74015, shape=(), dtype=int64)
Times in: tf.Tensor([81204 81228 81252], shape=(3,), dtype=int64) Times out: tf.Tensor(81252, shape=(), dtype=int64)
Times in: tf.Tensor([47463 47487 47511], shape=(3,), dtype=int64) Times out: tf.Tensor(47511, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_659&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_660 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1318 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1319 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_659 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1318 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_659 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1319 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.5591 - mse: 43.5092 - mae: 5.0986 - val_loss: 28.7421 - val_mse: 28.6842 - val_mae: 4.3043
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0510 - mse: 32.9883 - mae: 4.4871 - val_loss: 27.6866 - val_mse: 27.6179 - val_mae: 4.2302
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2868 - mse: 31.2113 - mae: 4.3628 - val_loss: 26.8175 - val_mse: 26.7360 - val_mae: 4.1637
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4124 - mse: 30.3258 - mae: 4.2978 - val_loss: 26.4095 - val_mse: 26.3181 - val_mae: 4.1329
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8813 - mse: 29.7862 - mae: 4.2584 - val_loss: 26.3751 - val_mse: 26.2763 - val_mae: 4.1305
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7210 - mse: 29.6190 - mae: 4.2458 - val_loss: 25.9926 - val_mse: 25.8878 - val_mae: 4.0991
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4053 - mse: 29.2981 - mae: 4.2213 - val_loss: 26.1451 - val_mse: 26.0356 - val_mae: 4.1120
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1875 - mse: 29.0757 - mae: 4.2028 - val_loss: 26.5729 - val_mse: 26.4589 - val_mae: 4.1448
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7535 - mse: 28.6373 - mae: 4.1723 - val_loss: 26.4146 - val_mse: 26.2960 - val_mae: 4.1347
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4029 - mse: 28.2822 - mae: 4.1428 - val_loss: 24.8384 - val_mse: 24.7157 - val_mae: 4.0154
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1917 - mse: 28.0672 - mae: 4.1242 - val_loss: 24.9262 - val_mse: 24.7997 - val_mae: 4.0207
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8941 - mse: 27.7663 - mae: 4.1031 - val_loss: 24.3835 - val_mse: 24.2540 - val_mae: 3.9807
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6776 - mse: 27.5468 - mae: 4.0865 - val_loss: 24.7640 - val_mse: 24.6317 - val_mae: 4.0117
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5063 - mse: 27.3726 - mae: 4.0743 - val_loss: 25.3488 - val_mse: 25.2138 - val_mae: 4.0568
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4393 - mse: 27.3029 - mae: 4.0650 - val_loss: 24.4309 - val_mse: 24.2932 - val_mae: 3.9853
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2304 - mse: 27.0916 - mae: 4.0496 - val_loss: 24.2263 - val_mse: 24.0864 - val_mae: 3.9687
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2451 - mse: 27.1042 - mae: 4.0529 - val_loss: 24.0390 - val_mse: 23.8972 - val_mae: 3.9508
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0898 - mse: 26.9469 - mae: 4.0377 - val_loss: 24.5156 - val_mse: 24.3717 - val_mae: 3.9917
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0137 - mse: 26.8691 - mae: 4.0360 - val_loss: 24.1508 - val_mse: 24.0055 - val_mae: 3.9559
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9178 - mse: 26.7717 - mae: 4.0271 - val_loss: 24.0033 - val_mse: 23.8565 - val_mae: 3.9493
bias -0.008539498
si 0.47074583
rmse 0.048843123
kgeprime [0.62456625]
rmse_95 0.058706548
rmse_99 0.07238627
pearson 0.8628447667027
pearson_95 0.6098292311254463
pearson_99 0.6600239288723927
rscore 0.7351094208379941
rscore_95 -0.9495472233992779
rscore_99 -8.060478498187159
nse [0.73510942]
nse_95 [-0.94954722]
nse_99 [-8.0604785]
kge [0.71709698]
ext_kge_95 [0.49868007]
ext_kge_99 [-0.33488454]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.143
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.95
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([56226 56250 56274], shape=(3,), dtype=int64) Times out: tf.Tensor(56274, shape=(), dtype=int64)
Times in: tf.Tensor([19793 19817 19841], shape=(3,), dtype=int64) Times out: tf.Tensor(19841, shape=(), dtype=int64)
Times in: tf.Tensor([70692 70716 70740], shape=(3,), dtype=int64) Times out: tf.Tensor(70740, shape=(), dtype=int64)
Times in: tf.Tensor([118944 118968 118992], shape=(3,), dtype=int64) Times out: tf.Tensor(118992, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_660&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_661 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1320 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1321 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_660 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1320 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_660 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1321 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.0366 - mse: 44.9874 - mae: 5.1714 - val_loss: 28.8458 - val_mse: 28.7857 - val_mae: 4.3110
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4593 - mse: 32.3937 - mae: 4.4394 - val_loss: 27.4291 - val_mse: 27.3576 - val_mae: 4.2137
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9621 - mse: 30.8850 - mae: 4.3354 - val_loss: 26.5402 - val_mse: 26.4579 - val_mae: 4.1478
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3572 - mse: 30.2698 - mae: 4.2870 - val_loss: 26.0193 - val_mse: 25.9272 - val_mae: 4.1049
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9550 - mse: 29.8589 - mae: 4.2596 - val_loss: 25.5284 - val_mse: 25.4284 - val_mae: 4.0645
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3652 - mse: 29.2614 - mae: 4.2149 - val_loss: 25.1826 - val_mse: 25.0752 - val_mae: 4.0329
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9667 - mse: 28.8558 - mae: 4.1843 - val_loss: 24.7422 - val_mse: 24.6281 - val_mae: 3.9988
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6285 - mse: 28.5119 - mae: 4.1585 - val_loss: 24.5419 - val_mse: 24.4228 - val_mae: 3.9849
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3234 - mse: 28.2021 - mae: 4.1407 - val_loss: 24.2453 - val_mse: 24.1217 - val_mae: 3.9605
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1081 - mse: 27.9828 - mae: 4.1194 - val_loss: 24.2301 - val_mse: 24.1031 - val_mae: 3.9623
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0119 - mse: 27.8835 - mae: 4.1167 - val_loss: 23.8618 - val_mse: 23.7319 - val_mae: 3.9282
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9295 - mse: 27.7982 - mae: 4.1060 - val_loss: 24.3129 - val_mse: 24.1801 - val_mae: 3.9688
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8470 - mse: 27.7129 - mae: 4.1000 - val_loss: 24.0879 - val_mse: 23.9521 - val_mae: 3.9480
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6585 - mse: 27.5217 - mae: 4.0877 - val_loss: 23.8174 - val_mse: 23.6794 - val_mae: 3.9265
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6861 - mse: 27.5473 - mae: 4.0857 - val_loss: 23.6754 - val_mse: 23.5356 - val_mae: 3.9129
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5022 - mse: 27.3613 - mae: 4.0702 - val_loss: 23.9684 - val_mse: 23.8263 - val_mae: 3.9392
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6458 - mse: 27.5028 - mae: 4.0822 - val_loss: 24.0419 - val_mse: 23.8979 - val_mae: 3.9444
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4474 - mse: 27.3024 - mae: 4.0678 - val_loss: 24.1542 - val_mse: 24.0082 - val_mae: 3.9558
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2442 - mse: 27.0972 - mae: 4.0525 - val_loss: 24.1275 - val_mse: 23.9796 - val_mae: 3.9535
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2589 - mse: 27.1102 - mae: 4.0562 - val_loss: 23.4407 - val_mse: 23.2909 - val_mae: 3.8930
bias -0.0029518604
si 0.46969935
rmse 0.048260618
kgeprime [0.75213554]
rmse_95 0.064185895
rmse_99 0.077494055
pearson 0.8627042112766736
pearson_95 0.6256383802857595
pearson_99 0.69132943926697
rscore 0.7432199576842835
rscore_95 -1.2726426281755976
rscore_99 -8.14214806738291
nse [0.74321996]
nse_95 [-1.27264263]
nse_99 [-8.14214807]
kge [0.79659255]
ext_kge_95 [0.49744975]
ext_kge_99 [-0.245936]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.659 -9.488 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.09 11.15 ... 1.797
    uw2             (time, latitude, longitude) float32 93.29 90.02 ... 11.01
    vw2             (time, latitude, longitude) float32 122.9 124.3 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.7 14.64 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([31015 31039 31063], shape=(3,), dtype=int64) Times out: tf.Tensor(31063, shape=(), dtype=int64)
Times in: tf.Tensor([77615 77639 77663], shape=(3,), dtype=int64) Times out: tf.Tensor(77663, shape=(), dtype=int64)
Times in: tf.Tensor([47803 47827 47851], shape=(3,), dtype=int64) Times out: tf.Tensor(47851, shape=(), dtype=int64)
Times in: tf.Tensor([78071 78095 78119], shape=(3,), dtype=int64) Times out: tf.Tensor(78119, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_661&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_662 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1322 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1323 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_661 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1322 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_661 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1323 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.1715 - mse: 42.1130 - mae: 5.0076 - val_loss: 30.8054 - val_mse: 30.7342 - val_mae: 4.4395
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3293 - mse: 32.2496 - mae: 4.4386 - val_loss: 29.1911 - val_mse: 29.1042 - val_mae: 4.3260
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4139 - mse: 31.3213 - mae: 4.3681 - val_loss: 28.9526 - val_mse: 28.8557 - val_mae: 4.3105
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.9082 - mse: 30.8074 - mae: 4.3285 - val_loss: 28.9497 - val_mse: 28.8460 - val_mae: 4.3051
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5413 - mse: 30.4341 - mae: 4.2995 - val_loss: 28.5961 - val_mse: 28.4860 - val_mae: 4.2789
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1517 - mse: 30.0383 - mae: 4.2688 - val_loss: 27.7416 - val_mse: 27.6253 - val_mae: 4.2274
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6012 - mse: 29.4807 - mae: 4.2301 - val_loss: 28.4297 - val_mse: 28.3057 - val_mae: 4.2717
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9663 - mse: 28.8385 - mae: 4.1864 - val_loss: 27.5576 - val_mse: 27.4265 - val_mae: 4.2114
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4867 - mse: 28.3521 - mae: 4.1503 - val_loss: 27.0253 - val_mse: 26.8879 - val_mae: 4.1728
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1806 - mse: 28.0403 - mae: 4.1218 - val_loss: 26.7948 - val_mse: 26.6524 - val_mae: 4.1562
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8520 - mse: 27.7074 - mae: 4.1014 - val_loss: 26.2099 - val_mse: 26.0636 - val_mae: 4.1111
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7729 - mse: 27.6243 - mae: 4.0985 - val_loss: 25.2769 - val_mse: 25.1264 - val_mae: 4.0377
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5710 - mse: 27.4185 - mae: 4.0759 - val_loss: 25.7875 - val_mse: 25.6333 - val_mae: 4.0798
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4688 - mse: 27.3126 - mae: 4.0650 - val_loss: 25.3077 - val_mse: 25.1499 - val_mae: 4.0442
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1858 - mse: 27.0263 - mae: 4.0478 - val_loss: 26.3360 - val_mse: 26.1751 - val_mae: 4.1266
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1791 - mse: 27.0166 - mae: 4.0450 - val_loss: 25.9705 - val_mse: 25.8066 - val_mae: 4.0992
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0910 - mse: 26.9255 - mae: 4.0378 - val_loss: 25.0001 - val_mse: 24.8336 - val_mae: 4.0164
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0625 - mse: 26.8943 - mae: 4.0334 - val_loss: 25.1876 - val_mse: 25.0180 - val_mae: 4.0364
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9226 - mse: 26.7515 - mae: 4.0256 - val_loss: 25.0003 - val_mse: 24.8280 - val_mae: 4.0256
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9120 - mse: 26.7381 - mae: 4.0257 - val_loss: 24.6532 - val_mse: 24.4780 - val_mae: 3.9962
bias -0.0061850143
si 0.46487802
rmse 0.049475264
kgeprime [0.66073107]
rmse_95 0.06781648
rmse_99 0.08125241
pearson 0.865675557976377
pearson_95 0.7160154842981274
pearson_99 0.7399534030853573
rscore 0.7450148060506834
rscore_95 -1.1579024387087888
rscore_99 -9.871212019135898
nse [0.74501481]
nse_95 [-1.15790244]
nse_99 [-9.87121202]
kge [0.74212408]
ext_kge_95 [0.57445367]
ext_kge_99 [-0.38717165]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.659 -9.488 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.09 11.15 ... 1.797
    uw2             (time, latitude, longitude) float32 93.29 90.02 ... 11.01
    vw2             (time, latitude, longitude) float32 122.9 124.3 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.7 14.64 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([85516 85540 85564], shape=(3,), dtype=int64) Times out: tf.Tensor(85564, shape=(), dtype=int64)
Times in: tf.Tensor([61494 61518 61542], shape=(3,), dtype=int64) Times out: tf.Tensor(61542, shape=(), dtype=int64)
Times in: tf.Tensor([94187 94211 94235], shape=(3,), dtype=int64) Times out: tf.Tensor(94235, shape=(), dtype=int64)
Times in: tf.Tensor([70768 70792 70816], shape=(3,), dtype=int64) Times out: tf.Tensor(70816, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_662&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_663 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1324 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1325 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_662 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1324 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_662 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1325 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.5768 - mse: 47.5232 - mae: 5.3073 - val_loss: 31.3015 - val_mse: 31.2363 - val_mae: 4.4752
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2685 - mse: 34.1965 - mae: 4.5615 - val_loss: 29.5277 - val_mse: 29.4502 - val_mae: 4.3444
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3364 - mse: 33.2549 - mae: 4.4973 - val_loss: 29.7443 - val_mse: 29.6596 - val_mae: 4.3663
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0376 - mse: 32.9499 - mae: 4.4736 - val_loss: 29.0259 - val_mse: 28.9360 - val_mae: 4.3096
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7306 - mse: 32.6376 - mae: 4.4492 - val_loss: 28.8461 - val_mse: 28.7505 - val_mae: 4.2969
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4994 - mse: 32.4007 - mae: 4.4366 - val_loss: 28.7325 - val_mse: 28.6310 - val_mae: 4.2908
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1213 - mse: 32.0164 - mae: 4.4094 - val_loss: 28.4793 - val_mse: 28.3713 - val_mae: 4.2703
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9108 - mse: 31.7993 - mae: 4.3957 - val_loss: 28.0640 - val_mse: 27.9490 - val_mae: 4.2393
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6247 - mse: 31.5059 - mae: 4.3675 - val_loss: 28.1467 - val_mse: 28.0247 - val_mae: 4.2551
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1505 - mse: 31.0249 - mae: 4.3388 - val_loss: 27.3518 - val_mse: 27.2230 - val_mae: 4.1975
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7317 - mse: 30.5997 - mae: 4.3085 - val_loss: 26.9465 - val_mse: 26.8117 - val_mae: 4.1673
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4395 - mse: 30.3021 - mae: 4.2847 - val_loss: 26.8862 - val_mse: 26.7467 - val_mae: 4.1643
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2405 - mse: 30.0988 - mae: 4.2730 - val_loss: 26.7350 - val_mse: 26.5912 - val_mae: 4.1571
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0337 - mse: 29.8879 - mae: 4.2521 - val_loss: 26.4203 - val_mse: 26.2730 - val_mae: 4.1294
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9102 - mse: 29.7612 - mae: 4.2472 - val_loss: 27.0787 - val_mse: 26.9284 - val_mae: 4.1866
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7776 - mse: 29.6254 - mae: 4.2343 - val_loss: 26.4168 - val_mse: 26.2635 - val_mae: 4.1341
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5707 - mse: 29.4157 - mae: 4.2218 - val_loss: 26.2476 - val_mse: 26.0914 - val_mae: 4.1164
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4993 - mse: 29.3414 - mae: 4.2112 - val_loss: 26.0014 - val_mse: 25.8426 - val_mae: 4.0895
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3436 - mse: 29.1833 - mae: 4.2034 - val_loss: 26.3881 - val_mse: 26.2267 - val_mae: 4.1258
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3731 - mse: 29.2104 - mae: 4.1968 - val_loss: 26.0951 - val_mse: 25.9313 - val_mae: 4.1059
bias -0.009022948
si 0.4704175
rmse 0.05092282
kgeprime [0.59527662]
rmse_95 0.066388234
rmse_99 0.07682374
pearson 0.8620377070798497
pearson_95 0.7142549405609522
pearson_99 0.7390162186747311
rscore 0.7346938225575805
rscore_95 -0.993744082494826
rscore_99 -8.016397755284313
nse [0.73469382]
nse_95 [-0.99374408]
nse_99 [-8.01639776]
kge [0.69608924]
ext_kge_95 [0.58953145]
ext_kge_99 [-0.2821336]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.439 -9.289 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.48 10.25 ... -1.613
    uw2             (time, latitude, longitude) float32 89.09 86.29 ... 6.584
    vw2             (time, latitude, longitude) float32 109.8 105.0 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 14.1 13.83 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([94003 94027 94051], shape=(3,), dtype=int64) Times out: tf.Tensor(94051, shape=(), dtype=int64)
Times in: tf.Tensor([67694 67718 67742], shape=(3,), dtype=int64) Times out: tf.Tensor(67742, shape=(), dtype=int64)
Times in: tf.Tensor([54746 54770 54794], shape=(3,), dtype=int64) Times out: tf.Tensor(54794, shape=(), dtype=int64)
Times in: tf.Tensor([70907 70931 70955], shape=(3,), dtype=int64) Times out: tf.Tensor(70955, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_663&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_664 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1326 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1327 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_663 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1326 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_663 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1327 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 56.5365 - mse: 56.4734 - mae: 5.7937 - val_loss: 40.1632 - val_mse: 40.0884 - val_mae: 5.0493
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.9835 - mse: 41.9037 - mae: 5.0405 - val_loss: 37.3140 - val_mse: 37.2294 - val_mae: 4.8432
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.4382 - mse: 40.3501 - mae: 4.9515 - val_loss: 36.4158 - val_mse: 36.3247 - val_mae: 4.7948
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8931 - mse: 39.7991 - mae: 4.9210 - val_loss: 36.6474 - val_mse: 36.5512 - val_mae: 4.8067
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5419 - mse: 39.4436 - mae: 4.8936 - val_loss: 36.0522 - val_mse: 35.9521 - val_mae: 4.7710
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2440 - mse: 39.1421 - mae: 4.8792 - val_loss: 36.0529 - val_mse: 35.9495 - val_mae: 4.7760
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9185 - mse: 38.8135 - mae: 4.8585 - val_loss: 35.7305 - val_mse: 35.6242 - val_mae: 4.7540
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8479 - mse: 38.7398 - mae: 4.8549 - val_loss: 36.1102 - val_mse: 36.0007 - val_mae: 4.7811
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5178 - mse: 38.4066 - mae: 4.8374 - val_loss: 36.5285 - val_mse: 36.4156 - val_mae: 4.8013
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3680 - mse: 38.2534 - mae: 4.8272 - val_loss: 35.7735 - val_mse: 35.6572 - val_mae: 4.7532
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2545 - mse: 38.1363 - mae: 4.8162 - val_loss: 35.9604 - val_mse: 35.8404 - val_mae: 4.7677
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0560 - mse: 37.9345 - mae: 4.8065 - val_loss: 35.4231 - val_mse: 35.2996 - val_mae: 4.7357
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8142 - mse: 37.6885 - mae: 4.7922 - val_loss: 35.3704 - val_mse: 35.2422 - val_mae: 4.7312
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2999 - mse: 37.1691 - mae: 4.7580 - val_loss: 34.9127 - val_mse: 34.7794 - val_mae: 4.6981
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0359 - mse: 36.9003 - mae: 4.7376 - val_loss: 34.2536 - val_mse: 34.1161 - val_mae: 4.6599
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6807 - mse: 36.5409 - mae: 4.7137 - val_loss: 34.6517 - val_mse: 34.5098 - val_mae: 4.6874
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4212 - mse: 36.2777 - mae: 4.6912 - val_loss: 34.0477 - val_mse: 33.9028 - val_mae: 4.6458
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2117 - mse: 36.0651 - mae: 4.6818 - val_loss: 34.0351 - val_mse: 33.8870 - val_mae: 4.6492
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0408 - mse: 35.8909 - mae: 4.6710 - val_loss: 33.8236 - val_mse: 33.6723 - val_mae: 4.6304
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8821 - mse: 35.7289 - mae: 4.6602 - val_loss: 32.7973 - val_mse: 32.6426 - val_mae: 4.5665
bias -0.0029644214
si 0.50701565
rmse 0.05713371
kgeprime [0.72797269]
rmse_95 0.083708726
rmse_99 0.09233158
pearson 0.8388846072751649
pearson_95 0.682951466143681
pearson_99 0.5419502573659646
rscore 0.7027938985950977
rscore_95 -2.2863788847995465
rscore_99 -16.07778259817747
nse [0.7027939]
nse_95 [-2.28637888]
nse_99 [-16.0777826]
kge [0.76857711]
ext_kge_95 [0.49122875]
ext_kge_99 [-0.64011323]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.439 -9.289 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.48 10.25 ... -1.613
    uw2             (time, latitude, longitude) float32 89.09 86.29 ... 6.584
    vw2             (time, latitude, longitude) float32 109.8 105.0 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 14.1 13.83 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([89512 89536 89560], shape=(3,), dtype=int64) Times out: tf.Tensor(89560, shape=(), dtype=int64)
Times in: tf.Tensor([129624 129648 129672], shape=(3,), dtype=int64) Times out: tf.Tensor(129672, shape=(), dtype=int64)
Times in: tf.Tensor([55771 55795 55819], shape=(3,), dtype=int64) Times out: tf.Tensor(55819, shape=(), dtype=int64)
Times in: tf.Tensor([9600 9624 9648], shape=(3,), dtype=int64) Times out: tf.Tensor(9648, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_664&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_665 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1328 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1329 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_664 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1328 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_664 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1329 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.8916 - mse: 58.8396 - mae: 5.8860 - val_loss: 39.1789 - val_mse: 39.1143 - val_mae: 4.9823
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.9914 - mse: 43.9225 - mae: 5.1343 - val_loss: 36.8091 - val_mse: 36.7367 - val_mae: 4.8118
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.5188 - mse: 42.4439 - mae: 5.0555 - val_loss: 35.9929 - val_mse: 35.9158 - val_mae: 4.7601
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.0983 - mse: 42.0192 - mae: 5.0334 - val_loss: 35.6280 - val_mse: 35.5472 - val_mae: 4.7440
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.7769 - mse: 41.6944 - mae: 5.0145 - val_loss: 35.3192 - val_mse: 35.2350 - val_mae: 4.7211
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.5824 - mse: 41.4966 - mae: 4.9994 - val_loss: 35.2183 - val_mse: 35.1310 - val_mae: 4.7149
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.3242 - mse: 41.2353 - mae: 4.9839 - val_loss: 34.9594 - val_mse: 34.8687 - val_mae: 4.6997
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9527 - mse: 40.8601 - mae: 4.9621 - val_loss: 34.8975 - val_mse: 34.8031 - val_mae: 4.6886
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7569 - mse: 40.6605 - mae: 4.9530 - val_loss: 34.7624 - val_mse: 34.6640 - val_mae: 4.6760
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.5296 - mse: 40.4288 - mae: 4.9413 - val_loss: 34.8598 - val_mse: 34.7572 - val_mae: 4.6921
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.3489 - mse: 40.2440 - mae: 4.9312 - val_loss: 34.4956 - val_mse: 34.3886 - val_mae: 4.6706
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.0969 - mse: 39.9871 - mae: 4.9148 - val_loss: 34.7073 - val_mse: 34.5951 - val_mae: 4.6828
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.8938 - mse: 39.7789 - mae: 4.9005 - val_loss: 34.3371 - val_mse: 34.2199 - val_mae: 4.6573
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4935 - mse: 39.3734 - mae: 4.8827 - val_loss: 34.4991 - val_mse: 34.3764 - val_mae: 4.6723
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4509 - mse: 39.3254 - mae: 4.8737 - val_loss: 34.2940 - val_mse: 34.1662 - val_mae: 4.6604
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1893 - mse: 39.0584 - mae: 4.8606 - val_loss: 34.8235 - val_mse: 34.6900 - val_mae: 4.6949
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1027 - mse: 38.9662 - mae: 4.8580 - val_loss: 34.2878 - val_mse: 34.1491 - val_mae: 4.6567
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0698 - mse: 38.9279 - mae: 4.8482 - val_loss: 34.4236 - val_mse: 34.2790 - val_mae: 4.6759
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8441 - mse: 38.6969 - mae: 4.8342 - val_loss: 34.4407 - val_mse: 34.2910 - val_mae: 4.6752
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.7824 - mse: 38.6302 - mae: 4.8355 - val_loss: 34.7197 - val_mse: 34.5649 - val_mae: 4.6873
bias -0.008113559
si 0.5255167
rmse 0.05879188
kgeprime [0.592911]
rmse_95 0.086741745
rmse_99 0.10425164
pearson 0.8266881689167311
pearson_95 0.6580813391027374
pearson_99 0.6001474900075561
rscore 0.6771813038043855
rscore_95 -2.583985100266736
rscore_99 -19.132475424836393
nse [0.6771813]
nse_95 [-2.5839851]
nse_99 [-19.13247542]
kge [0.68550767]
ext_kge_95 [0.50327908]
ext_kge_99 [-0.57864326]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 1.107
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 14.56
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([113379 113403 113427], shape=(3,), dtype=int64) Times out: tf.Tensor(113427, shape=(), dtype=int64)
Times in: tf.Tensor([73891 73915 73939], shape=(3,), dtype=int64) Times out: tf.Tensor(73939, shape=(), dtype=int64)
Times in: tf.Tensor([131281 131305 131329], shape=(3,), dtype=int64) Times out: tf.Tensor(131329, shape=(), dtype=int64)
Times in: tf.Tensor([67560 67584 67608], shape=(3,), dtype=int64) Times out: tf.Tensor(67608, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_665&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_666 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1330 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1331 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_665 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1330 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_665 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1331 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.3050 - mse: 39.2550 - mae: 4.8220 - val_loss: 25.5997 - val_mse: 25.5377 - val_mae: 4.0490
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0801 - mse: 29.0127 - mae: 4.2132 - val_loss: 24.9831 - val_mse: 24.9111 - val_mae: 4.0101
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3766 - mse: 28.3019 - mae: 4.1570 - val_loss: 25.0584 - val_mse: 24.9813 - val_mae: 4.0163
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1416 - mse: 28.0626 - mae: 4.1401 - val_loss: 25.2174 - val_mse: 25.1362 - val_mae: 4.0280
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9824 - mse: 27.8996 - mae: 4.1270 - val_loss: 25.1627 - val_mse: 25.0782 - val_mae: 4.0228
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7410 - mse: 27.6553 - mae: 4.1062 - val_loss: 24.5501 - val_mse: 24.4628 - val_mae: 3.9734
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5684 - mse: 27.4798 - mae: 4.0943 - val_loss: 24.2437 - val_mse: 24.1535 - val_mae: 3.9530
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4843 - mse: 27.3928 - mae: 4.0840 - val_loss: 23.9513 - val_mse: 23.8581 - val_mae: 3.9283
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4454 - mse: 27.3508 - mae: 4.0778 - val_loss: 24.4807 - val_mse: 24.3845 - val_mae: 3.9765
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2482 - mse: 27.1505 - mae: 4.0606 - val_loss: 23.3790 - val_mse: 23.2796 - val_mae: 3.8769
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9341 - mse: 26.8333 - mae: 4.0390 - val_loss: 24.1966 - val_mse: 24.0940 - val_mae: 3.9509
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7965 - mse: 26.6922 - mae: 4.0315 - val_loss: 23.5587 - val_mse: 23.4524 - val_mae: 3.8977
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3878 - mse: 26.2797 - mae: 4.0000 - val_loss: 23.2132 - val_mse: 23.1031 - val_mae: 3.8722
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3145 - mse: 26.2028 - mae: 3.9944 - val_loss: 23.3093 - val_mse: 23.1960 - val_mae: 3.8793
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0609 - mse: 25.9463 - mae: 3.9674 - val_loss: 22.5651 - val_mse: 22.4491 - val_mae: 3.8189
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9475 - mse: 25.8302 - mae: 3.9625 - val_loss: 22.6541 - val_mse: 22.5353 - val_mae: 3.8270
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8327 - mse: 25.7129 - mae: 3.9507 - val_loss: 22.6175 - val_mse: 22.4966 - val_mae: 3.8196
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8151 - mse: 25.6933 - mae: 3.9495 - val_loss: 21.8080 - val_mse: 21.6855 - val_mae: 3.7490
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6583 - mse: 25.5348 - mae: 3.9339 - val_loss: 22.1233 - val_mse: 21.9989 - val_mae: 3.7743
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5897 - mse: 25.4645 - mae: 3.9318 - val_loss: 22.3587 - val_mse: 22.2327 - val_mae: 3.7984
bias -0.0075268433
si 0.4813542
rmse 0.04715156
kgeprime [0.63370962]
rmse_95 0.056942124
rmse_99 0.0659622
pearson 0.8575927748445143
pearson_95 0.5917431201644778
pearson_99 0.35868596466956515
rscore 0.7266749134939028
rscore_95 -1.3972463380169442
rscore_99 -7.388425538995456
nse [0.72667491]
nse_95 [-1.39724634]
nse_99 [-7.38842554]
kge [0.72291093]
ext_kge_95 [0.39689176]
ext_kge_99 [-0.35450064]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.4 -10.16 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.63 10.82 ... 1.107
    uw2             (time, latitude, longitude) float32 108.1 103.2 ... 14.56
    vw2             (time, latitude, longitude) float32 113.0 117.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.84 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([12508 12532 12556], shape=(3,), dtype=int64) Times out: tf.Tensor(12556, shape=(), dtype=int64)
Times in: tf.Tensor([127092 127116 127140], shape=(3,), dtype=int64) Times out: tf.Tensor(127140, shape=(), dtype=int64)
Times in: tf.Tensor([14022 14046 14070], shape=(3,), dtype=int64) Times out: tf.Tensor(14070, shape=(), dtype=int64)
Times in: tf.Tensor([20325 20349 20373], shape=(3,), dtype=int64) Times out: tf.Tensor(20373, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_666&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_667 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1332 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1333 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_666 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1332 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_666 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1333 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 49.6758 - mse: 49.6200 - mae: 5.4725 - val_loss: 35.4454 - val_mse: 35.3815 - val_mae: 4.7120
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4070 - mse: 38.3425 - mae: 4.8313 - val_loss: 27.8715 - val_mse: 27.8061 - val_mae: 4.2242
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6827 - mse: 31.6125 - mae: 4.4017 - val_loss: 25.8961 - val_mse: 25.8205 - val_mae: 4.0840
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9080 - mse: 29.8254 - mae: 4.2696 - val_loss: 24.7734 - val_mse: 24.6844 - val_mae: 3.9954
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9575 - mse: 28.8623 - mae: 4.1944 - val_loss: 24.1110 - val_mse: 24.0109 - val_mae: 3.9401
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6010 - mse: 28.4967 - mae: 4.1667 - val_loss: 23.8847 - val_mse: 23.7774 - val_mae: 3.9241
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3779 - mse: 28.2674 - mae: 4.1501 - val_loss: 23.6693 - val_mse: 23.5562 - val_mae: 3.9046
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1554 - mse: 28.0395 - mae: 4.1282 - val_loss: 23.5336 - val_mse: 23.4153 - val_mae: 3.8982
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7828 - mse: 27.6614 - mae: 4.1030 - val_loss: 23.1442 - val_mse: 23.0205 - val_mae: 3.8605
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5130 - mse: 27.3865 - mae: 4.0814 - val_loss: 22.9817 - val_mse: 22.8529 - val_mae: 3.8522
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2523 - mse: 27.1211 - mae: 4.0640 - val_loss: 22.8453 - val_mse: 22.7123 - val_mae: 3.8411
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0678 - mse: 26.9330 - mae: 4.0438 - val_loss: 22.4118 - val_mse: 22.2755 - val_mae: 3.8035
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8844 - mse: 26.7467 - mae: 4.0294 - val_loss: 22.4099 - val_mse: 22.2709 - val_mae: 3.8047
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6563 - mse: 26.5160 - mae: 4.0158 - val_loss: 22.1962 - val_mse: 22.0552 - val_mae: 3.7835
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6850 - mse: 26.5426 - mae: 4.0148 - val_loss: 22.2507 - val_mse: 22.1076 - val_mae: 3.7889
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5660 - mse: 26.4219 - mae: 4.0063 - val_loss: 22.0177 - val_mse: 21.8730 - val_mae: 3.7678
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6494 - mse: 26.5036 - mae: 4.0140 - val_loss: 22.5434 - val_mse: 22.3970 - val_mae: 3.8169
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4495 - mse: 26.3023 - mae: 3.9942 - val_loss: 21.9654 - val_mse: 21.8177 - val_mae: 3.7585
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4361 - mse: 26.2874 - mae: 3.9985 - val_loss: 21.9685 - val_mse: 21.8191 - val_mae: 3.7642
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4304 - mse: 26.2803 - mae: 3.9938 - val_loss: 22.0082 - val_mse: 21.8576 - val_mae: 3.7682
bias -0.0059500765
si 0.473068
rmse 0.046752132
kgeprime [0.65949928]
rmse_95 0.060408898
rmse_99 0.0717728
pearson 0.8616308002916531
pearson_95 0.6195292455872805
pearson_99 0.44016754741745845
rscore 0.7381666338244649
rscore_95 -1.5394668506020657
rscore_99 -7.886313983978111
nse [0.73816663]
nse_95 [-1.53946685]
nse_99 [-7.88631398]
kge [0.7423076]
ext_kge_95 [0.46291056]
ext_kge_99 [-0.131469]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.4 -10.16 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.63 10.82 ... 1.107
    uw2             (time, latitude, longitude) float32 108.1 103.2 ... 14.56
    vw2             (time, latitude, longitude) float32 113.0 117.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.84 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([15253 15277 15301], shape=(3,), dtype=int64) Times out: tf.Tensor(15301, shape=(), dtype=int64)
Times in: tf.Tensor([5649 5673 5697], shape=(3,), dtype=int64) Times out: tf.Tensor(5697, shape=(), dtype=int64)
Times in: tf.Tensor([13890 13914 13938], shape=(3,), dtype=int64) Times out: tf.Tensor(13938, shape=(), dtype=int64)
Times in: tf.Tensor([93416 93440 93464], shape=(3,), dtype=int64) Times out: tf.Tensor(93464, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_667&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_668 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1334 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1335 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_667 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1334 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_667 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1335 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.1318 - mse: 40.0748 - mae: 4.8879 - val_loss: 25.9759 - val_mse: 25.9052 - val_mae: 4.0901
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2203 - mse: 30.1428 - mae: 4.2894 - val_loss: 25.2516 - val_mse: 25.1689 - val_mae: 4.0382
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4413 - mse: 29.3546 - mae: 4.2284 - val_loss: 24.7459 - val_mse: 24.6559 - val_mae: 3.9915
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1294 - mse: 29.0371 - mae: 4.2033 - val_loss: 24.7486 - val_mse: 24.6543 - val_mae: 3.9912
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8718 - mse: 28.7761 - mae: 4.1798 - val_loss: 24.3295 - val_mse: 24.2320 - val_mae: 3.9573
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4696 - mse: 28.3707 - mae: 4.1552 - val_loss: 24.1498 - val_mse: 24.0494 - val_mae: 3.9426
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3790 - mse: 28.2769 - mae: 4.1452 - val_loss: 23.8718 - val_mse: 23.7680 - val_mae: 3.9205
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9983 - mse: 27.8925 - mae: 4.1138 - val_loss: 23.2373 - val_mse: 23.1299 - val_mae: 3.8628
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8000 - mse: 27.6907 - mae: 4.1016 - val_loss: 22.9344 - val_mse: 22.8231 - val_mae: 3.8414
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4718 - mse: 27.3588 - mae: 4.0748 - val_loss: 22.7626 - val_mse: 22.6480 - val_mae: 3.8267
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1770 - mse: 27.0609 - mae: 4.0485 - val_loss: 22.5875 - val_mse: 22.4696 - val_mae: 3.8127
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0539 - mse: 26.9347 - mae: 4.0449 - val_loss: 22.6297 - val_mse: 22.5090 - val_mae: 3.8208
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7862 - mse: 26.6641 - mae: 4.0224 - val_loss: 22.1505 - val_mse: 22.0269 - val_mae: 3.7734
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7828 - mse: 26.6578 - mae: 4.0232 - val_loss: 22.0892 - val_mse: 21.9630 - val_mae: 3.7706
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5923 - mse: 26.4649 - mae: 4.0072 - val_loss: 22.4678 - val_mse: 22.3391 - val_mae: 3.8080
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5758 - mse: 26.4456 - mae: 4.0089 - val_loss: 22.1794 - val_mse: 22.0482 - val_mae: 3.7832
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6068 - mse: 26.4746 - mae: 4.0023 - val_loss: 22.3633 - val_mse: 22.2301 - val_mae: 3.7987
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4388 - mse: 26.3045 - mae: 3.9886 - val_loss: 21.7801 - val_mse: 21.6449 - val_mae: 3.7473
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3910 - mse: 26.2548 - mae: 3.9876 - val_loss: 21.9221 - val_mse: 21.7849 - val_mae: 3.7599
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3079 - mse: 26.1697 - mae: 3.9789 - val_loss: 21.7301 - val_mse: 21.5909 - val_mae: 3.7414
bias -0.004086565
si 0.46928567
rmse 0.04646601
kgeprime [0.70218868]
rmse_95 0.062144667
rmse_99 0.07545639
pearson 0.8640485250924433
pearson_95 0.6110325466877711
pearson_99 0.4614641883016536
rscore 0.7443334936908501
rscore_95 -1.5889223306935416
rscore_99 -8.784363337609165
nse [0.74433349]
nse_95 [-1.58892233]
nse_99 [-8.78436334]
kge [0.76610163]
ext_kge_95 [0.47625815]
ext_kge_99 [-0.16770496]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.4 -10.16 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.63 10.82 ... 1.107
    uw2             (time, latitude, longitude) float32 108.1 103.2 ... 14.56
    vw2             (time, latitude, longitude) float32 113.0 117.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.84 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([6428 6452 6476], shape=(3,), dtype=int64) Times out: tf.Tensor(6476, shape=(), dtype=int64)
Times in: tf.Tensor([110268 110292 110316], shape=(3,), dtype=int64) Times out: tf.Tensor(110316, shape=(), dtype=int64)
Times in: tf.Tensor([145395 145419 145443], shape=(3,), dtype=int64) Times out: tf.Tensor(145443, shape=(), dtype=int64)
Times in: tf.Tensor([63555 63579 63603], shape=(3,), dtype=int64) Times out: tf.Tensor(63603, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_668&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_669 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1336 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1337 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_668 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1336 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_668 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1337 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.3198 - mse: 46.2772 - mae: 5.2646 - val_loss: 27.3990 - val_mse: 27.3454 - val_mae: 4.1919
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3872 - mse: 32.3235 - mae: 4.4430 - val_loss: 26.3905 - val_mse: 26.3163 - val_mae: 4.1220
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1524 - mse: 30.0700 - mae: 4.2860 - val_loss: 26.6329 - val_mse: 26.5433 - val_mae: 4.1366
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1102 - mse: 29.0152 - mae: 4.2017 - val_loss: 25.2024 - val_mse: 25.1031 - val_mae: 4.0241
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7009 - mse: 28.5991 - mae: 4.1698 - val_loss: 24.6219 - val_mse: 24.5181 - val_mae: 3.9781
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3439 - mse: 28.2381 - mae: 4.1398 - val_loss: 25.4111 - val_mse: 25.3040 - val_mae: 4.0400
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0264 - mse: 27.9176 - mae: 4.1190 - val_loss: 25.1924 - val_mse: 25.0822 - val_mae: 4.0224
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7959 - mse: 27.6841 - mae: 4.0995 - val_loss: 24.2836 - val_mse: 24.1706 - val_mae: 3.9526
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5417 - mse: 27.4272 - mae: 4.0765 - val_loss: 24.1828 - val_mse: 24.0672 - val_mae: 3.9422
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1556 - mse: 27.0387 - mae: 4.0526 - val_loss: 23.7448 - val_mse: 23.6270 - val_mae: 3.9098
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0054 - mse: 26.8864 - mae: 4.0392 - val_loss: 23.8939 - val_mse: 23.7739 - val_mae: 3.9236
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8057 - mse: 26.6850 - mae: 4.0216 - val_loss: 23.3252 - val_mse: 23.2038 - val_mae: 3.8746
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7549 - mse: 26.6326 - mae: 4.0170 - val_loss: 23.2635 - val_mse: 23.1406 - val_mae: 3.8685
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5454 - mse: 26.4218 - mae: 3.9990 - val_loss: 22.8694 - val_mse: 22.7454 - val_mae: 3.8392
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4744 - mse: 26.3497 - mae: 3.9977 - val_loss: 23.1019 - val_mse: 22.9767 - val_mae: 3.8607
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3537 - mse: 26.2280 - mae: 3.9861 - val_loss: 22.7615 - val_mse: 22.6353 - val_mae: 3.8299
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3753 - mse: 26.2483 - mae: 3.9867 - val_loss: 23.6975 - val_mse: 23.5700 - val_mae: 3.9048
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3237 - mse: 26.1958 - mae: 3.9814 - val_loss: 22.9100 - val_mse: 22.7816 - val_mae: 3.8424
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1760 - mse: 26.0470 - mae: 3.9718 - val_loss: 22.2472 - val_mse: 22.1179 - val_mae: 3.7855
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0769 - mse: 25.9470 - mae: 3.9642 - val_loss: 23.1454 - val_mse: 23.0151 - val_mae: 3.8613
bias -0.010372855
si 0.4731244
rmse 0.04797405
kgeprime [0.55753872]
rmse_95 0.05600334
rmse_99 0.0687542
pearson 0.861917631395882
pearson_95 0.6110346357177273
pearson_99 0.49433565464773566
rscore 0.7292742361123628
rscore_95 -1.0577429701129581
rscore_99 -7.045687268770552
nse [0.72927424]
nse_95 [-1.05774297]
nse_99 [-7.04568727]
kge [0.66342451]
ext_kge_95 [0.46825711]
ext_kge_99 [-0.26991715]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.4 -10.16 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.63 10.82 ... 0.9614
    uw2             (time, latitude, longitude) float32 108.1 103.2 ... 13.08
    vw2             (time, latitude, longitude) float32 113.0 117.0 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.84 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([137846 137870 137894], shape=(3,), dtype=int64) Times out: tf.Tensor(137894, shape=(), dtype=int64)
Times in: tf.Tensor([34250 34274 34298], shape=(3,), dtype=int64) Times out: tf.Tensor(34298, shape=(), dtype=int64)
Times in: tf.Tensor([67685 67709 67733], shape=(3,), dtype=int64) Times out: tf.Tensor(67733, shape=(), dtype=int64)
Times in: tf.Tensor([47445 47469 47493], shape=(3,), dtype=int64) Times out: tf.Tensor(47493, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_669&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_670 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1338 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1339 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_669 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1338 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_669 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1339 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.7868 - mse: 42.7336 - mae: 5.0275 - val_loss: 26.6787 - val_mse: 26.6147 - val_mae: 4.1344
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2658 - mse: 31.1991 - mae: 4.3565 - val_loss: 27.1234 - val_mse: 27.0544 - val_mae: 4.1821
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6740 - mse: 30.6033 - mae: 4.3154 - val_loss: 25.7606 - val_mse: 25.6878 - val_mae: 4.0796
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2802 - mse: 30.2059 - mae: 4.2851 - val_loss: 25.4337 - val_mse: 25.3578 - val_mae: 4.0521
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0287 - mse: 29.9516 - mae: 4.2602 - val_loss: 25.4030 - val_mse: 25.3246 - val_mae: 4.0491
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9058 - mse: 29.8264 - mae: 4.2536 - val_loss: 25.0412 - val_mse: 24.9605 - val_mae: 4.0203
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8542 - mse: 29.7725 - mae: 4.2480 - val_loss: 25.6467 - val_mse: 25.5641 - val_mae: 4.0685
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5341 - mse: 29.4502 - mae: 4.2258 - val_loss: 25.1385 - val_mse: 25.0535 - val_mae: 4.0286
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5537 - mse: 29.4677 - mae: 4.2270 - val_loss: 25.8539 - val_mse: 25.7668 - val_mae: 4.0869
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3217 - mse: 29.2334 - mae: 4.2077 - val_loss: 24.6375 - val_mse: 24.5479 - val_mae: 3.9852
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3380 - mse: 29.2473 - mae: 4.2074 - val_loss: 24.8610 - val_mse: 24.7692 - val_mae: 4.0064
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2453 - mse: 29.1524 - mae: 4.1984 - val_loss: 24.8700 - val_mse: 24.7759 - val_mae: 4.0067
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0007 - mse: 28.9058 - mae: 4.1780 - val_loss: 25.3041 - val_mse: 25.2079 - val_mae: 4.0378
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9052 - mse: 28.8079 - mae: 4.1691 - val_loss: 25.1852 - val_mse: 25.0865 - val_mae: 4.0286
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8169 - mse: 28.7168 - mae: 4.1640 - val_loss: 23.6653 - val_mse: 23.5636 - val_mae: 3.9021
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5085 - mse: 28.4056 - mae: 4.1397 - val_loss: 24.9516 - val_mse: 24.8472 - val_mae: 4.0093
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2817 - mse: 28.1760 - mae: 4.1259 - val_loss: 23.6621 - val_mse: 23.5553 - val_mae: 3.9041
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0987 - mse: 27.9907 - mae: 4.1097 - val_loss: 23.5129 - val_mse: 23.4039 - val_mae: 3.8913
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0014 - mse: 27.8916 - mae: 4.0978 - val_loss: 23.7578 - val_mse: 23.6473 - val_mae: 3.9098
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9282 - mse: 27.8170 - mae: 4.0958 - val_loss: 24.1029 - val_mse: 23.9908 - val_mae: 3.9387
bias -0.013721064
si 0.47360924
rmse 0.04898038
kgeprime [0.43953461]
rmse_95 0.05760492
rmse_99 0.06714165
pearson 0.8611490008757363
pearson_95 0.6123295281949825
pearson_99 0.516766816438901
rscore 0.7191752225461989
rscore_95 -1.1596689229602175
rscore_99 -6.588693151339549
nse [0.71917522]
nse_95 [-1.15966892]
nse_99 [-6.58869315]
kge [0.56688898]
ext_kge_95 [0.44199011]
ext_kge_99 [-0.19989689]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.4 -10.16 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.63 10.82 ... 0.9614
    uw2             (time, latitude, longitude) float32 108.1 103.2 ... 13.08
    vw2             (time, latitude, longitude) float32 113.0 117.0 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.87 14.84 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([5880 5904 5928], shape=(3,), dtype=int64) Times out: tf.Tensor(5928, shape=(), dtype=int64)
Times in: tf.Tensor([90006 90030 90054], shape=(3,), dtype=int64) Times out: tf.Tensor(90054, shape=(), dtype=int64)
Times in: tf.Tensor([57673 57697 57721], shape=(3,), dtype=int64) Times out: tf.Tensor(57721, shape=(), dtype=int64)
Times in: tf.Tensor([124249 124273 124297], shape=(3,), dtype=int64) Times out: tf.Tensor(124297, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_670&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_671 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1340 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1341 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_670 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1340 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_670 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1341 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.4269 - mse: 38.3787 - mae: 4.7831 - val_loss: 26.3338 - val_mse: 26.2752 - val_mae: 4.1239
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6002 - mse: 29.5364 - mae: 4.2463 - val_loss: 25.5766 - val_mse: 25.5068 - val_mae: 4.0688
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8552 - mse: 28.7807 - mae: 4.1901 - val_loss: 25.0899 - val_mse: 25.0107 - val_mae: 4.0270
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4483 - mse: 28.3654 - mae: 4.1560 - val_loss: 24.7625 - val_mse: 24.6755 - val_mae: 3.9976
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9424 - mse: 27.8515 - mae: 4.1165 - val_loss: 24.5624 - val_mse: 24.4672 - val_mae: 3.9790
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3536 - mse: 27.2545 - mae: 4.0709 - val_loss: 24.0139 - val_mse: 23.9111 - val_mae: 3.9323
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9306 - mse: 26.8247 - mae: 4.0398 - val_loss: 23.8395 - val_mse: 23.7304 - val_mae: 3.9190
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6841 - mse: 26.5721 - mae: 4.0161 - val_loss: 23.7901 - val_mse: 23.6751 - val_mae: 3.9154
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3344 - mse: 26.2172 - mae: 3.9919 - val_loss: 23.2080 - val_mse: 23.0884 - val_mae: 3.8740
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2375 - mse: 26.1158 - mae: 3.9833 - val_loss: 22.9893 - val_mse: 22.8656 - val_mae: 3.8500
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0483 - mse: 25.9228 - mae: 3.9678 - val_loss: 23.4549 - val_mse: 23.3276 - val_mae: 3.8906
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0848 - mse: 25.9560 - mae: 3.9666 - val_loss: 22.7819 - val_mse: 22.6515 - val_mae: 3.8326
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9110 - mse: 25.7792 - mae: 3.9527 - val_loss: 23.1627 - val_mse: 23.0294 - val_mae: 3.8626
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7503 - mse: 25.6159 - mae: 3.9388 - val_loss: 22.4141 - val_mse: 22.2784 - val_mae: 3.7974
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6724 - mse: 25.5357 - mae: 3.9362 - val_loss: 23.5199 - val_mse: 23.3820 - val_mae: 3.8949
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7384 - mse: 25.5996 - mae: 3.9384 - val_loss: 22.5582 - val_mse: 22.4184 - val_mae: 3.8127
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5425 - mse: 25.4018 - mae: 3.9236 - val_loss: 22.7938 - val_mse: 22.6523 - val_mae: 3.8319
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.5483 - mse: 25.4059 - mae: 3.9230 - val_loss: 23.0874 - val_mse: 22.9437 - val_mae: 3.8564
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4789 - mse: 25.3344 - mae: 3.9192 - val_loss: 22.5575 - val_mse: 22.4120 - val_mae: 3.8113
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3630 - mse: 25.2167 - mae: 3.9107 - val_loss: 22.2429 - val_mse: 22.0957 - val_mae: 3.7840
bias -0.0058666854
si 0.46799135
rmse 0.047006086
kgeprime [0.67943523]
rmse_95 0.05874622
rmse_99 0.072933465
pearson 0.8645291368227933
pearson_95 0.6209711101411683
pearson_99 0.5116687497602019
rscore 0.7431655029214475
rscore_95 -1.2047899116260048
rscore_99 -7.970996002837875
nse [0.7431655]
nse_95 [-1.20478991]
nse_99 [-7.970996]
kge [0.75787946]
ext_kge_95 [0.48659738]
ext_kge_99 [-0.26119993]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 0.9614
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 13.08
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([93918 93942 93966], shape=(3,), dtype=int64) Times out: tf.Tensor(93966, shape=(), dtype=int64)
Times in: tf.Tensor([80632 80656 80680], shape=(3,), dtype=int64) Times out: tf.Tensor(80680, shape=(), dtype=int64)
Times in: tf.Tensor([79723 79747 79771], shape=(3,), dtype=int64) Times out: tf.Tensor(79771, shape=(), dtype=int64)
Times in: tf.Tensor([39831 39855 39879], shape=(3,), dtype=int64) Times out: tf.Tensor(39879, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_671&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_672 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1342 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1343 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_671 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1342 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_671 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1343 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.9636 - mse: 39.9168 - mae: 4.8789 - val_loss: 26.8431 - val_mse: 26.7872 - val_mae: 4.1568
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1660 - mse: 30.1048 - mae: 4.2852 - val_loss: 25.6977 - val_mse: 25.6312 - val_mae: 4.0785
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3444 - mse: 29.2731 - mae: 4.2258 - val_loss: 26.4686 - val_mse: 26.3926 - val_mae: 4.1345
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9596 - mse: 28.8799 - mae: 4.1934 - val_loss: 25.3075 - val_mse: 25.2240 - val_mae: 4.0442
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7058 - mse: 28.6191 - mae: 4.1757 - val_loss: 24.9897 - val_mse: 24.8997 - val_mae: 4.0201
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4293 - mse: 28.3362 - mae: 4.1545 - val_loss: 25.0729 - val_mse: 24.9764 - val_mae: 4.0257
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3321 - mse: 28.2327 - mae: 4.1464 - val_loss: 24.9460 - val_mse: 24.8436 - val_mae: 4.0148
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1235 - mse: 28.0185 - mae: 4.1253 - val_loss: 24.9686 - val_mse: 24.8607 - val_mae: 4.0177
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9534 - mse: 27.8428 - mae: 4.1118 - val_loss: 25.3872 - val_mse: 25.2738 - val_mae: 4.0548
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7692 - mse: 27.6532 - mae: 4.0945 - val_loss: 24.4126 - val_mse: 24.2936 - val_mae: 3.9680
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6400 - mse: 27.5187 - mae: 4.0900 - val_loss: 24.3984 - val_mse: 24.2744 - val_mae: 3.9696
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5115 - mse: 27.3849 - mae: 4.0772 - val_loss: 24.3821 - val_mse: 24.2529 - val_mae: 3.9693
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2097 - mse: 27.0783 - mae: 4.0585 - val_loss: 23.8882 - val_mse: 23.7545 - val_mae: 3.9273
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0123 - mse: 26.8768 - mae: 4.0397 - val_loss: 23.7204 - val_mse: 23.5830 - val_mae: 3.9151
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7220 - mse: 26.5830 - mae: 4.0228 - val_loss: 23.3419 - val_mse: 23.2014 - val_mae: 3.8795
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5819 - mse: 26.4402 - mae: 4.0091 - val_loss: 24.2143 - val_mse: 24.0712 - val_mae: 3.9508
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4199 - mse: 26.2756 - mae: 3.9963 - val_loss: 23.3255 - val_mse: 23.1801 - val_mae: 3.8785
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4171 - mse: 26.2708 - mae: 3.9933 - val_loss: 23.2843 - val_mse: 23.1370 - val_mae: 3.8768
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2712 - mse: 26.1233 - mae: 3.9860 - val_loss: 23.9663 - val_mse: 23.8175 - val_mae: 3.9351
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2198 - mse: 26.0705 - mae: 3.9795 - val_loss: 23.4015 - val_mse: 23.2515 - val_mae: 3.8879
bias -0.009108359
si 0.47328842
rmse 0.048219807
kgeprime [0.58816959]
rmse_95 0.05865744
rmse_99 0.071726985
pearson 0.8611264156664709
pearson_95 0.6143905952359954
pearson_99 0.5820455733464889
rscore 0.731713564804497
rscore_95 -1.1705870236423173
rscore_99 -7.404781387829992
nse [0.73171356]
nse_95 [-1.17058702]
nse_99 [-7.40478139]
kge [0.68986554]
ext_kge_95 [0.48997606]
ext_kge_99 [-0.14441468]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.8 164.1 164.4 ... 169.7 170.0 170.3
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.16 -9.89 ... -3.617
    vgrd10m         (time, latitude, longitude) float32 10.82 10.98 ... 0.9614
    uw2             (time, latitude, longitude) float32 103.2 97.8 ... 13.08
    vw2             (time, latitude, longitude) float32 117.0 120.5 ... 0.9243
    wind_magnitude  (time, latitude, longitude) float32 14.84 14.78 ... 3.743
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([45011 45035 45059], shape=(3,), dtype=int64) Times out: tf.Tensor(45059, shape=(), dtype=int64)
Times in: tf.Tensor([4928 4952 4976], shape=(3,), dtype=int64) Times out: tf.Tensor(4976, shape=(), dtype=int64)
Times in: tf.Tensor([88787 88811 88835], shape=(3,), dtype=int64) Times out: tf.Tensor(88835, shape=(), dtype=int64)
Times in: tf.Tensor([5692 5716 5740], shape=(3,), dtype=int64) Times out: tf.Tensor(5740, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_672&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_673 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1344 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1345 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_672 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1344 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_672 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1345 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.0726 - mse: 39.0178 - mae: 4.8359 - val_loss: 27.5833 - val_mse: 27.5210 - val_mae: 4.2191
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3200 - mse: 31.2532 - mae: 4.3664 - val_loss: 26.7130 - val_mse: 26.6414 - val_mae: 4.1499
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8895 - mse: 29.8134 - mae: 4.2613 - val_loss: 26.0531 - val_mse: 25.9732 - val_mae: 4.0991
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4289 - mse: 29.3459 - mae: 4.2221 - val_loss: 25.9233 - val_mse: 25.8375 - val_mae: 4.0852
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1143 - mse: 29.0263 - mae: 4.2009 - val_loss: 25.3830 - val_mse: 25.2930 - val_mae: 4.0424
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7721 - mse: 28.6798 - mae: 4.1765 - val_loss: 25.1486 - val_mse: 25.0542 - val_mae: 4.0247
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4471 - mse: 28.3504 - mae: 4.1480 - val_loss: 24.6405 - val_mse: 24.5413 - val_mae: 3.9811
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0224 - mse: 27.9208 - mae: 4.1176 - val_loss: 24.1667 - val_mse: 24.0627 - val_mae: 3.9429
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4545 - mse: 27.3482 - mae: 4.0756 - val_loss: 23.6859 - val_mse: 23.5777 - val_mae: 3.8998
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1759 - mse: 27.0656 - mae: 4.0549 - val_loss: 23.4986 - val_mse: 23.3867 - val_mae: 3.8865
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9789 - mse: 26.8653 - mae: 4.0380 - val_loss: 23.5691 - val_mse: 23.4541 - val_mae: 3.8956
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8460 - mse: 26.7295 - mae: 4.0237 - val_loss: 23.2977 - val_mse: 23.1800 - val_mae: 3.8764
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7537 - mse: 26.6345 - mae: 4.0145 - val_loss: 23.0493 - val_mse: 22.9293 - val_mae: 3.8561
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4655 - mse: 26.3443 - mae: 3.9948 - val_loss: 23.5697 - val_mse: 23.4475 - val_mae: 3.9058
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4724 - mse: 26.3490 - mae: 3.9918 - val_loss: 23.4214 - val_mse: 23.2973 - val_mae: 3.8902
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3207 - mse: 26.1953 - mae: 3.9819 - val_loss: 23.1498 - val_mse: 23.0235 - val_mae: 3.8642
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2679 - mse: 26.1407 - mae: 3.9770 - val_loss: 23.0708 - val_mse: 22.9429 - val_mae: 3.8618
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1721 - mse: 26.0432 - mae: 3.9735 - val_loss: 22.6806 - val_mse: 22.5511 - val_mae: 3.8267
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1244 - mse: 25.9939 - mae: 3.9690 - val_loss: 22.9944 - val_mse: 22.8630 - val_mae: 3.8569
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0040 - mse: 25.8717 - mae: 3.9588 - val_loss: 22.4960 - val_mse: 22.3631 - val_mae: 3.8115
bias -0.0044197864
si 0.46719906
rmse 0.047289707
kgeprime [0.69935684]
rmse_95 0.063856006
rmse_99 0.07812028
pearson 0.8648248620129801
pearson_95 0.6317252914281944
pearson_99 0.6181960364877168
rscore 0.7454847815484982
rscore_95 -1.5488514819946366
rscore_99 -8.885903491011925
nse [0.74548478]
nse_95 [-1.54885148]
nse_99 [-8.88590349]
kge [0.7655229]
ext_kge_95 [0.49064379]
ext_kge_99 [-0.12298014]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.143
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.95
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([73400 73424 73448], shape=(3,), dtype=int64) Times out: tf.Tensor(73448, shape=(), dtype=int64)
Times in: tf.Tensor([151476 151500 151524], shape=(3,), dtype=int64) Times out: tf.Tensor(151524, shape=(), dtype=int64)
Times in: tf.Tensor([43127 43151 43175], shape=(3,), dtype=int64) Times out: tf.Tensor(43175, shape=(), dtype=int64)
Times in: tf.Tensor([11350 11374 11398], shape=(3,), dtype=int64) Times out: tf.Tensor(11398, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_673&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_674 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1346 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1347 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_673 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1346 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_673 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1347 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.6932 - mse: 40.6366 - mae: 4.9140 - val_loss: 28.8383 - val_mse: 28.7696 - val_mae: 4.3097
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2504 - mse: 31.1751 - mae: 4.3633 - val_loss: 28.1316 - val_mse: 28.0503 - val_mae: 4.2592
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4881 - mse: 30.4030 - mae: 4.3025 - val_loss: 27.3831 - val_mse: 27.2944 - val_mae: 4.2010
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0325 - mse: 29.9402 - mae: 4.2698 - val_loss: 27.2471 - val_mse: 27.1512 - val_mae: 4.1922
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6523 - mse: 29.5533 - mae: 4.2392 - val_loss: 26.8360 - val_mse: 26.7335 - val_mae: 4.1621
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4323 - mse: 29.3268 - mae: 4.2246 - val_loss: 27.5314 - val_mse: 27.4222 - val_mae: 4.2184
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0083 - mse: 28.8958 - mae: 4.1960 - val_loss: 27.0905 - val_mse: 26.9743 - val_mae: 4.1848
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7697 - mse: 28.6502 - mae: 4.1730 - val_loss: 26.5530 - val_mse: 26.4299 - val_mae: 4.1446
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2300 - mse: 28.1038 - mae: 4.1316 - val_loss: 25.6723 - val_mse: 25.5427 - val_mae: 4.0790
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9247 - mse: 27.7924 - mae: 4.1131 - val_loss: 25.6121 - val_mse: 25.4771 - val_mae: 4.0772
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6592 - mse: 27.5218 - mae: 4.0901 - val_loss: 25.5417 - val_mse: 25.4016 - val_mae: 4.0699
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4586 - mse: 27.3169 - mae: 4.0762 - val_loss: 24.8966 - val_mse: 24.7530 - val_mae: 4.0188
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3604 - mse: 27.2154 - mae: 4.0681 - val_loss: 24.7986 - val_mse: 24.6516 - val_mae: 4.0108
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2190 - mse: 27.0710 - mae: 4.0536 - val_loss: 25.3159 - val_mse: 25.1664 - val_mae: 4.0530
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0332 - mse: 26.8823 - mae: 4.0451 - val_loss: 25.1320 - val_mse: 24.9799 - val_mae: 4.0349
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1181 - mse: 26.9650 - mae: 4.0452 - val_loss: 24.5262 - val_mse: 24.3718 - val_mae: 3.9861
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9248 - mse: 26.7696 - mae: 4.0353 - val_loss: 25.8463 - val_mse: 25.6897 - val_mae: 4.0897
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8446 - mse: 26.6873 - mae: 4.0243 - val_loss: 25.1286 - val_mse: 24.9701 - val_mae: 4.0334
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7740 - mse: 26.6149 - mae: 4.0189 - val_loss: 24.9510 - val_mse: 24.7908 - val_mae: 4.0182
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7362 - mse: 26.5753 - mae: 4.0185 - val_loss: 24.6431 - val_mse: 24.4810 - val_mae: 3.9969
bias -0.010935475
si 0.4697256
rmse 0.04947828
kgeprime [0.55110583]
rmse_95 0.06028477
rmse_99 0.074203536
pearson 0.8628980039308948
pearson_95 0.5959438861572489
pearson_99 0.7335179777567304
rscore 0.7311620144975278
rscore_95 -0.9778203148473859
rscore_99 -7.600652224702227
nse [0.73116201]
nse_95 [-0.97782031]
nse_99 [-7.60065222]
kge [0.65972253]
ext_kge_95 [0.48370879]
ext_kge_99 [-0.3103256]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.143
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.95
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([69325 69349 69373], shape=(3,), dtype=int64) Times out: tf.Tensor(69373, shape=(), dtype=int64)
Times in: tf.Tensor([152660 152684 152708], shape=(3,), dtype=int64) Times out: tf.Tensor(152708, shape=(), dtype=int64)
Times in: tf.Tensor([27564 27588 27612], shape=(3,), dtype=int64) Times out: tf.Tensor(27612, shape=(), dtype=int64)
Times in: tf.Tensor([24440 24464 24488], shape=(3,), dtype=int64) Times out: tf.Tensor(24488, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_674&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_675 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1348 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1349 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_674 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1348 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_674 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1349 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.3950 - mse: 43.3320 - mae: 5.1007 - val_loss: 30.1215 - val_mse: 30.0422 - val_mae: 4.3999
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1305 - mse: 33.0429 - mae: 4.4983 - val_loss: 29.5981 - val_mse: 29.5025 - val_mae: 4.3603
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3403 - mse: 31.2376 - mae: 4.3655 - val_loss: 29.5738 - val_mse: 29.4636 - val_mae: 4.3566
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4524 - mse: 30.3367 - mae: 4.3034 - val_loss: 28.8901 - val_mse: 28.7695 - val_mae: 4.3072
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9131 - mse: 29.7889 - mae: 4.2569 - val_loss: 28.8429 - val_mse: 28.7148 - val_mae: 4.3065
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2100 - mse: 29.0786 - mae: 4.2073 - val_loss: 26.6332 - val_mse: 26.4983 - val_mae: 4.1425
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6593 - mse: 28.5213 - mae: 4.1641 - val_loss: 26.7639 - val_mse: 26.6229 - val_mae: 4.1563
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1492 - mse: 28.0057 - mae: 4.1223 - val_loss: 26.9678 - val_mse: 26.8221 - val_mae: 4.1747
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8262 - mse: 27.6780 - mae: 4.0997 - val_loss: 25.2696 - val_mse: 25.1193 - val_mae: 4.0401
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5560 - mse: 27.4038 - mae: 4.0776 - val_loss: 26.4869 - val_mse: 26.3328 - val_mae: 4.1382
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4455 - mse: 27.2897 - mae: 4.0706 - val_loss: 24.9724 - val_mse: 24.8150 - val_mae: 4.0153
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3418 - mse: 27.1829 - mae: 4.0586 - val_loss: 24.8795 - val_mse: 24.7189 - val_mae: 4.0105
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1979 - mse: 27.0359 - mae: 4.0529 - val_loss: 25.3926 - val_mse: 25.2293 - val_mae: 4.0493
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0495 - mse: 26.8847 - mae: 4.0343 - val_loss: 25.3409 - val_mse: 25.1750 - val_mae: 4.0475
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0022 - mse: 26.8347 - mae: 4.0337 - val_loss: 24.6130 - val_mse: 24.4444 - val_mae: 3.9874
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8745 - mse: 26.7046 - mae: 4.0269 - val_loss: 26.1297 - val_mse: 25.9585 - val_mae: 4.1055
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7947 - mse: 26.6227 - mae: 4.0149 - val_loss: 25.2010 - val_mse: 25.0281 - val_mae: 4.0310
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7856 - mse: 26.6118 - mae: 4.0107 - val_loss: 25.3302 - val_mse: 25.1554 - val_mae: 4.0422
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6515 - mse: 26.4756 - mae: 4.0047 - val_loss: 24.3185 - val_mse: 24.1422 - val_mae: 3.9606
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5862 - mse: 26.4089 - mae: 3.9988 - val_loss: 25.5882 - val_mse: 25.4102 - val_mae: 4.0626
bias -0.015029058
si 0.4654819
rmse 0.050408572
kgeprime [0.43962721]
rmse_95 0.05680356
rmse_99 0.072930194
pearson 0.8653465473872968
pearson_95 0.6255042174487306
pearson_99 0.7381268796798677
rscore 0.7243137143505118
rscore_95 -0.6845695496831963
rscore_99 -7.433311387653939
nse [0.72431371]
nse_95 [-0.68456955]
nse_99 [-7.43331139]
kge [0.56464275]
ext_kge_95 [0.53845319]
ext_kge_99 [-0.38848041]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.659 -9.488 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.09 11.15 ... 1.797
    uw2             (time, latitude, longitude) float32 93.29 90.02 ... 11.01
    vw2             (time, latitude, longitude) float32 122.9 124.3 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.7 14.64 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([38162 38186 38210], shape=(3,), dtype=int64) Times out: tf.Tensor(38210, shape=(), dtype=int64)
Times in: tf.Tensor([1756 1780 1804], shape=(3,), dtype=int64) Times out: tf.Tensor(1804, shape=(), dtype=int64)
Times in: tf.Tensor([11438 11462 11486], shape=(3,), dtype=int64) Times out: tf.Tensor(11486, shape=(), dtype=int64)
Times in: tf.Tensor([51291 51315 51339], shape=(3,), dtype=int64) Times out: tf.Tensor(51339, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_675&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_676 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1350 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1351 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_675 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1350 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_675 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1351 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 49.6975 - mse: 49.6489 - mae: 5.4300 - val_loss: 31.9157 - val_mse: 31.8577 - val_mae: 4.5247
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9198 - mse: 35.8585 - mae: 4.6625 - val_loss: 29.7711 - val_mse: 29.7065 - val_mae: 4.3787
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1530 - mse: 34.0854 - mae: 4.5388 - val_loss: 30.4739 - val_mse: 30.4030 - val_mae: 4.4303
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4045 - mse: 33.3307 - mae: 4.4959 - val_loss: 29.1922 - val_mse: 29.1153 - val_mae: 4.3404
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8724 - mse: 32.7934 - mae: 4.4605 - val_loss: 29.6008 - val_mse: 29.5196 - val_mae: 4.3685
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5669 - mse: 32.4837 - mae: 4.4367 - val_loss: 28.3862 - val_mse: 28.3009 - val_mae: 4.2806
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3081 - mse: 32.2209 - mae: 4.4205 - val_loss: 28.4151 - val_mse: 28.3256 - val_mae: 4.2824
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8795 - mse: 31.7875 - mae: 4.3863 - val_loss: 27.7468 - val_mse: 27.6520 - val_mae: 4.2336
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3588 - mse: 31.2612 - mae: 4.3520 - val_loss: 27.6613 - val_mse: 27.5605 - val_mae: 4.2331
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8714 - mse: 30.7679 - mae: 4.3164 - val_loss: 26.9705 - val_mse: 26.8643 - val_mae: 4.1845
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6820 - mse: 30.5730 - mae: 4.3041 - val_loss: 26.8860 - val_mse: 26.7745 - val_mae: 4.1806
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4604 - mse: 30.3463 - mae: 4.2895 - val_loss: 26.0397 - val_mse: 25.9233 - val_mae: 4.1145
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0479 - mse: 29.9292 - mae: 4.2575 - val_loss: 27.2999 - val_mse: 27.1789 - val_mae: 4.2103
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9357 - mse: 29.8127 - mae: 4.2430 - val_loss: 26.5001 - val_mse: 26.3752 - val_mae: 4.1487
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8698 - mse: 29.7429 - mae: 4.2376 - val_loss: 25.9475 - val_mse: 25.8187 - val_mae: 4.1103
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5807 - mse: 29.4499 - mae: 4.2203 - val_loss: 26.3429 - val_mse: 26.2101 - val_mae: 4.1397
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6561 - mse: 29.5214 - mae: 4.2220 - val_loss: 26.4766 - val_mse: 26.3399 - val_mae: 4.1490
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5230 - mse: 29.3847 - mae: 4.2104 - val_loss: 25.6725 - val_mse: 25.5325 - val_mae: 4.0852
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4646 - mse: 29.3230 - mae: 4.2073 - val_loss: 25.8883 - val_mse: 25.7450 - val_mae: 4.1034
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3654 - mse: 29.2207 - mae: 4.2026 - val_loss: 25.3887 - val_mse: 25.2425 - val_mae: 4.0649
bias -0.0050879763
si 0.4726039
rmse 0.050241955
kgeprime [0.70818043]
rmse_95 0.06524093
rmse_99 0.07653161
pearson 0.8608350693355624
pearson_95 0.706099068071617
pearson_99 0.6873856670391004
rscore 0.7380197460965126
rscore_95 -0.9717993070716866
rscore_99 -8.086009218056232
nse [0.73801975]
nse_95 [-0.97179931]
nse_99 [-8.08600922]
kge [0.7748297]
ext_kge_95 [0.56869719]
ext_kge_99 [-0.4238197]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.6 166.9 167.2 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.439 -9.289 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.48 10.25 ... -1.613
    uw2             (time, latitude, longitude) float32 89.09 86.29 ... 6.584
    vw2             (time, latitude, longitude) float32 109.8 105.0 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 14.1 13.83 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([154781 154805 154829], shape=(3,), dtype=int64) Times out: tf.Tensor(154829, shape=(), dtype=int64)
Times in: tf.Tensor([58812 58836 58860], shape=(3,), dtype=int64) Times out: tf.Tensor(58860, shape=(), dtype=int64)
Times in: tf.Tensor([108958 108982 109006], shape=(3,), dtype=int64) Times out: tf.Tensor(109006, shape=(), dtype=int64)
Times in: tf.Tensor([87828 87852 87876], shape=(3,), dtype=int64) Times out: tf.Tensor(87876, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_676&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_677 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1352 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1353 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_676 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1352 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_676 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1353 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 65.5878 - mse: 65.5448 - mae: 6.2189 - val_loss: 41.0360 - val_mse: 40.9806 - val_mae: 5.0701
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 48.9819 - mse: 48.9230 - mae: 5.3911 - val_loss: 38.5489 - val_mse: 38.4876 - val_mae: 4.9136
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.5675 - mse: 47.5046 - mae: 5.3200 - val_loss: 37.7024 - val_mse: 37.6379 - val_mae: 4.8593
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 47.0861 - mse: 47.0209 - mae: 5.2870 - val_loss: 37.3584 - val_mse: 37.2924 - val_mae: 4.8358
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.7640 - mse: 46.6976 - mae: 5.2690 - val_loss: 37.0332 - val_mse: 36.9662 - val_mae: 4.8166
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.4693 - mse: 46.4020 - mae: 5.2631 - val_loss: 36.9630 - val_mse: 36.8954 - val_mae: 4.8097
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.3378 - mse: 46.2701 - mae: 5.2537 - val_loss: 36.9574 - val_mse: 36.8891 - val_mae: 4.8063
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 46.2360 - mse: 46.1674 - mae: 5.2444 - val_loss: 36.7029 - val_mse: 36.6342 - val_mae: 4.7916
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.9033 - mse: 45.8343 - mae: 5.2227 - val_loss: 36.6719 - val_mse: 36.6026 - val_mae: 4.7878
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.7153 - mse: 45.6458 - mae: 5.2170 - val_loss: 36.5043 - val_mse: 36.4344 - val_mae: 4.7774
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.4522 - mse: 45.3820 - mae: 5.2097 - val_loss: 36.4521 - val_mse: 36.3815 - val_mae: 4.7785
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.3551 - mse: 45.2841 - mae: 5.1962 - val_loss: 36.2677 - val_mse: 36.1963 - val_mae: 4.7649
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.1213 - mse: 45.0498 - mae: 5.1880 - val_loss: 36.2210 - val_mse: 36.1492 - val_mae: 4.7650
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.1438 - mse: 45.0718 - mae: 5.1888 - val_loss: 36.3217 - val_mse: 36.2492 - val_mae: 4.7690
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.9470 - mse: 44.8742 - mae: 5.1742 - val_loss: 36.1694 - val_mse: 36.0963 - val_mae: 4.7621
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 45.0893 - mse: 45.0161 - mae: 5.1832 - val_loss: 36.4611 - val_mse: 36.3873 - val_mae: 4.7821
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.7062 - mse: 44.6321 - mae: 5.1644 - val_loss: 36.1084 - val_mse: 36.0341 - val_mae: 4.7620
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.4911 - mse: 44.4164 - mae: 5.1515 - val_loss: 36.0661 - val_mse: 35.9910 - val_mae: 4.7579
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.4832 - mse: 44.4079 - mae: 5.1462 - val_loss: 36.0843 - val_mse: 36.0085 - val_mae: 4.7634
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.3613 - mse: 44.2852 - mae: 5.1453 - val_loss: 36.5650 - val_mse: 36.4885 - val_mae: 4.7839
bias -0.0076728226
si 0.533155
rmse 0.060405705
kgeprime [0.55756886]
rmse_95 0.10002171
rmse_99 0.12001762
pearson 0.8225857305250933
pearson_95 0.627647041579218
pearson_99 0.45735328038964024
rscore 0.6676898181242508
rscore_95 -3.726170541335203
rscore_99 -29.080714897929685
nse [0.66768982]
nse_95 [-3.72617054]
nse_99 [-29.0807149]
kge [0.64854281]
ext_kge_95 [0.49298098]
ext_kge_99 [-0.40221824]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([52025 52049 52073], shape=(3,), dtype=int64) Times out: tf.Tensor(52073, shape=(), dtype=int64)
Times in: tf.Tensor([53953 53977 54001], shape=(3,), dtype=int64) Times out: tf.Tensor(54001, shape=(), dtype=int64)
Times in: tf.Tensor([127354 127378 127402], shape=(3,), dtype=int64) Times out: tf.Tensor(127402, shape=(), dtype=int64)
Times in: tf.Tensor([97303 97327 97351], shape=(3,), dtype=int64) Times out: tf.Tensor(97351, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_677&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_678 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1354 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1355 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_677 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1354 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_677 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1355 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.6531 - mse: 54.6090 - mae: 5.6989 - val_loss: 38.9308 - val_mse: 38.8813 - val_mae: 4.9549
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9439 - mse: 40.8911 - mae: 4.9827 - val_loss: 37.9543 - val_mse: 37.8987 - val_mae: 4.9012
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7151 - mse: 39.6564 - mae: 4.9086 - val_loss: 36.4969 - val_mse: 36.4355 - val_mae: 4.8173
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2505 - mse: 39.1870 - mae: 4.8773 - val_loss: 36.4568 - val_mse: 36.3916 - val_mae: 4.8077
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9492 - mse: 38.8826 - mae: 4.8572 - val_loss: 36.1307 - val_mse: 36.0631 - val_mae: 4.7794
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.8078 - mse: 38.7391 - mae: 4.8519 - val_loss: 36.0073 - val_mse: 35.9376 - val_mae: 4.7801
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4414 - mse: 38.3707 - mae: 4.8256 - val_loss: 35.7604 - val_mse: 35.6887 - val_mae: 4.7710
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2858 - mse: 38.2130 - mae: 4.8213 - val_loss: 35.5682 - val_mse: 35.4941 - val_mae: 4.7512
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0941 - mse: 38.0186 - mae: 4.8039 - val_loss: 35.7867 - val_mse: 35.7100 - val_mae: 4.7605
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9152 - mse: 37.8369 - mae: 4.7962 - val_loss: 36.0191 - val_mse: 35.9392 - val_mae: 4.7878
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7488 - mse: 37.6671 - mae: 4.7877 - val_loss: 36.5570 - val_mse: 36.4735 - val_mae: 4.8241
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4842 - mse: 37.3987 - mae: 4.7679 - val_loss: 35.8140 - val_mse: 35.7261 - val_mae: 4.7779
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2260 - mse: 37.1355 - mae: 4.7518 - val_loss: 36.3557 - val_mse: 36.2626 - val_mae: 4.8088
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8703 - mse: 36.7744 - mae: 4.7281 - val_loss: 34.4775 - val_mse: 34.3787 - val_mae: 4.6848
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.5532 - mse: 36.4517 - mae: 4.7098 - val_loss: 34.1664 - val_mse: 34.0624 - val_mae: 4.6646
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.1549 - mse: 36.0485 - mae: 4.6808 - val_loss: 34.3053 - val_mse: 34.1967 - val_mae: 4.6713
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9801 - mse: 35.8695 - mae: 4.6675 - val_loss: 33.7892 - val_mse: 33.6765 - val_mae: 4.6380
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.7893 - mse: 35.6744 - mae: 4.6532 - val_loss: 33.8115 - val_mse: 33.6947 - val_mae: 4.6444
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.6898 - mse: 35.5714 - mae: 4.6464 - val_loss: 33.2943 - val_mse: 33.1740 - val_mae: 4.6085
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 35.4114 - mse: 35.2892 - mae: 4.6254 - val_loss: 33.3536 - val_mse: 33.2297 - val_mae: 4.6201
bias -0.0070439572
si 0.51660013
rmse 0.057645172
kgeprime [0.64440773]
rmse_95 0.07976441
rmse_99 0.09455619
pearson 0.8343992159490529
pearson_95 0.6688006021214923
pearson_99 0.5579983318505044
rscore 0.6900152248226168
rscore_95 -2.065925655691003
rscore_99 -16.837877636007203
nse [0.69001522]
nse_95 [-2.06592566]
nse_99 [-16.83787764]
kge [0.72546647]
ext_kge_95 [0.52594377]
ext_kge_99 [-0.5821547]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 1.107
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 14.56
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([80189 80213 80237], shape=(3,), dtype=int64) Times out: tf.Tensor(80237, shape=(), dtype=int64)
Times in: tf.Tensor([9562 9586 9610], shape=(3,), dtype=int64) Times out: tf.Tensor(9610, shape=(), dtype=int64)
Times in: tf.Tensor([64876 64900 64924], shape=(3,), dtype=int64) Times out: tf.Tensor(64924, shape=(), dtype=int64)
Times in: tf.Tensor([14073 14097 14121], shape=(3,), dtype=int64) Times out: tf.Tensor(14121, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_678&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_679 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1356 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1357 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_678 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1356 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_678 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1357 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.5897 - mse: 42.5364 - mae: 5.0118 - val_loss: 27.0105 - val_mse: 26.9419 - val_mae: 4.1565
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5601 - mse: 30.4847 - mae: 4.3082 - val_loss: 26.4482 - val_mse: 26.3675 - val_mae: 4.1244
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8785 - mse: 29.7951 - mae: 4.2601 - val_loss: 26.6623 - val_mse: 26.5762 - val_mae: 4.1380
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5916 - mse: 29.5038 - mae: 4.2361 - val_loss: 25.2981 - val_mse: 25.2084 - val_mae: 4.0368
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4143 - mse: 29.3225 - mae: 4.2193 - val_loss: 25.5073 - val_mse: 25.4132 - val_mae: 4.0545
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0467 - mse: 28.9507 - mae: 4.1924 - val_loss: 25.0034 - val_mse: 24.9051 - val_mae: 4.0174
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9917 - mse: 28.8915 - mae: 4.1910 - val_loss: 25.0845 - val_mse: 24.9824 - val_mae: 4.0252
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6683 - mse: 28.5640 - mae: 4.1615 - val_loss: 24.8515 - val_mse: 24.7446 - val_mae: 4.0042
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3644 - mse: 28.2556 - mae: 4.1395 - val_loss: 24.0235 - val_mse: 23.9125 - val_mae: 3.9367
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1198 - mse: 28.0069 - mae: 4.1225 - val_loss: 23.8636 - val_mse: 23.7486 - val_mae: 3.9172
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8773 - mse: 27.7604 - mae: 4.1011 - val_loss: 23.5155 - val_mse: 23.3966 - val_mae: 3.8945
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6674 - mse: 27.5470 - mae: 4.0904 - val_loss: 23.3254 - val_mse: 23.2032 - val_mae: 3.8777
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3666 - mse: 27.2431 - mae: 4.0684 - val_loss: 23.4127 - val_mse: 23.2876 - val_mae: 3.8879
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2547 - mse: 27.1284 - mae: 4.0552 - val_loss: 23.2270 - val_mse: 23.0991 - val_mae: 3.8689
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1793 - mse: 27.0502 - mae: 4.0475 - val_loss: 23.5086 - val_mse: 23.3780 - val_mae: 3.8952
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0019 - mse: 26.8707 - mae: 4.0342 - val_loss: 22.9187 - val_mse: 22.7863 - val_mae: 3.8463
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9854 - mse: 26.8523 - mae: 4.0326 - val_loss: 22.8930 - val_mse: 22.7586 - val_mae: 3.8416
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8376 - mse: 26.7026 - mae: 4.0240 - val_loss: 22.7890 - val_mse: 22.6528 - val_mae: 3.8351
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8494 - mse: 26.7128 - mae: 4.0236 - val_loss: 22.7078 - val_mse: 22.5701 - val_mae: 3.8316
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6763 - mse: 26.5381 - mae: 4.0073 - val_loss: 22.7975 - val_mse: 22.6586 - val_mae: 3.8349
bias -0.0067182467
si 0.47433123
rmse 0.047601055
kgeprime [0.6381161]
rmse_95 0.062365998
rmse_99 0.073603675
pearson 0.8607336055988385
pearson_95 0.6154543805791746
pearson_99 0.49099959517685654
rscore 0.7355838903978306
rscore_95 -1.7279658562322249
rscore_99 -8.392792618684405
nse [0.73558389]
nse_95 [-1.72796586]
nse_99 [-8.39279262]
kge [0.72717348]
ext_kge_95 [0.45741614]
ext_kge_99 [-0.10747856]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.0 170.3 170.6
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.457
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.143
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.95
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 1.306
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.641
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([636 660 684], shape=(3,), dtype=int64) Times out: tf.Tensor(684, shape=(), dtype=int64)
Times in: tf.Tensor([32641 32665 32689], shape=(3,), dtype=int64) Times out: tf.Tensor(32689, shape=(), dtype=int64)
Times in: tf.Tensor([37042 37066 37090], shape=(3,), dtype=int64) Times out: tf.Tensor(37090, shape=(), dtype=int64)
Times in: tf.Tensor([94504 94528 94552], shape=(3,), dtype=int64) Times out: tf.Tensor(94552, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_679&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_680 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1358 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1359 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_679 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1358 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_679 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1359 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.9729 - mse: 46.9174 - mae: 5.2798 - val_loss: 29.7641 - val_mse: 29.6933 - val_mae: 4.3659
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4819 - mse: 33.4027 - mae: 4.5154 - val_loss: 28.2922 - val_mse: 28.2048 - val_mae: 4.2623
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9906 - mse: 31.8971 - mae: 4.4079 - val_loss: 27.5919 - val_mse: 27.4934 - val_mae: 4.2121
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5726 - mse: 31.4705 - mae: 4.3771 - val_loss: 27.2607 - val_mse: 27.1555 - val_mae: 4.1888
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2166 - mse: 31.1092 - mae: 4.3466 - val_loss: 26.9729 - val_mse: 26.8634 - val_mae: 4.1675
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8619 - mse: 30.7499 - mae: 4.3270 - val_loss: 26.9211 - val_mse: 26.8068 - val_mae: 4.1635
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6280 - mse: 30.5117 - mae: 4.3062 - val_loss: 26.8246 - val_mse: 26.7059 - val_mae: 4.1606
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5230 - mse: 30.4020 - mae: 4.2957 - val_loss: 26.5202 - val_mse: 26.3968 - val_mae: 4.1364
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3822 - mse: 30.2566 - mae: 4.2853 - val_loss: 26.5559 - val_mse: 26.4279 - val_mae: 4.1419
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0585 - mse: 29.9282 - mae: 4.2614 - val_loss: 26.4223 - val_mse: 26.2896 - val_mae: 4.1344
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8632 - mse: 29.7280 - mae: 4.2460 - val_loss: 26.0613 - val_mse: 25.9236 - val_mae: 4.1030
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6072 - mse: 29.4666 - mae: 4.2316 - val_loss: 25.8161 - val_mse: 25.6730 - val_mae: 4.0866
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3549 - mse: 29.2095 - mae: 4.2100 - val_loss: 25.3489 - val_mse: 25.2012 - val_mae: 4.0497
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9729 - mse: 28.8231 - mae: 4.1796 - val_loss: 24.9181 - val_mse: 24.7663 - val_mae: 4.0133
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7113 - mse: 28.5581 - mae: 4.1595 - val_loss: 24.9336 - val_mse: 24.7791 - val_mae: 4.0174
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7516 - mse: 28.5959 - mae: 4.1603 - val_loss: 24.7667 - val_mse: 24.6098 - val_mae: 4.0051
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4829 - mse: 28.3246 - mae: 4.1421 - val_loss: 24.5783 - val_mse: 24.4191 - val_mae: 3.9907
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5258 - mse: 28.3655 - mae: 4.1441 - val_loss: 24.3318 - val_mse: 24.1706 - val_mae: 3.9628
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3354 - mse: 28.1732 - mae: 4.1291 - val_loss: 24.3297 - val_mse: 24.1667 - val_mae: 3.9687
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1992 - mse: 28.0352 - mae: 4.1221 - val_loss: 24.9458 - val_mse: 24.7811 - val_mae: 4.0169
bias -0.009091641
si 0.4741473
rmse 0.049780603
kgeprime [0.56668476]
rmse_95 0.06626367
rmse_99 0.08142813
pearson 0.8607290558886536
pearson_95 0.6319649431142942
pearson_99 0.7601614969846194
rscore 0.7305373771237095
rscore_95 -1.3038056187351605
rscore_99 -9.83303729990659
nse [0.73053738]
nse_95 [-1.30380562]
nse_99 [-9.8330373]
kge [0.67297924]
ext_kge_95 [0.52701197]
ext_kge_99 [-0.23999131]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.797
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.01
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([106398 106422 106446], shape=(3,), dtype=int64) Times out: tf.Tensor(106446, shape=(), dtype=int64)
Times in: tf.Tensor([129489 129513 129537], shape=(3,), dtype=int64) Times out: tf.Tensor(129537, shape=(), dtype=int64)
Times in: tf.Tensor([57757 57781 57805], shape=(3,), dtype=int64) Times out: tf.Tensor(57805, shape=(), dtype=int64)
Times in: tf.Tensor([79899 79923 79947], shape=(3,), dtype=int64) Times out: tf.Tensor(79947, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_680&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_681 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1360 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1361 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_680 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1360 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_680 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1361 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.9236 - mse: 41.8702 - mae: 4.9813 - val_loss: 29.0958 - val_mse: 29.0311 - val_mae: 4.3228
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9959 - mse: 31.9261 - mae: 4.4106 - val_loss: 27.8404 - val_mse: 27.7665 - val_mae: 4.2293
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3869 - mse: 31.3096 - mae: 4.3638 - val_loss: 27.9390 - val_mse: 27.8582 - val_mae: 4.2410
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0014 - mse: 30.9169 - mae: 4.3348 - val_loss: 27.3386 - val_mse: 27.2502 - val_mae: 4.1990
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5069 - mse: 30.4148 - mae: 4.2985 - val_loss: 27.0890 - val_mse: 26.9930 - val_mae: 4.1803
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2093 - mse: 30.1095 - mae: 4.2764 - val_loss: 26.7853 - val_mse: 26.6815 - val_mae: 4.1585
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9203 - mse: 29.8125 - mae: 4.2570 - val_loss: 26.8201 - val_mse: 26.7083 - val_mae: 4.1642
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7120 - mse: 29.5964 - mae: 4.2395 - val_loss: 26.6897 - val_mse: 26.5703 - val_mae: 4.1528
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3560 - mse: 29.2327 - mae: 4.2156 - val_loss: 26.2363 - val_mse: 26.1094 - val_mae: 4.1164
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9672 - mse: 28.8369 - mae: 4.1811 - val_loss: 26.0416 - val_mse: 25.9077 - val_mae: 4.1014
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7690 - mse: 28.6316 - mae: 4.1699 - val_loss: 25.8725 - val_mse: 25.7317 - val_mae: 4.0934
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.4105 - mse: 28.2667 - mae: 4.1409 - val_loss: 25.3143 - val_mse: 25.1678 - val_mae: 4.0442
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2159 - mse: 28.0671 - mae: 4.1248 - val_loss: 26.0458 - val_mse: 25.8947 - val_mae: 4.1070
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1113 - mse: 27.9579 - mae: 4.1207 - val_loss: 25.5904 - val_mse: 25.4351 - val_mae: 4.0722
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9275 - mse: 27.7705 - mae: 4.1017 - val_loss: 25.1583 - val_mse: 24.9999 - val_mae: 4.0350
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8378 - mse: 27.6779 - mae: 4.0958 - val_loss: 25.0953 - val_mse: 24.9339 - val_mae: 4.0308
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6671 - mse: 27.5043 - mae: 4.0845 - val_loss: 25.3153 - val_mse: 25.1514 - val_mae: 4.0481
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5179 - mse: 27.3527 - mae: 4.0793 - val_loss: 25.0092 - val_mse: 24.8430 - val_mae: 4.0194
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4788 - mse: 27.3114 - mae: 4.0733 - val_loss: 24.6786 - val_mse: 24.5102 - val_mae: 3.9951
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4642 - mse: 27.2949 - mae: 4.0711 - val_loss: 25.0517 - val_mse: 24.8817 - val_mae: 4.0270
bias -0.009565406
si 0.4717483
rmse 0.049881518
kgeprime [0.57400974]
rmse_95 0.06367122
rmse_99 0.07927212
pearson 0.8614897638686868
pearson_95 0.6788591674492525
pearson_99 0.7529962914479492
rscore 0.7322532686907612
rscore_95 -1.097408041282414
rscore_99 -10.773165487962393
nse [0.73225327]
nse_95 [-1.09740804]
nse_99 [-10.77316549]
kge [0.67960188]
ext_kge_95 [0.57752212]
ext_kge_99 [-0.44599167]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.797
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.01
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([47238 47262 47286], shape=(3,), dtype=int64) Times out: tf.Tensor(47286, shape=(), dtype=int64)
Times in: tf.Tensor([80349 80373 80397], shape=(3,), dtype=int64) Times out: tf.Tensor(80397, shape=(), dtype=int64)
Times in: tf.Tensor([107145 107169 107193], shape=(3,), dtype=int64) Times out: tf.Tensor(107193, shape=(), dtype=int64)
Times in: tf.Tensor([102081 102105 102129], shape=(3,), dtype=int64) Times out: tf.Tensor(102129, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_681&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_682 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1362 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1363 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_681 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1362 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_681 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1363 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 40.7521 - mse: 40.6998 - mae: 4.9304 - val_loss: 29.3884 - val_mse: 29.3264 - val_mae: 4.3392
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4211 - mse: 32.3533 - mae: 4.4390 - val_loss: 28.6222 - val_mse: 28.5497 - val_mae: 4.2926
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7348 - mse: 31.6589 - mae: 4.3921 - val_loss: 28.1312 - val_mse: 28.0523 - val_mae: 4.2528
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4167 - mse: 31.3355 - mae: 4.3654 - val_loss: 28.1727 - val_mse: 28.0892 - val_mae: 4.2570
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0177 - mse: 30.9312 - mae: 4.3341 - val_loss: 27.7614 - val_mse: 27.6713 - val_mae: 4.2323
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7633 - mse: 30.6695 - mae: 4.3123 - val_loss: 27.3774 - val_mse: 27.2798 - val_mae: 4.2047
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3473 - mse: 30.2455 - mae: 4.2842 - val_loss: 27.3349 - val_mse: 27.2290 - val_mae: 4.2054
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1045 - mse: 29.9944 - mae: 4.2666 - val_loss: 27.0718 - val_mse: 26.9576 - val_mae: 4.1892
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9504 - mse: 29.8323 - mae: 4.2518 - val_loss: 26.7851 - val_mse: 26.6629 - val_mae: 4.1706
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5617 - mse: 29.4356 - mae: 4.2218 - val_loss: 26.7503 - val_mse: 26.6202 - val_mae: 4.1674
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2973 - mse: 29.1632 - mae: 4.2080 - val_loss: 26.6213 - val_mse: 26.4834 - val_mae: 4.1606
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0919 - mse: 28.9502 - mae: 4.1939 - val_loss: 26.1434 - val_mse: 25.9980 - val_mae: 4.1167
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7528 - mse: 28.6037 - mae: 4.1630 - val_loss: 26.3586 - val_mse: 26.2059 - val_mae: 4.1359
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5596 - mse: 28.4038 - mae: 4.1514 - val_loss: 25.7478 - val_mse: 25.5891 - val_mae: 4.0858
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2181 - mse: 28.0569 - mae: 4.1224 - val_loss: 25.3625 - val_mse: 25.1990 - val_mae: 4.0564
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9861 - mse: 27.8203 - mae: 4.1077 - val_loss: 25.2661 - val_mse: 25.0985 - val_mae: 4.0500
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7253 - mse: 27.5560 - mae: 4.0875 - val_loss: 25.4230 - val_mse: 25.2523 - val_mae: 4.0604
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6503 - mse: 27.4778 - mae: 4.0817 - val_loss: 26.3524 - val_mse: 26.1782 - val_mae: 4.1301
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6089 - mse: 27.4334 - mae: 4.0801 - val_loss: 25.0592 - val_mse: 24.8824 - val_mae: 4.0316
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4648 - mse: 27.2866 - mae: 4.0702 - val_loss: 25.0869 - val_mse: 24.9075 - val_mae: 4.0305
bias -0.0080829095
si 0.47147113
rmse 0.049907386
kgeprime [0.62224776]
rmse_95 0.0643018
rmse_99 0.07871824
pearson 0.861622445278092
pearson_95 0.6973944058281053
pearson_99 0.7453710229302923
rscore 0.7354226408298352
rscore_95 -1.029103700123199
rscore_99 -9.300122961092317
nse [0.73542264]
nse_95 [-1.0291037]
nse_99 [-9.30012296]
kge [0.71639355]
ext_kge_95 [0.58213475]
ext_kge_99 [-0.40846001]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.797
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.01
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([102676 102700 102724], shape=(3,), dtype=int64) Times out: tf.Tensor(102724, shape=(), dtype=int64)
Times in: tf.Tensor([125844 125868 125892], shape=(3,), dtype=int64) Times out: tf.Tensor(125892, shape=(), dtype=int64)
Times in: tf.Tensor([18015 18039 18063], shape=(3,), dtype=int64) Times out: tf.Tensor(18063, shape=(), dtype=int64)
Times in: tf.Tensor([22236 22260 22284], shape=(3,), dtype=int64) Times out: tf.Tensor(22284, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_682&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_683 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1364 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1365 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_682 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1364 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_682 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1365 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 48.2886 - mse: 48.2390 - mae: 5.3370 - val_loss: 30.5324 - val_mse: 30.4723 - val_mae: 4.4118
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1331 - mse: 35.0704 - mae: 4.6095 - val_loss: 29.5143 - val_mse: 29.4498 - val_mae: 4.3493
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4021 - mse: 34.3361 - mae: 4.5601 - val_loss: 28.9981 - val_mse: 28.9305 - val_mae: 4.3140
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1236 - mse: 34.0544 - mae: 4.5418 - val_loss: 28.5625 - val_mse: 28.4918 - val_mae: 4.2808
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9589 - mse: 33.8865 - mae: 4.5302 - val_loss: 29.0558 - val_mse: 28.9813 - val_mae: 4.3265
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8070 - mse: 33.7306 - mae: 4.5175 - val_loss: 28.6352 - val_mse: 28.5567 - val_mae: 4.2947
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6128 - mse: 33.5322 - mae: 4.5022 - val_loss: 28.2458 - val_mse: 28.1629 - val_mae: 4.2641
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3144 - mse: 33.2292 - mae: 4.4841 - val_loss: 28.3023 - val_mse: 28.2149 - val_mae: 4.2742
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3096 - mse: 33.2198 - mae: 4.4816 - val_loss: 28.3105 - val_mse: 28.2180 - val_mae: 4.2737
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0646 - mse: 32.9699 - mae: 4.4616 - val_loss: 28.0251 - val_mse: 27.9278 - val_mae: 4.2529
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8027 - mse: 32.7031 - mae: 4.4487 - val_loss: 27.9835 - val_mse: 27.8814 - val_mae: 4.2523
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6508 - mse: 32.5464 - mae: 4.4401 - val_loss: 27.8694 - val_mse: 27.7625 - val_mae: 4.2467
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6538 - mse: 32.5449 - mae: 4.4353 - val_loss: 27.6385 - val_mse: 27.5270 - val_mae: 4.2225
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3808 - mse: 32.2670 - mae: 4.4113 - val_loss: 27.6146 - val_mse: 27.4984 - val_mae: 4.2229
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3628 - mse: 32.2445 - mae: 4.4127 - val_loss: 27.9811 - val_mse: 27.8604 - val_mae: 4.2600
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0572 - mse: 31.9343 - mae: 4.3909 - val_loss: 28.0588 - val_mse: 27.9335 - val_mae: 4.2707
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0655 - mse: 31.9383 - mae: 4.3935 - val_loss: 27.8320 - val_mse: 27.7026 - val_mae: 4.2512
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9509 - mse: 31.8196 - mae: 4.3847 - val_loss: 27.9759 - val_mse: 27.8425 - val_mae: 4.2719
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6423 - mse: 31.5070 - mae: 4.3623 - val_loss: 27.9559 - val_mse: 27.8187 - val_mae: 4.2624
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5073 - mse: 31.3684 - mae: 4.3531 - val_loss: 27.1758 - val_mse: 27.0351 - val_mae: 4.2012
bias -0.0020944732
si 0.4945289
rmse 0.051995285
kgeprime [0.76111007]
rmse_95 0.077635475
rmse_99 0.09160644
pearson 0.8466869301752471
pearson_95 0.6937135292828086
pearson_99 0.7336415525656884
rscore 0.7159128216981694
rscore_95 -1.8707454460163673
rscore_99 -12.633705093485567
nse [0.71591282]
nse_95 [-1.87074545]
nse_99 [-12.63370509]
kge [0.7914094]
ext_kge_95 [0.56413742]
ext_kge_99 [-0.14598741]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.4 164.7 165.0 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.659 -9.488 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 11.09 11.15 ... 1.797
    uw2             (time, latitude, longitude) float32 93.29 90.02 ... 11.01
    vw2             (time, latitude, longitude) float32 122.9 124.3 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.7 14.64 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([35933 35957 35981], shape=(3,), dtype=int64) Times out: tf.Tensor(35981, shape=(), dtype=int64)
Times in: tf.Tensor([23414 23438 23462], shape=(3,), dtype=int64) Times out: tf.Tensor(23462, shape=(), dtype=int64)
Times in: tf.Tensor([123854 123878 123902], shape=(3,), dtype=int64) Times out: tf.Tensor(123902, shape=(), dtype=int64)
Times in: tf.Tensor([103314 103338 103362], shape=(3,), dtype=int64) Times out: tf.Tensor(103362, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_683&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_684 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1366 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1367 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_683 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1366 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_683 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1367 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 49.8109 - mse: 49.7618 - mae: 5.4250 - val_loss: 30.6492 - val_mse: 30.5842 - val_mae: 4.4249
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3840 - mse: 35.3121 - mae: 4.6307 - val_loss: 29.4785 - val_mse: 29.4006 - val_mae: 4.3493
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4689 - mse: 34.3876 - mae: 4.5699 - val_loss: 28.7465 - val_mse: 28.6621 - val_mae: 4.2895
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9087 - mse: 33.8222 - mae: 4.5277 - val_loss: 28.5818 - val_mse: 28.4933 - val_mae: 4.2785
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6880 - mse: 33.5978 - mae: 4.5093 - val_loss: 28.6440 - val_mse: 28.5521 - val_mae: 4.2852
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3826 - mse: 33.2893 - mae: 4.4879 - val_loss: 28.2758 - val_mse: 28.1810 - val_mae: 4.2572
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3280 - mse: 33.2312 - mae: 4.4874 - val_loss: 28.2640 - val_mse: 28.1653 - val_mae: 4.2598
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9854 - mse: 32.8847 - mae: 4.4600 - val_loss: 28.4071 - val_mse: 28.3040 - val_mae: 4.2726
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8329 - mse: 32.7276 - mae: 4.4508 - val_loss: 27.8058 - val_mse: 27.6982 - val_mae: 4.2265
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6027 - mse: 32.4928 - mae: 4.4382 - val_loss: 27.6268 - val_mse: 27.5142 - val_mae: 4.2126
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5431 - mse: 32.4280 - mae: 4.4250 - val_loss: 27.9780 - val_mse: 27.8602 - val_mae: 4.2469
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.3238 - mse: 32.2035 - mae: 4.4097 - val_loss: 27.8951 - val_mse: 27.7725 - val_mae: 4.2432
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8786 - mse: 31.7531 - mae: 4.3814 - val_loss: 27.7640 - val_mse: 27.6355 - val_mae: 4.2309
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7856 - mse: 31.6545 - mae: 4.3754 - val_loss: 27.1558 - val_mse: 27.0222 - val_mae: 4.1881
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5109 - mse: 31.3746 - mae: 4.3559 - val_loss: 27.8633 - val_mse: 27.7244 - val_mae: 4.2413
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4617 - mse: 31.3203 - mae: 4.3511 - val_loss: 26.7468 - val_mse: 26.6029 - val_mae: 4.1547
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3376 - mse: 31.1913 - mae: 4.3419 - val_loss: 27.0892 - val_mse: 26.9405 - val_mae: 4.1880
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1443 - mse: 30.9935 - mae: 4.3218 - val_loss: 26.8386 - val_mse: 26.6856 - val_mae: 4.1632
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8258 - mse: 30.6707 - mae: 4.3014 - val_loss: 26.5063 - val_mse: 26.3492 - val_mae: 4.1375
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6492 - mse: 30.4903 - mae: 4.2889 - val_loss: 26.5661 - val_mse: 26.4055 - val_mae: 4.1511
bias -0.006013811
si 0.4829081
rmse 0.051386334
kgeprime [0.69370377]
rmse_95 0.06537482
rmse_99 0.07290186
pearson 0.8550639986903934
pearson_95 0.7008003295671182
pearson_99 0.7103657814353145
rscore 0.7256335256708102
rscore_95 -0.9908349030221326
rscore_99 -7.281485140094151
nse [0.72563353]
nse_95 [-0.9908349]
nse_99 [-7.28148514]
kge [0.76530967]
ext_kge_95 [0.55857978]
ext_kge_99 [-0.35166337]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([112809 112833 112857], shape=(3,), dtype=int64) Times out: tf.Tensor(112857, shape=(), dtype=int64)
Times in: tf.Tensor([54041 54065 54089], shape=(3,), dtype=int64) Times out: tf.Tensor(54089, shape=(), dtype=int64)
Times in: tf.Tensor([151034 151058 151082], shape=(3,), dtype=int64) Times out: tf.Tensor(151082, shape=(), dtype=int64)
Times in: tf.Tensor([152954 152978 153002], shape=(3,), dtype=int64) Times out: tf.Tensor(153002, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_684&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_685 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1368 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1369 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_684 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1368 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_684 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1369 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 53.1005 - mse: 53.0448 - mae: 5.6239 - val_loss: 40.7119 - val_mse: 40.6453 - val_mae: 5.0715
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.3657 - mse: 41.2928 - mae: 5.0132 - val_loss: 38.1319 - val_mse: 38.0529 - val_mae: 4.8869
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2852 - mse: 40.2021 - mae: 4.9453 - val_loss: 37.1223 - val_mse: 37.0353 - val_mae: 4.8278
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5592 - mse: 39.4689 - mae: 4.8976 - val_loss: 37.1754 - val_mse: 37.0821 - val_mae: 4.8286
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2563 - mse: 39.1601 - mae: 4.8796 - val_loss: 37.6062 - val_mse: 37.5075 - val_mae: 4.8629
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9164 - mse: 38.8154 - mae: 4.8542 - val_loss: 36.2673 - val_mse: 36.1642 - val_mae: 4.7757
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6342 - mse: 38.5288 - mae: 4.8426 - val_loss: 36.8533 - val_mse: 36.7460 - val_mae: 4.8154
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3334 - mse: 38.2239 - mae: 4.8183 - val_loss: 36.5906 - val_mse: 36.4792 - val_mae: 4.7995
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0974 - mse: 37.9840 - mae: 4.8061 - val_loss: 36.8504 - val_mse: 36.7348 - val_mae: 4.8125
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7742 - mse: 37.6561 - mae: 4.7883 - val_loss: 35.9162 - val_mse: 35.7961 - val_mae: 4.7528
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2710 - mse: 37.1487 - mae: 4.7455 - val_loss: 36.0034 - val_mse: 35.8789 - val_mae: 4.7615
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0174 - mse: 36.8907 - mae: 4.7341 - val_loss: 35.3567 - val_mse: 35.2280 - val_mae: 4.7171
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6979 - mse: 36.5673 - mae: 4.7114 - val_loss: 35.3339 - val_mse: 35.2017 - val_mae: 4.7186
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5074 - mse: 36.3733 - mae: 4.7006 - val_loss: 35.0910 - val_mse: 34.9552 - val_mae: 4.7046
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1344 - mse: 35.9969 - mae: 4.6770 - val_loss: 34.6112 - val_mse: 34.4720 - val_mae: 4.6780
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0377 - mse: 35.8968 - mae: 4.6694 - val_loss: 34.0859 - val_mse: 33.9434 - val_mae: 4.6443
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8512 - mse: 35.7070 - mae: 4.6500 - val_loss: 34.0557 - val_mse: 33.9097 - val_mae: 4.6433
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5843 - mse: 35.4367 - mae: 4.6354 - val_loss: 33.4619 - val_mse: 33.3126 - val_mae: 4.6116
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5485 - mse: 35.3973 - mae: 4.6344 - val_loss: 33.3283 - val_mse: 33.1757 - val_mae: 4.5970
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5439 - mse: 35.3896 - mae: 4.6293 - val_loss: 33.3607 - val_mse: 33.2049 - val_mae: 4.6020
bias -0.009816083
si 0.5048301
rmse 0.057623703
kgeprime [0.56261061]
rmse_95 0.07954738
rmse_99 0.09538767
pearson 0.8411899552523784
pearson_95 0.6664091555399212
pearson_99 0.5858728794301354
rscore 0.6988449916885404
rscore_95 -1.944410095787025
rscore_99 -16.595548278591256
nse [0.69884499]
nse_95 [-1.9444101]
nse_99 [-16.59554828]
kge [0.66677281]
ext_kge_95 [0.53607669]
ext_kge_99 [-0.50128953]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([64049 64073 64097], shape=(3,), dtype=int64) Times out: tf.Tensor(64097, shape=(), dtype=int64)
Times in: tf.Tensor([99436 99460 99484], shape=(3,), dtype=int64) Times out: tf.Tensor(99484, shape=(), dtype=int64)
Times in: tf.Tensor([142058 142082 142106], shape=(3,), dtype=int64) Times out: tf.Tensor(142106, shape=(), dtype=int64)
Times in: tf.Tensor([69631 69655 69679], shape=(3,), dtype=int64) Times out: tf.Tensor(69679, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_685&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_686 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1370 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1371 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_685 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1370 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_685 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1371 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 10s 2ms/step - loss: 56.8107 - mse: 56.7542 - mae: 5.8086 - val_loss: 40.9779 - val_mse: 40.9108 - val_mae: 5.0850
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.4353 - mse: 42.3638 - mae: 5.0681 - val_loss: 37.9263 - val_mse: 37.8503 - val_mae: 4.8931
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.1349 - mse: 41.0561 - mae: 4.9906 - val_loss: 37.5225 - val_mse: 37.4408 - val_mae: 4.8629
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.6305 - mse: 40.5469 - mae: 4.9601 - val_loss: 36.7788 - val_mse: 36.6934 - val_mae: 4.8080
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.3166 - mse: 40.2298 - mae: 4.9392 - val_loss: 37.6844 - val_mse: 37.5961 - val_mae: 4.8702
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.9279 - mse: 39.8385 - mae: 4.9217 - val_loss: 36.7206 - val_mse: 36.6300 - val_mae: 4.8083
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7596 - mse: 39.6676 - mae: 4.9077 - val_loss: 36.6553 - val_mse: 36.5617 - val_mae: 4.8069
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4054 - mse: 39.3103 - mae: 4.8845 - val_loss: 35.9062 - val_mse: 35.8093 - val_mae: 4.7573
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1736 - mse: 39.0748 - mae: 4.8696 - val_loss: 36.0684 - val_mse: 35.9675 - val_mae: 4.7744
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7659 - mse: 38.6626 - mae: 4.8383 - val_loss: 36.0215 - val_mse: 35.9162 - val_mae: 4.7615
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.3480 - mse: 38.2408 - mae: 4.8162 - val_loss: 34.6224 - val_mse: 34.5132 - val_mae: 4.6803
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9118 - mse: 37.8004 - mae: 4.7828 - val_loss: 34.8617 - val_mse: 34.7487 - val_mae: 4.6934
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7396 - mse: 37.6248 - mae: 4.7705 - val_loss: 34.4558 - val_mse: 34.3395 - val_mae: 4.6675
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6372 - mse: 37.5192 - mae: 4.7669 - val_loss: 34.8693 - val_mse: 34.7497 - val_mae: 4.6958
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3356 - mse: 37.2145 - mae: 4.7501 - val_loss: 34.1670 - val_mse: 34.0446 - val_mae: 4.6471
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2200 - mse: 37.0962 - mae: 4.7419 - val_loss: 34.0123 - val_mse: 33.8870 - val_mae: 4.6346
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0490 - mse: 36.9224 - mae: 4.7244 - val_loss: 33.8795 - val_mse: 33.7514 - val_mae: 4.6324
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9003 - mse: 36.7709 - mae: 4.7215 - val_loss: 34.0964 - val_mse: 33.9658 - val_mae: 4.6455
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7858 - mse: 36.6539 - mae: 4.7143 - val_loss: 34.2916 - val_mse: 34.1581 - val_mae: 4.6559
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6926 - mse: 36.5579 - mae: 4.7030 - val_loss: 33.2713 - val_mse: 33.1353 - val_mae: 4.5915
bias -0.0073421346
si 0.51258516
rmse 0.057563294
kgeprime [0.62547731]
rmse_95 0.078868076
rmse_99 0.09299247
pearson 0.8363842368440615
pearson_95 0.6582167696410867
pearson_99 0.5490343666391493
rscore 0.6943175075703862
rscore_95 -1.9660873638331995
rscore_99 -16.34188521644939
nse [0.69431751]
nse_95 [-1.96608736]
nse_99 [-16.34188522]
kge [0.71181445]
ext_kge_95 [0.51299354]
ext_kge_99 [-0.59951009]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([78555 78579 78603], shape=(3,), dtype=int64) Times out: tf.Tensor(78603, shape=(), dtype=int64)
Times in: tf.Tensor([24722 24746 24770], shape=(3,), dtype=int64) Times out: tf.Tensor(24770, shape=(), dtype=int64)
Times in: tf.Tensor([73939 73963 73987], shape=(3,), dtype=int64) Times out: tf.Tensor(73987, shape=(), dtype=int64)
Times in: tf.Tensor([80270 80294 80318], shape=(3,), dtype=int64) Times out: tf.Tensor(80318, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_686&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_687 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1372 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1373 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_686 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1372 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_686 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1373 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.4652 - mse: 50.4149 - mae: 5.4888 - val_loss: 37.2551 - val_mse: 37.1928 - val_mae: 4.8750
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1522 - mse: 39.0820 - mae: 4.8780 - val_loss: 35.7546 - val_mse: 35.6770 - val_mae: 4.7701
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6810 - mse: 37.5974 - mae: 4.7832 - val_loss: 35.0305 - val_mse: 34.9419 - val_mae: 4.7189
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1541 - mse: 37.0615 - mae: 4.7485 - val_loss: 34.4422 - val_mse: 34.3461 - val_mae: 4.6768
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7530 - mse: 36.6537 - mae: 4.7226 - val_loss: 34.4325 - val_mse: 34.3304 - val_mae: 4.6841
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4145 - mse: 36.3095 - mae: 4.7004 - val_loss: 34.1847 - val_mse: 34.0772 - val_mae: 4.6634
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1108 - mse: 36.0004 - mae: 4.6792 - val_loss: 33.5032 - val_mse: 33.3899 - val_mae: 4.6213
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6534 - mse: 35.5370 - mae: 4.6530 - val_loss: 33.0683 - val_mse: 32.9489 - val_mae: 4.5989
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0778 - mse: 34.9553 - mae: 4.6098 - val_loss: 33.0598 - val_mse: 32.9347 - val_mae: 4.5903
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6944 - mse: 34.5668 - mae: 4.5849 - val_loss: 32.4837 - val_mse: 32.3538 - val_mae: 4.5471
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.3079 - mse: 34.1758 - mae: 4.5599 - val_loss: 32.4544 - val_mse: 32.3202 - val_mae: 4.5447
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1362 - mse: 34.0002 - mae: 4.5471 - val_loss: 32.2987 - val_mse: 32.1609 - val_mae: 4.5383
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9571 - mse: 33.8176 - mae: 4.5374 - val_loss: 32.2745 - val_mse: 32.1332 - val_mae: 4.5362
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8536 - mse: 33.7106 - mae: 4.5284 - val_loss: 31.9680 - val_mse: 31.8233 - val_mae: 4.5187
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7228 - mse: 33.5766 - mae: 4.5158 - val_loss: 31.9496 - val_mse: 31.8019 - val_mae: 4.5141
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5209 - mse: 33.3714 - mae: 4.5082 - val_loss: 32.1810 - val_mse: 32.0296 - val_mae: 4.5280
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4577 - mse: 33.3047 - mae: 4.4968 - val_loss: 31.7170 - val_mse: 31.5627 - val_mae: 4.4969
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3334 - mse: 33.1774 - mae: 4.4959 - val_loss: 31.7750 - val_mse: 31.6174 - val_mae: 4.5029
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2131 - mse: 33.0539 - mae: 4.4809 - val_loss: 31.5629 - val_mse: 31.4021 - val_mae: 4.4895
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1615 - mse: 32.9993 - mae: 4.4806 - val_loss: 31.9141 - val_mse: 31.7507 - val_mae: 4.5151
bias -0.006654597
si 0.52002525
rmse 0.05634771
kgeprime [0.63446621]
rmse_95 0.076582365
rmse_99 0.0891911
pearson 0.8326741538590702
pearson_95 0.6648400179110296
pearson_99 0.6022432091827924
rscore 0.688334902340771
rscore_95 -2.061246805757277
rscore_99 -14.393208407093482
nse [0.6883349]
nse_95 [-2.06124681]
nse_99 [-14.39320841]
kge [0.71733808]
ext_kge_95 [0.51986746]
ext_kge_99 [-0.32160795]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 1.107
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 14.56
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([16237 16261 16285], shape=(3,), dtype=int64) Times out: tf.Tensor(16285, shape=(), dtype=int64)
Times in: tf.Tensor([59941 59965 59989], shape=(3,), dtype=int64) Times out: tf.Tensor(59989, shape=(), dtype=int64)
Times in: tf.Tensor([121628 121652 121676], shape=(3,), dtype=int64) Times out: tf.Tensor(121676, shape=(), dtype=int64)
Times in: tf.Tensor([27764 27788 27812], shape=(3,), dtype=int64) Times out: tf.Tensor(27812, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_687&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_688 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1374 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1375 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_687 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1374 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_687 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1375 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.7251 - mse: 37.6706 - mae: 4.7398 - val_loss: 26.3815 - val_mse: 26.3139 - val_mae: 4.1247
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0413 - mse: 28.9643 - mae: 4.2100 - val_loss: 25.4204 - val_mse: 25.3349 - val_mae: 4.0503
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3794 - mse: 28.2873 - mae: 4.1620 - val_loss: 25.3347 - val_mse: 25.2370 - val_mae: 4.0352
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8731 - mse: 27.7705 - mae: 4.1193 - val_loss: 25.0878 - val_mse: 24.9804 - val_mae: 4.0266
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6544 - mse: 27.5420 - mae: 4.1004 - val_loss: 24.4893 - val_mse: 24.3722 - val_mae: 3.9678
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2606 - mse: 27.1387 - mae: 4.0693 - val_loss: 24.2842 - val_mse: 24.1573 - val_mae: 3.9495
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0081 - mse: 26.8760 - mae: 4.0463 - val_loss: 24.0706 - val_mse: 23.9339 - val_mae: 3.9409
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7308 - mse: 26.5891 - mae: 4.0301 - val_loss: 23.8252 - val_mse: 23.6793 - val_mae: 3.9163
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4332 - mse: 26.2830 - mae: 4.0060 - val_loss: 23.4766 - val_mse: 23.3230 - val_mae: 3.8864
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 26.0990 - mse: 25.9418 - mae: 3.9795 - val_loss: 23.2460 - val_mse: 23.0857 - val_mae: 3.8629
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8638 - mse: 25.7008 - mae: 3.9598 - val_loss: 22.9492 - val_mse: 22.7838 - val_mae: 3.8414
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6666 - mse: 25.4987 - mae: 3.9478 - val_loss: 22.8670 - val_mse: 22.6970 - val_mae: 3.8352
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5565 - mse: 25.3846 - mae: 3.9351 - val_loss: 22.6591 - val_mse: 22.4857 - val_mae: 3.8172
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4249 - mse: 25.2497 - mae: 3.9243 - val_loss: 22.5792 - val_mse: 22.4023 - val_mae: 3.8093
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3117 - mse: 25.1333 - mae: 3.9119 - val_loss: 22.4540 - val_mse: 22.2742 - val_mae: 3.8004
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2140 - mse: 25.0326 - mae: 3.9053 - val_loss: 22.4035 - val_mse: 22.2207 - val_mae: 3.7978
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1396 - mse: 24.9557 - mae: 3.8999 - val_loss: 22.3623 - val_mse: 22.1772 - val_mae: 3.7933
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.0233 - mse: 24.8370 - mae: 3.8908 - val_loss: 22.1842 - val_mse: 21.9970 - val_mae: 3.7768
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9820 - mse: 24.7934 - mae: 3.8853 - val_loss: 22.2709 - val_mse: 22.0811 - val_mae: 3.7848
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.7419 - mse: 24.5508 - mae: 3.8682 - val_loss: 22.3447 - val_mse: 22.1527 - val_mae: 3.7943
bias -0.005173156
si 0.46693587
rmse 0.047066614
kgeprime [0.69789406]
rmse_95 0.05860982
rmse_99 0.07002211
pearson 0.8654276073051085
pearson_95 0.6024617524326793
pearson_99 0.4786494902362675
rscore 0.7457038933466138
rscore_95 -1.3699775661540734
rscore_99 -7.757781146338841
nse [0.74570389]
nse_95 [-1.36997757]
nse_99 [-7.75778115]
kge [0.77003122]
ext_kge_95 [0.44458571]
ext_kge_99 [-0.27319363]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.797
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.01
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([82349 82373 82397], shape=(3,), dtype=int64) Times out: tf.Tensor(82397, shape=(), dtype=int64)
Times in: tf.Tensor([8383 8407 8431], shape=(3,), dtype=int64) Times out: tf.Tensor(8431, shape=(), dtype=int64)
Times in: tf.Tensor([10019 10043 10067], shape=(3,), dtype=int64) Times out: tf.Tensor(10067, shape=(), dtype=int64)
Times in: tf.Tensor([98563 98587 98611], shape=(3,), dtype=int64) Times out: tf.Tensor(98611, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_688&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_689 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1376 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1377 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_688 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1376 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_688 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1377 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.4835 - mse: 42.4254 - mae: 5.0143 - val_loss: 29.3861 - val_mse: 29.3160 - val_mae: 4.3401
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0694 - mse: 31.9928 - mae: 4.4164 - val_loss: 28.1185 - val_mse: 28.0365 - val_mae: 4.2519
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2869 - mse: 31.2001 - mae: 4.3587 - val_loss: 27.3235 - val_mse: 27.2326 - val_mae: 4.1894
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8169 - mse: 30.7223 - mae: 4.3239 - val_loss: 27.4063 - val_mse: 27.3085 - val_mae: 4.2000
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.5919 - mse: 30.4909 - mae: 4.3051 - val_loss: 27.3679 - val_mse: 27.2642 - val_mae: 4.2018
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3981 - mse: 30.2912 - mae: 4.2929 - val_loss: 27.0627 - val_mse: 26.9530 - val_mae: 4.1858
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1450 - mse: 30.0320 - mae: 4.2708 - val_loss: 27.2029 - val_mse: 27.0871 - val_mae: 4.1925
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8534 - mse: 29.7343 - mae: 4.2488 - val_loss: 26.8788 - val_mse: 26.7570 - val_mae: 4.1765
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6935 - mse: 29.5684 - mae: 4.2350 - val_loss: 26.7209 - val_mse: 26.5930 - val_mae: 4.1617
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.4944 - mse: 29.3632 - mae: 4.2184 - val_loss: 26.7429 - val_mse: 26.6092 - val_mae: 4.1701
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3747 - mse: 29.2376 - mae: 4.2086 - val_loss: 26.0365 - val_mse: 25.8966 - val_mae: 4.1118
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0258 - mse: 28.8830 - mae: 4.1859 - val_loss: 25.7725 - val_mse: 25.6273 - val_mae: 4.0870
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6361 - mse: 28.4879 - mae: 4.1596 - val_loss: 26.5715 - val_mse: 26.4213 - val_mae: 4.1530
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2605 - mse: 28.1082 - mae: 4.1288 - val_loss: 26.5030 - val_mse: 26.3491 - val_mae: 4.1524
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.1952 - mse: 28.0394 - mae: 4.1220 - val_loss: 26.2771 - val_mse: 26.1199 - val_mae: 4.1293
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.0788 - mse: 27.9199 - mae: 4.1172 - val_loss: 25.7193 - val_mse: 25.5590 - val_mae: 4.0865
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 27.9895 - mse: 27.8277 - mae: 4.1043 - val_loss: 25.7558 - val_mse: 25.5929 - val_mae: 4.0874
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 27.7988 - mse: 27.6346 - mae: 4.0929 - val_loss: 25.4734 - val_mse: 25.3079 - val_mae: 4.0671
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 27.6626 - mse: 27.4960 - mae: 4.0871 - val_loss: 26.0256 - val_mse: 25.8580 - val_mae: 4.1081
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 27.5696 - mse: 27.4008 - mae: 4.0776 - val_loss: 25.4980 - val_mse: 25.3284 - val_mae: 4.0690
bias -0.008387117
si 0.47901097
rmse 0.050327305
kgeprime [0.63890075]
rmse_95 0.061587285
rmse_99 0.078593224
pearson 0.858581954842511
pearson_95 0.6689885210412431
pearson_99 0.7437312192081903
rscore 0.7265125605774893
rscore_95 -0.9767271742482129
rscore_99 -9.38602595834497
nse [0.72651256]
nse_95 [-0.97672717]
nse_99 [-9.38602596]
kge [0.72568966]
ext_kge_95 [0.57218098]
ext_kge_99 [-0.37543443]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 164.1 164.4 164.7 ... 170.3 170.6 170.9
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.89 -9.659 ... -3.318
    vgrd10m         (time, latitude, longitude) float32 10.98 11.09 ... 1.797
    uw2             (time, latitude, longitude) float32 97.8 93.29 ... 11.01
    vw2             (time, latitude, longitude) float32 120.5 122.9 ... 3.228
    wind_magnitude  (time, latitude, longitude) float32 14.78 14.7 ... 3.773
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([129306 129330 129354], shape=(3,), dtype=int64) Times out: tf.Tensor(129354, shape=(), dtype=int64)
Times in: tf.Tensor([59345 59369 59393], shape=(3,), dtype=int64) Times out: tf.Tensor(59393, shape=(), dtype=int64)
Times in: tf.Tensor([26564 26588 26612], shape=(3,), dtype=int64) Times out: tf.Tensor(26612, shape=(), dtype=int64)
Times in: tf.Tensor([122140 122164 122188], shape=(3,), dtype=int64) Times out: tf.Tensor(122188, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_689&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_690 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1378 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1379 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_689 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1378 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_689 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1379 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 44.1280 - mse: 44.0780 - mae: 5.1260 - val_loss: 30.6344 - val_mse: 30.5731 - val_mae: 4.4289
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7814 - mse: 33.7138 - mae: 4.5323 - val_loss: 28.6214 - val_mse: 28.5492 - val_mae: 4.2878
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7401 - mse: 32.6644 - mae: 4.4622 - val_loss: 29.2629 - val_mse: 29.1843 - val_mae: 4.3377
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2753 - mse: 32.1947 - mae: 4.4265 - val_loss: 28.2071 - val_mse: 28.1244 - val_mae: 4.2630
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0235 - mse: 31.9389 - mae: 4.4020 - val_loss: 28.3796 - val_mse: 28.2934 - val_mae: 4.2770
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8008 - mse: 31.7124 - mae: 4.3903 - val_loss: 27.5723 - val_mse: 27.4819 - val_mae: 4.2131
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5188 - mse: 31.4263 - mae: 4.3679 - val_loss: 27.2627 - val_mse: 27.1682 - val_mae: 4.1894
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1993 - mse: 31.1028 - mae: 4.3450 - val_loss: 27.7930 - val_mse: 27.6945 - val_mae: 4.2374
Epoch 9/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.0311 - mse: 30.9303 - mae: 4.3298 - val_loss: 27.9313 - val_mse: 27.8283 - val_mae: 4.2511
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.8216 - mse: 30.7162 - mae: 4.3119 - val_loss: 27.1950 - val_mse: 27.0872 - val_mae: 4.2003
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3548 - mse: 30.2445 - mae: 4.2797 - val_loss: 26.6984 - val_mse: 26.5855 - val_mae: 4.1560
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9841 - mse: 29.8690 - mae: 4.2476 - val_loss: 26.2111 - val_mse: 26.0941 - val_mae: 4.1275
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7619 - mse: 29.6428 - mae: 4.2347 - val_loss: 26.3788 - val_mse: 26.2579 - val_mae: 4.1406
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5787 - mse: 29.4564 - mae: 4.2197 - val_loss: 25.9673 - val_mse: 25.8433 - val_mae: 4.1070
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3425 - mse: 29.2170 - mae: 4.2027 - val_loss: 26.3055 - val_mse: 26.1784 - val_mae: 4.1405
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1591 - mse: 29.0305 - mae: 4.1911 - val_loss: 26.0584 - val_mse: 25.9287 - val_mae: 4.1231
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.0513 - mse: 28.9200 - mae: 4.1846 - val_loss: 25.2417 - val_mse: 25.1092 - val_mae: 4.0493
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0582 - mse: 28.9244 - mae: 4.1833 - val_loss: 25.7853 - val_mse: 25.6500 - val_mae: 4.0938
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9477 - mse: 28.8114 - mae: 4.1725 - val_loss: 25.0214 - val_mse: 24.8840 - val_mae: 4.0365
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 28.8664 - mse: 28.7277 - mae: 4.1657 - val_loss: 25.5770 - val_mse: 25.4374 - val_mae: 4.0826
bias -0.008686649
si 0.47595578
rmse 0.050435465
kgeprime [0.62808686]
rmse_95 0.061684705
rmse_99 0.076818876
pearson 0.8599132743756918
pearson_95 0.6866786106060503
pearson_99 0.7469380766994812
rscore 0.7294112810717812
rscore_95 -0.8862583846009628
rscore_99 -8.788635214489718
nse [0.72941128]
nse_95 [-0.88625838]
nse_99 [-8.78863521]
kge [0.71864274]
ext_kge_95 [0.58271029]
ext_kge_99 [-0.2972171]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([8238 8262 8286], shape=(3,), dtype=int64) Times out: tf.Tensor(8286, shape=(), dtype=int64)
Times in: tf.Tensor([67293 67317 67341], shape=(3,), dtype=int64) Times out: tf.Tensor(67341, shape=(), dtype=int64)
Times in: tf.Tensor([49394 49418 49442], shape=(3,), dtype=int64) Times out: tf.Tensor(49442, shape=(), dtype=int64)
Times in: tf.Tensor([10432 10456 10480], shape=(3,), dtype=int64) Times out: tf.Tensor(10480, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_690&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_691 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1380 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1381 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_690 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1380 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_690 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1381 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.7986 - mse: 54.7447 - mae: 5.7047 - val_loss: 39.0759 - val_mse: 39.0092 - val_mae: 4.9631
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.0051 - mse: 39.9314 - mae: 4.9328 - val_loss: 37.0471 - val_mse: 36.9668 - val_mae: 4.8366
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7232 - mse: 38.6377 - mae: 4.8461 - val_loss: 36.6769 - val_mse: 36.5861 - val_mae: 4.8142
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9819 - mse: 37.8870 - mae: 4.8000 - val_loss: 36.6065 - val_mse: 36.5073 - val_mae: 4.8172
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4908 - mse: 37.3880 - mae: 4.7687 - val_loss: 36.4641 - val_mse: 36.3573 - val_mae: 4.8059
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1518 - mse: 37.0417 - mae: 4.7485 - val_loss: 37.2496 - val_mse: 37.1354 - val_mae: 4.8635
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9951 - mse: 36.8773 - mae: 4.7351 - val_loss: 35.7910 - val_mse: 35.6690 - val_mae: 4.7699
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6199 - mse: 36.4937 - mae: 4.7121 - val_loss: 35.9444 - val_mse: 35.8139 - val_mae: 4.7813
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1916 - mse: 36.0569 - mae: 4.6871 - val_loss: 35.8209 - val_mse: 35.6814 - val_mae: 4.7661
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5776 - mse: 35.4340 - mae: 4.6440 - val_loss: 34.2112 - val_mse: 34.0636 - val_mae: 4.6589
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.1930 - mse: 35.0417 - mae: 4.6202 - val_loss: 34.3055 - val_mse: 34.1507 - val_mae: 4.6705
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8322 - mse: 34.6739 - mae: 4.5938 - val_loss: 33.7728 - val_mse: 33.6115 - val_mae: 4.6325
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7340 - mse: 34.5701 - mae: 4.5900 - val_loss: 34.3138 - val_mse: 34.1469 - val_mae: 4.6744
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5461 - mse: 34.3773 - mae: 4.5751 - val_loss: 33.5669 - val_mse: 33.3958 - val_mae: 4.6269
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2466 - mse: 34.0737 - mae: 4.5542 - val_loss: 33.2109 - val_mse: 33.0360 - val_mae: 4.5980
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1624 - mse: 33.9855 - mae: 4.5499 - val_loss: 35.5604 - val_mse: 35.3815 - val_mae: 4.7572
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0600 - mse: 33.8797 - mae: 4.5414 - val_loss: 32.9452 - val_mse: 32.7629 - val_mae: 4.5834
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9361 - mse: 33.7525 - mae: 4.5313 - val_loss: 33.5342 - val_mse: 33.3488 - val_mae: 4.6223
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9102 - mse: 33.7234 - mae: 4.5325 - val_loss: 33.4698 - val_mse: 33.2813 - val_mae: 4.6157
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.8189 - mse: 33.6288 - mae: 4.5285 - val_loss: 33.0764 - val_mse: 32.8847 - val_mae: 4.5906
bias -0.011391493
si 0.5156042
rmse 0.05734521
kgeprime [0.51859095]
rmse_95 0.07299832
rmse_99 0.086700924
pearson 0.8353796882701253
pearson_95 0.6451633756460957
pearson_99 0.5511852701981672
rscore 0.6848681609541254
rscore_95 -1.7123297821810208
rscore_99 -13.599377607120347
nse [0.68486816]
nse_95 [-1.71232978]
nse_99 [-13.59937761]
kge [0.63025662]
ext_kge_95 [0.52023832]
ext_kge_99 [-0.33808899]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 1.107
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 14.56
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([110633 110657 110681], shape=(3,), dtype=int64) Times out: tf.Tensor(110681, shape=(), dtype=int64)
Times in: tf.Tensor([53338 53362 53386], shape=(3,), dtype=int64) Times out: tf.Tensor(53386, shape=(), dtype=int64)
Times in: tf.Tensor([64445 64469 64493], shape=(3,), dtype=int64) Times out: tf.Tensor(64493, shape=(), dtype=int64)
Times in: tf.Tensor([112386 112410 112434], shape=(3,), dtype=int64) Times out: tf.Tensor(112434, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_691&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_692 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1382 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1383 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_691 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1382 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_691 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1383 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.0003 - mse: 44.9573 - mae: 5.1479 - val_loss: 26.5308 - val_mse: 26.4743 - val_mae: 4.0999
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4077 - mse: 32.3457 - mae: 4.4162 - val_loss: 25.2988 - val_mse: 25.2331 - val_mae: 4.0289
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6907 - mse: 31.6234 - mae: 4.3685 - val_loss: 25.0717 - val_mse: 25.0029 - val_mae: 4.0096
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3215 - mse: 31.2514 - mae: 4.3418 - val_loss: 24.8733 - val_mse: 24.8023 - val_mae: 3.9977
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0974 - mse: 31.0252 - mae: 4.3295 - val_loss: 24.7493 - val_mse: 24.6763 - val_mae: 3.9873
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8065 - mse: 30.7324 - mae: 4.3045 - val_loss: 24.7619 - val_mse: 24.6868 - val_mae: 3.9878
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7231 - mse: 30.6466 - mae: 4.2951 - val_loss: 24.5817 - val_mse: 24.5042 - val_mae: 3.9766
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.6253 - mse: 30.5463 - mae: 4.2881 - val_loss: 24.4090 - val_mse: 24.3291 - val_mae: 3.9588
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3134 - mse: 30.2319 - mae: 4.2663 - val_loss: 24.5162 - val_mse: 24.4337 - val_mae: 3.9672
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1318 - mse: 30.0474 - mae: 4.2552 - val_loss: 24.6065 - val_mse: 24.5206 - val_mae: 3.9793
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9554 - mse: 29.8680 - mae: 4.2392 - val_loss: 24.7177 - val_mse: 24.6286 - val_mae: 3.9942
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.8935 - mse: 29.8028 - mae: 4.2295 - val_loss: 24.0628 - val_mse: 23.9706 - val_mae: 3.9355
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5022 - mse: 29.4085 - mae: 4.2102 - val_loss: 24.2486 - val_mse: 24.1536 - val_mae: 3.9505
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5223 - mse: 29.4256 - mae: 4.2120 - val_loss: 23.9591 - val_mse: 23.8609 - val_mae: 3.9257
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2992 - mse: 29.1995 - mae: 4.1953 - val_loss: 24.0314 - val_mse: 23.9305 - val_mae: 3.9326
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.2749 - mse: 29.1724 - mae: 4.1908 - val_loss: 24.0579 - val_mse: 23.9540 - val_mae: 3.9313
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1088 - mse: 29.0036 - mae: 4.1856 - val_loss: 23.8446 - val_mse: 23.7380 - val_mae: 3.9139
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0325 - mse: 28.9244 - mae: 4.1722 - val_loss: 23.8411 - val_mse: 23.7320 - val_mae: 3.9079
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8502 - mse: 28.7392 - mae: 4.1648 - val_loss: 23.7167 - val_mse: 23.6047 - val_mae: 3.9003
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7291 - mse: 28.6156 - mae: 4.1522 - val_loss: 23.8283 - val_mse: 23.7136 - val_mae: 3.9138
bias -0.007121246
si 0.48753667
rmse 0.048696652
kgeprime [0.61940994]
rmse_95 0.06638017
rmse_99 0.07998485
pearson 0.8526019941435973
pearson_95 0.5946620079252919
pearson_99 0.4643117031000131
rscore 0.7209596931736588
rscore_95 -2.080298657235239
rscore_99 -10.090934118702506
nse [0.72095969]
nse_95 [-2.08029866]
nse_99 [-10.09093412]
kge [0.71186326]
ext_kge_95 [0.45738878]
ext_kge_99 [-0.06607671]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -3.816
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 1.107
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 14.56
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 1.225
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 3.973
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([107429 107453 107477], shape=(3,), dtype=int64) Times out: tf.Tensor(107477, shape=(), dtype=int64)
Times in: tf.Tensor([39777 39801 39825], shape=(3,), dtype=int64) Times out: tf.Tensor(39825, shape=(), dtype=int64)
Times in: tf.Tensor([115929 115953 115977], shape=(3,), dtype=int64) Times out: tf.Tensor(115977, shape=(), dtype=int64)
Times in: tf.Tensor([117009 117033 117057], shape=(3,), dtype=int64) Times out: tf.Tensor(117057, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_692&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_693 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1384 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1385 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_692 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1384 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_692 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1385 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.1422 - mse: 41.0915 - mae: 4.9562 - val_loss: 27.8420 - val_mse: 27.7794 - val_mae: 4.2351
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4409 - mse: 31.3726 - mae: 4.3799 - val_loss: 26.5010 - val_mse: 26.4269 - val_mae: 4.1396
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4755 - mse: 30.3966 - mae: 4.3032 - val_loss: 26.4643 - val_mse: 26.3822 - val_mae: 4.1329
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.9813 - mse: 29.8970 - mae: 4.2669 - val_loss: 26.0893 - val_mse: 26.0033 - val_mae: 4.1023
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6488 - mse: 29.5615 - mae: 4.2442 - val_loss: 26.3731 - val_mse: 26.2847 - val_mae: 4.1257
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5452 - mse: 29.4560 - mae: 4.2352 - val_loss: 25.9499 - val_mse: 25.8597 - val_mae: 4.0941
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.3795 - mse: 29.2883 - mae: 4.2226 - val_loss: 25.3113 - val_mse: 25.2192 - val_mae: 4.0423
Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 29.1360 - mse: 29.0424 - mae: 4.2016 - val_loss: 25.3214 - val_mse: 25.2265 - val_mae: 4.0468
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.0210 - mse: 28.9246 - mae: 4.1895 - val_loss: 26.5173 - val_mse: 26.4191 - val_mae: 4.1374
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6764 - mse: 28.5766 - mae: 4.1659 - val_loss: 25.4866 - val_mse: 25.3851 - val_mae: 4.0550
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3697 - mse: 28.2664 - mae: 4.1413 - val_loss: 24.2596 - val_mse: 24.1546 - val_mae: 3.9554
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9760 - mse: 27.8691 - mae: 4.1138 - val_loss: 25.0688 - val_mse: 24.9600 - val_mae: 4.0230
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8604 - mse: 27.7503 - mae: 4.1077 - val_loss: 23.1268 - val_mse: 23.0154 - val_mae: 3.8607
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6442 - mse: 27.5313 - mae: 4.0878 - val_loss: 23.7639 - val_mse: 23.6497 - val_mae: 3.9182
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5957 - mse: 27.4801 - mae: 4.0843 - val_loss: 23.5410 - val_mse: 23.4242 - val_mae: 3.8988
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4400 - mse: 27.3219 - mae: 4.0687 - val_loss: 22.6262 - val_mse: 22.5072 - val_mae: 3.8168
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3686 - mse: 27.2484 - mae: 4.0655 - val_loss: 24.0497 - val_mse: 23.9286 - val_mae: 3.9424
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2588 - mse: 27.1367 - mae: 4.0560 - val_loss: 23.4848 - val_mse: 23.3619 - val_mae: 3.8946
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3482 - mse: 27.2243 - mae: 4.0612 - val_loss: 22.4304 - val_mse: 22.3055 - val_mae: 3.8008
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1560 - mse: 27.0303 - mae: 4.0512 - val_loss: 22.5126 - val_mse: 22.3862 - val_mae: 3.8105
bias -0.005507463
si 0.46808514
rmse 0.04731402
kgeprime [0.68198502]
rmse_95 0.060503148
rmse_99 0.07183266
pearson 0.8645636684144493
pearson_95 0.6149114410857734
pearson_99 0.5337357997471543
rscore 0.7439841147015183
rscore_95 -1.507640718144823
rscore_99 -8.542250960183312
nse [0.74398411]
nse_95 [-1.50764072]
nse_99 [-8.54225096]
kge [0.75854169]
ext_kge_95 [0.46057958]
ext_kge_99 [-0.22402376]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -43.24 -42.93
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.566
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.613
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.584
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 2.602
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.031
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([117554 117578 117602], shape=(3,), dtype=int64) Times out: tf.Tensor(117602, shape=(), dtype=int64)
Times in: tf.Tensor([105791 105815 105839], shape=(3,), dtype=int64) Times out: tf.Tensor(105839, shape=(), dtype=int64)
Times in: tf.Tensor([22849 22873 22897], shape=(3,), dtype=int64) Times out: tf.Tensor(22897, shape=(), dtype=int64)
Times in: tf.Tensor([89456 89480 89504], shape=(3,), dtype=int64) Times out: tf.Tensor(89504, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_693&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_694 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1386 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1387 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_693 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1386 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_693 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1387 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 54.6441 - mse: 54.5969 - mae: 5.6982 - val_loss: 39.2485 - val_mse: 39.1892 - val_mae: 4.9798
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.1488 - mse: 42.0839 - mae: 5.0476 - val_loss: 37.2699 - val_mse: 37.2001 - val_mae: 4.8513
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.0504 - mse: 40.9777 - mae: 4.9856 - val_loss: 36.3112 - val_mse: 36.2358 - val_mae: 4.7872
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.4525 - mse: 40.3756 - mae: 4.9478 - val_loss: 36.2541 - val_mse: 36.1755 - val_mae: 4.7823
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2969 - mse: 40.2173 - mae: 4.9378 - val_loss: 35.8377 - val_mse: 35.7569 - val_mae: 4.7528
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7906 - mse: 39.7086 - mae: 4.9080 - val_loss: 36.9535 - val_mse: 36.8699 - val_mae: 4.8324
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8255 - mse: 39.7403 - mae: 4.9105 - val_loss: 35.9497 - val_mse: 35.8627 - val_mae: 4.7732
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6662 - mse: 39.5776 - mae: 4.8999 - val_loss: 35.8544 - val_mse: 35.7639 - val_mae: 4.7649
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.4420 - mse: 39.3499 - mae: 4.8896 - val_loss: 35.3229 - val_mse: 35.2290 - val_mae: 4.7291
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1890 - mse: 39.0933 - mae: 4.8753 - val_loss: 35.3871 - val_mse: 35.2894 - val_mae: 4.7352
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1511 - mse: 39.0515 - mae: 4.8732 - val_loss: 35.9192 - val_mse: 35.8175 - val_mae: 4.7711
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9708 - mse: 38.8670 - mae: 4.8618 - val_loss: 35.7747 - val_mse: 35.6688 - val_mae: 4.7655
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6431 - mse: 38.5352 - mae: 4.8395 - val_loss: 35.8871 - val_mse: 35.7771 - val_mae: 4.7674
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5146 - mse: 38.4024 - mae: 4.8372 - val_loss: 35.3787 - val_mse: 35.2642 - val_mae: 4.7352
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4509 - mse: 38.3342 - mae: 4.8284 - val_loss: 35.2316 - val_mse: 35.1123 - val_mae: 4.7268
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.3731 - mse: 38.2516 - mae: 4.8226 - val_loss: 35.9407 - val_mse: 35.8167 - val_mae: 4.7733
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2481 - mse: 38.1222 - mae: 4.8118 - val_loss: 36.9193 - val_mse: 36.7911 - val_mae: 4.8331
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2082 - mse: 38.0781 - mae: 4.8077 - val_loss: 35.3354 - val_mse: 35.2028 - val_mae: 4.7220
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0538 - mse: 37.9192 - mae: 4.7991 - val_loss: 35.4359 - val_mse: 35.2989 - val_mae: 4.7385
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7709 - mse: 37.6319 - mae: 4.7833 - val_loss: 35.3342 - val_mse: 35.1930 - val_mae: 4.7325
bias -0.009811928
si 0.52976966
rmse 0.059323706
kgeprime [0.55147607]
rmse_95 0.08339589
rmse_99 0.10033796
pearson 0.824734918246028
pearson_95 0.6227154932236502
pearson_99 0.5035575098961518
rscore 0.6708123183061286
rscore_95 -2.404486992101095
rscore_99 -19.370478291662632
nse [0.67081232]
nse_95 [-2.40448699]
nse_99 [-19.37047829]
kge [0.65503134]
ext_kge_95 [0.47598503]
ext_kge_99 [-0.75492055]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -4.54
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 0.07264
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 20.61
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 0.005276
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 4.54
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([147634 147658 147682], shape=(3,), dtype=int64) Times out: tf.Tensor(147682, shape=(), dtype=int64)
Times in: tf.Tensor([20334 20358 20382], shape=(3,), dtype=int64) Times out: tf.Tensor(20382, shape=(), dtype=int64)
Times in: tf.Tensor([83280 83304 83328], shape=(3,), dtype=int64) Times out: tf.Tensor(83328, shape=(), dtype=int64)
Times in: tf.Tensor([97555 97579 97603], shape=(3,), dtype=int64) Times out: tf.Tensor(97603, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_694&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_695 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1388 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1389 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_694 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1388 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_694 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1389 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.0992 - mse: 37.0402 - mae: 4.7123 - val_loss: 26.5353 - val_mse: 26.4662 - val_mae: 4.1331
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.4672 - mse: 29.3916 - mae: 4.2496 - val_loss: 26.1709 - val_mse: 26.0888 - val_mae: 4.1117
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6297 - mse: 28.5424 - mae: 4.1813 - val_loss: 25.1889 - val_mse: 25.0966 - val_mae: 4.0290
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9279 - mse: 27.8322 - mae: 4.1252 - val_loss: 25.5869 - val_mse: 25.4878 - val_mae: 4.0595
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5693 - mse: 27.4676 - mae: 4.0961 - val_loss: 24.6361 - val_mse: 24.5318 - val_mae: 3.9831
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1872 - mse: 27.0805 - mae: 4.0638 - val_loss: 24.5112 - val_mse: 24.4020 - val_mae: 3.9712
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8300 - mse: 26.7190 - mae: 4.0358 - val_loss: 24.0741 - val_mse: 23.9609 - val_mae: 3.9367
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3995 - mse: 26.2844 - mae: 4.0036 - val_loss: 23.5158 - val_mse: 23.3987 - val_mae: 3.8853
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0758 - mse: 25.9569 - mae: 3.9794 - val_loss: 23.4527 - val_mse: 23.3320 - val_mae: 3.8871
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8249 - mse: 25.7026 - mae: 3.9592 - val_loss: 22.8538 - val_mse: 22.7297 - val_mae: 3.8309
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6626 - mse: 25.5373 - mae: 3.9437 - val_loss: 22.4751 - val_mse: 22.3482 - val_mae: 3.7989
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5392 - mse: 25.4111 - mae: 3.9368 - val_loss: 22.4851 - val_mse: 22.3557 - val_mae: 3.8023
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3622 - mse: 25.2317 - mae: 3.9237 - val_loss: 22.8977 - val_mse: 22.7661 - val_mae: 3.8412
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2170 - mse: 25.0844 - mae: 3.9096 - val_loss: 22.5546 - val_mse: 22.4211 - val_mae: 3.8116
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2100 - mse: 25.0756 - mae: 3.9045 - val_loss: 22.3318 - val_mse: 22.1966 - val_mae: 3.7941
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1232 - mse: 24.9872 - mae: 3.9044 - val_loss: 22.5399 - val_mse: 22.4030 - val_mae: 3.8105
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.0444 - mse: 24.9069 - mae: 3.8929 - val_loss: 22.0754 - val_mse: 21.9371 - val_mae: 3.7666
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 24.9718 - mse: 24.8328 - mae: 3.8872 - val_loss: 22.1686 - val_mse: 22.0289 - val_mae: 3.7795
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9301 - mse: 24.7897 - mae: 3.8853 - val_loss: 21.9017 - val_mse: 21.7606 - val_mae: 3.7555
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9962 - mse: 24.8545 - mae: 3.8870 - val_loss: 22.1870 - val_mse: 22.0448 - val_mae: 3.7822
bias -0.0070741414
si 0.4656362
rmse 0.046951927
kgeprime [0.64786515]
rmse_95 0.05581602
rmse_99 0.065432906
pearson 0.8664172759781694
pearson_95 0.6304166759935566
pearson_99 0.4602168368654127
rscore 0.7445620611186146
rscore_95 -1.1768599429290996
rscore_99 -7.4146824110824365
nse [0.74456206]
nse_95 [-1.17685994]
nse_99 [-7.41468241]
kge [0.73628462]
ext_kge_95 [0.45859232]
ext_kge_99 [-0.36091411]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 172.8 173.1 173.4
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 2.517
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -1.735
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 6.334
    vw2             (time, latitude, longitude) float32 105.0 100.6 ... 3.009
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.057
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([105745 105769 105793], shape=(3,), dtype=int64) Times out: tf.Tensor(105793, shape=(), dtype=int64)
Times in: tf.Tensor([21410 21434 21458], shape=(3,), dtype=int64) Times out: tf.Tensor(21458, shape=(), dtype=int64)
Times in: tf.Tensor([75295 75319 75343], shape=(3,), dtype=int64) Times out: tf.Tensor(75343, shape=(), dtype=int64)
Times in: tf.Tensor([70097 70121 70145], shape=(3,), dtype=int64) Times out: tf.Tensor(70145, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_695&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_696 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1390 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1391 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_695 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1390 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_695 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1391 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 56.1314 - mse: 56.0777 - mae: 5.7639 - val_loss: 39.6118 - val_mse: 39.5453 - val_mae: 4.9908
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.2704 - mse: 41.1973 - mae: 5.0035 - val_loss: 37.5042 - val_mse: 37.4253 - val_mae: 4.8501
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.1389 - mse: 40.0559 - mae: 4.9328 - val_loss: 36.9135 - val_mse: 36.8267 - val_mae: 4.8080
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.6628 - mse: 39.5731 - mae: 4.9066 - val_loss: 36.7391 - val_mse: 36.6462 - val_mae: 4.8003
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2981 - mse: 39.2026 - mae: 4.8810 - val_loss: 37.0943 - val_mse: 36.9956 - val_mae: 4.8259
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1554 - mse: 39.0541 - mae: 4.8733 - val_loss: 35.8087 - val_mse: 35.7045 - val_mae: 4.7432
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.5743 - mse: 38.4671 - mae: 4.8356 - val_loss: 35.8083 - val_mse: 35.6978 - val_mae: 4.7511
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4654 - mse: 38.3520 - mae: 4.8276 - val_loss: 36.3192 - val_mse: 36.2027 - val_mae: 4.7829
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.2548 - mse: 38.1353 - mae: 4.8147 - val_loss: 36.3581 - val_mse: 36.2354 - val_mae: 4.7855
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.9053 - mse: 37.7799 - mae: 4.7937 - val_loss: 36.0783 - val_mse: 35.9495 - val_mae: 4.7771
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.7035 - mse: 37.5717 - mae: 4.7769 - val_loss: 36.3263 - val_mse: 36.1912 - val_mae: 4.7847
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5265 - mse: 37.3887 - mae: 4.7743 - val_loss: 35.8043 - val_mse: 35.6635 - val_mae: 4.7579
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3929 - mse: 37.2491 - mae: 4.7623 - val_loss: 36.3619 - val_mse: 36.2153 - val_mae: 4.7947
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.1146 - mse: 36.9654 - mae: 4.7424 - val_loss: 35.8500 - val_mse: 35.6978 - val_mae: 4.7562
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0869 - mse: 36.9320 - mae: 4.7454 - val_loss: 35.4373 - val_mse: 35.2799 - val_mae: 4.7351
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.9978 - mse: 36.8381 - mae: 4.7361 - val_loss: 36.0742 - val_mse: 35.9118 - val_mae: 4.7750
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7475 - mse: 36.5828 - mae: 4.7221 - val_loss: 35.7968 - val_mse: 35.6296 - val_mae: 4.7532
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.6654 - mse: 36.4962 - mae: 4.7137 - val_loss: 36.2926 - val_mse: 36.1209 - val_mae: 4.7884
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.5957 - mse: 36.4223 - mae: 4.7057 - val_loss: 36.0482 - val_mse: 35.8725 - val_mae: 4.7785
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3857 - mse: 36.2084 - mae: 4.6973 - val_loss: 35.0982 - val_mse: 34.9188 - val_mae: 4.7104
bias -0.011235132
si 0.5221592
rmse 0.05909215
kgeprime [0.51647154]
rmse_95 0.08334073
rmse_99 0.10067965
pearson 0.829542410643364
pearson_95 0.6101281390405322
pearson_99 0.5109645565897639
rscore 0.6764271962128733
rscore_95 -2.4219845265927225
rscore_99 -19.980488109847286
nse [0.6764272]
nse_95 [-2.42198453]
nse_99 [-19.98048811]
kge [0.62845878]
ext_kge_95 [0.4556829]
ext_kge_99 [-0.91032582]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 173.1 173.4 173.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 3.867
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -0.01923
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 14.95
    vw2             (time, latitude, longitude) float32 105.0 ... 0.0003697
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.867
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([85438 85462 85486], shape=(3,), dtype=int64) Times out: tf.Tensor(85486, shape=(), dtype=int64)
Times in: tf.Tensor([39225 39249 39273], shape=(3,), dtype=int64) Times out: tf.Tensor(39273, shape=(), dtype=int64)
Times in: tf.Tensor([145783 145807 145831], shape=(3,), dtype=int64) Times out: tf.Tensor(145831, shape=(), dtype=int64)
Times in: tf.Tensor([92447 92471 92495], shape=(3,), dtype=int64) Times out: tf.Tensor(92495, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_696&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_697 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1392 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1393 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_696 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1392 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_696 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1393 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 58.1964 - mse: 58.1329 - mae: 5.8924 - val_loss: 41.7410 - val_mse: 41.6629 - val_mae: 5.1145
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.6905 - mse: 44.6065 - mae: 5.1904 - val_loss: 39.4293 - val_mse: 39.3399 - val_mae: 4.9650
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.1033 - mse: 43.0100 - mae: 5.0921 - val_loss: 37.8495 - val_mse: 37.7527 - val_mae: 4.8633
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 42.3645 - mse: 42.2655 - mae: 5.0416 - val_loss: 37.2134 - val_mse: 37.1130 - val_mae: 4.8237
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.8608 - mse: 41.7589 - mae: 5.0121 - val_loss: 37.0979 - val_mse: 36.9952 - val_mae: 4.8192
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.6283 - mse: 41.5247 - mae: 4.9986 - val_loss: 37.0204 - val_mse: 36.9162 - val_mae: 4.8163
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.5063 - mse: 41.4014 - mae: 4.9889 - val_loss: 36.5197 - val_mse: 36.4140 - val_mae: 4.7835
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.4484 - mse: 41.3416 - mae: 4.9866 - val_loss: 36.3470 - val_mse: 36.2396 - val_mae: 4.7760
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 41.1528 - mse: 41.0442 - mae: 4.9703 - val_loss: 36.4744 - val_mse: 36.3650 - val_mae: 4.7902
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9532 - mse: 40.8425 - mae: 4.9554 - val_loss: 36.4990 - val_mse: 36.3873 - val_mae: 4.7907
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7897 - mse: 40.6768 - mae: 4.9476 - val_loss: 36.3087 - val_mse: 36.1946 - val_mae: 4.7796
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.7372 - mse: 40.6213 - mae: 4.9426 - val_loss: 36.5560 - val_mse: 36.4388 - val_mae: 4.7985
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.6089 - mse: 40.4900 - mae: 4.9316 - val_loss: 36.8460 - val_mse: 36.7256 - val_mae: 4.8180
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2389 - mse: 40.1167 - mae: 4.9079 - val_loss: 36.3539 - val_mse: 36.2301 - val_mae: 4.7866
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.2396 - mse: 40.1139 - mae: 4.9114 - val_loss: 36.0435 - val_mse: 35.9162 - val_mae: 4.7657
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.8188 - mse: 39.6893 - mae: 4.8845 - val_loss: 36.5889 - val_mse: 36.4574 - val_mae: 4.7985
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.5856 - mse: 39.4519 - mae: 4.8705 - val_loss: 35.6965 - val_mse: 35.5607 - val_mae: 4.7383
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.2794 - mse: 39.1416 - mae: 4.8544 - val_loss: 34.6002 - val_mse: 34.4606 - val_mae: 4.6636
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0593 - mse: 38.9178 - mae: 4.8325 - val_loss: 35.3273 - val_mse: 35.1841 - val_mae: 4.7205
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.9348 - mse: 38.7898 - mae: 4.8259 - val_loss: 34.7382 - val_mse: 34.5915 - val_mae: 4.6759
bias -0.008740038
si 0.5259375
rmse 0.05881451
kgeprime [0.55674617]
rmse_95 0.083934896
rmse_99 0.09995225
pearson 0.8280126483820824
pearson_95 0.6369921713756801
pearson_99 0.48306779746423795
rscore 0.6781914638701502
rscore_95 -2.37326850125497
rscore_99 -19.14293838740205
nse [0.67819146]
nse_95 [-2.3732685]
nse_99 [-19.14293839]
kge [0.65780399]
ext_kge_95 [0.51106341]
ext_kge_99 [-0.48325686]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -4.822
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 0.3632
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 23.25
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 0.1319
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 4.836
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([140525 140549 140573], shape=(3,), dtype=int64) Times out: tf.Tensor(140573, shape=(), dtype=int64)
Times in: tf.Tensor([125297 125321 125345], shape=(3,), dtype=int64) Times out: tf.Tensor(125345, shape=(), dtype=int64)
Times in: tf.Tensor([106614 106638 106662], shape=(3,), dtype=int64) Times out: tf.Tensor(106662, shape=(), dtype=int64)
Times in: tf.Tensor([85150 85174 85198], shape=(3,), dtype=int64) Times out: tf.Tensor(85198, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_697&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_698 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1394 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1395 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_697 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1394 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_697 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1395 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.5070 - mse: 39.4436 - mae: 4.8502 - val_loss: 25.8939 - val_mse: 25.8164 - val_mae: 4.0601
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.1950 - mse: 29.1121 - mae: 4.2198 - val_loss: 24.9818 - val_mse: 24.8929 - val_mae: 3.9995
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3163 - mse: 28.2234 - mae: 4.1521 - val_loss: 24.2125 - val_mse: 24.1145 - val_mae: 3.9409
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9157 - mse: 27.8143 - mae: 4.1191 - val_loss: 24.4474 - val_mse: 24.3415 - val_mae: 3.9582
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5884 - mse: 27.4799 - mae: 4.0953 - val_loss: 24.0659 - val_mse: 23.9540 - val_mae: 3.9256
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2896 - mse: 27.1752 - mae: 4.0703 - val_loss: 23.7407 - val_mse: 23.6230 - val_mae: 3.8999
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0212 - mse: 26.9013 - mae: 4.0477 - val_loss: 23.4184 - val_mse: 23.2955 - val_mae: 3.8729
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7282 - mse: 26.6030 - mae: 4.0262 - val_loss: 23.2237 - val_mse: 23.0953 - val_mae: 3.8577
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4593 - mse: 26.3293 - mae: 4.0055 - val_loss: 22.7842 - val_mse: 22.6517 - val_mae: 3.8201
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1628 - mse: 26.0288 - mae: 3.9826 - val_loss: 22.8956 - val_mse: 22.7596 - val_mae: 3.8321
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0700 - mse: 25.9329 - mae: 3.9711 - val_loss: 22.7441 - val_mse: 22.6053 - val_mae: 3.8197
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9320 - mse: 25.7919 - mae: 3.9635 - val_loss: 22.8331 - val_mse: 22.6912 - val_mae: 3.8279
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7443 - mse: 25.6016 - mae: 3.9476 - val_loss: 23.4845 - val_mse: 23.3402 - val_mae: 3.8856
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8490 - mse: 25.7042 - mae: 3.9544 - val_loss: 22.4254 - val_mse: 22.2789 - val_mae: 3.7899
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7508 - mse: 25.6037 - mae: 3.9457 - val_loss: 22.6900 - val_mse: 22.5418 - val_mae: 3.8150
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5968 - mse: 25.4481 - mae: 3.9346 - val_loss: 22.3643 - val_mse: 22.2143 - val_mae: 3.7834
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5077 - mse: 25.3573 - mae: 3.9285 - val_loss: 22.2898 - val_mse: 22.1385 - val_mae: 3.7785
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4580 - mse: 25.3060 - mae: 3.9220 - val_loss: 22.1482 - val_mse: 21.9951 - val_mae: 3.7670
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5669 - mse: 25.4136 - mae: 3.9292 - val_loss: 22.3812 - val_mse: 22.2270 - val_mae: 3.7893
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3834 - mse: 25.2289 - mae: 3.9134 - val_loss: 22.3861 - val_mse: 22.2309 - val_mae: 3.7896
bias -0.009739399
si 0.47468334
rmse 0.04714967
kgeprime [0.55210882]
rmse_95 0.057975695
rmse_99 0.06664955
pearson 0.8613955378344064
pearson_95 0.6392751494568187
pearson_99 0.40114954147014403
rscore 0.7303983266610703
rscore_95 -1.4014716909918965
rscore_99 -7.3062255109393845
nse [0.73039833]
nse_95 [-1.40147169]
nse_99 [-7.30622551]
kge [0.66113103]
ext_kge_95 [0.42571578]
ext_kge_99 [-0.29189752]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -4.822
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 0.3632
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 23.25
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 0.1319
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 4.836
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([90667 90691 90715], shape=(3,), dtype=int64) Times out: tf.Tensor(90715, shape=(), dtype=int64)
Times in: tf.Tensor([115370 115394 115418], shape=(3,), dtype=int64) Times out: tf.Tensor(115418, shape=(), dtype=int64)
Times in: tf.Tensor([90327 90351 90375], shape=(3,), dtype=int64) Times out: tf.Tensor(90375, shape=(), dtype=int64)
Times in: tf.Tensor([14677 14701 14725], shape=(3,), dtype=int64) Times out: tf.Tensor(14725, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_698&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_699 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1396 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1397 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_698 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1396 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_698 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1397 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.7706 - mse: 39.7090 - mae: 4.8639 - val_loss: 25.5912 - val_mse: 25.5143 - val_mae: 4.0380
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.5022 - mse: 29.4199 - mae: 4.2362 - val_loss: 25.0269 - val_mse: 24.9403 - val_mae: 4.0087
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8487 - mse: 28.7586 - mae: 4.1896 - val_loss: 24.7752 - val_mse: 24.6816 - val_mae: 3.9870
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5165 - mse: 28.4203 - mae: 4.1621 - val_loss: 24.6707 - val_mse: 24.5721 - val_mae: 3.9770
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2397 - mse: 28.1388 - mae: 4.1435 - val_loss: 24.4146 - val_mse: 24.3111 - val_mae: 3.9590
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0575 - mse: 27.9522 - mae: 4.1257 - val_loss: 24.1147 - val_mse: 24.0069 - val_mae: 3.9350
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9393 - mse: 27.8293 - mae: 4.1178 - val_loss: 23.9682 - val_mse: 23.8557 - val_mae: 3.9198
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7140 - mse: 27.5997 - mae: 4.1016 - val_loss: 24.0689 - val_mse: 23.9526 - val_mae: 3.9301
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4982 - mse: 27.3803 - mae: 4.0852 - val_loss: 23.5996 - val_mse: 23.4797 - val_mae: 3.8906
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3820 - mse: 27.2602 - mae: 4.0734 - val_loss: 23.3695 - val_mse: 23.2461 - val_mae: 3.8726
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2263 - mse: 27.1007 - mae: 4.0635 - val_loss: 23.3433 - val_mse: 23.2160 - val_mae: 3.8734
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0081 - mse: 26.8790 - mae: 4.0401 - val_loss: 23.4957 - val_mse: 23.3651 - val_mae: 3.8826
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7436 - mse: 26.6111 - mae: 4.0214 - val_loss: 22.8905 - val_mse: 22.7566 - val_mae: 3.8226
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5237 - mse: 26.3883 - mae: 4.0043 - val_loss: 22.8380 - val_mse: 22.7012 - val_mae: 3.8260
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4513 - mse: 26.3134 - mae: 4.0005 - val_loss: 22.8054 - val_mse: 22.6666 - val_mae: 3.8242
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2054 - mse: 26.0656 - mae: 3.9816 - val_loss: 22.6927 - val_mse: 22.5522 - val_mae: 3.8121
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2693 - mse: 26.1282 - mae: 3.9862 - val_loss: 22.4745 - val_mse: 22.3329 - val_mae: 3.7990
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1112 - mse: 25.9687 - mae: 3.9738 - val_loss: 22.7464 - val_mse: 22.6033 - val_mae: 3.8184
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1046 - mse: 25.9609 - mae: 3.9719 - val_loss: 22.4300 - val_mse: 22.2857 - val_mae: 3.7931
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0296 - mse: 25.8849 - mae: 3.9641 - val_loss: 22.5221 - val_mse: 22.3771 - val_mae: 3.8018
bias -0.008012734
si 0.47406116
rmse 0.047304396
kgeprime [0.58809992]
rmse_95 0.06108392
rmse_99 0.071282916
pearson 0.8616841856209579
pearson_95 0.6129337261440909
pearson_99 0.4773590043951206
rscore 0.7344589425169767
rscore_95 -1.6782057673601893
rscore_99 -8.76635322748858
nse [0.73445894]
nse_95 [-1.67820577]
nse_99 [-8.76635323]
kge [0.69023059]
ext_kge_95 [0.44574003]
ext_kge_99 [-0.18263786]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.61 -10.4 ... -4.54
    vgrd10m         (time, latitude, longitude) float32 10.44 10.63 ... 0.07264
    uw2             (time, latitude, longitude) float32 112.6 108.1 ... 20.61
    vw2             (time, latitude, longitude) float32 109.0 113.0 ... 0.005276
    wind_magnitude  (time, latitude, longitude) float32 14.88 14.87 ... 4.54
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([148501 148525 148549], shape=(3,), dtype=int64) Times out: tf.Tensor(148549, shape=(), dtype=int64)
Times in: tf.Tensor([11793 11817 11841], shape=(3,), dtype=int64) Times out: tf.Tensor(11841, shape=(), dtype=int64)
Times in: tf.Tensor([91941 91965 91989], shape=(3,), dtype=int64) Times out: tf.Tensor(91989, shape=(), dtype=int64)
Times in: tf.Tensor([154418 154442 154466], shape=(3,), dtype=int64) Times out: tf.Tensor(154466, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_699&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_700 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1398 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1399 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_699 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1398 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_699 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1399 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.2456 - mse: 39.1859 - mae: 4.8413 - val_loss: 26.4456 - val_mse: 26.3742 - val_mae: 4.1238
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.7467 - mse: 29.6683 - mae: 4.2698 - val_loss: 25.6266 - val_mse: 25.5407 - val_mae: 4.0624
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.6977 - mse: 28.6051 - mae: 4.1843 - val_loss: 25.0464 - val_mse: 24.9472 - val_mae: 4.0150
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1453 - mse: 28.0411 - mae: 4.1376 - val_loss: 24.4446 - val_mse: 24.3360 - val_mae: 3.9630
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7365 - mse: 27.6243 - mae: 4.1105 - val_loss: 24.1852 - val_mse: 24.0695 - val_mae: 3.9418
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3544 - mse: 27.2355 - mae: 4.0771 - val_loss: 23.7758 - val_mse: 23.6539 - val_mae: 3.9026
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0052 - mse: 26.8803 - mae: 4.0528 - val_loss: 23.7206 - val_mse: 23.5926 - val_mae: 3.9018
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6202 - mse: 26.4901 - mae: 4.0237 - val_loss: 23.1476 - val_mse: 23.0153 - val_mae: 3.8495
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2322 - mse: 26.0980 - mae: 3.9889 - val_loss: 22.8622 - val_mse: 22.7262 - val_mae: 3.8237
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0914 - mse: 25.9536 - mae: 3.9772 - val_loss: 22.6824 - val_mse: 22.5429 - val_mae: 3.8101
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9169 - mse: 25.7757 - mae: 3.9645 - val_loss: 22.7476 - val_mse: 22.6046 - val_mae: 3.8206
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6744 - mse: 25.5299 - mae: 3.9431 - val_loss: 22.3921 - val_mse: 22.2461 - val_mae: 3.7877
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6029 - mse: 25.4556 - mae: 3.9385 - val_loss: 22.3727 - val_mse: 22.2240 - val_mae: 3.7882
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.5057 - mse: 25.3558 - mae: 3.9318 - val_loss: 22.2007 - val_mse: 22.0498 - val_mae: 3.7709
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.3896 - mse: 25.2374 - mae: 3.9251 - val_loss: 22.5312 - val_mse: 22.3778 - val_mae: 3.8062
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.1981 - mse: 25.0437 - mae: 3.9033 - val_loss: 22.0574 - val_mse: 21.9017 - val_mae: 3.7610
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.2181 - mse: 25.0617 - mae: 3.9025 - val_loss: 21.9944 - val_mse: 21.8371 - val_mae: 3.7551
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.0375 - mse: 24.8794 - mae: 3.8963 - val_loss: 22.1551 - val_mse: 21.9961 - val_mae: 3.7729
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 24.9181 - mse: 24.7584 - mae: 3.8821 - val_loss: 21.7591 - val_mse: 21.5987 - val_mae: 3.7364
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 24.9950 - mse: 24.8335 - mae: 3.8864 - val_loss: 22.0785 - val_mse: 21.9161 - val_mae: 3.7668
bias -0.0062683355
si 0.46890974
rmse 0.046814594
kgeprime [0.66526595]
rmse_95 0.056631953
rmse_99 0.065366276
pearson 0.864545626100325
pearson_95 0.6124986436252919
pearson_99 0.48398197307691293
rscore 0.7425626658992522
rscore_95 -1.2995369659143168
rscore_99 -7.489431789020635
nse [0.74256267]
nse_95 [-1.29953697]
nse_99 [-7.48943179]
kge [0.74824012]
ext_kge_95 [0.42612302]
ext_kge_99 [-0.30851625]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 173.1 173.4 173.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 3.867
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -0.01923
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 14.95
    vw2             (time, latitude, longitude) float32 105.0 ... 0.0003697
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.867
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([154228 154252 154276], shape=(3,), dtype=int64) Times out: tf.Tensor(154276, shape=(), dtype=int64)
Times in: tf.Tensor([91096 91120 91144], shape=(3,), dtype=int64) Times out: tf.Tensor(91144, shape=(), dtype=int64)
Times in: tf.Tensor([80406 80430 80454], shape=(3,), dtype=int64) Times out: tf.Tensor(80454, shape=(), dtype=int64)
Times in: tf.Tensor([148603 148627 148651], shape=(3,), dtype=int64) Times out: tf.Tensor(148651, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_700&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_701 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1400 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1401 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_700 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1400 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_700 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1401 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.3179 - mse: 55.2737 - mae: 5.7441 - val_loss: 42.1296 - val_mse: 42.0778 - val_mae: 5.1345
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 43.1378 - mse: 43.0804 - mae: 5.1041 - val_loss: 40.1965 - val_mse: 40.1330 - val_mae: 5.0140
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.9726 - mse: 40.9030 - mae: 4.9813 - val_loss: 38.5238 - val_mse: 38.4485 - val_mae: 4.9100
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 40.0890 - mse: 40.0084 - mae: 4.9263 - val_loss: 37.7751 - val_mse: 37.6894 - val_mae: 4.8638
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.7406 - mse: 39.6501 - mae: 4.9045 - val_loss: 36.6641 - val_mse: 36.5691 - val_mae: 4.7932
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.1167 - mse: 39.0170 - mae: 4.8683 - val_loss: 38.9058 - val_mse: 38.8017 - val_mae: 4.9393
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 39.0396 - mse: 38.9312 - mae: 4.8571 - val_loss: 36.7647 - val_mse: 36.6521 - val_mae: 4.8082
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.7594 - mse: 38.6427 - mae: 4.8441 - val_loss: 37.2018 - val_mse: 37.0809 - val_mae: 4.8389
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.4577 - mse: 38.3325 - mae: 4.8270 - val_loss: 36.2420 - val_mse: 36.1128 - val_mae: 4.7744
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.0745 - mse: 37.9412 - mae: 4.7998 - val_loss: 36.3341 - val_mse: 36.1968 - val_mae: 4.7828
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.6696 - mse: 37.5284 - mae: 4.7796 - val_loss: 36.5714 - val_mse: 36.4266 - val_mae: 4.7935
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.3923 - mse: 37.2443 - mae: 4.7557 - val_loss: 36.0429 - val_mse: 35.8921 - val_mae: 4.7627
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.2334 - mse: 37.0796 - mae: 4.7470 - val_loss: 36.1886 - val_mse: 36.0325 - val_mae: 4.7769
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.0195 - mse: 36.8613 - mae: 4.7311 - val_loss: 35.6591 - val_mse: 35.4987 - val_mae: 4.7402
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.7577 - mse: 36.5952 - mae: 4.7120 - val_loss: 36.1070 - val_mse: 35.9427 - val_mae: 4.7700
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.5810 - mse: 36.4148 - mae: 4.6983 - val_loss: 35.8250 - val_mse: 35.6568 - val_mae: 4.7517
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3223 - mse: 36.1525 - mae: 4.6877 - val_loss: 37.6459 - val_mse: 37.4747 - val_mae: 4.8795
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.3675 - mse: 36.1948 - mae: 4.6887 - val_loss: 35.7306 - val_mse: 35.5564 - val_mae: 4.7494
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.2032 - mse: 36.0276 - mae: 4.6757 - val_loss: 35.8905 - val_mse: 35.7135 - val_mae: 4.7631
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9989 - mse: 35.8203 - mae: 4.6637 - val_loss: 34.7690 - val_mse: 34.5891 - val_mae: 4.6886
bias -0.013246125
si 0.51304823
rmse 0.058812466
kgeprime [0.47238378]
rmse_95 0.076425195
rmse_99 0.093179986
pearson 0.8363350624214558
pearson_95 0.6398811103515055
pearson_99 0.5330490588952317
rscore 0.6833862836403793
rscore_95 -1.7472494238698677
rscore_99 -16.004004539406974
nse [0.68338628]
nse_95 [-1.74724942]
nse_99 [-16.00400454]
kge [0.59278699]
ext_kge_95 [0.52726033]
ext_kge_99 [-0.54397246]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.49 -49.18 -48.86 ... -42.93 -42.62
  * longitude       (longitude) float32 166.9 167.2 167.5 ... 173.1 173.4 173.8
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.289 -9.05 ... 3.867
    vgrd10m         (time, latitude, longitude) float32 10.25 10.03 ... -0.01923
    uw2             (time, latitude, longitude) float32 86.29 81.9 ... 14.95
    vw2             (time, latitude, longitude) float32 105.0 ... 0.0003697
    wind_magnitude  (time, latitude, longitude) float32 13.83 13.51 ... 3.867
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 

4857/4857 [==============================] - 7s 2ms/step - loss: 31.2554 - mse: 31.1084 - mae: 4.3703 - val_loss: 30.5646 - val_mse: 30.4160 - val_mae: 4.4151
bias -0.010422727
si 0.54835135
rmse 0.055150747
kgeprime [0.48791607]
rmse_95 0.06905551
rmse_99 0.0833982
pearson 0.8150656766548728
pearson_95 0.5753993076354851
pearson_99 0.6042344520111973
rscore 0.6503495370584929
rscore_95 -2.6166400398743654
rscore_99 -11.69364101008927
nse [0.65034954]
nse_95 [-2.61664004]
nse_99 [-11.69364101]
kge [0.60181656]
ext_kge_95 [0.43481576]
ext_kge_99 [0.01313588]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.93 -42.62
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 4.049
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.632
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 16.39
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.928
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.829
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([45823 45847 45871], shape=(3,), dtype=int64) Times out: tf.Tensor(45871, shape=(), dtype=int64)
Times in: tf.Tensor([130780 130804 130828], shape=(3,), dtype=int64) Times out: tf.Tensor(130828, shape=(), dtype=int64)
Times in: tf.Tensor([9814 9838 9862], shape=(3,), dtype=int64) Times out: tf.Tensor(9862, shape=(), dtype=int64)
Times in: tf.Tensor([139615 139639 139663], shape=(3,), dtype=int64) Times out: tf.Tensor(139663, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_714&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_715 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1428 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1429 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_714 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1428 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_714 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1429 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 41.9840 - mse: 41.9429 - mae: 5.0308 - val_loss: 31.9609 - val_mse: 31.9133 - val_mae: 4.5085
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0984 - mse: 34.0449 - mae: 4.5697 - val_loss: 31.0472 - val_mse: 30.9879 - val_mae: 4.4395
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0236 - mse: 32.9598 - mae: 4.4916 - val_loss: 30.3905 - val_mse: 30.3227 - val_mae: 4.3846
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5163 - mse: 32.4451 - mae: 4.4581 - val_loss: 30.1214 - val_mse: 30.0471 - val_mae: 4.3568
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2238 - mse: 32.1469 - mae: 4.4386 - val_loss: 29.9591 - val_mse: 29.8797 - val_mae: 4.3471
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0757 - mse: 31.9938 - mae: 4.4324 - val_loss: 30.1968 - val_mse: 30.1125 - val_mae: 4.3617
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7162 - mse: 31.6297 - mae: 4.4021 - val_loss: 28.7364 - val_mse: 28.6477 - val_mae: 4.2621
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5064 - mse: 31.4156 - mae: 4.3854 - val_loss: 29.3835 - val_mse: 29.2907 - val_mae: 4.3014
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2667 - mse: 31.1719 - mae: 4.3650 - val_loss: 29.1934 - val_mse: 29.0967 - val_mae: 4.2873
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0006 - mse: 30.9023 - mae: 4.3486 - val_loss: 29.0358 - val_mse: 28.9356 - val_mae: 4.2791
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0151 - mse: 30.9135 - mae: 4.3494 - val_loss: 29.0003 - val_mse: 28.8973 - val_mae: 4.2757
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8152 - mse: 30.7109 - mae: 4.3385 - val_loss: 29.4957 - val_mse: 29.3902 - val_mae: 4.3062
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7234 - mse: 30.6164 - mae: 4.3284 - val_loss: 28.3930 - val_mse: 28.2846 - val_mae: 4.2386
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.7106 - mse: 30.6008 - mae: 4.3226 - val_loss: 28.6630 - val_mse: 28.5518 - val_mae: 4.2502
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.4856 - mse: 30.3732 - mae: 4.3121 - val_loss: 28.8279 - val_mse: 28.7144 - val_mae: 4.2618
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3528 - mse: 30.2380 - mae: 4.3051 - val_loss: 29.4291 - val_mse: 29.3131 - val_mae: 4.3023
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3050 - mse: 30.1875 - mae: 4.2989 - val_loss: 28.3248 - val_mse: 28.2061 - val_mae: 4.2293
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3226 - mse: 30.2027 - mae: 4.3000 - val_loss: 29.4396 - val_mse: 29.3186 - val_mae: 4.3042
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.1391 - mse: 30.0168 - mae: 4.2846 - val_loss: 28.8624 - val_mse: 28.7391 - val_mae: 4.2624
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0760 - mse: 29.9513 - mae: 4.2779 - val_loss: 28.8911 - val_mse: 28.7653 - val_mae: 4.2615
bias -0.012332847
si 0.54551
rmse 0.05363326
kgeprime [0.40013199]
rmse_95 0.06827498
rmse_99 0.08193738
pearson 0.8166642523222547
pearson_95 0.5981482447683576
pearson_99 0.6080388142158486
rscore 0.6483393687202963
rscore_95 -2.5898275087123754
rscore_99 -13.891415903935096
nse [0.64833937]
nse_95 [-2.58982751]
nse_99 [-13.8914159]
kge [0.52860501]
ext_kge_95 [0.43209415]
ext_kge_99 [-0.14395422]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.822
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... 0.3632
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.25
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.1319
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.836
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([96315 96339 96363], shape=(3,), dtype=int64) Times out: tf.Tensor(96363, shape=(), dtype=int64)
Times in: tf.Tensor([2309 2333 2357], shape=(3,), dtype=int64) Times out: tf.Tensor(2357, shape=(), dtype=int64)
Times in: tf.Tensor([90786 90810 90834], shape=(3,), dtype=int64) Times out: tf.Tensor(90834, shape=(), dtype=int64)
Times in: tf.Tensor([114794 114818 114842], shape=(3,), dtype=int64) Times out: tf.Tensor(114842, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_715&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_716 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1430 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1431 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_715 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1430 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_715 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1431 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.4919 - mse: 43.4544 - mae: 5.1010 - val_loss: 26.6610 - val_mse: 26.6149 - val_mae: 4.1202
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.2168 - mse: 30.1664 - mae: 4.2911 - val_loss: 25.4528 - val_mse: 25.3977 - val_mae: 4.0349
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5165 - mse: 28.4573 - mae: 4.1658 - val_loss: 24.2189 - val_mse: 24.1554 - val_mae: 3.9394
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8092 - mse: 27.7428 - mae: 4.1124 - val_loss: 24.7887 - val_mse: 24.7194 - val_mae: 3.9783
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5872 - mse: 27.5163 - mae: 4.0913 - val_loss: 23.7302 - val_mse: 23.6573 - val_mae: 3.8971
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3438 - mse: 27.2696 - mae: 4.0694 - val_loss: 23.6027 - val_mse: 23.5269 - val_mae: 3.8830
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0984 - mse: 27.0214 - mae: 4.0518 - val_loss: 23.2717 - val_mse: 23.1932 - val_mae: 3.8568
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8010 - mse: 26.7213 - mae: 4.0282 - val_loss: 23.1295 - val_mse: 23.0483 - val_mae: 3.8468
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6057 - mse: 26.5232 - mae: 4.0113 - val_loss: 22.5744 - val_mse: 22.4903 - val_mae: 3.8008
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3616 - mse: 26.2763 - mae: 3.9926 - val_loss: 22.3902 - val_mse: 22.3034 - val_mae: 3.7826
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1794 - mse: 26.0914 - mae: 3.9785 - val_loss: 22.3556 - val_mse: 22.2661 - val_mae: 3.7814
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0655 - mse: 25.9747 - mae: 3.9680 - val_loss: 22.5001 - val_mse: 22.4078 - val_mae: 3.7982
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9247 - mse: 25.8311 - mae: 3.9562 - val_loss: 21.9916 - val_mse: 21.8965 - val_mae: 3.7514
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7131 - mse: 25.6166 - mae: 3.9454 - val_loss: 22.4483 - val_mse: 22.3503 - val_mae: 3.7952
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6566 - mse: 25.5572 - mae: 3.9367 - val_loss: 21.9329 - val_mse: 21.8320 - val_mae: 3.7492
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6495 - mse: 25.5473 - mae: 3.9386 - val_loss: 22.0756 - val_mse: 21.9719 - val_mae: 3.7617
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5475 - mse: 25.4424 - mae: 3.9310 - val_loss: 22.2431 - val_mse: 22.1365 - val_mae: 3.7781
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4542 - mse: 25.3462 - mae: 3.9212 - val_loss: 22.3436 - val_mse: 22.2342 - val_mae: 3.7876
Epoch 19/20
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4857/4857 [==============================] - 8s 2ms/step - loss: 25.2414 - mse: 25.1307 - mae: 3.9023 - val_loss: 21.7565 - val_mse: 21.6443 - val_mae: 3.7345
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 25.3711 - mse: 25.2579 - mae: 3.9159 - val_loss: 22.6475 - val_mse: 22.5332 - val_mae: 3.8119
bias -0.012945885
si 0.4739716
rmse 0.04746911
kgeprime [0.45260727]
rmse_95 0.053818803
rmse_99 0.061010655
pearson 0.8619943930283698
pearson_95 0.6390607280487071
pearson_99 0.3376707489837004
rscore 0.7223469992906153
rscore_95 -1.2220968076922292
rscore_99 -8.174731851554656
nse [0.722347]
nse_95 [-1.22209681]
nse_99 [-8.17473185]
kge [0.5758985]
ext_kge_95 [0.44486628]
ext_kge_99 [-0.36486662]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.93 -42.62
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 4.049
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.632
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 16.39
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.928
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.829
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([95930 95954 95978], shape=(3,), dtype=int64) Times out: tf.Tensor(95978, shape=(), dtype=int64)
Times in: tf.Tensor([112010 112034 112058], shape=(3,), dtype=int64) Times out: tf.Tensor(112058, shape=(), dtype=int64)
Times in: tf.Tensor([139127 139151 139175], shape=(3,), dtype=int64) Times out: tf.Tensor(139175, shape=(), dtype=int64)
Times in: tf.Tensor([79043 79067 79091], shape=(3,), dtype=int64) Times out: tf.Tensor(79091, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_716&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_717 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1432 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1433 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_716 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1432 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_716 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1433 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.0559 - mse: 43.0026 - mae: 5.0864 - val_loss: 33.4795 - val_mse: 33.4143 - val_mae: 4.6161
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4235 - mse: 34.3515 - mae: 4.5930 - val_loss: 32.4946 - val_mse: 32.4167 - val_mae: 4.5359
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5451 - mse: 33.4623 - mae: 4.5321 - val_loss: 31.9526 - val_mse: 31.8658 - val_mae: 4.4917
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1720 - mse: 33.0819 - mae: 4.5069 - val_loss: 31.5608 - val_mse: 31.4675 - val_mae: 4.4632
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8745 - mse: 32.7787 - mae: 4.4866 - val_loss: 31.5533 - val_mse: 31.4550 - val_mae: 4.4621
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6283 - mse: 32.5274 - mae: 4.4692 - val_loss: 31.8690 - val_mse: 31.7656 - val_mae: 4.4902
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4380 - mse: 32.3323 - mae: 4.4565 - val_loss: 32.2383 - val_mse: 32.1304 - val_mae: 4.5115
Epoch 8/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.2182 - mse: 32.1081 - mae: 4.4418 - val_loss: 31.1450 - val_mse: 31.0325 - val_mae: 4.4325
Epoch 9/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.0917 - mse: 31.9764 - mae: 4.4330 - val_loss: 31.7413 - val_mse: 31.6233 - val_mae: 4.4703
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.7317 - mse: 31.6114 - mae: 4.4075 - val_loss: 31.3606 - val_mse: 31.2378 - val_mae: 4.4471
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.6933 - mse: 31.5688 - mae: 4.4018 - val_loss: 31.1559 - val_mse: 31.0289 - val_mae: 4.4342
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.4862 - mse: 31.3574 - mae: 4.3894 - val_loss: 32.6080 - val_mse: 32.4771 - val_mae: 4.5286
Epoch 13/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.4204 - mse: 31.2877 - mae: 4.3826 - val_loss: 31.5032 - val_mse: 31.3687 - val_mae: 4.4533
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.3063 - mse: 31.1698 - mae: 4.3738 - val_loss: 31.3154 - val_mse: 31.1770 - val_mae: 4.4394
Epoch 15/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.1365 - mse: 30.9962 - mae: 4.3635 - val_loss: 30.9418 - val_mse: 30.7995 - val_mae: 4.4137
Epoch 16/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.0267 - mse: 30.8827 - mae: 4.3565 - val_loss: 31.5188 - val_mse: 31.3726 - val_mae: 4.4534
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.9563 - mse: 30.8085 - mae: 4.3502 - val_loss: 30.5859 - val_mse: 30.4362 - val_mae: 4.3909
Epoch 18/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.8111 - mse: 30.6599 - mae: 4.3361 - val_loss: 30.4570 - val_mse: 30.3040 - val_mae: 4.3845
Epoch 19/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.7610 - mse: 30.6065 - mae: 4.3332 - val_loss: 31.2332 - val_mse: 31.0769 - val_mae: 4.4362
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 30.6378 - mse: 30.4797 - mae: 4.3277 - val_loss: 30.0545 - val_mse: 29.8947 - val_mae: 4.3641
bias -0.010355213
si 0.5528449
rmse 0.054676097
kgeprime [0.48047051]
rmse_95 0.067795746
rmse_99 0.08198006
pearson 0.8132788297491214
pearson_95 0.5738064894238385
pearson_99 0.5632507091667754
rscore 0.6464687479936002
rscore_95 -2.3623464008248445
rscore_99 -12.119891472631517
nse [0.64646875]
nse_95 [-2.3623464]
nse_99 [-12.11989147]
kge [0.59470294]
ext_kge_95 [0.43620343]
ext_kge_99 [-0.100372]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.93 -42.62
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.822
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... 0.3632
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.25
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.1319
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.836
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([155309 155333 155357], shape=(3,), dtype=int64) Times out: tf.Tensor(155357, shape=(), dtype=int64)
Times in: tf.Tensor([123487 123511 123535], shape=(3,), dtype=int64) Times out: tf.Tensor(123535, shape=(), dtype=int64)
Times in: tf.Tensor([53836 53860 53884], shape=(3,), dtype=int64) Times out: tf.Tensor(53884, shape=(), dtype=int64)
Times in: tf.Tensor([99452 99476 99500], shape=(3,), dtype=int64) Times out: tf.Tensor(99500, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_717&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_718 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1434 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1435 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_717 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1434 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_717 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1435 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.3505 - mse: 38.2984 - mae: 4.7808 - val_loss: 24.7842 - val_mse: 24.7218 - val_mae: 3.9729
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.5523 - mse: 28.4850 - mae: 4.1669 - val_loss: 23.8599 - val_mse: 23.7877 - val_mae: 3.9016
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5794 - mse: 27.5027 - mae: 4.0923 - val_loss: 23.6344 - val_mse: 23.5534 - val_mae: 3.8839
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1971 - mse: 27.1127 - mae: 4.0617 - val_loss: 23.4473 - val_mse: 23.3600 - val_mae: 3.8658
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9492 - mse: 26.8594 - mae: 4.0377 - val_loss: 23.5027 - val_mse: 23.4106 - val_mae: 3.8720
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8056 - mse: 26.7111 - mae: 4.0287 - val_loss: 22.8248 - val_mse: 22.7283 - val_mae: 3.8137
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5980 - mse: 26.4996 - mae: 4.0093 - val_loss: 23.4604 - val_mse: 23.3604 - val_mae: 3.8689
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5239 - mse: 26.4221 - mae: 4.0030 - val_loss: 23.0705 - val_mse: 22.9669 - val_mae: 3.8373
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3960 - mse: 26.2905 - mae: 3.9945 - val_loss: 23.2802 - val_mse: 23.1730 - val_mae: 3.8583
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2666 - mse: 26.1578 - mae: 3.9841 - val_loss: 22.9978 - val_mse: 22.8873 - val_mae: 3.8323
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1019 - mse: 25.9896 - mae: 3.9689 - val_loss: 22.3724 - val_mse: 22.2585 - val_mae: 3.7831
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8444 - mse: 25.7287 - mae: 3.9491 - val_loss: 22.3072 - val_mse: 22.1899 - val_mae: 3.7789
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6947 - mse: 25.5760 - mae: 3.9367 - val_loss: 22.2117 - val_mse: 22.0915 - val_mae: 3.7699
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6498 - mse: 25.5280 - mae: 3.9299 - val_loss: 21.6776 - val_mse: 21.5547 - val_mae: 3.7260
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4767 - mse: 25.3525 - mae: 3.9220 - val_loss: 22.2144 - val_mse: 22.0891 - val_mae: 3.7735
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3486 - mse: 25.2223 - mae: 3.9090 - val_loss: 21.7924 - val_mse: 21.6650 - val_mae: 3.7375
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3857 - mse: 25.2575 - mae: 3.9115 - val_loss: 21.8600 - val_mse: 21.7309 - val_mae: 3.7452
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2441 - mse: 25.1142 - mae: 3.9020 - val_loss: 21.3292 - val_mse: 21.1983 - val_mae: 3.6966
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2451 - mse: 25.1136 - mae: 3.9052 - val_loss: 21.5879 - val_mse: 21.4556 - val_mae: 3.7215
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1023 - mse: 24.9693 - mae: 3.8917 - val_loss: 22.1709 - val_mse: 22.0372 - val_mae: 3.7718
bias -0.010660691
si 0.47786355
rmse 0.046943747
kgeprime [0.50794894]
rmse_95 0.05741494
rmse_99 0.06507071
pearson 0.8597042502223984
pearson_95 0.6153967322097627
pearson_99 0.29042835056213406
rscore 0.7248699934468987
rscore_95 -1.59798096291521
rscore_99 -10.681301670316536
nse [0.72486999]
nse_95 [-1.59798096]
nse_99 [-10.68130167]
kge [0.62526973]
ext_kge_95 [0.41033979]
ext_kge_99 [-0.47316173]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.93 -42.62
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 4.049
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.632
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 16.39
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.928
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.829
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([111476 111500 111524], shape=(3,), dtype=int64) Times out: tf.Tensor(111524, shape=(), dtype=int64)
Times in: tf.Tensor([22347 22371 22395], shape=(3,), dtype=int64) Times out: tf.Tensor(22395, shape=(), dtype=int64)
Times in: tf.Tensor([146557 146581 146605], shape=(3,), dtype=int64) Times out: tf.Tensor(146605, shape=(), dtype=int64)
Times in: tf.Tensor([101376 101400 101424], shape=(3,), dtype=int64) Times out: tf.Tensor(101424, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_718&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_719 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1436 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1437 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_718 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1436 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_718 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1437 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.6925 - mse: 42.6372 - mae: 5.0722 - val_loss: 33.7194 - val_mse: 33.6540 - val_mae: 4.6259
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2663 - mse: 35.1939 - mae: 4.6467 - val_loss: 32.9321 - val_mse: 32.8526 - val_mae: 4.5498
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2418 - mse: 34.1569 - mae: 4.5841 - val_loss: 31.8211 - val_mse: 31.7310 - val_mae: 4.4797
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7794 - mse: 33.6848 - mae: 4.5511 - val_loss: 31.3527 - val_mse: 31.2540 - val_mae: 4.4555
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4415 - mse: 33.3387 - mae: 4.5312 - val_loss: 31.5816 - val_mse: 31.4753 - val_mae: 4.4627
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1520 - mse: 33.0412 - mae: 4.5079 - val_loss: 30.8531 - val_mse: 30.7380 - val_mae: 4.4082
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8638 - mse: 32.7443 - mae: 4.4905 - val_loss: 30.6876 - val_mse: 30.5642 - val_mae: 4.3952
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4251 - mse: 32.2973 - mae: 4.4582 - val_loss: 30.3973 - val_mse: 30.2662 - val_mae: 4.3789
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2831 - mse: 32.1480 - mae: 4.4456 - val_loss: 30.6147 - val_mse: 30.4761 - val_mae: 4.3934
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0389 - mse: 31.8970 - mae: 4.4288 - val_loss: 30.5966 - val_mse: 30.4518 - val_mae: 4.3892
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9295 - mse: 31.7815 - mae: 4.4165 - val_loss: 30.4467 - val_mse: 30.2961 - val_mae: 4.3830
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7828 - mse: 31.6296 - mae: 4.4086 - val_loss: 30.4418 - val_mse: 30.2859 - val_mae: 4.3779
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5957 - mse: 31.4372 - mae: 4.3966 - val_loss: 30.5086 - val_mse: 30.3479 - val_mae: 4.3892
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4046 - mse: 31.2417 - mae: 4.3834 - val_loss: 30.0051 - val_mse: 29.8401 - val_mae: 4.3459
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3495 - mse: 31.1823 - mae: 4.3742 - val_loss: 30.2059 - val_mse: 30.0369 - val_mae: 4.3637
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.2528 - mse: 31.0817 - mae: 4.3755 - val_loss: 30.0560 - val_mse: 29.8832 - val_mae: 4.3447
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.1277 - mse: 30.9529 - mae: 4.3618 - val_loss: 30.0119 - val_mse: 29.8357 - val_mae: 4.3493
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0543 - mse: 30.8761 - mae: 4.3533 - val_loss: 30.0343 - val_mse: 29.8546 - val_mae: 4.3447
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.0024 - mse: 30.8207 - mae: 4.3500 - val_loss: 30.2846 - val_mse: 30.1015 - val_mae: 4.3593
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.8965 - mse: 30.7118 - mae: 4.3472 - val_loss: 30.0878 - val_mse: 29.9019 - val_mae: 4.3484
bias -0.006942445
si 0.54946995
rmse 0.054682568
kgeprime [0.56212452]
rmse_95 0.0761129
rmse_99 0.09205186
pearson 0.8147309788874014
pearson_95 0.5562239075478882
pearson_99 0.5923827359969472
rscore 0.6582709141890416
rscore_95 -3.1146314474417567
rscore_99 -14.947347117822739
nse [0.65827091]
nse_95 [-3.11463145]
nse_99 [-14.94734712]
kge [0.65923098]
ext_kge_95 [0.42176813]
ext_kge_99 [-0.0809385]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... -0.4935
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.11
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([126052 126076 126100], shape=(3,), dtype=int64) Times out: tf.Tensor(126100, shape=(), dtype=int64)
Times in: tf.Tensor([71960 71984 72008], shape=(3,), dtype=int64) Times out: tf.Tensor(72008, shape=(), dtype=int64)
Times in: tf.Tensor([56703 56727 56751], shape=(3,), dtype=int64) Times out: tf.Tensor(56751, shape=(), dtype=int64)
Times in: tf.Tensor([37421 37445 37469], shape=(3,), dtype=int64) Times out: tf.Tensor(37469, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_719&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_720 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1438 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1439 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_719 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1438 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_719 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1439 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.3030 - mse: 37.2592 - mae: 4.7170 - val_loss: 24.6336 - val_mse: 24.5788 - val_mae: 3.9590
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2632 - mse: 28.2021 - mae: 4.1506 - val_loss: 23.9903 - val_mse: 23.9229 - val_mae: 3.9174
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9452 - mse: 26.8735 - mae: 4.0459 - val_loss: 24.1498 - val_mse: 24.0748 - val_mae: 3.9264
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5228 - mse: 26.4459 - mae: 4.0082 - val_loss: 23.0241 - val_mse: 22.9454 - val_mae: 3.8304
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2381 - mse: 26.1583 - mae: 3.9863 - val_loss: 22.7854 - val_mse: 22.7042 - val_mae: 3.8120
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8789 - mse: 25.7967 - mae: 3.9573 - val_loss: 23.6581 - val_mse: 23.5747 - val_mae: 3.8866
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5016 - mse: 25.4173 - mae: 3.9250 - val_loss: 22.3448 - val_mse: 22.2588 - val_mae: 3.7755
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2481 - mse: 25.1610 - mae: 3.9088 - val_loss: 22.1232 - val_mse: 22.0346 - val_mae: 3.7632
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9622 - mse: 24.8725 - mae: 3.8807 - val_loss: 21.7773 - val_mse: 21.6860 - val_mae: 3.7310
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.8332 - mse: 24.7410 - mae: 3.8728 - val_loss: 22.1584 - val_mse: 22.0649 - val_mae: 3.7706
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6555 - mse: 24.5610 - mae: 3.8589 - val_loss: 21.2794 - val_mse: 21.1838 - val_mae: 3.6920
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.5395 - mse: 24.4431 - mae: 3.8459 - val_loss: 21.4421 - val_mse: 21.3447 - val_mae: 3.7134
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.4352 - mse: 24.3372 - mae: 3.8375 - val_loss: 21.5884 - val_mse: 21.4894 - val_mae: 3.7250
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.4104 - mse: 24.3108 - mae: 3.8359 - val_loss: 21.1787 - val_mse: 21.0781 - val_mae: 3.6877
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2978 - mse: 24.1967 - mae: 3.8283 - val_loss: 21.5176 - val_mse: 21.4157 - val_mae: 3.7193
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2260 - mse: 24.1235 - mae: 3.8263 - val_loss: 21.3409 - val_mse: 21.2375 - val_mae: 3.7078
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.1811 - mse: 24.0773 - mae: 3.8157 - val_loss: 21.1409 - val_mse: 21.0364 - val_mae: 3.6903
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0732 - mse: 23.9682 - mae: 3.8071 - val_loss: 21.1759 - val_mse: 21.0700 - val_mae: 3.6926
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0460 - mse: 23.9397 - mae: 3.8079 - val_loss: 20.9018 - val_mse: 20.7949 - val_mae: 3.6674
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0586 - mse: 23.9514 - mae: 3.8078 - val_loss: 21.3505 - val_mse: 21.2425 - val_mae: 3.7091
bias -0.009488267
si 0.47576067
rmse 0.046089623
kgeprime [0.55323271]
rmse_95 0.055285074
rmse_99 0.06354817
pearson 0.8614453494466934
pearson_95 0.60062990582797
pearson_99 0.2715231483248918
rscore 0.7303191487161649
rscore_95 -1.4813407911513763
rscore_99 -10.025960586843594
nse [0.73031915]
nse_95 [-1.48134079]
nse_99 [-10.02596059]
kge [0.66130347]
ext_kge_95 [0.40224592]
ext_kge_99 [-0.48566065]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... -0.4935
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.11
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([98455 98479 98503], shape=(3,), dtype=int64) Times out: tf.Tensor(98503, shape=(), dtype=int64)
Times in: tf.Tensor([131091 131115 131139], shape=(3,), dtype=int64) Times out: tf.Tensor(131139, shape=(), dtype=int64)
Times in: tf.Tensor([144971 144995 145019], shape=(3,), dtype=int64) Times out: tf.Tensor(145019, shape=(), dtype=int64)
Times in: tf.Tensor([1302 1326 1350], shape=(3,), dtype=int64) Times out: tf.Tensor(1350, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_720&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_721 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1440 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1441 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_720 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1440 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_720 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1441 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 39.8047 - mse: 39.7530 - mae: 4.8772 - val_loss: 26.5391 - val_mse: 26.4790 - val_mae: 4.1075
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.3936 - mse: 30.3292 - mae: 4.3040 - val_loss: 27.3926 - val_mse: 27.3225 - val_mae: 4.1813
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.9226 - mse: 28.8477 - mae: 4.1927 - val_loss: 25.6795 - val_mse: 25.5994 - val_mae: 4.0458
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7291 - mse: 27.6451 - mae: 4.1080 - val_loss: 24.9612 - val_mse: 24.8730 - val_mae: 3.9885
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2566 - mse: 27.1656 - mae: 4.0687 - val_loss: 23.8404 - val_mse: 23.7463 - val_mae: 3.9001
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9999 - mse: 26.9038 - mae: 4.0481 - val_loss: 24.2583 - val_mse: 24.1597 - val_mae: 3.9343
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6709 - mse: 26.5704 - mae: 4.0220 - val_loss: 23.1485 - val_mse: 23.0462 - val_mae: 3.8445
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4136 - mse: 26.3093 - mae: 4.0022 - val_loss: 24.2414 - val_mse: 24.1351 - val_mae: 3.9308
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1251 - mse: 26.0174 - mae: 3.9813 - val_loss: 23.6898 - val_mse: 23.5804 - val_mae: 3.8890
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8648 - mse: 25.7538 - mae: 3.9582 - val_loss: 23.1325 - val_mse: 23.0198 - val_mae: 3.8454
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6627 - mse: 25.5489 - mae: 3.9454 - val_loss: 21.8431 - val_mse: 21.7281 - val_mae: 3.7315
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5623 - mse: 25.4461 - mae: 3.9353 - val_loss: 21.9007 - val_mse: 21.7831 - val_mae: 3.7435
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4471 - mse: 25.3287 - mae: 3.9286 - val_loss: 22.9901 - val_mse: 22.8704 - val_mae: 3.8358
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2972 - mse: 25.1766 - mae: 3.9178 - val_loss: 22.7317 - val_mse: 22.6100 - val_mae: 3.8138
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2763 - mse: 25.1536 - mae: 3.9174 - val_loss: 22.7852 - val_mse: 22.6614 - val_mae: 3.8184
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1798 - mse: 25.0554 - mae: 3.9075 - val_loss: 23.1408 - val_mse: 23.0154 - val_mae: 3.8488
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1420 - mse: 25.0159 - mae: 3.9015 - val_loss: 22.2187 - val_mse: 22.0917 - val_mae: 3.7704
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.0693 - mse: 24.9415 - mae: 3.8977 - val_loss: 22.6472 - val_mse: 22.5186 - val_mae: 3.8068
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9181 - mse: 24.7889 - mae: 3.8867 - val_loss: 22.5579 - val_mse: 22.4278 - val_mae: 3.7999
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9327 - mse: 24.8022 - mae: 3.8834 - val_loss: 21.5634 - val_mse: 21.4320 - val_mae: 3.7133
bias -0.0076564853
si 0.47243628
rmse 0.04629476
kgeprime [0.61857487]
rmse_95 0.055712286
rmse_99 0.06473229
pearson 0.8631771910947811
pearson_95 0.6132861876069409
pearson_99 0.2591443090228165
rscore 0.7374618127269457
rscore_95 -1.4195119837748185
rscore_99 -10.869408100080603
nse [0.73746181]
nse_95 [-1.41951198]
nse_99 [-10.8694081]
kge [0.71360634]
ext_kge_95 [0.4036095]
ext_kge_99 [-0.71024425]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 15.98
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([106090 106114 106138], shape=(3,), dtype=int64) Times out: tf.Tensor(106138, shape=(), dtype=int64)
Times in: tf.Tensor([78839 78863 78887], shape=(3,), dtype=int64) Times out: tf.Tensor(78887, shape=(), dtype=int64)
Times in: tf.Tensor([17656 17680 17704], shape=(3,), dtype=int64) Times out: tf.Tensor(17704, shape=(), dtype=int64)
Times in: tf.Tensor([152489 152513 152537], shape=(3,), dtype=int64) Times out: tf.Tensor(152537, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_721&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_722 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1442 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1443 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_721 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1442 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_721 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1443 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 55.9458 - mse: 55.9052 - mae: 5.8029 - val_loss: 45.2045 - val_mse: 45.1599 - val_mae: 5.2639
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 44.6926 - mse: 44.6465 - mae: 5.1998 - val_loss: 35.7890 - val_mse: 35.7408 - val_mae: 4.7383
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8091 - mse: 37.7551 - mae: 4.8119 - val_loss: 34.5326 - val_mse: 34.4733 - val_mae: 4.6693
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4371 - mse: 36.3730 - mae: 4.7234 - val_loss: 33.6559 - val_mse: 33.5874 - val_mae: 4.6097
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7641 - mse: 35.6921 - mae: 4.6779 - val_loss: 33.2745 - val_mse: 33.1995 - val_mae: 4.5830
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3686 - mse: 35.2909 - mae: 4.6486 - val_loss: 33.6987 - val_mse: 33.6184 - val_mae: 4.6130
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2321 - mse: 35.1492 - mae: 4.6400 - val_loss: 32.4647 - val_mse: 32.3793 - val_mae: 4.5273
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8198 - mse: 34.7316 - mae: 4.6141 - val_loss: 32.1070 - val_mse: 32.0162 - val_mae: 4.5005
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4730 - mse: 34.3790 - mae: 4.5924 - val_loss: 32.7505 - val_mse: 32.6539 - val_mae: 4.5433
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2424 - mse: 34.1429 - mae: 4.5688 - val_loss: 32.2311 - val_mse: 32.1292 - val_mae: 4.5108
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0891 - mse: 33.9847 - mae: 4.5634 - val_loss: 32.4511 - val_mse: 32.3445 - val_mae: 4.5245
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8471 - mse: 33.7383 - mae: 4.5439 - val_loss: 32.2607 - val_mse: 32.1500 - val_mae: 4.5065
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5897 - mse: 33.4769 - mae: 4.5270 - val_loss: 32.1045 - val_mse: 31.9901 - val_mae: 4.4956
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6516 - mse: 33.5352 - mae: 4.5317 - val_loss: 31.9070 - val_mse: 31.7889 - val_mae: 4.4815
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4830 - mse: 33.3633 - mae: 4.5187 - val_loss: 31.9523 - val_mse: 31.8310 - val_mae: 4.4875
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4135 - mse: 33.2905 - mae: 4.5163 - val_loss: 32.0152 - val_mse: 31.8908 - val_mae: 4.4920
Epoch 17/20
4857/4857 [==============================] - 8s 2ms/step - loss: 33.3286 - mse: 33.2029 - mae: 4.5065 - val_loss: 31.2954 - val_mse: 31.1684 - val_mae: 4.4419
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2405 - mse: 33.1120 - mae: 4.4996 - val_loss: 31.6895 - val_mse: 31.5598 - val_mae: 4.4712
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0894 - mse: 32.9584 - mae: 4.4925 - val_loss: 31.6407 - val_mse: 31.5086 - val_mae: 4.4594
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0473 - mse: 32.9137 - mae: 4.4905 - val_loss: 32.2876 - val_mse: 32.1527 - val_mae: 4.5043
bias -0.013395569
si 0.5548221
rmse 0.056703333
kgeprime [0.36811505]
rmse_95 0.07482225
rmse_99 0.09353247
pearson 0.8106477307887274
pearson_95 0.5195751504511353
pearson_99 0.5661512623074527
rscore 0.6368839820202707
rscore_95 -3.039869175137186
rscore_99 -15.077310457016118
nse [0.63688398]
nse_95 [-3.03986918]
nse_99 [-15.07731046]
kge [0.49988676]
ext_kge_95 [0.42225732]
ext_kge_99 [0.10625482]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... -0.4935
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.11
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([121687 121711 121735], shape=(3,), dtype=int64) Times out: tf.Tensor(121735, shape=(), dtype=int64)
Times in: tf.Tensor([24304 24328 24352], shape=(3,), dtype=int64) Times out: tf.Tensor(24352, shape=(), dtype=int64)
Times in: tf.Tensor([115041 115065 115089], shape=(3,), dtype=int64) Times out: tf.Tensor(115089, shape=(), dtype=int64)
Times in: tf.Tensor([131346 131370 131394], shape=(3,), dtype=int64) Times out: tf.Tensor(131394, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_722&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_723 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1444 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1445 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_722 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1444 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_722 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1445 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 43.4026 - mse: 43.3485 - mae: 5.0962 - val_loss: 27.1518 - val_mse: 27.0830 - val_mae: 4.1333
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1612 - mse: 32.0810 - mae: 4.4255 - val_loss: 26.4686 - val_mse: 26.3750 - val_mae: 4.0875
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 30.0178 - mse: 29.9131 - mae: 4.2724 - val_loss: 25.0899 - val_mse: 24.9756 - val_mae: 3.9896
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.8294 - mse: 28.7071 - mae: 4.1769 - val_loss: 24.7849 - val_mse: 24.6550 - val_mae: 3.9738
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0889 - mse: 27.9544 - mae: 4.1104 - val_loss: 23.5814 - val_mse: 23.4432 - val_mae: 3.8752
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.7249 - mse: 27.5847 - mae: 4.0800 - val_loss: 23.0407 - val_mse: 22.8986 - val_mae: 3.8295
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2559 - mse: 27.1127 - mae: 4.0439 - val_loss: 22.2124 - val_mse: 22.0682 - val_mae: 3.7564
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0024 - mse: 26.8578 - mae: 4.0187 - val_loss: 23.8830 - val_mse: 23.7374 - val_mae: 3.9016
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7973 - mse: 26.6516 - mae: 4.0044 - val_loss: 23.4955 - val_mse: 23.3493 - val_mae: 3.8723
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6080 - mse: 26.4615 - mae: 3.9973 - val_loss: 22.7379 - val_mse: 22.5908 - val_mae: 3.8092
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4737 - mse: 26.3264 - mae: 3.9833 - val_loss: 21.9819 - val_mse: 21.8342 - val_mae: 3.7482
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2749 - mse: 26.1270 - mae: 3.9621 - val_loss: 22.6269 - val_mse: 22.4786 - val_mae: 3.8041
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2541 - mse: 26.1056 - mae: 3.9634 - val_loss: 21.8673 - val_mse: 21.7184 - val_mae: 3.7364
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0578 - mse: 25.9085 - mae: 3.9497 - val_loss: 21.7972 - val_mse: 21.6477 - val_mae: 3.7334
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1665 - mse: 26.0169 - mae: 3.9575 - val_loss: 21.5369 - val_mse: 21.3866 - val_mae: 3.7097
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0355 - mse: 25.8851 - mae: 3.9474 - val_loss: 21.8743 - val_mse: 21.7236 - val_mae: 3.7396
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9475 - mse: 25.7966 - mae: 3.9425 - val_loss: 21.4375 - val_mse: 21.2861 - val_mae: 3.7031
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8407 - mse: 25.6893 - mae: 3.9373 - val_loss: 21.4297 - val_mse: 21.2779 - val_mae: 3.7002
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8981 - mse: 25.7461 - mae: 3.9365 - val_loss: 21.9486 - val_mse: 21.7962 - val_mae: 3.7475
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7831 - mse: 25.6306 - mae: 3.9261 - val_loss: 22.7619 - val_mse: 22.6093 - val_mae: 3.8162
bias -0.013902862
si 0.4771046
rmse 0.04754919
kgeprime [0.41950599]
rmse_95 0.052403633
rmse_99 0.059888612
pearson 0.8604979457014974
pearson_95 0.6214469046637164
pearson_99 0.2450740316235349
rscore 0.7159584978941256
rscore_95 -1.1863259801609436
rscore_99 -8.903448237151675
nse [0.7159585]
nse_95 [-1.18632598]
nse_99 [-8.90344824]
kge [0.54493619]
ext_kge_95 [0.40381163]
ext_kge_99 [-0.54916319]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 15.98
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([104645 104669 104693], shape=(3,), dtype=int64) Times out: tf.Tensor(104693, shape=(), dtype=int64)
Times in: tf.Tensor([139974 139998 140022], shape=(3,), dtype=int64) Times out: tf.Tensor(140022, shape=(), dtype=int64)
Times in: tf.Tensor([2697 2721 2745], shape=(3,), dtype=int64) Times out: tf.Tensor(2745, shape=(), dtype=int64)
Times in: tf.Tensor([29200 29224 29248], shape=(3,), dtype=int64) Times out: tf.Tensor(29248, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_723&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_724 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1446 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1447 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_723 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1446 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_723 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1447 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.1031 - mse: 46.0461 - mae: 5.2636 - val_loss: 34.4550 - val_mse: 34.3840 - val_mae: 4.6542
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.8275 - mse: 36.7489 - mae: 4.7450 - val_loss: 32.6996 - val_mse: 32.6144 - val_mae: 4.5371
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.7325 - mse: 35.6424 - mae: 4.6731 - val_loss: 32.3795 - val_mse: 32.2854 - val_mae: 4.5152
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2227 - mse: 35.1251 - mae: 4.6475 - val_loss: 31.9300 - val_mse: 31.8296 - val_mae: 4.4887
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9870 - mse: 34.8840 - mae: 4.6277 - val_loss: 31.6133 - val_mse: 31.5078 - val_mae: 4.4742
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6725 - mse: 34.5641 - mae: 4.6064 - val_loss: 31.6082 - val_mse: 31.4974 - val_mae: 4.4690
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4840 - mse: 34.3705 - mae: 4.5933 - val_loss: 31.6030 - val_mse: 31.4868 - val_mae: 4.4692
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3491 - mse: 34.2304 - mae: 4.5818 - val_loss: 31.3973 - val_mse: 31.2761 - val_mae: 4.4567
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1518 - mse: 34.0282 - mae: 4.5723 - val_loss: 31.4478 - val_mse: 31.3216 - val_mae: 4.4564
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7546 - mse: 33.6259 - mae: 4.5451 - val_loss: 31.1566 - val_mse: 31.0259 - val_mae: 4.4333
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8036 - mse: 33.6706 - mae: 4.5500 - val_loss: 31.6103 - val_mse: 31.4747 - val_mae: 4.4616
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5688 - mse: 33.4311 - mae: 4.5346 - val_loss: 31.5566 - val_mse: 31.4165 - val_mae: 4.4608
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3645 - mse: 33.2226 - mae: 4.5215 - val_loss: 31.4305 - val_mse: 31.2866 - val_mae: 4.4460
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3176 - mse: 33.1720 - mae: 4.5162 - val_loss: 31.1816 - val_mse: 31.0343 - val_mae: 4.4282
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0714 - mse: 32.9223 - mae: 4.4939 - val_loss: 31.3851 - val_mse: 31.2346 - val_mae: 4.4406
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0274 - mse: 32.8754 - mae: 4.4923 - val_loss: 30.7480 - val_mse: 30.5950 - val_mae: 4.4010
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0040 - mse: 32.8497 - mae: 4.4844 - val_loss: 30.6720 - val_mse: 30.5165 - val_mae: 4.3949
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7626 - mse: 32.6058 - mae: 4.4699 - val_loss: 31.0434 - val_mse: 30.8854 - val_mae: 4.4175
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5759 - mse: 32.4166 - mae: 4.4578 - val_loss: 30.7698 - val_mse: 30.6097 - val_mae: 4.4002
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5978 - mse: 32.4367 - mae: 4.4568 - val_loss: 30.5028 - val_mse: 30.3406 - val_mae: 4.3765
bias -0.005855445
si 0.55071294
rmse 0.05508235
kgeprime [0.59272803]
rmse_95 0.080683716
rmse_99 0.100013226
pearson 0.8134288045267952
pearson_95 0.5111311084876875
pearson_99 0.5514685317904019
rscore 0.6577994060739581
rscore_95 -3.688767587094836
rscore_99 -14.999752143289685
nse [0.65779941]
nse_95 [-3.68876759]
nse_99 [-14.99975214]
kge [0.67890506]
ext_kge_95 [0.37437073]
ext_kge_99 [-0.03592428]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 15.98
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([122312 122336 122360], shape=(3,), dtype=int64) Times out: tf.Tensor(122360, shape=(), dtype=int64)
Times in: tf.Tensor([14839 14863 14887], shape=(3,), dtype=int64) Times out: tf.Tensor(14887, shape=(), dtype=int64)
Times in: tf.Tensor([28947 28971 28995], shape=(3,), dtype=int64) Times out: tf.Tensor(28995, shape=(), dtype=int64)
Times in: tf.Tensor([47341 47365 47389], shape=(3,), dtype=int64) Times out: tf.Tensor(47389, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_724&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_725 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1448 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1449 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_724 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1448 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_724 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1449 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.5770 - mse: 45.5198 - mae: 5.2375 - val_loss: 34.5505 - val_mse: 34.4799 - val_mae: 4.6722
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4221 - mse: 36.3445 - mae: 4.7204 - val_loss: 33.1125 - val_mse: 33.0287 - val_mae: 4.5915
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3751 - mse: 35.2859 - mae: 4.6499 - val_loss: 32.2843 - val_mse: 32.1907 - val_mae: 4.5206
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.9036 - mse: 34.8066 - mae: 4.6196 - val_loss: 32.7526 - val_mse: 32.6529 - val_mae: 4.5486
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.5841 - mse: 34.4815 - mae: 4.5973 - val_loss: 31.9660 - val_mse: 31.8605 - val_mae: 4.5036
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3113 - mse: 34.2030 - mae: 4.5837 - val_loss: 31.9261 - val_mse: 31.8151 - val_mae: 4.4947
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9175 - mse: 33.8032 - mae: 4.5553 - val_loss: 32.0339 - val_mse: 31.9166 - val_mae: 4.5029
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.5854 - mse: 33.4649 - mae: 4.5338 - val_loss: 31.3484 - val_mse: 31.2248 - val_mae: 4.4582
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3247 - mse: 33.1981 - mae: 4.5160 - val_loss: 31.4077 - val_mse: 31.2784 - val_mae: 4.4543
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1892 - mse: 33.0579 - mae: 4.5067 - val_loss: 31.0580 - val_mse: 30.9246 - val_mae: 4.4292
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9992 - mse: 32.8639 - mae: 4.4948 - val_loss: 31.4974 - val_mse: 31.3603 - val_mae: 4.4533
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8318 - mse: 32.6930 - mae: 4.4843 - val_loss: 31.8674 - val_mse: 31.7270 - val_mae: 4.4767
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7909 - mse: 32.6487 - mae: 4.4751 - val_loss: 31.0333 - val_mse: 30.8896 - val_mae: 4.4241
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5689 - mse: 32.4236 - mae: 4.4625 - val_loss: 31.5097 - val_mse: 31.3631 - val_mae: 4.4514
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5580 - mse: 32.4099 - mae: 4.4573 - val_loss: 30.6419 - val_mse: 30.4924 - val_mae: 4.3990
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5651 - mse: 32.4143 - mae: 4.4594 - val_loss: 31.1652 - val_mse: 31.0131 - val_mae: 4.4266
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4224 - mse: 32.2691 - mae: 4.4521 - val_loss: 31.2221 - val_mse: 31.0675 - val_mae: 4.4307
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2378 - mse: 32.0822 - mae: 4.4387 - val_loss: 30.7566 - val_mse: 30.6001 - val_mae: 4.3994
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0779 - mse: 31.9201 - mae: 4.4283 - val_loss: 31.2947 - val_mse: 31.1356 - val_mae: 4.4372
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1654 - mse: 32.0049 - mae: 4.4361 - val_loss: 30.8655 - val_mse: 30.7037 - val_mae: 4.4059
bias -0.0075838994
si 0.55311805
rmse 0.05541096
kgeprime [0.55303363]
rmse_95 0.0758027
rmse_99 0.09186066
pearson 0.812667339725002
pearson_95 0.5103051896488279
pearson_99 0.5743562647321437
rscore 0.6533931057119591
rscore_95 -3.131612621246912
rscore_99 -14.22592211689582
nse [0.65339311]
nse_95 [-3.13161262]
nse_99 [-14.22592212]
kge [0.65340304]
ext_kge_95 [0.37864564]
ext_kge_99 [-0.05091588]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.37 -10.13 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.33 10.51 ... -0.4935
    uw2             (time, latitude, longitude) float32 107.5 102.6 ... 23.11
    vw2             (time, latitude, longitude) float32 106.7 110.4 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.64 14.6 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([40356 40380 40404], shape=(3,), dtype=int64) Times out: tf.Tensor(40404, shape=(), dtype=int64)
Times in: tf.Tensor([43467 43491 43515], shape=(3,), dtype=int64) Times out: tf.Tensor(43515, shape=(), dtype=int64)
Times in: tf.Tensor([28526 28550 28574], shape=(3,), dtype=int64) Times out: tf.Tensor(28574, shape=(), dtype=int64)
Times in: tf.Tensor([2796 2820 2844], shape=(3,), dtype=int64) Times out: tf.Tensor(2844, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_725&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_726 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1450 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1451 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_725 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1450 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_725 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1451 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 42.0328 - mse: 41.9849 - mae: 4.9980 - val_loss: 24.5677 - val_mse: 24.5076 - val_mae: 3.9381
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 29.6350 - mse: 29.5705 - mae: 4.2457 - val_loss: 23.4804 - val_mse: 23.4111 - val_mae: 3.8590
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.7466 - mse: 28.6737 - mae: 4.1744 - val_loss: 23.0424 - val_mse: 22.9663 - val_mae: 3.8193
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.2950 - mse: 28.2167 - mae: 4.1431 - val_loss: 22.8601 - val_mse: 22.7793 - val_mae: 3.8073
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.0478 - mse: 27.9657 - mae: 4.1215 - val_loss: 22.5268 - val_mse: 22.4429 - val_mae: 3.7734
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8885 - mse: 27.8035 - mae: 4.1065 - val_loss: 22.4427 - val_mse: 22.3560 - val_mae: 3.7672
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.8334 - mse: 27.7454 - mae: 4.1043 - val_loss: 22.4668 - val_mse: 22.3773 - val_mae: 3.7747
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.6514 - mse: 27.5609 - mae: 4.0922 - val_loss: 22.1877 - val_mse: 22.0959 - val_mae: 3.7490
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5013 - mse: 27.4085 - mae: 4.0761 - val_loss: 22.0618 - val_mse: 21.9679 - val_mae: 3.7340
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4506 - mse: 27.3559 - mae: 4.0692 - val_loss: 22.2154 - val_mse: 22.1197 - val_mae: 3.7555
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5480 - mse: 27.4515 - mae: 4.0723 - val_loss: 22.3780 - val_mse: 22.2804 - val_mae: 3.7703
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.4017 - mse: 27.3035 - mae: 4.0631 - val_loss: 22.1755 - val_mse: 22.0764 - val_mae: 3.7501
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2720 - mse: 27.1722 - mae: 4.0558 - val_loss: 22.0603 - val_mse: 21.9594 - val_mae: 3.7431
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.2405 - mse: 27.1391 - mae: 4.0526 - val_loss: 21.7934 - val_mse: 21.6910 - val_mae: 3.7174
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.1731 - mse: 27.0701 - mae: 4.0396 - val_loss: 21.7952 - val_mse: 21.6911 - val_mae: 3.7187
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0662 - mse: 26.9616 - mae: 4.0361 - val_loss: 22.1948 - val_mse: 22.0893 - val_mae: 3.7540
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9975 - mse: 26.8913 - mae: 4.0329 - val_loss: 21.8058 - val_mse: 21.6989 - val_mae: 3.7206
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.9332 - mse: 26.8256 - mae: 4.0254 - val_loss: 21.4728 - val_mse: 21.3644 - val_mae: 3.6909
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8687 - mse: 26.7595 - mae: 4.0177 - val_loss: 21.6957 - val_mse: 21.5856 - val_mae: 3.7109
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7141 - mse: 26.6035 - mae: 4.0076 - val_loss: 21.4835 - val_mse: 21.3721 - val_mae: 3.6941
bias -0.005780295
si 0.4846397
rmse 0.046229925
kgeprime [0.63008219]
rmse_95 0.06390151
rmse_99 0.07263921
pearson 0.8560871398032138
pearson_95 0.5987756903220353
pearson_99 0.2631110160379495
rscore 0.7279698921244161
rscore_95 -2.2859719283818185
rscore_99 -13.880226899850536
nse [0.72796989]
nse_95 [-2.28597193]
nse_99 [-13.8802269]
kge [0.71741866]
ext_kge_95 [0.35313431]
ext_kge_99 [-0.58027957]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 23, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -49.18 -48.86 -48.55 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.61 -8.42 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.659 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 74.13 70.89 ... 15.98
    vw2             (time, latitude, longitude) float32 93.29 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.94 12.69 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([62403 62427 62451], shape=(3,), dtype=int64) Times out: tf.Tensor(62451, shape=(), dtype=int64)
Times in: tf.Tensor([42984 43008 43032], shape=(3,), dtype=int64) Times out: tf.Tensor(43032, shape=(), dtype=int64)
Times in: tf.Tensor([22914 22938 22962], shape=(3,), dtype=int64) Times out: tf.Tensor(22962, shape=(), dtype=int64)
Times in: tf.Tensor([127018 127042 127066], shape=(3,), dtype=int64) Times out: tf.Tensor(127066, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_726&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_727 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1452 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1453 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_726 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1452 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_726 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1453 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.0196 - mse: 44.9629 - mae: 5.2040 - val_loss: 34.2546 - val_mse: 34.1855 - val_mae: 4.6674
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9104 - mse: 35.8327 - mae: 4.6908 - val_loss: 32.8821 - val_mse: 32.7960 - val_mae: 4.5627
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7168 - mse: 34.6235 - mae: 4.6118 - val_loss: 32.4391 - val_mse: 32.3391 - val_mae: 4.5313
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2202 - mse: 34.1142 - mae: 4.5764 - val_loss: 32.0835 - val_mse: 31.9726 - val_mae: 4.5120
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7861 - mse: 33.6702 - mae: 4.5455 - val_loss: 32.1323 - val_mse: 32.0121 - val_mae: 4.5006
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4791 - mse: 33.3547 - mae: 4.5282 - val_loss: 32.0750 - val_mse: 31.9469 - val_mae: 4.4981
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2178 - mse: 33.0855 - mae: 4.5068 - val_loss: 32.1022 - val_mse: 31.9661 - val_mae: 4.4997
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8934 - mse: 32.7533 - mae: 4.4846 - val_loss: 32.0764 - val_mse: 31.9329 - val_mae: 4.4878
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5502 - mse: 32.4033 - mae: 4.4611 - val_loss: 31.4676 - val_mse: 31.3182 - val_mae: 4.4557
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4387 - mse: 32.2866 - mae: 4.4507 - val_loss: 31.4486 - val_mse: 31.2940 - val_mae: 4.4433
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2117 - mse: 32.0548 - mae: 4.4387 - val_loss: 31.2743 - val_mse: 31.1152 - val_mae: 4.4298
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1118 - mse: 31.9507 - mae: 4.4320 - val_loss: 31.8176 - val_mse: 31.6549 - val_mae: 4.4685
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9321 - mse: 31.7675 - mae: 4.4209 - val_loss: 31.2464 - val_mse: 31.0802 - val_mae: 4.4331
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9169 - mse: 31.7488 - mae: 4.4152 - val_loss: 31.0354 - val_mse: 30.8658 - val_mae: 4.4123
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8645 - mse: 31.6932 - mae: 4.4096 - val_loss: 31.6601 - val_mse: 31.4877 - val_mae: 4.4601
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7406 - mse: 31.5668 - mae: 4.4060 - val_loss: 30.7038 - val_mse: 30.5290 - val_mae: 4.3882
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6048 - mse: 31.4285 - mae: 4.3986 - val_loss: 31.0236 - val_mse: 30.8462 - val_mae: 4.4160
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.4932 - mse: 31.3143 - mae: 4.3844 - val_loss: 30.9956 - val_mse: 30.8157 - val_mae: 4.4074
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.5871 - mse: 31.4058 - mae: 4.3911 - val_loss: 31.1461 - val_mse: 30.9640 - val_mae: 4.4202
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.3932 - mse: 31.2099 - mae: 4.3783 - val_loss: 31.6651 - val_mse: 31.4809 - val_mae: 4.4555
bias -0.0115924515
si 0.55027324
rmse 0.05610784
kgeprime [0.43885753]
rmse_95 0.07332566
rmse_99 0.09022125
pearson 0.8139877812294194
pearson_95 0.5015664765785214
pearson_99 0.577364489919656
rscore 0.6471196157565998
rscore_95 -2.900847076557294
rscore_99 -11.836992565727225
nse [0.64711962]
nse_95 [-2.90084708]
nse_99 [-11.83699257]
kge [0.56127051]
ext_kge_95 [0.37563352]
ext_kge_99 [-0.00378452]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.07 -9.819 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.17 10.33 ... -0.4935
    uw2             (time, latitude, longitude) float32 101.4 96.41 ... 23.11
    vw2             (time, latitude, longitude) float32 103.4 106.7 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.31 14.25 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([119235 119259 119283], shape=(3,), dtype=int64) Times out: tf.Tensor(119283, shape=(), dtype=int64)
Times in: tf.Tensor([46600 46624 46648], shape=(3,), dtype=int64) Times out: tf.Tensor(46648, shape=(), dtype=int64)
Times in: tf.Tensor([17851 17875 17899], shape=(3,), dtype=int64) Times out: tf.Tensor(17899, shape=(), dtype=int64)
Times in: tf.Tensor([62588 62612 62636], shape=(3,), dtype=int64) Times out: tf.Tensor(62636, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_727&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_728 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1454 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1455 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_727 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1454 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_727 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1455 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.8077 - mse: 37.7544 - mae: 4.7485 - val_loss: 24.4316 - val_mse: 24.3690 - val_mae: 3.9226
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.3232 - mse: 28.2556 - mae: 4.1624 - val_loss: 22.9146 - val_mse: 22.8417 - val_mae: 3.8113
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7380 - mse: 26.6597 - mae: 4.0390 - val_loss: 23.0430 - val_mse: 22.9594 - val_mae: 3.8166
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0837 - mse: 25.9963 - mae: 3.9841 - val_loss: 22.2733 - val_mse: 22.1823 - val_mae: 3.7509
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8055 - mse: 25.7118 - mae: 3.9629 - val_loss: 22.1921 - val_mse: 22.0960 - val_mae: 3.7423
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5207 - mse: 25.4224 - mae: 3.9308 - val_loss: 22.0890 - val_mse: 21.9885 - val_mae: 3.7319
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1462 - mse: 25.0437 - mae: 3.9042 - val_loss: 22.0834 - val_mse: 21.9789 - val_mae: 3.7326
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.7936 - mse: 24.6876 - mae: 3.8749 - val_loss: 22.3697 - val_mse: 22.2618 - val_mae: 3.7640
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.5457 - mse: 24.4368 - mae: 3.8544 - val_loss: 21.9119 - val_mse: 21.8018 - val_mae: 3.7246
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2976 - mse: 24.1863 - mae: 3.8358 - val_loss: 21.4716 - val_mse: 21.3591 - val_mae: 3.6869
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2043 - mse: 24.0912 - mae: 3.8267 - val_loss: 20.6474 - val_mse: 20.5336 - val_mae: 3.6138
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0826 - mse: 23.9680 - mae: 3.8163 - val_loss: 20.5710 - val_mse: 20.4558 - val_mae: 3.6060
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.9806 - mse: 23.8644 - mae: 3.8086 - val_loss: 20.4590 - val_mse: 20.3417 - val_mae: 3.5975
Epoch 14/20
4857/4857 [==============================] - 8s 2ms/step - loss: 23.9677 - mse: 23.8500 - mae: 3.8100 - val_loss: 20.3421 - val_mse: 20.2236 - val_mae: 3.5842
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.8574 - mse: 23.7384 - mae: 3.7997 - val_loss: 20.5942 - val_mse: 20.4745 - val_mae: 3.6126
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.7697 - mse: 23.6496 - mae: 3.7918 - val_loss: 20.2266 - val_mse: 20.1059 - val_mae: 3.5791
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.7424 - mse: 23.6208 - mae: 3.7901 - val_loss: 20.6911 - val_mse: 20.5686 - val_mae: 3.6235
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6272 - mse: 23.5042 - mae: 3.7793 - val_loss: 20.2085 - val_mse: 20.0850 - val_mae: 3.5785
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6082 - mse: 23.4840 - mae: 3.7734 - val_loss: 20.3556 - val_mse: 20.2308 - val_mae: 3.5909
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6195 - mse: 23.4942 - mae: 3.7748 - val_loss: 20.3652 - val_mse: 20.2394 - val_mae: 3.5955
bias -0.007829308
si 0.47240928
rmse 0.044988263
kgeprime [0.58937714]
rmse_95 0.056061916
rmse_99 0.063984655
pearson 0.863627986093643
pearson_95 0.6004450060341516
pearson_99 0.286234887029775
rscore 0.7379113715557699
rscore_95 -1.5687228223815426
rscore_99 -11.006408729543688
nse [0.73791137]
nse_95 [-1.56872282]
nse_99 [-11.00640873]
kge [0.69188053]
ext_kge_95 [0.41284477]
ext_kge_99 [-0.42539345]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([42678 42702 42726], shape=(3,), dtype=int64) Times out: tf.Tensor(42726, shape=(), dtype=int64)
Times in: tf.Tensor([91291 91315 91339], shape=(3,), dtype=int64) Times out: tf.Tensor(91339, shape=(), dtype=int64)
Times in: tf.Tensor([49573 49597 49621], shape=(3,), dtype=int64) Times out: tf.Tensor(49621, shape=(), dtype=int64)
Times in: tf.Tensor([21617 21641 21665], shape=(3,), dtype=int64) Times out: tf.Tensor(21665, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_728&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_729 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1456 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1457 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_728 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1456 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_728 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1457 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.6236 - mse: 46.5690 - mae: 5.2970 - val_loss: 35.2447 - val_mse: 35.1776 - val_mae: 4.7119
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7446 - mse: 36.6693 - mae: 4.7375 - val_loss: 32.9640 - val_mse: 32.8814 - val_mae: 4.5577
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4350 - mse: 35.3462 - mae: 4.6571 - val_loss: 32.5305 - val_mse: 32.4360 - val_mae: 4.5281
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8226 - mse: 34.7232 - mae: 4.6173 - val_loss: 32.1767 - val_mse: 32.0729 - val_mae: 4.5041
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4669 - mse: 34.3594 - mae: 4.5926 - val_loss: 31.5501 - val_mse: 31.4392 - val_mae: 4.4685
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1498 - mse: 34.0351 - mae: 4.5728 - val_loss: 31.3210 - val_mse: 31.2031 - val_mae: 4.4491
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8448 - mse: 33.7231 - mae: 4.5513 - val_loss: 31.1228 - val_mse: 30.9980 - val_mae: 4.4249
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4625 - mse: 33.3343 - mae: 4.5260 - val_loss: 31.5151 - val_mse: 31.3836 - val_mae: 4.4484
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.2586 - mse: 33.1240 - mae: 4.5104 - val_loss: 30.8520 - val_mse: 30.7145 - val_mae: 4.4097
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.0334 - mse: 32.8930 - mae: 4.4945 - val_loss: 31.2595 - val_mse: 31.1163 - val_mae: 4.4234
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7763 - mse: 32.6306 - mae: 4.4780 - val_loss: 30.8918 - val_mse: 30.7437 - val_mae: 4.4054
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6461 - mse: 32.4957 - mae: 4.4660 - val_loss: 31.1819 - val_mse: 31.0294 - val_mae: 4.4292
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.4892 - mse: 32.3344 - mae: 4.4600 - val_loss: 30.4193 - val_mse: 30.2625 - val_mae: 4.3758
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3300 - mse: 32.1712 - mae: 4.4441 - val_loss: 30.7883 - val_mse: 30.6277 - val_mae: 4.4022
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2260 - mse: 32.0634 - mae: 4.4366 - val_loss: 31.1056 - val_mse: 30.9413 - val_mae: 4.4208
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1986 - mse: 32.0323 - mae: 4.4384 - val_loss: 30.7721 - val_mse: 30.6038 - val_mae: 4.3957
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.0321 - mse: 31.8620 - mae: 4.4227 - val_loss: 30.8966 - val_mse: 30.7249 - val_mae: 4.4051
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8464 - mse: 31.6730 - mae: 4.4084 - val_loss: 30.6840 - val_mse: 30.5091 - val_mae: 4.3860
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9016 - mse: 31.7254 - mae: 4.4092 - val_loss: 30.2753 - val_mse: 30.0978 - val_mae: 4.3590
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7434 - mse: 31.5643 - mae: 4.4073 - val_loss: 30.7540 - val_mse: 30.5732 - val_mae: 4.3979
bias -0.0077140206
si 0.5460823
rmse 0.055292998
kgeprime [0.56335137]
rmse_95 0.07705804
rmse_99 0.09440754
pearson 0.8169402082867752
pearson_95 0.5119647891406679
pearson_99 0.5664753231560444
rscore 0.6600476659492711
rscore_95 -3.370212472472427
rscore_99 -12.921107143584123
nse [0.66004767]
nse_95 [-3.37021247]
nse_99 [-12.92110714]
kge [0.66229583]
ext_kge_95 [0.38791992]
ext_kge_99 [0.05368493]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([96530 96554 96578], shape=(3,), dtype=int64) Times out: tf.Tensor(96578, shape=(), dtype=int64)
Times in: tf.Tensor([6559 6583 6607], shape=(3,), dtype=int64) Times out: tf.Tensor(6607, shape=(), dtype=int64)
Times in: tf.Tensor([135949 135973 135997], shape=(3,), dtype=int64) Times out: tf.Tensor(135997, shape=(), dtype=int64)
Times in: tf.Tensor([137123 137147 137171], shape=(3,), dtype=int64) Times out: tf.Tensor(137171, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_729&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_730 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1458 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1459 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_729 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1458 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_729 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1459 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 50.8596 - mse: 50.8231 - mae: 5.5358 - val_loss: 37.1394 - val_mse: 37.0918 - val_mae: 4.8223
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 38.6618 - mse: 38.6064 - mae: 4.8545 - val_loss: 34.7602 - val_mse: 34.6975 - val_mae: 4.6732
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7717 - mse: 36.7031 - mae: 4.7454 - val_loss: 34.6253 - val_mse: 34.5513 - val_mae: 4.6647
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.1158 - mse: 36.0372 - mae: 4.7049 - val_loss: 33.4334 - val_mse: 33.3506 - val_mae: 4.5837
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.6321 - mse: 35.5458 - mae: 4.6717 - val_loss: 32.9837 - val_mse: 32.8939 - val_mae: 4.5542
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3786 - mse: 35.2855 - mae: 4.6507 - val_loss: 33.6710 - val_mse: 33.5748 - val_mae: 4.5911
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2148 - mse: 35.1155 - mae: 4.6457 - val_loss: 33.3648 - val_mse: 33.2623 - val_mae: 4.5758
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0618 - mse: 34.9563 - mae: 4.6359 - val_loss: 33.2012 - val_mse: 33.0924 - val_mae: 4.5633
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7062 - mse: 34.5944 - mae: 4.6107 - val_loss: 33.5748 - val_mse: 33.4600 - val_mae: 4.5859
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.6547 - mse: 34.5370 - mae: 4.6068 - val_loss: 32.6467 - val_mse: 32.5259 - val_mae: 4.5156
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.4942 - mse: 34.3709 - mae: 4.5946 - val_loss: 32.5559 - val_mse: 32.4296 - val_mae: 4.5163
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2052 - mse: 34.0762 - mae: 4.5754 - val_loss: 32.6538 - val_mse: 32.5223 - val_mae: 4.5238
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.1362 - mse: 34.0020 - mae: 4.5705 - val_loss: 32.6725 - val_mse: 32.5356 - val_mae: 4.5242
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0393 - mse: 33.9001 - mae: 4.5646 - val_loss: 33.9812 - val_mse: 33.8392 - val_mae: 4.6065
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.8636 - mse: 33.7195 - mae: 4.5548 - val_loss: 33.1505 - val_mse: 33.0043 - val_mae: 4.5514
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7853 - mse: 33.6368 - mae: 4.5457 - val_loss: 32.6502 - val_mse: 32.4994 - val_mae: 4.5246
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6248 - mse: 33.4720 - mae: 4.5348 - val_loss: 32.8776 - val_mse: 32.7225 - val_mae: 4.5402
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3158 - mse: 33.1592 - mae: 4.5165 - val_loss: 32.6640 - val_mse: 32.5055 - val_mae: 4.5209
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4739 - mse: 33.3139 - mae: 4.5241 - val_loss: 33.7013 - val_mse: 33.5393 - val_mae: 4.5893
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1446 - mse: 32.9809 - mae: 4.5018 - val_loss: 33.5385 - val_mse: 33.3730 - val_mae: 4.5761
bias -0.017124666
si 0.55359346
rmse 0.0577694
kgeprime [0.25622294]
rmse_95 0.07378619
rmse_99 0.091230616
pearson 0.8119872717977324
pearson_95 0.4984333408158027
pearson_99 0.5196531380746328
rscore 0.6265032583433712
rscore_95 -2.970140280593176
rscore_99 -12.792769577353644
nse [0.62650326]
nse_95 [-2.97014028]
nse_99 [-12.79276958]
kge [0.39627051]
ext_kge_95 [0.37038383]
ext_kge_99 [-0.07677105]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.1 169.4 169.7
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.07 -9.819 ... -4.807
    vgrd10m         (time, latitude, longitude) float32 10.17 10.33 ... -0.4935
    uw2             (time, latitude, longitude) float32 101.4 96.41 ... 23.11
    vw2             (time, latitude, longitude) float32 103.4 106.7 ... 0.2436
    wind_magnitude  (time, latitude, longitude) float32 14.31 14.25 ... 4.832
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([34 58 82], shape=(3,), dtype=int64) Times out: tf.Tensor(82, shape=(), dtype=int64)
Times in: tf.Tensor([58952 58976 59000], shape=(3,), dtype=int64) Times out: tf.Tensor(59000, shape=(), dtype=int64)
Times in: tf.Tensor([109640 109664 109688], shape=(3,), dtype=int64) Times out: tf.Tensor(109688, shape=(), dtype=int64)
Times in: tf.Tensor([108254 108278 108302], shape=(3,), dtype=int64) Times out: tf.Tensor(108302, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_730&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_731 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1460 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1461 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_730 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1460 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_730 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1461 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.0997 - mse: 34.0437 - mae: 4.5110 - val_loss: 23.0129 - val_mse: 22.9458 - val_mae: 3.8112
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5508 - mse: 26.4763 - mae: 4.0264 - val_loss: 22.0957 - val_mse: 22.0147 - val_mae: 3.7405
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7468 - mse: 25.6602 - mae: 3.9611 - val_loss: 21.6909 - val_mse: 21.5995 - val_mae: 3.7053
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3100 - mse: 25.2149 - mae: 3.9202 - val_loss: 21.3698 - val_mse: 21.2714 - val_mae: 3.6724
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9208 - mse: 24.8199 - mae: 3.8875 - val_loss: 21.0556 - val_mse: 20.9524 - val_mae: 3.6427
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6805 - mse: 24.5754 - mae: 3.8661 - val_loss: 20.8868 - val_mse: 20.7799 - val_mae: 3.6278
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.3370 - mse: 24.2284 - mae: 3.8377 - val_loss: 21.2088 - val_mse: 21.0984 - val_mae: 3.6587
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0102 - mse: 23.8984 - mae: 3.8105 - val_loss: 20.2622 - val_mse: 20.1494 - val_mae: 3.5804
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.8739 - mse: 23.7599 - mae: 3.7987 - val_loss: 20.1903 - val_mse: 20.0754 - val_mae: 3.5746
Epoch 10/20
4857/4857 [==============================] - 8s 2ms/step - loss: 23.6666 - mse: 23.5503 - mae: 3.7856 - val_loss: 20.1507 - val_mse: 20.0333 - val_mae: 3.5696
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6386 - mse: 23.5201 - mae: 3.7781 - val_loss: 20.1068 - val_mse: 19.9875 - val_mae: 3.5734
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.5471 - mse: 23.4268 - mae: 3.7727 - val_loss: 19.9379 - val_mse: 19.8168 - val_mae: 3.5573
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.3874 - mse: 23.2654 - mae: 3.7607 - val_loss: 20.0033 - val_mse: 19.8806 - val_mae: 3.5631
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.2897 - mse: 23.1662 - mae: 3.7495 - val_loss: 20.2322 - val_mse: 20.1079 - val_mae: 3.5850
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.1894 - mse: 23.0643 - mae: 3.7450 - val_loss: 19.7837 - val_mse: 19.6579 - val_mae: 3.5433
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.2927 - mse: 23.1661 - mae: 3.7503 - val_loss: 19.6555 - val_mse: 19.5283 - val_mae: 3.5289
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.1744 - mse: 23.0465 - mae: 3.7416 - val_loss: 19.9446 - val_mse: 19.8161 - val_mae: 3.5584
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.1245 - mse: 22.9954 - mae: 3.7381 - val_loss: 19.8513 - val_mse: 19.7216 - val_mae: 3.5504
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.0041 - mse: 22.8740 - mae: 3.7255 - val_loss: 19.7705 - val_mse: 19.6400 - val_mae: 3.5391
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.0587 - mse: 22.9275 - mae: 3.7278 - val_loss: 19.5877 - val_mse: 19.4559 - val_mae: 3.5224
bias -0.0030245362
si 0.47328126
rmse 0.044108886
kgeprime [0.72364155]
rmse_95 0.059810694
rmse_99 0.06756495
pearson 0.8633037658227962
pearson_95 0.6265842452513796
pearson_99 0.20780349981199778
rscore 0.7439518636509108
rscore_95 -2.03372612700456
rscore_99 -14.044004805450422
nse [0.74395186]
nse_95 [-2.03372613]
nse_99 [-14.04400481]
kge [0.77760799]
ext_kge_95 [0.39090701]
ext_kge_99 [-0.608636]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.07 -9.819 ... -4.429
    vgrd10m         (time, latitude, longitude) float32 10.17 10.33 ... -0.9657
    uw2             (time, latitude, longitude) float32 101.4 96.41 ... 19.61
    vw2             (time, latitude, longitude) float32 103.4 106.7 ... 0.9325
    wind_magnitude  (time, latitude, longitude) float32 14.31 14.25 ... 4.533
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([25148 25172 25196], shape=(3,), dtype=int64) Times out: tf.Tensor(25196, shape=(), dtype=int64)
Times in: tf.Tensor([98623 98647 98671], shape=(3,), dtype=int64) Times out: tf.Tensor(98671, shape=(), dtype=int64)
Times in: tf.Tensor([80759 80783 80807], shape=(3,), dtype=int64) Times out: tf.Tensor(80807, shape=(), dtype=int64)
Times in: tf.Tensor([1957 1981 2005], shape=(3,), dtype=int64) Times out: tf.Tensor(2005, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_731&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_732 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1462 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1463 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_731 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1462 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_731 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1463 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.6747 - mse: 34.6128 - mae: 4.5463 - val_loss: 23.1861 - val_mse: 23.1103 - val_mae: 3.8237
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.7545 - mse: 26.6720 - mae: 4.0444 - val_loss: 22.6605 - val_mse: 22.5726 - val_mae: 3.7819
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1518 - mse: 26.0595 - mae: 3.9923 - val_loss: 22.5331 - val_mse: 22.4372 - val_mae: 3.7694
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7633 - mse: 25.6637 - mae: 3.9658 - val_loss: 22.0790 - val_mse: 21.9763 - val_mae: 3.7320
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5175 - mse: 25.4112 - mae: 3.9395 - val_loss: 21.8384 - val_mse: 21.7289 - val_mae: 3.7128
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3239 - mse: 25.2108 - mae: 3.9219 - val_loss: 21.5880 - val_mse: 21.4714 - val_mae: 3.6902
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9083 - mse: 24.7884 - mae: 3.8930 - val_loss: 21.5186 - val_mse: 21.3958 - val_mae: 3.6907
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6165 - mse: 24.4907 - mae: 3.8626 - val_loss: 21.1009 - val_mse: 20.9723 - val_mae: 3.6556
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.3692 - mse: 24.2384 - mae: 3.8435 - val_loss: 20.7730 - val_mse: 20.6400 - val_mae: 3.6302
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.1807 - mse: 24.0456 - mae: 3.8293 - val_loss: 20.8775 - val_mse: 20.7407 - val_mae: 3.6420
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.0439 - mse: 23.9053 - mae: 3.8157 - val_loss: 21.0673 - val_mse: 20.9273 - val_mae: 3.6640
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.9049 - mse: 23.7632 - mae: 3.8042 - val_loss: 20.8019 - val_mse: 20.6589 - val_mae: 3.6417
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.7195 - mse: 23.5750 - mae: 3.7929 - val_loss: 21.3009 - val_mse: 21.1554 - val_mae: 3.6848
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6969 - mse: 23.5498 - mae: 3.7927 - val_loss: 20.5706 - val_mse: 20.4223 - val_mae: 3.6220
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6212 - mse: 23.4718 - mae: 3.7871 - val_loss: 20.5847 - val_mse: 20.4345 - val_mae: 3.6245
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6470 - mse: 23.4954 - mae: 3.7833 - val_loss: 20.5568 - val_mse: 20.4043 - val_mae: 3.6221
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.4674 - mse: 23.3139 - mae: 3.7679 - val_loss: 20.5886 - val_mse: 20.4342 - val_mae: 3.6219
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.4644 - mse: 23.3087 - mae: 3.7738 - val_loss: 21.2107 - val_mse: 21.0544 - val_mae: 3.6777
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.3639 - mse: 23.2065 - mae: 3.7609 - val_loss: 21.1813 - val_mse: 21.0229 - val_mae: 3.6729
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.3240 - mse: 23.1646 - mae: 3.7531 - val_loss: 20.6192 - val_mse: 20.4590 - val_mae: 3.6279
bias -0.0065139597
si 0.4725347
rmse 0.045231678
kgeprime [0.6480922]
rmse_95 0.05577067
rmse_99 0.06454471
pearson 0.8639368197089329
pearson_95 0.6233275506740255
pearson_99 0.27609597213890436
rscore 0.7403975028005804
rscore_95 -1.4795256125383753
rscore_99 -13.917665954176714
nse [0.7403975]
nse_95 [-1.47952561]
nse_99 [-13.91766595]
kge [0.73579069]
ext_kge_95 [0.44360059]
ext_kge_99 [-0.65770171]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([96438 96462 96486], shape=(3,), dtype=int64) Times out: tf.Tensor(96486, shape=(), dtype=int64)
Times in: tf.Tensor([143248 143272 143296], shape=(3,), dtype=int64) Times out: tf.Tensor(143296, shape=(), dtype=int64)
Times in: tf.Tensor([23155 23179 23203], shape=(3,), dtype=int64) Times out: tf.Tensor(23203, shape=(), dtype=int64)
Times in: tf.Tensor([94622 94646 94670], shape=(3,), dtype=int64) Times out: tf.Tensor(94670, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_732&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_733 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1464 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1465 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_732 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1464 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_732 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1465 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 46.8072 - mse: 46.7564 - mae: 5.3154 - val_loss: 35.6032 - val_mse: 35.5432 - val_mae: 4.7380
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.4374 - mse: 37.3697 - mae: 4.7831 - val_loss: 33.7667 - val_mse: 33.6915 - val_mae: 4.6072
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.9902 - mse: 35.9086 - mae: 4.6902 - val_loss: 32.6939 - val_mse: 32.6062 - val_mae: 4.5304
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8553 - mse: 34.7626 - mae: 4.6189 - val_loss: 32.6234 - val_mse: 32.5255 - val_mae: 4.5165
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3585 - mse: 34.2565 - mae: 4.5875 - val_loss: 31.8550 - val_mse: 31.7485 - val_mae: 4.4610
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0314 - mse: 33.9209 - mae: 4.5645 - val_loss: 31.5387 - val_mse: 31.4240 - val_mae: 4.4469
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6528 - mse: 33.5341 - mae: 4.5366 - val_loss: 31.4008 - val_mse: 31.2781 - val_mae: 4.4264
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3200 - mse: 33.1935 - mae: 4.5113 - val_loss: 31.2139 - val_mse: 31.0838 - val_mae: 4.4117
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9318 - mse: 32.7984 - mae: 4.4892 - val_loss: 30.9871 - val_mse: 30.8501 - val_mae: 4.4004
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.8927 - mse: 32.7532 - mae: 4.4856 - val_loss: 30.9718 - val_mse: 30.8292 - val_mae: 4.4000
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7262 - mse: 32.5809 - mae: 4.4748 - val_loss: 31.0102 - val_mse: 30.8623 - val_mae: 4.3948
Epoch 12/20
4857/4857 [==============================] - 8s 2ms/step - loss: 32.5387 - mse: 32.3885 - mae: 4.4535 - val_loss: 30.7404 - val_mse: 30.5876 - val_mae: 4.3868
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3433 - mse: 32.1883 - mae: 4.4457 - val_loss: 31.0053 - val_mse: 30.8480 - val_mae: 4.3963
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1469 - mse: 31.9877 - mae: 4.4302 - val_loss: 31.6409 - val_mse: 31.4795 - val_mae: 4.4385
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1042 - mse: 31.9413 - mae: 4.4261 - val_loss: 30.7669 - val_mse: 30.6023 - val_mae: 4.3790
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9876 - mse: 31.8212 - mae: 4.4191 - val_loss: 30.8770 - val_mse: 30.7088 - val_mae: 4.3931
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9364 - mse: 31.7667 - mae: 4.4122 - val_loss: 30.9689 - val_mse: 30.7975 - val_mae: 4.3921
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.8726 - mse: 31.7000 - mae: 4.4075 - val_loss: 30.5486 - val_mse: 30.3743 - val_mae: 4.3689
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.7154 - mse: 31.5401 - mae: 4.3982 - val_loss: 30.8571 - val_mse: 30.6800 - val_mae: 4.3861
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.6837 - mse: 31.5053 - mae: 4.3979 - val_loss: 31.2914 - val_mse: 31.1115 - val_mae: 4.4134
bias -0.0098250285
si 0.5484253
rmse 0.055777717
kgeprime [0.48336298]
rmse_95 0.074352525
rmse_99 0.09135455
pearson 0.8156259003412094
pearson_95 0.5069892930944542
pearson_99 0.5963462463986842
rscore 0.654487727963672
rscore_95 -3.010865965694772
rscore_99 -12.346329824111011
nse [0.65448773]
nse_95 [-3.01086597]
nse_99 [-12.34632982]
kge [0.59932483]
ext_kge_95 [0.37631814]
ext_kge_99 [-0.01809095]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.07 -9.819 ... -4.429
    vgrd10m         (time, latitude, longitude) float32 10.17 10.33 ... -0.9657
    uw2             (time, latitude, longitude) float32 101.4 96.41 ... 19.61
    vw2             (time, latitude, longitude) float32 103.4 106.7 ... 0.9325
    wind_magnitude  (time, latitude, longitude) float32 14.31 14.25 ... 4.533
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([146535 146559 146583], shape=(3,), dtype=int64) Times out: tf.Tensor(146583, shape=(), dtype=int64)
Times in: tf.Tensor([103810 103834 103858], shape=(3,), dtype=int64) Times out: tf.Tensor(103858, shape=(), dtype=int64)
Times in: tf.Tensor([35665 35689 35713], shape=(3,), dtype=int64) Times out: tf.Tensor(35713, shape=(), dtype=int64)
Times in: tf.Tensor([46444 46468 46492], shape=(3,), dtype=int64) Times out: tf.Tensor(46492, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_733&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_734 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1466 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1467 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_733 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1466 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_733 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1467 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.2793 - mse: 34.2194 - mae: 4.5269 - val_loss: 23.7037 - val_mse: 23.6326 - val_mae: 3.8590
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6290 - mse: 26.5501 - mae: 4.0342 - val_loss: 22.3903 - val_mse: 22.3042 - val_mae: 3.7642
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.8385 - mse: 25.7469 - mae: 3.9643 - val_loss: 21.9663 - val_mse: 21.8704 - val_mae: 3.7202
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.5130 - mse: 25.4135 - mae: 3.9404 - val_loss: 22.4654 - val_mse: 22.3635 - val_mae: 3.7641
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3317 - mse: 25.2268 - mae: 3.9205 - val_loss: 21.8380 - val_mse: 21.7311 - val_mae: 3.7122
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1503 - mse: 25.0408 - mae: 3.9043 - val_loss: 21.6347 - val_mse: 21.5231 - val_mae: 3.6939
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.7799 - mse: 24.6658 - mae: 3.8771 - val_loss: 21.2391 - val_mse: 21.1231 - val_mae: 3.6551
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.5879 - mse: 24.4697 - mae: 3.8645 - val_loss: 21.6457 - val_mse: 21.5258 - val_mae: 3.6959
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.3836 - mse: 24.2616 - mae: 3.8434 - val_loss: 20.9628 - val_mse: 20.8394 - val_mae: 3.6433
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2349 - mse: 24.1096 - mae: 3.8292 - val_loss: 20.4415 - val_mse: 20.3151 - val_mae: 3.5931
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.9935 - mse: 23.8652 - mae: 3.8123 - val_loss: 20.2845 - val_mse: 20.1552 - val_mae: 3.5845
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.8625 - mse: 23.7318 - mae: 3.7994 - val_loss: 20.7806 - val_mse: 20.6492 - val_mae: 3.6284
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.7768 - mse: 23.6439 - mae: 3.7931 - val_loss: 20.3293 - val_mse: 20.1958 - val_mae: 3.5910
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.7135 - mse: 23.5785 - mae: 3.7857 - val_loss: 20.8476 - val_mse: 20.7119 - val_mae: 3.6368
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.6460 - mse: 23.5092 - mae: 3.7801 - val_loss: 21.5724 - val_mse: 21.4350 - val_mae: 3.6979
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.5894 - mse: 23.4508 - mae: 3.7757 - val_loss: 20.3498 - val_mse: 20.2104 - val_mae: 3.5941
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.5442 - mse: 23.4036 - mae: 3.7709 - val_loss: 20.0179 - val_mse: 19.8769 - val_mae: 3.5626
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.4667 - mse: 23.3244 - mae: 3.7655 - val_loss: 19.9259 - val_mse: 19.7832 - val_mae: 3.5545
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.3875 - mse: 23.2437 - mae: 3.7584 - val_loss: 19.9336 - val_mse: 19.7893 - val_mae: 3.5569
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 23.3242 - mse: 23.1790 - mae: 3.7504 - val_loss: 20.1817 - val_mse: 20.0359 - val_mae: 3.5831
bias -0.007218602
si 0.4729699
rmse 0.04476146
kgeprime [0.61512635]
rmse_95 0.055641122
rmse_99 0.06388681
pearson 0.8637311387229398
pearson_95 0.6274289960581857
pearson_99 0.27915137033954696
rscore 0.7390457485481772
rscore_95 -1.5388952563590284
rscore_99 -14.072442609142394
nse [0.73904575]
nse_95 [-1.53889526]
nse_99 [-14.07244261]
kge [0.71134104]
ext_kge_95 [0.42631792]
ext_kge_99 [-0.69818481]
Loading U
Done
Loading V
Done
Calculating relative winds
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 23, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.1 163.4 163.8 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -10.07 -9.819 ... -4.429
    vgrd10m         (time, latitude, longitude) float32 10.17 10.33 ... -0.9657
    uw2             (time, latitude, longitude) float32 101.4 96.41 ... 19.61
    vw2             (time, latitude, longitude) float32 103.4 106.7 ... 0.9325
    wind_magnitude  (time, latitude, longitude) float32 14.31 14.25 ... 4.533
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([21816 21840 21864], shape=(3,), dtype=int64) Times out: tf.Tensor(21864, shape=(), dtype=int64)
Times in: tf.Tensor([27256 27280 27304], shape=(3,), dtype=int64) Times out: tf.Tensor(27304, shape=(), dtype=int64)
Times in: tf.Tensor([138695 138719 138743], shape=(3,), dtype=int64) Times out: tf.Tensor(138743, shape=(), dtype=int64)
Times in: tf.Tensor([86921 86945 86969], shape=(3,), dtype=int64) Times out: tf.Tensor(86969, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_734&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_735 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1468 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1469 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_734 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1468 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_734 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1469 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 38.6079 - mse: 38.5678 - mae: 4.7917 - val_loss: 24.1767 - val_mse: 24.1307 - val_mae: 3.9087
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 28.1120 - mse: 28.0636 - mae: 4.1426 - val_loss: 22.4554 - val_mse: 22.4051 - val_mae: 3.7750
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.3060 - mse: 27.2534 - mae: 4.0779 - val_loss: 22.8458 - val_mse: 22.7911 - val_mae: 3.8090
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8459 - mse: 26.7889 - mae: 4.0472 - val_loss: 22.7816 - val_mse: 22.7228 - val_mae: 3.8059
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6533 - mse: 26.5925 - mae: 4.0286 - val_loss: 22.3911 - val_mse: 22.3286 - val_mae: 3.7719
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.4674 - mse: 26.4033 - mae: 4.0139 - val_loss: 22.2753 - val_mse: 22.2097 - val_mae: 3.7624
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.3101 - mse: 26.2429 - mae: 3.9966 - val_loss: 21.5161 - val_mse: 21.4475 - val_mae: 3.6981
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.0513 - mse: 25.9808 - mae: 3.9770 - val_loss: 21.8228 - val_mse: 21.7508 - val_mae: 3.7239
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9893 - mse: 25.9157 - mae: 3.9695 - val_loss: 21.4104 - val_mse: 21.3354 - val_mae: 3.6918
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7877 - mse: 25.7110 - mae: 3.9504 - val_loss: 21.9040 - val_mse: 21.8259 - val_mae: 3.7333
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6542 - mse: 25.5744 - mae: 3.9417 - val_loss: 21.7572 - val_mse: 21.6759 - val_mae: 3.7234
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4809 - mse: 25.3981 - mae: 3.9341 - val_loss: 20.8291 - val_mse: 20.7451 - val_mae: 3.6475
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2951 - mse: 25.2096 - mae: 3.9165 - val_loss: 21.1448 - val_mse: 21.0578 - val_mae: 3.6776
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.2244 - mse: 25.1364 - mae: 3.9062 - val_loss: 21.3448 - val_mse: 21.2556 - val_mae: 3.6947
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1910 - mse: 25.1007 - mae: 3.9083 - val_loss: 20.8753 - val_mse: 20.7840 - val_mae: 3.6558
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9864 - mse: 24.8941 - mae: 3.8907 - val_loss: 21.1460 - val_mse: 21.0528 - val_mae: 3.6786
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9430 - mse: 24.8487 - mae: 3.8880 - val_loss: 20.8271 - val_mse: 20.7318 - val_mae: 3.6516
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.8710 - mse: 24.7747 - mae: 3.8843 - val_loss: 21.3785 - val_mse: 21.2812 - val_mae: 3.6998
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9305 - mse: 24.8324 - mae: 3.8826 - val_loss: 20.5557 - val_mse: 20.4565 - val_mae: 3.6291
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.7659 - mse: 24.6656 - mae: 3.8707 - val_loss: 20.7407 - val_mse: 20.6397 - val_mae: 3.6444
bias -0.007970796
si 0.47417325
rmse 0.045430873
kgeprime [0.5785227]
rmse_95 0.057432733
rmse_99 0.06534442
pearson 0.8629037177877241
pearson_95 0.6241935589554543
pearson_99 0.2574916852075227
rscore 0.7363630715020082
rscore_95 -1.6638463127176704
rscore_99 -15.392713830986459
nse [0.73636307]
nse_95 [-1.66384631]
nse_99 [-15.39271383]
kge [0.68338567]
ext_kge_95 [0.41666687]
ext_kge_99 [-0.83429258]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.819 -9.569 ... -4.429
    vgrd10m         (time, latitude, longitude) float32 10.33 10.48 ... -0.9657
    uw2             (time, latitude, longitude) float32 96.41 91.57 ... 19.61
    vw2             (time, latitude, longitude) float32 106.7 109.8 ... 0.9325
    wind_magnitude  (time, latitude, longitude) float32 14.25 14.19 ... 4.533
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([37906 37930 37954], shape=(3,), dtype=int64) Times out: tf.Tensor(37954, shape=(), dtype=int64)
Times in: tf.Tensor([120054 120078 120102], shape=(3,), dtype=int64) Times out: tf.Tensor(120102, shape=(), dtype=int64)
Times in: tf.Tensor([89994 90018 90042], shape=(3,), dtype=int64) Times out: tf.Tensor(90042, shape=(), dtype=int64)
Times in: tf.Tensor([155318 155342 155366], shape=(3,), dtype=int64) Times out: tf.Tensor(155366, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_735&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_736 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1470 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1471 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_735 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1470 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_735 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1471 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 36.7909 - mse: 36.7316 - mae: 4.6956 - val_loss: 24.1347 - val_mse: 24.0634 - val_mae: 3.9077
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.9665 - mse: 27.8884 - mae: 4.1427 - val_loss: 22.8920 - val_mse: 22.8075 - val_mae: 3.8161
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.0694 - mse: 26.9798 - mae: 4.0674 - val_loss: 22.3677 - val_mse: 22.2736 - val_mae: 3.7726
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.6518 - mse: 26.5543 - mae: 4.0317 - val_loss: 22.0957 - val_mse: 21.9952 - val_mae: 3.7488
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2431 - mse: 26.1402 - mae: 3.9986 - val_loss: 22.1131 - val_mse: 22.0080 - val_mae: 3.7512
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.9331 - mse: 25.8255 - mae: 3.9719 - val_loss: 21.7171 - val_mse: 21.6072 - val_mae: 3.7186
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.4777 - mse: 25.3659 - mae: 3.9370 - val_loss: 21.2813 - val_mse: 21.1677 - val_mae: 3.6857
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1695 - mse: 25.0541 - mae: 3.9135 - val_loss: 21.8248 - val_mse: 21.7077 - val_mae: 3.7370
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.0232 - mse: 24.9049 - mae: 3.9016 - val_loss: 20.7967 - val_mse: 20.6774 - val_mae: 3.6487
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.8856 - mse: 24.7654 - mae: 3.8899 - val_loss: 20.6108 - val_mse: 20.4898 - val_mae: 3.6352
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.8002 - mse: 24.6783 - mae: 3.8839 - val_loss: 20.9913 - val_mse: 20.8687 - val_mae: 3.6679
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6634 - mse: 24.5400 - mae: 3.8675 - val_loss: 21.7986 - val_mse: 21.6746 - val_mae: 3.7350
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6460 - mse: 24.5211 - mae: 3.8683 - val_loss: 20.4837 - val_mse: 20.3582 - val_mae: 3.6265
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.4373 - mse: 24.3109 - mae: 3.8509 - val_loss: 20.7876 - val_mse: 20.6605 - val_mae: 3.6511
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2860 - mse: 24.1583 - mae: 3.8418 - val_loss: 20.3804 - val_mse: 20.2522 - val_mae: 3.6157
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2708 - mse: 24.1419 - mae: 3.8362 - val_loss: 21.2478 - val_mse: 21.1181 - val_mae: 3.6911
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2850 - mse: 24.1549 - mae: 3.8370 - val_loss: 20.8661 - val_mse: 20.7354 - val_mae: 3.6604
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.1556 - mse: 24.0242 - mae: 3.8242 - val_loss: 20.9246 - val_mse: 20.7925 - val_mae: 3.6665
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.1886 - mse: 24.0560 - mae: 3.8253 - val_loss: 20.2538 - val_mse: 20.1205 - val_mae: 3.6067
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.1066 - mse: 23.9729 - mae: 3.8214 - val_loss: 20.3466 - val_mse: 20.2124 - val_mae: 3.6168
bias -0.0064226515
si 0.46841872
rmse 0.04495819
kgeprime [0.64680876]
rmse_95 0.05460469
rmse_99 0.06285915
pearson 0.8663249863985764
pearson_95 0.6251572321669397
pearson_99 0.3015734047920143
rscore 0.7451255865564459
rscore_95 -1.4075219208607943
rscore_99 -12.557193989662068
nse [0.74512559]
nse_95 [-1.40752192]
nse_99 [-12.55719399]
kge [0.73552235]
ext_kge_95 [0.43979539]
ext_kge_99 [-0.64154428]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([36877 36901 36925], shape=(3,), dtype=int64) Times out: tf.Tensor(36925, shape=(), dtype=int64)
Times in: tf.Tensor([108197 108221 108245], shape=(3,), dtype=int64) Times out: tf.Tensor(108245, shape=(), dtype=int64)
Times in: tf.Tensor([7172 7196 7220], shape=(3,), dtype=int64) Times out: tf.Tensor(7220, shape=(), dtype=int64)
Times in: tf.Tensor([36881 36905 36929], shape=(3,), dtype=int64) Times out: tf.Tensor(36929, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_736&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_737 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1472 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1473 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_736 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1472 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_736 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1473 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 49.3332 - mse: 49.2785 - mae: 5.4549 - val_loss: 36.4412 - val_mse: 36.3725 - val_mae: 4.7780
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.8713 - mse: 37.7958 - mae: 4.8087 - val_loss: 34.4054 - val_mse: 34.3240 - val_mae: 4.6539
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.7158 - mse: 36.6287 - mae: 4.7387 - val_loss: 33.6103 - val_mse: 33.5187 - val_mae: 4.5921
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.0551 - mse: 35.9607 - mae: 4.6981 - val_loss: 33.1695 - val_mse: 33.0729 - val_mae: 4.5708
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.8552 - mse: 35.7568 - mae: 4.6865 - val_loss: 32.9200 - val_mse: 32.8202 - val_mae: 4.5516
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.5042 - mse: 35.4030 - mae: 4.6624 - val_loss: 33.0122 - val_mse: 32.9095 - val_mae: 4.5569
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.3612 - mse: 35.2571 - mae: 4.6554 - val_loss: 32.6796 - val_mse: 32.5741 - val_mae: 4.5313
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.2373 - mse: 35.1301 - mae: 4.6427 - val_loss: 32.4720 - val_mse: 32.3632 - val_mae: 4.5193
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.0886 - mse: 34.9781 - mae: 4.6335 - val_loss: 32.6835 - val_mse: 32.5710 - val_mae: 4.5332
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.8588 - mse: 34.7446 - mae: 4.6173 - val_loss: 32.2001 - val_mse: 32.0841 - val_mae: 4.4960
Epoch 11/20
4857/4857 [==============================] - 8s 2ms/step - loss: 34.6524 - mse: 34.5344 - mae: 4.6049 - val_loss: 32.4306 - val_mse: 32.3107 - val_mae: 4.5139
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3226 - mse: 34.2005 - mae: 4.5844 - val_loss: 32.1539 - val_mse: 32.0301 - val_mae: 4.4883
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.2441 - mse: 34.1183 - mae: 4.5761 - val_loss: 31.4154 - val_mse: 31.2879 - val_mae: 4.4308
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.9655 - mse: 33.8360 - mae: 4.5568 - val_loss: 31.4062 - val_mse: 31.2749 - val_mae: 4.4338
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7946 - mse: 33.6613 - mae: 4.5473 - val_loss: 31.5591 - val_mse: 31.4243 - val_mae: 4.4442
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6788 - mse: 33.5423 - mae: 4.5368 - val_loss: 31.2219 - val_mse: 31.0839 - val_mae: 4.4238
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6558 - mse: 33.5163 - mae: 4.5377 - val_loss: 31.4904 - val_mse: 31.3495 - val_mae: 4.4348
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4162 - mse: 33.2739 - mae: 4.5209 - val_loss: 31.2548 - val_mse: 31.1112 - val_mae: 4.4241
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4240 - mse: 33.2791 - mae: 4.5182 - val_loss: 31.0538 - val_mse: 30.9076 - val_mae: 4.4132
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.3207 - mse: 33.1730 - mae: 4.5128 - val_loss: 31.1772 - val_mse: 31.0284 - val_mae: 4.4143
bias -0.0069809114
si 0.54747736
rmse 0.055703152
kgeprime [0.56893209]
rmse_95 0.08157567
rmse_99 0.10233364
pearson 0.8158340304254902
pearson_95 0.5024840549625642
pearson_99 0.5910433936410856
rscore 0.6602347287024972
rscore_95 -3.801210677667701
rscore_99 -15.0093326144633
nse [0.66023473]
nse_95 [-3.80121068]
nse_99 [-15.00933261]
kge [0.66449616]
ext_kge_95 [0.38616996]
ext_kge_99 [0.09431468]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([1407 1431 1455], shape=(3,), dtype=int64) Times out: tf.Tensor(1455, shape=(), dtype=int64)
Times in: tf.Tensor([55283 55307 55331], shape=(3,), dtype=int64) Times out: tf.Tensor(55331, shape=(), dtype=int64)
Times in: tf.Tensor([124656 124680 124704], shape=(3,), dtype=int64) Times out: tf.Tensor(124704, shape=(), dtype=int64)
Times in: tf.Tensor([22614 22638 22662], shape=(3,), dtype=int64) Times out: tf.Tensor(22662, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_737&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_738 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1474 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1475 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_737 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1474 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_737 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1475 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 45.8730 - mse: 45.8194 - mae: 5.2608 - val_loss: 36.0112 - val_mse: 35.9434 - val_mae: 4.7576
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 36.4854 - mse: 36.4082 - mae: 4.7241 - val_loss: 33.7407 - val_mse: 33.6542 - val_mae: 4.6049
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 35.4571 - mse: 35.3631 - mae: 4.6586 - val_loss: 33.2881 - val_mse: 33.1878 - val_mae: 4.5792
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.7976 - mse: 34.6915 - mae: 4.6120 - val_loss: 32.7170 - val_mse: 32.6055 - val_mae: 4.5318
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.3872 - mse: 34.2711 - mae: 4.5856 - val_loss: 32.3549 - val_mse: 32.2339 - val_mae: 4.5054
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 34.0502 - mse: 33.9247 - mae: 4.5658 - val_loss: 32.3547 - val_mse: 32.2245 - val_mae: 4.5001
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.7970 - mse: 33.6627 - mae: 4.5477 - val_loss: 32.0790 - val_mse: 31.9404 - val_mae: 4.4851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.6628 - mse: 33.5205 - mae: 4.5363 - val_loss: 32.4046 - val_mse: 32.2581 - val_mae: 4.5011
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.4766 - mse: 33.3269 - mae: 4.5246 - val_loss: 32.7005 - val_mse: 32.5467 - val_mae: 4.5224
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 33.1422 - mse: 32.9854 - mae: 4.5035 - val_loss: 32.3914 - val_mse: 32.2313 - val_mae: 4.5006
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.9461 - mse: 32.7830 - mae: 4.4883 - val_loss: 32.7026 - val_mse: 32.5363 - val_mae: 4.5169
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.7477 - mse: 32.5787 - mae: 4.4755 - val_loss: 32.2289 - val_mse: 32.0565 - val_mae: 4.4854
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.6603 - mse: 32.4857 - mae: 4.4660 - val_loss: 32.5577 - val_mse: 32.3806 - val_mae: 4.5070
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.5860 - mse: 32.4068 - mae: 4.4643 - val_loss: 31.0985 - val_mse: 30.9169 - val_mae: 4.4011
Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.3897 - mse: 32.2062 - mae: 4.4501 - val_loss: 32.7735 - val_mse: 32.5877 - val_mae: 4.5144
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1677 - mse: 31.9800 - mae: 4.4367 - val_loss: 33.1708 - val_mse: 32.9808 - val_mae: 4.5460
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.2215 - mse: 32.0300 - mae: 4.4342 - val_loss: 32.3684 - val_mse: 32.1748 - val_mae: 4.4852
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 32.1032 - mse: 31.9081 - mae: 4.4264 - val_loss: 32.3830 - val_mse: 32.1860 - val_mae: 4.4870
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 31.9405 - mse: 31.7421 - mae: 4.4148 - val_loss: 31.2954 - val_mse: 31.0951 - val_mae: 4.4124
Epoch 20/20
4857/4857 [==============================] - 8s 2ms/step - loss: 31.9608 - mse: 31.7589 - mae: 4.4123 - val_loss: 31.8800 - val_mse: 31.6764 - val_mae: 4.4538
bias -0.01190007
si 0.5518705
rmse 0.05628178
kgeprime [0.41622392]
rmse_95 0.0761546
rmse_99 0.093316264
pearson 0.8136846296704362
pearson_95 0.5090900552748973
pearson_99 0.6180376151030346
rscore 0.6461566564802899
rscore_95 -3.211984745931547
rscore_99 -12.90333374100265
nse [0.64615666]
nse_95 [-3.21198475]
nse_99 [-12.90333374]
kge [0.54212624]
ext_kge_95 [0.3962471]
ext_kge_99 [0.1106878]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 163.4 163.8 164.1 ... 169.4 169.7 170.0
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -9.819 -9.569 ... -4.429
    vgrd10m         (time, latitude, longitude) float32 10.33 10.48 ... -0.9657
    uw2             (time, latitude, longitude) float32 96.41 91.57 ... 19.61
    vw2             (time, latitude, longitude) float32 106.7 109.8 ... 0.9325
    wind_magnitude  (time, latitude, longitude) float32 14.25 14.19 ... 4.533
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([122015 122039 122063], shape=(3,), dtype=int64) Times out: tf.Tensor(122063, shape=(), dtype=int64)
Times in: tf.Tensor([134220 134244 134268], shape=(3,), dtype=int64) Times out: tf.Tensor(134268, shape=(), dtype=int64)
Times in: tf.Tensor([64037 64061 64085], shape=(3,), dtype=int64) Times out: tf.Tensor(64085, shape=(), dtype=int64)
Times in: tf.Tensor([97370 97394 97418], shape=(3,), dtype=int64) Times out: tf.Tensor(97418, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_738&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_739 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1476 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1477 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_738 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1476 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_738 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1477 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 37.0487 - mse: 36.9884 - mae: 4.6988 - val_loss: 23.6416 - val_mse: 23.5682 - val_mae: 3.8638
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 27.5733 - mse: 27.4945 - mae: 4.1097 - val_loss: 22.7065 - val_mse: 22.6234 - val_mae: 3.7940
Epoch 3/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.8166 - mse: 26.7303 - mae: 4.0468 - val_loss: 22.5753 - val_mse: 22.4866 - val_mae: 3.7848
Epoch 4/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.5519 - mse: 26.4615 - mae: 4.0250 - val_loss: 22.1429 - val_mse: 22.0512 - val_mae: 3.7454
Epoch 5/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.2835 - mse: 26.1905 - mae: 4.0029 - val_loss: 22.1085 - val_mse: 22.0148 - val_mae: 3.7482
Epoch 6/20
4857/4857 [==============================] - 7s 2ms/step - loss: 26.1203 - mse: 26.0248 - mae: 3.9880 - val_loss: 22.4792 - val_mse: 22.3826 - val_mae: 3.7772
Epoch 7/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.7984 - mse: 25.7001 - mae: 3.9643 - val_loss: 21.5369 - val_mse: 21.4374 - val_mae: 3.6987
Epoch 8/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.6717 - mse: 25.5705 - mae: 3.9516 - val_loss: 21.3322 - val_mse: 21.2294 - val_mae: 3.6844
Epoch 9/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.3414 - mse: 25.2368 - mae: 3.9246 - val_loss: 21.8290 - val_mse: 21.7232 - val_mae: 3.7296
Epoch 10/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.1517 - mse: 25.0444 - mae: 3.9103 - val_loss: 21.3497 - val_mse: 21.2412 - val_mae: 3.6922
Epoch 11/20
4857/4857 [==============================] - 7s 2ms/step - loss: 25.0199 - mse: 24.9103 - mae: 3.9024 - val_loss: 20.8530 - val_mse: 20.7425 - val_mae: 3.6524
Epoch 12/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.9316 - mse: 24.8201 - mae: 3.8949 - val_loss: 20.8081 - val_mse: 20.6957 - val_mae: 3.6476
Epoch 13/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.8758 - mse: 24.7624 - mae: 3.8820 - val_loss: 20.7906 - val_mse: 20.6766 - val_mae: 3.6496
Epoch 14/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6883 - mse: 24.5733 - mae: 3.8750 - val_loss: 20.6759 - val_mse: 20.5603 - val_mae: 3.6400
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.6042 - mse: 24.4875 - mae: 3.8644 - val_loss: 20.5385 - val_mse: 20.4211 - val_mae: 3.6311
Epoch 16/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.4985 - mse: 24.3800 - mae: 3.8568 - val_loss: 20.5380 - val_mse: 20.4191 - val_mae: 3.6281
Epoch 17/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.4496 - mse: 24.3298 - mae: 3.8543 - val_loss: 20.8741 - val_mse: 20.7539 - val_mae: 3.6600
Epoch 18/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.3950 - mse: 24.2735 - mae: 3.8440 - val_loss: 20.6038 - val_mse: 20.4819 - val_mae: 3.6384
Epoch 19/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.3205 - mse: 24.1978 - mae: 3.8405 - val_loss: 20.5658 - val_mse: 20.4427 - val_mae: 3.6332
Epoch 20/20
4857/4857 [==============================] - 7s 2ms/step - loss: 24.2603 - mse: 24.1362 - mae: 3.8340 - val_loss: 20.3099 - val_mse: 20.1852 - val_mae: 3.6095
bias -0.0048700836
si 0.47406617
rmse 0.044927973
kgeprime [0.69376111]
rmse_95 0.056496415
rmse_99 0.06514989
pearson 0.8632839634630793
pearson_95 0.6159696871877733
pearson_99 0.2522231299529923
rscore 0.7417276835751122
rscore_95 -1.6027016845162936
rscore_99 -15.11058035951745
nse [0.74172768]
nse_95 [-1.60270168]
nse_99 [-15.11058036]
kge [0.76730534]
ext_kge_95 [0.40665531]
ext_kge_99 [-0.82861363]
Loading U
Done
Loading V
Done
Calculating relative winds

 calculating winds with: 

 &lt;xarray.Dataset&gt;
Dimensions:         (latitude: 22, longitude: 22, time: 195745)
Coordinates:
  * latitude        (latitude) float32 -48.86 -48.55 -48.24 ... -42.62 -42.31
  * longitude       (longitude) float32 167.5 167.8 168.1 ... 173.4 173.8 174.1
  * time            (time) datetime64[ns] 1994-11-01 ... 2017-03-01
Data variables:
    ugrd10m         (time, latitude, longitude) float32 -8.398 -8.219 ... 3.997
    vgrd10m         (time, latitude, longitude) float32 9.599 9.499 ... 2.453
    uw2             (time, latitude, longitude) float32 70.53 67.55 ... 15.98
    vw2             (time, latitude, longitude) float32 92.14 90.22 ... 6.015
    wind_magnitude  (time, latitude, longitude) float32 12.75 12.56 ... 4.69
Attributes:
    short_name:  ugrd10m
    long_name:   U-Component of Wind
    level:       10 m above ground
    units:       m/s 

Done
Clearing U,V
Done
Loading MSLP
Done

 adding the wind to the predictor... 


 calculating the gradient of the sea-level-pressure fields... 


 pressure/gradient predictor both with shape: 
 (195745, 10, 10) 

Returning fold  0  of  5  e.g. 80.0 percent training data

1994-12-01 00:00:00 2012-08-26 10:00:00
&lt;class &#39;numpy.ndarray&#39;&gt;
All integer correspond to number of hours with respect to reference date
Times in: tf.Tensor([57259 57283 57307], shape=(3,), dtype=int64) Times out: tf.Tensor(57307, shape=(), dtype=int64)
Times in: tf.Tensor([94294 94318 94342], shape=(3,), dtype=int64) Times out: tf.Tensor(94342, shape=(), dtype=int64)
Times in: tf.Tensor([20925 20949 20973], shape=(3,), dtype=int64) Times out: tf.Tensor(20973, shape=(), dtype=int64)
Times in: tf.Tensor([71447 71471 71495], shape=(3,), dtype=int64) Times out: tf.Tensor(71495, shape=(), dtype=int64)

&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
&lt;class &#39;xarray.core.dataarray.DataArray&#39;&gt;
Model: &quot;model_739&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_740 (InputLayer)       [(None, 3, 10, 10, 3)]    0         
_________________________________________________________________
time_distributed_1478 (TimeD (None, 3, 10, 10, 24)     672       
_________________________________________________________________
time_distributed_1479 (TimeD (None, 3, 5, 5, 24)       0         
_________________________________________________________________
flatten_739 (Flatten)        (None, 1800)              0         
_________________________________________________________________
dense_1478 (Dense)           (None, 20)                36020     
_________________________________________________________________
dropout_739 (Dropout)        (None, 20)                0         
_________________________________________________________________
dense_1479 (Dense)           (None, 1)                 21        
=================================================================
Total params: 36,713
Trainable params: 36,713
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/20
4857/4857 [==============================] - 8s 2ms/step - loss: 47.3597 - mse: 47.3005 - mae: 5.3416 - val_loss: 35.7929 - val_mse: 35.7171 - val_mae: 4.7436
Epoch 2/20
4857/4857 [==============================] - 7s 2ms/step - loss: 37.5010 - mse: 37.4149 - mae: 4.7895 - val_loss: 34.7149 - val_mse: 34.6192 - val_mae: 4.6769
Epoch 3/20
4084/4857 [========================&gt;.....] - ETA: 1s - loss: 35.8921 - mse: 35.7887 - mae: 4.6883
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 355, 356, 357, 358, 359, 366, 367, 368, 369, 372, 373, 374, 375, 376, 380, 381, 382, 383, 384, 385, 386, 387, 388, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 427, 428, 429, 430, 431, 435, 436, 437, 442, 443, 444, 450, 451, 452, 462, 463, 464, 465, 466, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[40,
 41,
 42,
 43,
 44,
 45,
 46,
 47,
 48,
 49,
 50,
 51,
 52,
 53,
 54,
 55,
 56,
 57,
 58,
 59,
 60,
 61,
 62,
 63,
 64,
 65,
 66,
 67,
 68,
 69,
 70,
 71,
 72,
 73,
 74,
 75,
 76,
 77,
 78,
 79,
 80,
 81,
 82,
 83,
 84,
 85,
 86,
 87,
 88,
 89,
 90,
 91,
 92,
 93,
 94,
 95,
 96,
 97,
 98,
 99,
 100,
 101,
 102,
 103,
 104,
 105,
 106,
 107,
 108,
 109,
 110,
 111,
 112,
 113,
 114,
 115,
 116,
 117,
 118,
 119,
 120,
 121,
 122,
 123,
 124,
 125,
 126,
 127,
 128,
 129,
 130,
 131,
 132,
 133,
 134,
 135,
 136,
 137,
 138,
 139,
 140,
 141,
 142,
 143,
 144,
 145,
 146,
 147,
 148,
 149,
 150,
 151,
 152,
 153,
 154,
 155,
 156,
 157,
 158,
 159,
 160,
 161,
 162,
 163,
 164,
 165,
 166,
 167,
 168,
 169,
 170,
 171,
 172,
 173,
 174,
 175,
 176,
 177,
 178,
 179,
 180,
 181,
 182,
 183,
 184,
 185,
 186,
 187,
 188,
 189,
 190,
 191,
 192,
 193,
 194,
 195,
 196,
 197,
 198,
 199,
 200,
 201,
 202,
 203,
 204,
 205,
 206,
 207,
 208,
 209,
 210,
 211,
 212,
 213,
 214,
 215,
 216,
 217,
 218,
 219,
 220,
 221,
 222,
 223,
 224,
 225,
 226,
 227,
 228,
 229,
 230,
 231,
 232,
 233,
 234,
 235,
 236,
 237,
 238,
 239,
 240,
 241,
 242,
 243,
 244,
 245,
 246,
 247,
 248,
 249,
 250,
 251,
 252,
 253,
 254,
 255,
 256,
 257,
 258,
 259,
 260,
 261,
 262,
 263,
 264,
 265,
 266,
 267,
 268,
 269,
 270,
 271,
 272,
 273,
 274,
 275,
 276,
 277,
 278,
 279,
 280,
 281,
 282,
 283,
 284,
 285,
 286,
 287,
 288,
 289,
 290,
 291,
 292,
 293,
 294,
 295,
 296,
 297,
 298,
 299,
 300,
 301,
 302,
 303,
 304,
 305,
 306,
 307,
 308,
 309,
 310,
 311,
 312,
 313,
 314,
 315,
 316,
 317,
 318,
 319,
 320,
 321,
 322,
 323,
 324,
 325,
 326,
 327,
 328,
 329,
 330,
 331,
 332,
 333,
 334,
 335,
 336,
 337,
 338,
 339,
 340,
 341,
 342,
 343,
 344,
 345,
 346,
 347,
 348,
 349,
 350,
 355,
 356,
 357,
 358,
 359,
 366,
 367,
 368,
 369,
 372,
 373,
 374,
 375,
 376,
 380,
 381,
 382,
 383,
 384,
 385,
 386,
 387,
 388,
 392,
 393,
 394,
 395,
 396,
 397,
 398,
 399,
 400,
 401,
 402,
 403,
 404,
 405,
 406,
 409,
 410,
 411,
 412,
 413,
 414,
 415,
 416,
 417,
 418,
 419,
 420,
 427,
 428,
 429,
 430,
 431,
 435,
 436,
 437,
 442,
 443,
 444,
 450,
 451,
 452,
 462,
 463,
 464,
 465,
 466,
 470,
 471,
 472,
 473,
 474,
 475,
 476,
 477,
 478,
 479,
 480,
 481,
 482,
 483,
 484,
 485,
 486,
 487,
 488,
 489,
 490,
 491,
 492,
 493,
 494,
 495,
 496,
 497,
 498,
 499,
 500,
 501,
 502,
 503,
 504,
 505,
 506,
 507,
 508,
 509,
 510,
 511,
 512,
 513,
 514,
 515,
 516,
 517,
 518,
 519,
 520,
 521,
 522,
 523,
 524,
 525,
 526,
 527,
 528,
 529,
 530,
 531,
 532,
 533,
 534,
 535,
 536,
 537,
 538,
 539,
 540,
 541,
 542,
 543,
 544,
 545,
 546,
 547,
 548,
 549,
 550,
 551,
 552,
 553,
 554,
 555,
 556,
 557,
 558,
 559,
 560,
 561,
 562,
 563,
 564,
 565,
 566,
 567,
 568,
 569,
 570,
 571,
 572,
 573,
 574,
 575,
 576,
 577,
 578,
 579,
 580,
 581,
 582,
 583,
 584,
 585,
 586,
 587,
 588,
 589,
 590,
 591,
 592,
 593,
 594,
 595,
 596,
 597,
 598,
 599,
 600,
 601,
 602,
 603,
 604,
 605,
 606,
 607,
 608,
 609,
 610,
 611,
 612,
 613,
 614,
 615,
 616,
 617,
 618,
 619,
 620,
 621,
 622,
 623,
 624,
 625,
 626,
 627,
 628,
 629,
 630,
 631,
 632,
 633,
 634,
 635,
 636,
 637,
 638,
 639,
 640,
 641,
 642,
 643,
 644,
 645,
 646,
 647,
 648,
 649,
 650,
 651,
 652,
 653,
 654,
 655,
 656,
 657,
 658,
 659,
 660,
 661,
 662,
 663,
 664,
 665,
 666,
 667,
 668,
 669,
 670,
 671,
 672,
 673,
 674,
 675,
 676,
 677,
 678,
 679,
 680,
 681,
 682,
 683,
 684,
 685,
 686,
 687,
 688,
 689,
 690,
 691,
 692,
 693,
 694,
 695,
 696,
 697,
 698,
 699,
 700,
 701,
 702,
 703,
 704,
 705,
 706,
 707,
 708,
 709,
 710,
 711,
 712,
 713,
 714,
 715,
 716,
 717,
 718,
 719,
 720,
 721,
 722,
 723,
 724,
 725,
 726,
 727,
 728,
 729,
 730,
 731,
 732,
 733,
 734,
 735,
 736,
 737,
 738,
 739,
 740,
 741,
 742,
 743,
 744,
 745,
 746,
 747,
 748,
 749,
 750,
 751,
 752,
 753,
 754,
 755,
 756,
 757,
 758,
 759,
 760,
 761,
 762,
 763,
 764,
 765,
 766,
 767,
 768,
 769,
 770,
 771,
 772,
 773,
 774,
 775,
 776,
 777,
 778,
 779,
 780,
 781,
 782,
 783,
 784,
 785,
 786,
 787,
 788,
 789,
 790,
 791,
 792,
 793,
 794,
 795,
 796,
 797,
 798,
 799,
 800,
 801,
 802,
 803,
 804,
 805,
 806,
 807,
 808,
 809,
 810,
 811,
 812,
 813,
 814,
 815,
 816,
 817,
 818,
 819,
 820,
 821,
 822,
 823,
 824,
 825,
 826,
 827,
 828,
 829,
 830,
 831,
 832,
 833,
 834,
 835,
 836,
 837,
 838,
 839,
 840,
 841,
 842,
 843,
 844,
 845,
 846,
 847,
 848,
 849,
 850,
 851,
 852,
 853,
 854,
 855,
 856,
 857,
 858,
 859,
 860,
 861,
 862,
 863,
 864,
 865,
 866,
 867,
 868,
 869,
 870,
 871,
 872,
 873,
 874,
 875,
 876,
 877,
 878,
 879,
 880,
 881,
 882,
 883,
 884,
 885,
 886,
 887,
 888,
 889,
 890,
 891,
 892,
 893,
 894,
 895,
 896,
 897,
 898,
 899,
 900,
 901,
 902,
 903,
 904,
 905,
 906,
 907,
 908,
 909,
 910,
 911,
 912,
 913,
 914,
 915,
 916,
 917,
 918,
 919,
 920,
 921,
 922,
 923,
 924,
 925,
 926,
 927,
 928,
 929,
 930,
 931,
 932,
 933,
 934,
 935,
 936,
 937,
 938,
 939,
 940,
 941,
 942,
 943,
 944,
 945,
 946,
 947,
 948,
 949,
 950,
 951,
 952,
 953,
 954,
 955,
 956,
 957,
 958,
 959,
 960,
 961,
 962,
 963,
 964,
 965,
 966,
 967,
 968,
 969,
 970,
 971,
 972,
 973,
 974,
 975,
 976,
 977,
 978,
 979,
 980,
 981,
 982,
 983,
 984,
 985,
 986,
 987,
 988,
 989,
 990,
 991,
 992,
 993,
 994,
 995,
 996,
 997,
 998,
 999,
 1000,
 1001,
 1002,
 1003,
 1004,
 1005,
 1006,
 1007,
 1008,
 1009,
 1010,
 1011,
 1012,
 1013,
 1014,
 1015,
 1016,
 1017,
 1018,
 1019,
 1020,
 1021,
 1022,
 1023,
 1024,
 1025,
 1026,
 1027,
 1028,
 1029,
 1030,
 1031,
 1032,
 1033,
 1034,
 1035,
 1036,
 1037,
 1038,
 1039,
 1040,
 1041,
 1042,
 1043,
 1044,
 1045,
 1046,
 1047,
 1048,
 1049,
 1050,
 1051,
 1052,
 1053,
 1054,
 1055,
 1056,
 1057,
 1058,
 1059,
 1060,
 1061,
 1062,
 1063,
 1064,
 1065,
 1066,
 1067,
 1068,
 1069,
 1070,
 1071,
 1072,
 1073,
 1074,
 1075,
 1076,
 1077,
 1078,
 1079,
 1080,
 1081,
 1082,
 1083,
 1084,
 1085,
 1086,
 1087,
 1088,
 1089,
 ...]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dill</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;/home/metocean/single_site_cnn_all_results.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">linear_results</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="s1">&#39;/home/metocean/geocean-nz-ss/data/statistics/experiments/experiment_linear_final_20211113.nc&#39;</span><span class="p">)</span>
<span class="n">best_linear_results</span> <span class="o">=</span> <span class="n">linear_results</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">winds</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tlapse</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">region</span><span class="o">=</span><span class="s1">&#39;local_2.5_2.5&#39;</span><span class="p">,</span> <span class="n">tresample</span><span class="o">=</span><span class="s1">&#39;1D&#39;</span><span class="p">)</span>
<span class="n">best_linear_results</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pearson&#39;</span><span class="p">,</span> <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;rel_rmse&#39;</span><span class="p">,</span> <span class="s1">&#39;kgeprime&#39;</span><span class="p">]</span>

<span class="n">sites_linear</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">site</span><span class="o">.</span><span class="n">values</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">())]</span>
<span class="n">lons_linear</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span>
<span class="n">lats_linear</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span>

<span class="n">sites_nn</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">lons_nn</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_nn</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span>
<span class="n">lats_nn</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_nn</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
    
    <span class="n">vals_linear</span> <span class="o">=</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="c1">#vals_nn = stats_val[metric]</span>
    <span class="n">vals_nn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    
    <span class="c1">#vals_diff = vals_linear.squeeze() - np.array([stats_val[metric][np.where(sites_nn==s)[0][0]] for s in sites_linear]).squeeze()</span>
    <span class="n">vals_diff</span> <span class="o">=</span> <span class="n">vals_linear</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">results</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sites_linear</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    
    <span class="n">vmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">))</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">))</span>
    
    <span class="n">vdiff_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vals_diff</span><span class="p">))</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_linear</span><span class="p">,</span> <span class="n">lats_linear</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_linear</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Linear model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_nn</span><span class="p">,</span> <span class="n">lats_nn</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_nn</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>
    
    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_linear</span><span class="p">,</span> <span class="n">lats_linear</span><span class="p">,</span>
                         <span class="n">c</span><span class="o">=</span><span class="n">vals_diff</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="n">vdiff_max</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vdiff_max</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Linear model minus CNN model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">txt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sites_linear</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="p">(</span><span class="n">lons_linear</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">lats_linear</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/model_CNN-single_site_19_0.png" src="../_images/model_CNN-single_site_19_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">metric</span><span class="p">])</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8443933019092555
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">linear_results</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">open_dataset</span><span class="p">(</span><span class="s1">&#39;/home/metocean/geocean-nz-ss/data/statistics/experiments/linear_superfinal.nc&#39;</span><span class="p">)</span>
<span class="n">best_linear_results</span> <span class="o">=</span> <span class="n">linear_results</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">best_linear_results</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pearson&#39;</span><span class="p">,</span> <span class="s1">&#39;si&#39;</span><span class="p">,</span> <span class="s1">&#39;rel_rmse&#39;</span><span class="p">,</span> <span class="s1">&#39;kgeprime&#39;</span><span class="p">]</span>

<span class="n">sites_linear</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">site</span><span class="o">.</span><span class="n">values</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">())]</span>
<span class="n">lons_linear</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span>
<span class="n">lats_linear</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span>

<span class="n">sites_nn</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">lons_nn</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_nn</span><span class="p">)</span><span class="o">.</span><span class="n">lon</span><span class="o">.</span><span class="n">values</span>
<span class="n">lats_nn</span> <span class="o">=</span> <span class="n">ss_dset</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_nn</span><span class="p">)</span><span class="o">.</span><span class="n">lat</span><span class="o">.</span><span class="n">values</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
    
    <span class="n">vals_linear</span> <span class="o">=</span> <span class="n">best_linear_results</span><span class="o">.</span><span class="n">sel</span><span class="p">(</span><span class="n">site</span><span class="o">=</span><span class="n">sites_linear</span><span class="p">)[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="c1">#vals_nn = stats_val[metric]</span>
    <span class="n">vals_nn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    
    <span class="c1">#vals_diff = vals_linear.squeeze() - np.array([stats_val[metric][np.where(sites_nn==s)[0][0]] for s in sites_linear]).squeeze()</span>
    <span class="n">vals_diff</span> <span class="o">=</span> <span class="n">vals_linear</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">results</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sites_linear</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    
    <span class="n">vmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">))</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_linear</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vals_nn</span><span class="p">))</span>
    
    <span class="n">vdiff_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">vals_diff</span><span class="p">))</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_linear</span><span class="p">,</span> <span class="n">lats_linear</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_linear</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Linear model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>

    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_nn</span><span class="p">,</span> <span class="n">lats_nn</span><span class="p">,</span>
                      <span class="n">c</span><span class="o">=</span><span class="n">vals_nn</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CNN model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>
    
    <span class="n">p</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">lons_linear</span><span class="p">,</span> <span class="n">lats_linear</span><span class="p">,</span>
                         <span class="n">c</span><span class="o">=</span><span class="n">vals_diff</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="n">vdiff_max</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vdiff_max</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">&#39;5%&#39;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">im</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Linear model minus CNN model: &quot;</span><span class="o">+</span><span class="n">metric</span><span class="p">)</span>
    
    <span class="c1">#for i, txt in enumerate(sites_linear):</span>
    <span class="c1">#    axes[im,2].annotate(txt, (lons_linear[i], lats_linear[i]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/model_CNN-single_site_22_0.png" src="../_images/model_CNN-single_site_22_0.png" />
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "javitausia/geocean-nz-ss",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-.conda-ssnz-py"
        },
        kernelOptions: {
            kernelName: "conda-env-.conda-ssnz-py",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-.conda-ssnz-py'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Javier Tausa Hoyal<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>